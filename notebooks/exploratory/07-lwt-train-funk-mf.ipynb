{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61ee0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a64d5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f8f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable\n",
    "CATEGORY = \"Grocery_and_Gourmet_Food\"\n",
    "DATA_PATH = \"data/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4756c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35bbcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A23RYWDS884TUL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This curry paste makes a delicious curry.  I j...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>curry paste delicious curry fry chicken vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A945RBQWGZXCK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've purchased different curries in the grocer...</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>purchase different curry grocery store complet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3AMNY44OP8AOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I started a new diet restricting all added sug...</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>start new diet restrict added sugar brand suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3IB4CQ2QEJLJ8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>So many flavors. I can't begin to tell you how...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>flavor begin tell love mae ploy curry ask reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>AQA5DF3RWKETQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've used this a lot recently in some of my ch...</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>use lot recently chicken dish use lot like spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        asin                              title  \\\n",
       "0      0  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1      1  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2      3  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "3      4  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "4      5  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "\n",
       "                                          categories      reviewerID  overall  \\\n",
       "0  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A23RYWDS884TUL      5.0   \n",
       "1  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   A945RBQWGZXCK      5.0   \n",
       "2  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3AMNY44OP8AOU      4.0   \n",
       "3  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3IB4CQ2QEJLJ8      5.0   \n",
       "4  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   AQA5DF3RWKETQ      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  \\\n",
       "0  This curry paste makes a delicious curry.  I j...  2013-05-28   \n",
       "1  I've purchased different curries in the grocer...  2012-09-17   \n",
       "2  I started a new diet restricting all added sug...  2014-01-23   \n",
       "3  So many flavors. I can't begin to tell you how...  2014-04-27   \n",
       "4  I've used this a lot recently in some of my ch...  2012-11-27   \n",
       "\n",
       "                                 processedReviewText  \n",
       "0  curry paste delicious curry fry chicken vegeta...  \n",
       "1  purchase different curry grocery store complet...  \n",
       "2  start new diet restrict added sugar brand suga...  \n",
       "3  flavor begin tell love mae ploy curry ask reci...  \n",
       "4  use lot recently chicken dish use lot like spi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[['reviewerID', 'asin', 'overall']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4936fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating training set\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f213f36",
   "metadata": {},
   "source": [
    "# Training Funk's SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_factors=50, n_epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting to the trainset\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180a4e3",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432dc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "predictions = algo.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ac0a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in tqdm(predictions):\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in tqdm(top_n.items()):\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ad6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bb89f",
   "metadata": {},
   "source": [
    "# Evaluate Top-N Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce4146",
   "metadata": {},
   "source": [
    "### Defining Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "723f6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating precision@K - relevant / total recommended\n",
    "    precision_at_k = num_relevant / k\n",
    "    \n",
    "    return precision_at_k\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297f223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")\n",
    "\n",
    "# generating test rating history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "print(f\"For user: {random_user}:\")\n",
    "print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "# find the recommendations\n",
    "print(f\"\\nRecommending:\\n\")\n",
    "print(f\"{train[train['asin'].isin([i[0] for i in top_ns[random_user]])][['asin', 'title']].drop_duplicates(subset='asin')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87694d56",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da18a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae6acb",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65daae",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86881b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7881bd",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab11e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at how many get correct\n",
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1e638",
   "metadata": {},
   "source": [
    "# Evaluate `FunkMF` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f4ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from src.models import cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c887e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating funk's svd/mf\n",
    "funk_mf = cf.FunkMF(n_epochs=20, lr_all=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc66287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    }
   ],
   "source": [
    "# fitting to training data\n",
    "funk_mf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439523f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check trainset and testset availability\n",
    "funk_mf.testset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f63343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 18s, sys: 1min 26s, total: 7min 45s\n",
      "Wall time: 8min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generating predictions\n",
    "predictions = funk_mf.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17050dbe",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f148bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:15<00:00, 840487.24it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [01:15<00:00, 177.09it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46170.96it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 52741.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@10: 0.00069, average recall@10: 0.00309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba926c02",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba196bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [04:43<00:00, 223209.37it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:57<00:00, 231.29it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46216.13it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 44950.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@25: 0.00069, average recall@25: 0.00865.\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f8be8",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07fccf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:28<00:00, 718307.85it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [01:14<00:00, 178.75it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 42995.70it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 45999.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@30: 0.00069, average recall@30: 0.01029.\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b86cad",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f3b92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:41<00:00, 620753.80it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [01:22<00:00, 161.67it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 42421.66it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 45020.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@45: 0.00067, average recall@45: 0.01507.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d687bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>pred_asin</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A100DXY4SLAMPM</td>\n",
       "      <td>[B000FK63QA, B000KEJMRI]</td>\n",
       "      <td>[B0000DI085, B0000IJYK4, B00015HNMM, B0001CXUH...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>A10AFVU66A79Y1</td>\n",
       "      <td>[B000E1FZHS, B000JMAVYO, B001E6K6B2, B002NKPCZ...</td>\n",
       "      <td>[B002HG9R1I, B004LKVRKM, B000EITYUU, B000EDG3U...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A10BWUA2MGA9BK</td>\n",
       "      <td>[B000S8593W]</td>\n",
       "      <td>[B000216O16, B0002YGSJQ, B000EDDS6Q, B000EDK5L...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>A11OQUV1ZI2MT2</td>\n",
       "      <td>[B002DM62BY, B008YUL4KI, B00HKGB9ZW]</td>\n",
       "      <td>[B000KEPB9Q, B002HG9R1I, B000EMM976, B000F4DKA...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>A11OTLEDSW8ZXD</td>\n",
       "      <td>[B002RBRY0Y, B007K5KAJY, B00BNR7I18, B00C1CLQG...</td>\n",
       "      <td>[B0002YGSJQ, B000E5GFQE, B000EDG3UE, B000H11C6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13213</th>\n",
       "      <td>AZ61VB6SPTQWJ</td>\n",
       "      <td>[B000JMAVYO]</td>\n",
       "      <td>[B0000DI085, B00014JNI0, B0001EJ4CU, B0001M0Z6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13217</th>\n",
       "      <td>AZ6OA110XCE5F</td>\n",
       "      <td>[B000EVE3YE, B001ELL86Y]</td>\n",
       "      <td>[B0000DI085, B00014JNI0, B0001M0Z6Q, B000216O1...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13219</th>\n",
       "      <td>AZ8C1QH6OQ7T5</td>\n",
       "      <td>[B003OGKCDC]</td>\n",
       "      <td>[B0000DI085, B0000IJYK4, B00015HNMM, B0001EJ4C...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>AZNS7TH82KH9K</td>\n",
       "      <td>[B00DS842HS]</td>\n",
       "      <td>[B0000DI085, B00014JNI0, B0001EJ4CU, B000G82L6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13276</th>\n",
       "      <td>AZXON596A1VXC</td>\n",
       "      <td>[B001EO5S0I, B00271QQ7Q]</td>\n",
       "      <td>[B0000DI085, B0001M0Z6Q, B000216O16, B000BD0SD...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "7      A100DXY4SLAMPM                           [B000FK63QA, B000KEJMRI]   \n",
       "37     A10AFVU66A79Y1  [B000E1FZHS, B000JMAVYO, B001E6K6B2, B002NKPCZ...   \n",
       "44     A10BWUA2MGA9BK                                       [B000S8593W]   \n",
       "171    A11OQUV1ZI2MT2               [B002DM62BY, B008YUL4KI, B00HKGB9ZW]   \n",
       "173    A11OTLEDSW8ZXD  [B002RBRY0Y, B007K5KAJY, B00BNR7I18, B00C1CLQG...   \n",
       "...               ...                                                ...   \n",
       "13213   AZ61VB6SPTQWJ                                       [B000JMAVYO]   \n",
       "13217   AZ6OA110XCE5F                           [B000EVE3YE, B001ELL86Y]   \n",
       "13219   AZ8C1QH6OQ7T5                                       [B003OGKCDC]   \n",
       "13251   AZNS7TH82KH9K                                       [B00DS842HS]   \n",
       "13276   AZXON596A1VXC                           [B001EO5S0I, B00271QQ7Q]   \n",
       "\n",
       "                                               pred_asin  precision@k  \\\n",
       "7      [B0000DI085, B0000IJYK4, B00015HNMM, B0001CXUH...     0.022222   \n",
       "37     [B002HG9R1I, B004LKVRKM, B000EITYUU, B000EDG3U...     0.022222   \n",
       "44     [B000216O16, B0002YGSJQ, B000EDDS6Q, B000EDK5L...     0.022222   \n",
       "171    [B000KEPB9Q, B002HG9R1I, B000EMM976, B000F4DKA...     0.022222   \n",
       "173    [B0002YGSJQ, B000E5GFQE, B000EDG3UE, B000H11C6...     0.022222   \n",
       "...                                                  ...          ...   \n",
       "13213  [B0000DI085, B00014JNI0, B0001EJ4CU, B0001M0Z6...     0.022222   \n",
       "13217  [B0000DI085, B00014JNI0, B0001M0Z6Q, B000216O1...     0.022222   \n",
       "13219  [B0000DI085, B0000IJYK4, B00015HNMM, B0001EJ4C...     0.022222   \n",
       "13251  [B0000DI085, B00014JNI0, B0001EJ4CU, B000G82L6...     0.022222   \n",
       "13276  [B0000DI085, B0001M0Z6Q, B000216O16, B000BD0SD...     0.022222   \n",
       "\n",
       "       recall@k  \n",
       "7      0.500000  \n",
       "37     0.100000  \n",
       "44     1.000000  \n",
       "171    0.333333  \n",
       "173    0.111111  \n",
       "...         ...  \n",
       "13213  1.000000  \n",
       "13217  0.500000  \n",
       "13219  1.000000  \n",
       "13251  1.000000  \n",
       "13276  0.500000  \n",
       "\n",
       "[392 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at how many get correct\n",
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b92e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
