{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36551cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pandarallel import pandarallel\n",
    "from surprise import Dataset, Reader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import cf\n",
    "\n",
    "pandarallel.initialize()\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56bfe5",
   "metadata": {},
   "source": [
    "# Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e036df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = \"data/evaluation\"\n",
    "# D2V_PATH = \"models/d2v\"\n",
    "CATEGORY = \"Grocery_and_Gourmet_Food\"\n",
    "\n",
    "# training parameters\n",
    "N_EPOCHS = 10\n",
    "LR_ALL = 0.005\n",
    "BETA = 0.1\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b085128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A23RYWDS884TUL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This curry paste makes a delicious curry.  I j...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>curry paste delicious curry fry chicken vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A945RBQWGZXCK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've purchased different curries in the grocer...</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>purchase different curry grocery store complet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3AMNY44OP8AOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I started a new diet restricting all added sug...</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>start new diet restrict added sugar brand suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3IB4CQ2QEJLJ8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>So many flavors. I can't begin to tell you how...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>flavor begin tell love mae ploy curry ask reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>AQA5DF3RWKETQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've used this a lot recently in some of my ch...</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>use lot recently chicken dish use lot like spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47769</th>\n",
       "      <td>77420</td>\n",
       "      <td>B00I33696K</td>\n",
       "      <td>Reese's Miniature Peanut Butter Cups .31oz - 1...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Candy &amp; Chocolate'...</td>\n",
       "      <td>A192LQZWDYPR4U</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Another quality Reese Peanut Butter Cup produc...</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>quality reese peanut butter cup product great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47770</th>\n",
       "      <td>77421</td>\n",
       "      <td>B00I33696K</td>\n",
       "      <td>Reese's Miniature Peanut Butter Cups .31oz - 1...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Candy &amp; Chocolate'...</td>\n",
       "      <td>A2QKXW3LDQ66P5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I purchased these for my husband who has every...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>purchase husband love reeses valentine day pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47771</th>\n",
       "      <td>77430</td>\n",
       "      <td>B00ID9VSOM</td>\n",
       "      <td>Viva Labs Organic Coconut Sugar: Non-GMO, Low-...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A2P3TGJU301KXD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this stuff is INCREDIBILY yummy! SO much bette...</td>\n",
       "      <td>2014-07-15</td>\n",
       "      <td>stuff incredibily yummy good regular brown sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47772</th>\n",
       "      <td>77456</td>\n",
       "      <td>B00IRL93SY</td>\n",
       "      <td>Barrie House Kenya Estate - AA Single Cup Caps...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Beverages', 'Coffe...</td>\n",
       "      <td>AEFE9VDHTQ199</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very nice aroma, body and taste! Will buy this...</td>\n",
       "      <td>2014-05-24</td>\n",
       "      <td>nice aroma body taste buy coffee good coffee a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47773</th>\n",
       "      <td>77508</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A2AEZQ3DGBBLPR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This is a no go for diabetics according to my ...</td>\n",
       "      <td>2014-06-26</td>\n",
       "      <td>diabetic accord wife doctor order intention us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        asin                                              title  \\\n",
       "0          0  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1          1  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2          3  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "3          4  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "4          5  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "47769  77420  B00I33696K  Reese's Miniature Peanut Butter Cups .31oz - 1...   \n",
       "47770  77421  B00I33696K  Reese's Miniature Peanut Butter Cups .31oz - 1...   \n",
       "47771  77430  B00ID9VSOM  Viva Labs Organic Coconut Sugar: Non-GMO, Low-...   \n",
       "47772  77456  B00IRL93SY  Barrie House Kenya Estate - AA Single Cup Caps...   \n",
       "47773  77508  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A23RYWDS884TUL   \n",
       "1      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   A945RBQWGZXCK   \n",
       "2      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3AMNY44OP8AOU   \n",
       "3      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3IB4CQ2QEJLJ8   \n",
       "4      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   AQA5DF3RWKETQ   \n",
       "47769  ['Grocery & Gourmet Food', 'Candy & Chocolate'...  A192LQZWDYPR4U   \n",
       "47770  ['Grocery & Gourmet Food', 'Candy & Chocolate'...  A2QKXW3LDQ66P5   \n",
       "47771  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A2P3TGJU301KXD   \n",
       "47772  ['Grocery & Gourmet Food', 'Beverages', 'Coffe...   AEFE9VDHTQ199   \n",
       "47773  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A2AEZQ3DGBBLPR   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          5.0  This curry paste makes a delicious curry.  I j...  2013-05-28   \n",
       "1          5.0  I've purchased different curries in the grocer...  2012-09-17   \n",
       "2          4.0  I started a new diet restricting all added sug...  2014-01-23   \n",
       "3          5.0  So many flavors. I can't begin to tell you how...  2014-04-27   \n",
       "4          5.0  I've used this a lot recently in some of my ch...  2012-11-27   \n",
       "47769      5.0  Another quality Reese Peanut Butter Cup produc...  2014-02-27   \n",
       "47770      5.0  I purchased these for my husband who has every...  2013-02-20   \n",
       "47771      5.0  this stuff is INCREDIBILY yummy! SO much bette...  2014-07-15   \n",
       "47772      5.0  Very nice aroma, body and taste! Will buy this...  2014-05-24   \n",
       "47773      2.0  This is a no go for diabetics according to my ...  2014-06-26   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      curry paste delicious curry fry chicken vegeta...  \n",
       "1      purchase different curry grocery store complet...  \n",
       "2      start new diet restrict added sugar brand suga...  \n",
       "3      flavor begin tell love mae ploy curry ask reci...  \n",
       "4      use lot recently chicken dish use lot like spi...  \n",
       "47769  quality reese peanut butter cup product great ...  \n",
       "47770  purchase husband love reeses valentine day pre...  \n",
       "47771  stuff incredibily yummy good regular brown sug...  \n",
       "47772  nice aroma body taste buy coffee good coffee a...  \n",
       "47773  diabetic accord wife doctor order intention us...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking train dataframe\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3152a",
   "metadata": {},
   "source": [
    "# Train Doc2Vec Model (User & Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9b295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f07b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dm': 1, 'vector_size': 50, 'min_count': 1, 'negative': 5, 'ns_exponent': 0.5, 'sample': 1e-05, 'workers': 8, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# read params\n",
    "params = yaml.safe_load(open(\"params.yaml\"))[\"generate_vectors\"]\n",
    "MODEL_PARAMS = params[\"d2v_params\"]\n",
    "\n",
    "print(MODEL_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8c2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47774/47774 [00:00<00:00, 169357.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"processedReviewText\"] = train[\"processedReviewText\"].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f469a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corpus = [\n",
    "    TaggedDocument(review, [asin])\n",
    "    for asin, review in list(zip(train[\"asin\"], train[\"processedReviewText\"]))\n",
    "]\n",
    "\n",
    "user_corpus = [\n",
    "    TaggedDocument(review, [reviewerID])\n",
    "    for reviewerID, review in list(zip(train[\"reviewerID\"], train[\"processedReviewText\"]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef918f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = item_corpus + user_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d0bfa",
   "metadata": {},
   "source": [
    "## Training Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2e7978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Doc2Vec\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d50,n5,w5,s1e-05,t8)', 'datetime': '2021-09-09T22:05:44.571714', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.doc2vec:collecting all words and their counts\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #10000, processed 364241 words (4307179/s), 14898 word types, 904 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #20000, processed 744636 words (4586721/s), 21785 word types, 1940 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #30000, processed 1142910 words (4372544/s), 27143 word types, 2955 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #40000, processed 1580118 words (4593124/s), 31844 word types, 3871 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #50000, processed 2024668 words (4492668/s), 34875 word types, 6071 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #60000, processed 2387375 words (5098617/s), 34875 word types, 11377 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #70000, processed 2776398 words (5036650/s), 34875 word types, 14385 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #80000, processed 3180257 words (5137938/s), 34875 word types, 16433 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #90000, processed 3618851 words (5219545/s), 34875 word types, 17780 tags\n",
      "INFO:gensim.models.doc2vec:collected 34875 word types and 18126 unique tags from a corpus of 95548 examples and 3885234 words\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 34875 unique words (100.0%% of original 34875, drops 0)', 'datetime': '2021-09-09T22:05:45.635225', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 3885234 word corpus (100.0%% of original 3885234, drops 0)', 'datetime': '2021-09-09T22:05:45.635893', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 34875 items\n",
      "INFO:gensim.models.word2vec:sample=1e-05 downsamples 3103 most-common words\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 922863.0353926163 word corpus (23.8%% of prior 3885234)', 'datetime': '2021-09-09T22:05:45.819056', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 34875 words and 50 dimensions: 38637900 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 34875 vocabulary and 50 features, using sg=0 hs=0 sample=1e-05 negative=5 window=5', 'datetime': '2021-09-09T22:05:46.155959', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 14.29% examples, 135948 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 28.63% examples, 138127 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 40.36% examples, 132462 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 54.02% examples, 135291 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 69.28% examples, 137656 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 85.61% examples, 140860 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 1 : training on 3885234 raw words (1017975 effective words) took 7.0s, 146248 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 15.67% examples, 148566 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 31.85% examples, 153432 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 47.66% examples, 158277 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 63.91% examples, 157712 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 78.82% examples, 153957 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 94.52% examples, 155105 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 2 : training on 3885234 raw words (1017314 effective words) took 6.5s, 156759 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 13.99% examples, 134657 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 28.84% examples, 140373 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 45.52% examples, 150151 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 61.41% examples, 152492 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 77.09% examples, 153048 words/s, in_qsize 16, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 92.74% examples, 154512 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 51 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 51 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 3 : training on 3885234 raw words (1018378 effective words) took 6.5s, 156587 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 15.15% examples, 147673 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 31.01% examples, 150512 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 46.11% examples, 154392 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 62.29% examples, 155285 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 78.36% examples, 156230 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 93.66% examples, 156469 words/s, in_qsize 16, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 51 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 4 : training on 3885234 raw words (1017958 effective words) took 6.4s, 158121 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 14.29% examples, 137517 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 30.01% examples, 146522 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 45.94% examples, 152374 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 61.68% examples, 153716 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 77.55% examples, 153732 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 93.19% examples, 154865 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 52 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 5 : training on 3885234 raw words (1017864 effective words) took 6.5s, 156724 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 15.38% examples, 148959 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 31.21% examples, 150469 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 47.00% examples, 156743 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 62.57% examples, 155621 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 78.82% examples, 154634 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 95.31% examples, 157287 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 46 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 51 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 6 : training on 3885234 raw words (1017780 effective words) took 6.5s, 157492 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 15.15% examples, 146702 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 31.01% examples, 149504 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 45.92% examples, 152522 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 61.41% examples, 153298 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 76.78% examples, 152730 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 92.51% examples, 154128 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 51 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 7 : training on 3885234 raw words (1018735 effective words) took 6.5s, 155858 effective words/s\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 14.48% examples, 140007 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 30.61% examples, 148592 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 45.92% examples, 152326 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 61.05% examples, 152548 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 76.50% examples, 152586 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 91.13% examples, 152312 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 51 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 8 : training on 3885234 raw words (1019226 effective words) took 6.6s, 153686 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 14.29% examples, 136798 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 28.84% examples, 141142 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 44.75% examples, 148793 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 60.22% examples, 150644 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 75.21% examples, 149889 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 87.77% examples, 145239 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 46 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 47 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 52 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 9 : training on 3885234 raw words (1019410 effective words) took 6.9s, 147155 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 13.15% examples, 125917 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 26.09% examples, 127036 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 36.59% examples, 119618 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 47.66% examples, 119106 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 59.90% examples, 119642 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 72.90% examples, 120825 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 86.03% examples, 122101 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 391 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 48 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 46 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 99.05% examples, 124588 words/s, in_qsize 5, out_qsize 1\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 50 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 49 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 10 : training on 3885234 raw words (1018583 effective words) took 8.1s, 125491 effective words/s\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'training on 38852340 raw words (10183223 effective words) took 67.7s, 150521 effective words/s', 'datetime': '2021-09-09T22:06:53.810770', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(**MODEL_PARAMS)\n",
    "d2v.build_vocab(train_corpus)\n",
    "d2v.train(train_corpus, total_examples=d2v.corpus_count, epochs=d2v.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed374ca",
   "metadata": {},
   "source": [
    "# Generating User & Item Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33188222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_item_vectors(train: pd.DataFrame, d2v: Doc2Vec) -> tuple:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # get unique users and items\n",
    "    unique_users = train[\"reviewerID\"].unique().tolist()\n",
    "    unique_items = train[\"asin\"].unique().tolist()\n",
    "    \n",
    "    # generating mapping\n",
    "    user_idx_map = {j: unique_users[j] for j in range(len(unique_users))}\n",
    "    item_idx_map = {k: unique_items[k] for k in range(len(unique_items))}\n",
    "    user_vec_map = {j: d2v[j] for j in unique_users}\n",
    "    item_vec_map = {k: d2v[k] for k in unique_items}\n",
    "    \n",
    "    # loading user d2v vectors into DF\n",
    "    user_vecs = pd.DataFrame.from_dict(user_vec_map, orient='index')\n",
    "    user_vecs.index.name = 'reviewerID'\n",
    "    # loading item d2v vectors into DF\n",
    "    item_vecs = pd.DataFrame.from_dict(item_vec_map, orient='index')\n",
    "    item_vecs.index.name = 'asin'\n",
    "    \n",
    "    return user_idx_map, user_vecs, item_idx_map, item_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc02f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_map, user_vecs, item_idx_map, item_vecs = generate_user_item_vectors(train, d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455ba70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting factors into numpy obj\n",
    "user_factors = user_vecs.to_numpy()\n",
    "item_factors = item_vecs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06b73c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.01698896e-02, -2.05447176e-03,  1.21297427e-02,  3.04938573e-03,\n",
       "       -1.86814126e-02, -1.15144029e-02, -1.86024932e-03,  1.28131651e-05,\n",
       "       -4.64737043e-03,  2.47492287e-02,  1.84277538e-02,  1.81788150e-02,\n",
       "       -4.60735559e-02,  2.87961550e-02,  2.25295182e-02,  5.06839342e-03,\n",
       "        4.18663323e-02, -5.84903080e-03, -1.63989756e-02, -1.16623342e-02,\n",
       "       -2.44675148e-02, -1.59855280e-02,  2.32356042e-02, -7.04046618e-03,\n",
       "       -9.83982906e-03,  4.68950458e-02, -2.27734465e-02, -6.77542342e-03,\n",
       "       -4.08900753e-02,  7.80975679e-04,  2.66978592e-02,  4.06152243e-03,\n",
       "       -1.05919398e-03,  2.53511015e-02, -1.13817658e-02,  4.11136402e-03,\n",
       "       -1.51395975e-02,  5.51014207e-04,  3.13999839e-02,  8.56930390e-03,\n",
       "        3.15239374e-03, -3.12041957e-03, -1.42149944e-02, -2.83877309e-02,\n",
       "        6.17698813e-03, -3.86410858e-03,  2.08088532e-02, -2.22205985e-02,\n",
       "        3.04410909e-03,  1.07085165e-02], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check user factors\n",
    "user_factors[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0652aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33036214,  0.09933216, -0.08279146,  0.20955645, -0.09724324,\n",
       "        0.22373076, -0.04580458,  0.03147466,  0.25918925,  0.02754547,\n",
       "        0.02591094, -0.00948335, -0.22754323, -0.06776297,  0.25926092,\n",
       "       -0.2728187 ,  0.36369812, -0.13113324, -0.02920303, -0.22315627,\n",
       "        0.10133823,  0.03130703,  0.13151968, -0.04523718, -0.18187846,\n",
       "        0.3499963 , -0.3315193 ,  0.14636506, -0.369077  ,  0.06127454,\n",
       "        0.0188331 ,  0.09504317, -0.11739492,  0.11775835, -0.00802265,\n",
       "        0.00041661, -0.30812517, -0.11272635,  0.04930919,  0.3568229 ,\n",
       "       -0.32372668, -0.25754696, -0.03834489, -0.09389088, -0.08689753,\n",
       "       -0.21286209, -0.17648485, -0.0183565 ,  0.13319981, -0.15399422],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check item factors\n",
    "item_factors[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e16880",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148f0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in tqdm(predictions):\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in tqdm(top_n.items()):\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k\n",
    "\n",
    "def novelty_at_k(item_popularity, predicted_asins, k=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # finding avg novelty\n",
    "    popularity_sum = item_popularity.loc[predicted_asins].sum()\n",
    "    novelty_at_k = ((k*1) - popularity_sum) / k\n",
    "    \n",
    "    return novelty_at_k\n",
    "\n",
    "def generate_item_popularity(train: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a mapping of item popularatity\n",
    "    # based on sum(item's review / max reviews) / no items\n",
    "    max_reviews = (train.groupby(['asin'])\n",
    "                   .agg({'processedReviewText': 'count'})\n",
    "                   .max()\n",
    "                   .values[0])\n",
    "    item_popularity = (train.groupby(['asin'])\n",
    "                       .agg({'processedReviewText': 'count'})\n",
    "                       .apply(lambda x: x/max_reviews))\n",
    "    \n",
    "    return item_popularity\n",
    "    \n",
    "\n",
    "def evaluate_recommendations(top_ns: dict, user_rating_history: pd.DataFrame, item_popularity: pd.DataFrame, k=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        top_ns\n",
    "        user_rating_history\n",
    "    \"\"\"\n",
    "    \n",
    "    test_recommendations = pd.DataFrame(top_ns.items(), columns=[\"reviewerID\", \"pred_asin\"])\n",
    "    test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "    \n",
    "    # combined test history and recommendations\n",
    "    test_merged = pd.merge(user_rating_history, test_recommendations, on=\"reviewerID\", how=\"inner\")\n",
    "    \n",
    "    # generating recall@k metrics\n",
    "    test_merged[\"recall@k\"] = test_merged.apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "    test_merged[\"novelty@k\"] = test_merged.apply(lambda x: novelty_at_k(item_popularity, x.pred_asin, k=k), axis=1)\n",
    "    average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "    average_novelty_at_k = test_merged[\"novelty@k\"].mean()\n",
    "    \n",
    "    print(f\"The MOD-ECF has an average recall@{k}: {average_recall_at_k:.5f}, average novelty@{k}: {average_novelty_at_k:.5f}\")\n",
    "    \n",
    "    return test_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47668d",
   "metadata": {},
   "source": [
    "# Generate N-Recommendations = {10, 25, 30, 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f98d6",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b82429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A1TCSC0YWT82Q0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love ethnic foods and to cook them. I recent...</td>\n",
       "      <td>2013-08-03</td>\n",
       "      <td>love ethnic food cook recently purchase produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A1Z7Y2GMAP9SRY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I like to make my own curry but this is a tast...</td>\n",
       "      <td>2014-06-27</td>\n",
       "      <td>like curry tasty alternative use base kind dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>B00004S1C5</td>\n",
       "      <td>Ateco Food Coloring Kit, 6 colors</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A14YSMLYLJEMET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This product is no where near natural / organi...</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>product near natural organic wish review purch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>B00005344V</td>\n",
       "      <td>Traditional Medicinals Organic Breathe Easy Se...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Beverages', 'Coffe...</td>\n",
       "      <td>A2F488C4PLWGEI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If my wife drinks a cup of this tea when she f...</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>wife drink cup tea feel attack come help avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>B00005344V</td>\n",
       "      <td>Traditional Medicinals Organic Breathe Easy Se...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Beverages', 'Coffe...</td>\n",
       "      <td>AO1HXV7DWZZIR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I don't know about the medicinal aspects of th...</td>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>know medicinal aspect tea flavor downright scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28001</th>\n",
       "      <td>77519</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A1WT3TVHANP7ZF</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hmmm. I really wanted to love this sweetener. ...</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>hmmm want love sweetener half sugar half stevi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28002</th>\n",
       "      <td>77520</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A3NEAETOSXDBOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I confess I have a sweet tooth, and love the t...</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>confess sweet tooth love taste sugar recognize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28003</th>\n",
       "      <td>77521</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>AD1ZOPB0BBEHB</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It has a little of the stevia aftertaste, but ...</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>little stevia aftertaste fair compromise able ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>77522</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A18ECVX2RJ7HUE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i love marinade for grilled flank steak or lon...</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>love marinade grilled flank steak london broil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28005</th>\n",
       "      <td>77523</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A2G04D4QZAXL15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I've been using Truvia (a form of stevia) on m...</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>use truvia form stevia cereal greek yogurt yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        asin                                              title  \\\n",
       "0          2  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1          8  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2         23  B00004S1C5                  Ateco Food Coloring Kit, 6 colors   \n",
       "3         31  B00005344V  Traditional Medicinals Organic Breathe Easy Se...   \n",
       "4         32  B00005344V  Traditional Medicinals Organic Breathe Easy Se...   \n",
       "28001  77519  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28002  77520  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28003  77521  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28004  77522  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28005  77523  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A1TCSC0YWT82Q0   \n",
       "1      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A1Z7Y2GMAP9SRY   \n",
       "2      ['Grocery & Gourmet Food', 'Cooking & Baking',...  A14YSMLYLJEMET   \n",
       "3      ['Grocery & Gourmet Food', 'Beverages', 'Coffe...  A2F488C4PLWGEI   \n",
       "4      ['Grocery & Gourmet Food', 'Beverages', 'Coffe...   AO1HXV7DWZZIR   \n",
       "28001  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A1WT3TVHANP7ZF   \n",
       "28002  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A3NEAETOSXDBOM   \n",
       "28003  ['Grocery & Gourmet Food', 'Cooking & Baking',...   AD1ZOPB0BBEHB   \n",
       "28004  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A18ECVX2RJ7HUE   \n",
       "28005  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A2G04D4QZAXL15   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          5.0  I love ethnic foods and to cook them. I recent...  2013-08-03   \n",
       "1          5.0  I like to make my own curry but this is a tast...  2014-06-27   \n",
       "2          1.0  This product is no where near natural / organi...  2013-03-29   \n",
       "3          5.0  If my wife drinks a cup of this tea when she f...  2014-03-23   \n",
       "4          5.0  I don't know about the medicinal aspects of th...  2014-02-06   \n",
       "28001      3.0  Hmmm. I really wanted to love this sweetener. ...  2014-07-22   \n",
       "28002      5.0  I confess I have a sweet tooth, and love the t...  2014-06-30   \n",
       "28003      4.0  It has a little of the stevia aftertaste, but ...  2014-07-17   \n",
       "28004      5.0  i love marinade for grilled flank steak or lon...  2014-05-30   \n",
       "28005      3.0  I've been using Truvia (a form of stevia) on m...  2014-05-27   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      love ethnic food cook recently purchase produc...  \n",
       "1      like curry tasty alternative use base kind dif...  \n",
       "2      product near natural organic wish review purch...  \n",
       "3      wife drink cup tea feel attack come help avoid...  \n",
       "4      know medicinal aspect tea flavor downright scr...  \n",
       "28001  hmmm want love sweetener half sugar half stevi...  \n",
       "28002  confess sweet tooth love taste sugar recognize...  \n",
       "28003  little stevia aftertaste fair compromise able ...  \n",
       "28004  love marinade grilled flank steak london broil...  \n",
       "28005  use truvia form stevia cereal greek yogurt yea...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")\n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc34f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating test history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b19cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  reviewerID  \\\n",
      "0      A00177463W0XWB16A9O05   \n",
      "1      A022899328A0QROR32DCT   \n",
      "2      A068255029AHTHDXZURNU   \n",
      "3      A06944662TFWOKKV4GJKX   \n",
      "4             A1004703RC79J9   \n",
      "...                      ...   \n",
      "13274          AZWRZZAMX90VT   \n",
      "13275          AZXKAH2DE6C8A   \n",
      "13276          AZXON596A1VXC   \n",
      "13277          AZYXC63SS008M   \n",
      "13278          AZZ5ASC403N74   \n",
      "\n",
      "                                                    asin  \n",
      "0                               [B00474OR8G, B00BFM6OAW]  \n",
      "1                                           [B00CMQDKES]  \n",
      "2                                           [B001FA1K2G]  \n",
      "3                                           [B000GFYRHG]  \n",
      "4                                           [B003GTR8IO]  \n",
      "...                                                  ...  \n",
      "13274  [B0007R9L4M, B000CN7BMA, B001EQ5D1K, B002VT3GX...  \n",
      "13275   [B000MAK41I, B004X8TJP2, B006H34CUS, B007W14RMM]  \n",
      "13276                           [B001EO5S0I, B00271QQ7Q]  \n",
      "13277                                       [B0054TWPNC]  \n",
      "13278                                       [B00BIEU5PC]  \n",
      "\n",
      "[13279 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_user_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d650855",
   "metadata": {},
   "source": [
    "# Preparing Dataset for Surprise's Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05afcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "# generating trainset\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07343755",
   "metadata": {},
   "source": [
    "# Instantiate Pre-Initialised Matrix Factorization (Paragraph Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd71b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating mod-ecf\n",
    "mod_ecf = cf.PreInitialisedMF(user_map=user_idx_map,\n",
    "                              item_map=item_idx_map,\n",
    "                              user_factor=user_factors,\n",
    "                              item_factor=item_factors,\n",
    "                              learning_rate=LR_ALL,\n",
    "                              beta=BETA,\n",
    "                              num_epochs=N_EPOCHS,\n",
    "                              num_factors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eeabadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "CPU times: user 4min 7s, sys: 1.54 s, total: 4min 8s\n",
      "Wall time: 4min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fitting to training data\n",
    "mod_ecf.fit(trainset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa587004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.5 s, sys: 1.46 s, total: 31.9 s\n",
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate candidate items for user to predict rating\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8e539de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 1s, sys: 1min 50s, total: 9min 52s\n",
      "Wall time: 10min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "candidate_items = mod_ecf.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c2beb",
   "metadata": {},
   "source": [
    "## Loop through N = {10, 25, 30, 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98c854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate item popularity\n",
    "item_popularity = generate_item_popularity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2caa53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [00:43<00:00, 1471206.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:47<00:00, 283.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@10: 0.00489, average novelty@10: 0.96466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [01:07<00:00, 938558.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:47<00:00, 283.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@25: 0.01317, average novelty@25: 0.96496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [01:11<00:00, 882757.13it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:47<00:00, 280.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@30: 0.01524, average novelty@30: 0.96514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [01:12<00:00, 875510.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:51<00:00, 261.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@45: 0.02274, average novelty@45: 0.96588\n"
     ]
    }
   ],
   "source": [
    "n_recommendations = {}\n",
    "for n in [10, 25, 30, 45]:\n",
    "    # retrieve the top-n items based on similarities\n",
    "    top_ns = get_top_n(candidate_items, n)\n",
    "    # evaluate how well the recommended items predicted the future purchases\n",
    "    n_recommended_items = evaluate_recommendations(top_ns, test_user_history, item_popularity, n)\n",
    "    # saving the n-value and recommended items\n",
    "    n_recommendations[n] = (top_ns, n_recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e73163",
   "metadata": {},
   "source": [
    "# Evaluate N-Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9262bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_recommendations(train: pd.DataFrame, top_ns: dict):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # generating a random user\n",
    "    random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "    print(f\"For user: {random_user}:\")\n",
    "    print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "    # find the recommendations\n",
    "    print(f\"\\nRecommending:\\n\")\n",
    "    recommendations = (train[train['asin']\n",
    "                             .isin([i[0] for i in top_ns[random_user]])][['asin', 'title']]\n",
    "                       .drop_duplicates(subset='asin')\n",
    "                       .set_index('asin'))\n",
    "    print(f\"{recommendations.loc[[i[0] for i in top_ns[random_user]]].reset_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e36de",
   "metadata": {},
   "source": [
    "## N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e86fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A2IYX5W3A1N3VB:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "42065  B005V9YXTO  Eat Your Vegetables Sea Salt Veggie Chips, 4.5...\n",
      "46597  B00B18PAWI  Nestle Skinny Cow Divine Filled Chocolates, Ca...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "         asin                                              title\n",
      "0  B004IX03MK  Wedderspoon 100% Raw Organic Dandelion Honey, ...\n",
      "1  B004YTV5S4  Navitas Organics Hemp Seeds, 8 oz. Bags (Pack ...\n",
      "2  B005EF0HTK           Celebrate Good Times Gift Basket by ig4U\n",
      "3  B004DIR3TQ  SCHARFEEN BERGER Artisan Chocolate Bars, Bitte...\n",
      "4  B00B8DSFXC  Kevala Organic Black Raw and Unhulled Sesame S...\n",
      "5  B002RBRY0Y  Lindt LINDOR Dark Chocolate Truffles, Kosher, ...\n",
      "6  B005EF0HTA         Celebrate with a Crowd Gift Basket by ig4U\n",
      "7  B0029JASWA  Dove Dark Chocolate Promises, 9.5-Ounce Packag...\n",
      "8  B00474OQWI  Caribou Coffee, Caribou Blend Decaf, K-Cup Por...\n",
      "9  B006IOKA9S  San Francisco Bay OneCup Decaf French Roast (3...\n"
     ]
    }
   ],
   "source": [
    "top_ns_10 = n_recommendations[10][0]\n",
    "retrieve_recommendations(train, top_ns_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca424cf6",
   "metadata": {},
   "source": [
    "## N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4522e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: AWBMGLP57SAGK:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "22830  B001FSK3S0  Triscuit Crackers (Hint Of Salt, 9-Ounce Box, ...\n",
      "27871  B0029JHHO2  Ricochet Candies with Xylitol, Grape Escape, 1...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B004IX03MK  Wedderspoon 100% Raw Organic Dandelion Honey, ...\n",
      "1   B004YTV5S4  Navitas Organics Hemp Seeds, 8 oz. Bags (Pack ...\n",
      "2   B00B8DSFXC  Kevala Organic Black Raw and Unhulled Sesame S...\n",
      "3   B00856TSCC  Manitoba Harvest Hemp Hearts Raw Shelled Hemp ...\n",
      "4   B001EQ5G1C  Manitoba Harvest Organic Hemp Hearts Raw Shell...\n",
      "5   B003BI2EUW     YS BEE FARMS Raw Tupelo Blossom Honey, 13.5 OZ\n",
      "6   B004334FPG        Bob's Red Mill White Sesame Seeds, 16-ounce\n",
      "7   B008XCSXHO  Vitacost Organic Apple Cider Vinegar with ''Mo...\n",
      "8   B004TDTZEG  MW Polar Herring, Hot Tomato Sauce, 6-Ounce (P...\n",
      "9   B00B8DU1QQ           Kevala Organic Toasted Sesame Seeds 2Lbs\n",
      "10  B003S1TNIS  FiberGourmet Light Spaghetti, 8-Ounce Boxes (P...\n",
      "11  B007JBO41E  Emergency Preparedness &amp; Survival Gluten-F...\n",
      "12  B0029JES6W  M&amp;M'S Almond Chocolate Candy 9.9-Ounce Bag...\n",
      "13  B00DDT116M  Organic Matcha Green Tea Powder - Japanese Cul...\n",
      "14  B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "15  B001E50WDA  SPLENDA No Calorie Sweetener Granular, 9.7-Oun...\n",
      "16  B004VLVOJ0  Bob's Red Mill Organic Oats Whole Groats, 29 O...\n",
      "17  B005C3IVN8  Anderson's Pure Maple Syrup, Grade A Very Dark...\n",
      "18  B0000DI085  Simply Organic Almond Extract, Certified Organ...\n",
      "19  B000WSK5N2  NOW Foods Certified Organic Golden Flax Seeds,...\n",
      "20  B000JMAVYO  Spicy World Almonds Whole (Natural and Raw), 4...\n",
      "21  B004VLSW86    Bob's Red Mill Navy Beans, 29 Ounce (Pack of 4)\n",
      "22  B00474OQWI  Caribou Coffee, Caribou Blend Decaf, K-Cup Por...\n",
      "23  B001E5DYEE  Traverse Bay Fruit Dried Cherries, 8 Ounce (Pa...\n",
      "24  B003VTG7RC             Q Tonic Water Glass Bottle(Pack of 24)\n"
     ]
    }
   ],
   "source": [
    "top_ns_25 = n_recommendations[25][0]\n",
    "retrieve_recommendations(train, top_ns_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6bc5f",
   "metadata": {},
   "source": [
    "## N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02c52994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A1RTSVWEXMKAR1:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "46316  B00A16P8X2  DOVE PROMISES Valentine Milk Chocolate and Str...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B0029J6QLM         Snickers Dark Chocolate Candy (Pack of 24)\n",
      "1   B0029JES6W  M&amp;M'S Almond Chocolate Candy 9.9-Ounce Bag...\n",
      "2   B000HDJZWO  Enjoy Life Baking Chocolate, Soy free, Nut fre...\n",
      "3   B004DIR3TQ  SCHARFEEN BERGER Artisan Chocolate Bars, Bitte...\n",
      "4   B002RBRY0Y  Lindt LINDOR Dark Chocolate Truffles, Kosher, ...\n",
      "5   B000JMAVYO  Spicy World Almonds Whole (Natural and Raw), 4...\n",
      "6   B00B8DSFXC  Kevala Organic Black Raw and Unhulled Sesame S...\n",
      "7   B004YTV5S4  Navitas Organics Hemp Seeds, 8 oz. Bags (Pack ...\n",
      "8   B001PIH3MY  Annie's Organic Cheddar Bunnies, Baked Snack C...\n",
      "9   B0016BS3BK  Ghirardelli Double Chocolate Brownie Mix, 18-O...\n",
      "10  B00DUQNFSU       Werther's Original Popcorn, Caramel, 8 Ounce\n",
      "11  B004VLV6ES  Bob's Red Mill Whole White Popcorn, 27-ounce (...\n",
      "12  B0029JASWA  Dove Dark Chocolate Promises, 9.5-Ounce Packag...\n",
      "13  B0029J6HU2   MILKY WAY-- Single Size Candy Bars--Midnight ...\n",
      "14  B000CQ01IS  Annie's Bunny Grahams, Chocolate, Graham Snack...\n",
      "15  B000H11C6I  Blue Diamond Almond Nut-Thins Cracker Crisps, ...\n",
      "16  B002RBTVC8  Lindt LINDOR White Chocolate Truffles, Kosher,...\n",
      "17  B001HBXO54    Lindor Assorted Chocolate Truffles, 21.2 ounce \n",
      "18  B001E5E06U   Kashi, Breakfast Cereal, Organic Autumn Wheat...\n",
      "19  B001P1YWWK  Barney Butter Almond Butter, Crunchy, 16 Ounce...\n",
      "20  B005EF0HTA         Celebrate with a Crowd Gift Basket by ig4U\n",
      "21  B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "22  B001IZBIRA  KIT KAT White Cr&egrave;me Candy Bar (Pack of 24)\n",
      "23  B000S83YCK  Betty Crocker Brownie Mix Dark Chocolate Famil...\n",
      "24  B000H27PB8  Ritter Sport Bars, Dark Chocolate with Marzipa...\n",
      "25  B0029JEJR0  Dove Dark Chocolate Almond Promises, 8.5-Ounce...\n",
      "26  B003ZIR8YU  Kirkland Signature European Cookies with Belgi...\n",
      "27  B000VK4F5A  Kinnikinnick Gluten Free Animal Cookies, 8 Oun...\n",
      "28  B001E6K63A   Rice Krispies Treats Rice Cereal, 14.2-Ounce ...\n",
      "29  B0016BU8PE  Ghirardelli Chocolate Chip Cookie Mix, 20-Ounc...\n"
     ]
    }
   ],
   "source": [
    "top_ns_30 = n_recommendations[30][0]\n",
    "retrieve_recommendations(train, top_ns_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02489a59",
   "metadata": {},
   "source": [
    "## N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c842f86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: ASF0R1CMSF26F:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "3154   B000CQE3HS  Slim Jim Giant Smoked Snack Sticks, Tabasco, ....\n",
      "29957  B002NKPCZI  Peter Pan Creamy Honey Roast Peanut Spread, 16...\n",
      "36161  B004K00DGC  Jamba Juice Energy Drink, Crisp Apple, 8.4-Oun...\n",
      "41820  B005SPQENY  Chantea Aloe Vera Green Tea, Passion Fruit, 11...\n",
      "43121  B006BXV14E  Kellogg's Frosted Mini-Wheats Little Bites Fla...\n",
      "44829  B007K5KAJY    Nawgan Mandarin Orange, 11.5-Ounce (Pack of 24)\n",
      "44985  B007POT6VI         Quaker Instant Oats Variety Pack, 48-Count\n",
      "45325  B008JA73RG  V8 +Energy, Juice Drink with Green Tea, Peach ...\n",
      "46564  B00B18PAWI  Nestle Skinny Cow Divine Filled Chocolates, Ca...\n",
      "46897  B00BIEU5MK  Community Coffee Ground Coffee, French Vanilla...\n",
      "47331  B00DBSG2NC         Keebler Jumbo Dark Fudge Sticks, 6.6 Ounce\n",
      "47353  B00DBSGJ4E  Kellogg's Harvest Acres Fruit Snacks, Mixed Fr...\n",
      "47430  B00DBSG3K4  Keebler El Duende Cookies, Coconut, 11 Ounce (...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B007JBO41E  Emergency Preparedness &amp; Survival Gluten-F...\n",
      "1   B008JHROIM  Taba&ntilde;ero Original Hot Sauce Picante 8oz...\n",
      "2   B0039QXWPM  Harmony House Foods Soup Mix, Dried Vegetable,...\n",
      "3   B002HQP1V8  Homemade Dressings Italian Garden Salad Dressi...\n",
      "4   B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "5   B00DBSFXUK  Cheez-It Zingz Wafer Chipotle, Cheddar, 12.4 O...\n",
      "6   B000H23Z1C  Carroll Shelby's Original Texas Chili Kit, 4-O...\n",
      "7   B00826F95K  Igourmet Four Continents of Cheese on a Budget...\n",
      "8   B0001M0Z6Q  Spicy World Peppercorn (Whole)-Black Tellicher...\n",
      "9   B00DDT116M  Organic Matcha Green Tea Powder - Japanese Cul...\n",
      "10  B002ATCFX4             Melinda's Naga Jolokia Hot Sauce, 5 Oz\n",
      "11  B001EO5ZHO  Huy Fong, Sriracha Hot Chili Sauce, 17-Ounce B...\n",
      "12  B001E5DYEE  Traverse Bay Fruit Dried Cherries, 8 Ounce (Pa...\n",
      "13  B009M515HQ  Side Mates Pearl Couscous, Tuscan Medley, 6 Ou...\n",
      "14  B000MIFS3Y  Chef Boyardee Beef Ravioli, 14.25-Ounce Microw...\n",
      "15  B00286BJ90       Mr. Yoshida's Gourmet Sauce, 86 Fluid Ounce.\n",
      "16  B002NM1UYS  Bob's Red Mill Gluten Free Corn Grits/Polenta,...\n",
      "17  B001EO5XV2  More Than Gourmet Classic Roasted Vegetable De...\n",
      "18  B004BJVLWC  Myojo Chukazanmai Instant Ramen Soy Sauce Flav...\n",
      "19  B004XUGORG  Maruchan Yakisoba Beef Taco, 8-3.99-Ounce Pack...\n",
      "20  B0061JWQOW  NongShim Shin Black Noodle Soup, Spicy, 4.58 (...\n",
      "21  B00B8DSFXC  Kevala Organic Black Raw and Unhulled Sesame S...\n",
      "22  B003S1TNIS  FiberGourmet Light Spaghetti, 8-Ounce Boxes (P...\n",
      "23  B00DBSFXLY    Cheez-It Zingz Wafer Queso, Fundido, 12.4 Ounce\n",
      "24  B004H1YIBU  Crunchmaster Multi-Grain Crackers, Sea Salt, 4...\n",
      "25  B0001EJ4CU  Lee Kum Kee Premium Dark Soy Sauce - 16.9 fl. ...\n",
      "26  B002HG9R1I          Atomic Horseradish - Extra Hot - 6 Oz Jar\n",
      "27  B00439BEYU  Earthly Delights Organic Italian Pearled Farro...\n",
      "28  B003VTG7RC             Q Tonic Water Glass Bottle(Pack of 24)\n",
      "29  B00394JNAW  Antimo Caputo Italian &quot;00&quot; Farina Fl...\n",
      "30  B000G6TNTW             Pure Habanero Pepper Mash Puree 3.75oz\n",
      "31  B004770OLM  Celestial Seasonings Mandarin Orange Spice Her...\n",
      "32  B005ECLNIM                              True Orange 100 Count\n",
      "33  B003ZXCE7G  Koshihikari Premium Sprouted Brown Gaba Rice, ...\n",
      "34  B001EQ4MDK  Bellino Panettone Cake, 2 Pound Boxes (Pack of 2)\n",
      "35  B000LKXFBK  Mrs. Leeper's Creamy Tuna Dinner, 7.41-Ounce B...\n",
      "36  B0050IKSBI           Harissa Condiment In Tube - Spicy 120 Gr\n",
      "37  B004NRHAZO          Nishiki Premium Brown Rice, 15-Pounds Bag\n",
      "38  B005C3IVME     Anderson's Pure Maple Syrup, Grade A, 32-Ounce\n",
      "39  B000FK63QA  Tinkyada Brown Rice Pasta, Fettuccini Style, 1...\n",
      "40  B000EVE3YE  Glutino Gluten Free Pantry Muffin Mix, 15-Ounc...\n",
      "41  B004D6044O  Simply7 Lentil Chips, Creamy Dill, 4 Ounce (Pa...\n",
      "42  B001PEWJWC  Garbanzo Beans aka Chickpeas or Ceci Beans | N...\n",
      "43  B000FIAWVE  Santa Fe Bean Company Instant Fat Free Black R...\n",
      "44  B000E5GFQE       Bragg Organic Sprinkle Seasoning 1.50 Ounces\n"
     ]
    }
   ],
   "source": [
    "top_ns_45 = n_recommendations[45][0]\n",
    "retrieve_recommendations(train, top_ns_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a2ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
