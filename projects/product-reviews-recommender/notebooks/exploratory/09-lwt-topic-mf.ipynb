{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215181c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cfa4d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8729351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable\n",
    "CATEGORY = \"Grocery_and_Gourmet_Food\"\n",
    "DATA_PATH = \"data/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f77c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f53641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A23RYWDS884TUL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This curry paste makes a delicious curry.  I j...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>curry paste delicious curry fry chicken vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A945RBQWGZXCK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've purchased different curries in the grocer...</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>purchase different curry grocery store complet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3AMNY44OP8AOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I started a new diet restricting all added sug...</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>start new diet restrict added sugar brand suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3IB4CQ2QEJLJ8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>So many flavors. I can't begin to tell you how...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>flavor begin tell love mae ploy curry ask reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>AQA5DF3RWKETQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've used this a lot recently in some of my ch...</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>use lot recently chicken dish use lot like spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        asin                              title  \\\n",
       "0      0  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1      1  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2      3  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "3      4  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "4      5  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "\n",
       "                                          categories      reviewerID  overall  \\\n",
       "0  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A23RYWDS884TUL      5.0   \n",
       "1  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   A945RBQWGZXCK      5.0   \n",
       "2  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3AMNY44OP8AOU      4.0   \n",
       "3  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3IB4CQ2QEJLJ8      5.0   \n",
       "4  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   AQA5DF3RWKETQ      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  \\\n",
       "0  This curry paste makes a delicious curry.  I j...  2013-05-28   \n",
       "1  I've purchased different curries in the grocer...  2012-09-17   \n",
       "2  I started a new diet restricting all added sug...  2014-01-23   \n",
       "3  So many flavors. I can't begin to tell you how...  2014-04-27   \n",
       "4  I've used this a lot recently in some of my ch...  2012-11-27   \n",
       "\n",
       "                                 processedReviewText  \n",
       "0  curry paste delicious curry fry chicken vegeta...  \n",
       "1  purchase different curry grocery store complet...  \n",
       "2  start new diet restrict added sugar brand suga...  \n",
       "3  flavor begin tell love mae ploy curry ask reci...  \n",
       "4  use lot recently chicken dish use lot like spi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d5ca8",
   "metadata": {},
   "source": [
    "# Preparing Review Text for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d938b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 47774/47774 [00:00<00:00, 139790.53it/s]\n",
      "2021-08-24 16:16:41,209 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-08-24 16:16:41,568 : INFO : adding document #10000 to Dictionary(14898 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-24 16:16:41,956 : INFO : adding document #20000 to Dictionary(21785 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-24 16:16:42,360 : INFO : adding document #30000 to Dictionary(27143 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-24 16:16:42,779 : INFO : adding document #40000 to Dictionary(31844 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-24 16:16:43,143 : INFO : built Dictionary(34875 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...) from 47774 documents (total 1942617 corpus positions)\n",
      "2021-08-24 16:16:43,164 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(34875 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...) from 47774 documents (total 1942617 corpus positions)\", 'datetime': '2021-08-24T16:16:43.144694', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'created'}\n",
      "2021-08-24 16:16:43,230 : INFO : discarding 24820 tokens: [('scrambled', 4), ('yogurts', 1), ('icer', 2), ('curris', 1), ('matsaman', 1), ('panag', 1), ('wilson', 3), ('sebastopol', 2), ('vaposteam', 2), ('cleared', 2)]...\n",
      "2021-08-24 16:16:43,231 : INFO : keeping 10055 tokens which were in no less than 5 and no more than 35830 (=75.0%) documents\n",
      "2021-08-24 16:16:43,249 : INFO : resulting dictionary: Dictionary(10055 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "processed_reviews = train[\"processedReviewText\"].progress_apply(lambda x: x.split())\n",
    "\n",
    "# creating a bag-of-words\n",
    "dictionary = gensim.corpora.Dictionary(processed_reviews)\n",
    "\n",
    "# filtering out tokens that appear in less than 15 reviews\n",
    "# or more than 0.5 of the corpus\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.75)\n",
    "\n",
    "# creating dict how many words and time the word appear\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc400a",
   "metadata": {},
   "source": [
    "# Training LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d0b109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:16:44,632 : INFO : using symmetric alpha at 0.02\n",
      "2021-08-24 16:16:44,633 : INFO : using symmetric eta at 0.02\n",
      "2021-08-24 16:16:44,634 : INFO : using serial LDA version on this node\n",
      "2021-08-24 16:16:44,674 : INFO : running online LDA training, 50 topics, 20 passes over the supplied corpus of 47774 documents, updating every 16000 documents, evaluating every ~47774 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2021-08-24 16:16:44,676 : INFO : training LDA model using 8 processes\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "2021-08-24 16:16:49,427 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:16:49,441 : INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:16:49,443 : INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:16:49,445 : INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:16:49,454 : INFO : PROGRESS: pass 0, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:16:49,456 : INFO : PROGRESS: pass 0, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:16:49,467 : INFO : PROGRESS: pass 0, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:16:49,470 : INFO : PROGRESS: pass 0, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:16:49,472 : INFO : PROGRESS: pass 0, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:16:49,486 : INFO : PROGRESS: pass 0, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:16:49,488 : INFO : PROGRESS: pass 0, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:16:49,490 : INFO : PROGRESS: pass 0, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:16:49,505 : INFO : PROGRESS: pass 0, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:16:49,508 : INFO : PROGRESS: pass 0, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:16:49,512 : INFO : PROGRESS: pass 0, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:16:49,514 : INFO : PROGRESS: pass 0, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:16:49,518 : INFO : PROGRESS: pass 0, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:16:49,536 : INFO : PROGRESS: pass 0, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:16:49,541 : INFO : PROGRESS: pass 0, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:16:49,545 : INFO : PROGRESS: pass 0, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:16:49,551 : INFO : PROGRESS: pass 0, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:16:49,577 : INFO : PROGRESS: pass 0, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:16:49,607 : INFO : PROGRESS: pass 0, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:16:49,634 : INFO : PROGRESS: pass 0, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:16:51,997 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:16:52,044 : INFO : topic #28 (0.020): 0.022*\"good\" + 0.017*\"coffee\" + 0.016*\"flavor\" + 0.014*\"try\" + 0.014*\"taste\" + 0.013*\"great\" + 0.013*\"use\" + 0.011*\"like\" + 0.011*\"add\" + 0.009*\"love\"\n",
      "2021-08-24 16:16:52,046 : INFO : topic #5 (0.020): 0.015*\"like\" + 0.015*\"good\" + 0.014*\"taste\" + 0.014*\"great\" + 0.013*\"flavor\" + 0.012*\"salt\" + 0.011*\"use\" + 0.010*\"love\" + 0.009*\"product\" + 0.009*\"eat\"\n",
      "2021-08-24 16:16:52,047 : INFO : topic #49 (0.020): 0.017*\"sauce\" + 0.016*\"taste\" + 0.014*\"flavor\" + 0.014*\"like\" + 0.013*\"honey\" + 0.013*\"tea\" + 0.012*\"good\" + 0.012*\"product\" + 0.011*\"use\" + 0.008*\"sweet\"\n",
      "2021-08-24 16:16:52,050 : INFO : topic #36 (0.020): 0.019*\"coffee\" + 0.017*\"good\" + 0.015*\"taste\" + 0.011*\"love\" + 0.011*\"great\" + 0.011*\"flavor\" + 0.009*\"use\" + 0.009*\"like\" + 0.008*\"product\" + 0.007*\"eat\"\n",
      "2021-08-24 16:16:52,051 : INFO : topic #16 (0.020): 0.023*\"taste\" + 0.018*\"use\" + 0.015*\"flavor\" + 0.015*\"great\" + 0.015*\"good\" + 0.013*\"like\" + 0.011*\"brand\" + 0.008*\"tea\" + 0.008*\"sugar\" + 0.007*\"try\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:16:52,052 : INFO : topic diff=29.581743, rho=1.000000\n",
      "2021-08-24 16:16:55,107 : INFO : -8.107 per-word bound, 275.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:16:55,224 : INFO : merging changes from 18000 documents into a model of 47774 documents\n",
      "2021-08-24 16:16:55,262 : INFO : topic #8 (0.020): 0.016*\"good\" + 0.015*\"like\" + 0.015*\"flavor\" + 0.014*\"coffee\" + 0.012*\"taste\" + 0.012*\"use\" + 0.011*\"product\" + 0.010*\"buy\" + 0.008*\"great\" + 0.008*\"love\"\n",
      "2021-08-24 16:16:55,264 : INFO : topic #49 (0.020): 0.015*\"tea\" + 0.015*\"taste\" + 0.014*\"flavor\" + 0.014*\"like\" + 0.013*\"sauce\" + 0.012*\"honey\" + 0.012*\"good\" + 0.012*\"product\" + 0.011*\"use\" + 0.009*\"buy\"\n",
      "2021-08-24 16:16:55,266 : INFO : topic #25 (0.020): 0.018*\"flavor\" + 0.017*\"good\" + 0.012*\"product\" + 0.012*\"like\" + 0.011*\"use\" + 0.011*\"taste\" + 0.010*\"try\" + 0.008*\"rice\" + 0.006*\"tea\" + 0.006*\"pasta\"\n",
      "2021-08-24 16:16:55,275 : INFO : topic #35 (0.020): 0.017*\"good\" + 0.015*\"taste\" + 0.011*\"product\" + 0.010*\"great\" + 0.010*\"flavor\" + 0.009*\"price\" + 0.007*\"like\" + 0.007*\"add\" + 0.006*\"buy\" + 0.006*\"use\"\n",
      "2021-08-24 16:16:55,280 : INFO : topic #15 (0.020): 0.015*\"use\" + 0.013*\"hot\" + 0.012*\"sauce\" + 0.012*\"taste\" + 0.011*\"mix\" + 0.010*\"like\" + 0.009*\"bread\" + 0.009*\"flavor\" + 0.008*\"good\" + 0.008*\"buy\"\n",
      "2021-08-24 16:16:55,298 : INFO : topic diff=6.441514, rho=0.333333\n",
      "2021-08-24 16:16:57,706 : INFO : -7.924 per-word bound, 242.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:16:57,765 : INFO : merging changes from 13774 documents into a model of 47774 documents\n",
      "2021-08-24 16:16:57,787 : INFO : topic #40 (0.020): 0.022*\"good\" + 0.022*\"flavor\" + 0.016*\"taste\" + 0.014*\"like\" + 0.013*\"use\" + 0.012*\"product\" + 0.012*\"try\" + 0.009*\"great\" + 0.008*\"chocolate\" + 0.008*\"cooky\"\n",
      "2021-08-24 16:16:57,788 : INFO : topic #23 (0.020): 0.025*\"like\" + 0.023*\"taste\" + 0.018*\"sauce\" + 0.012*\"use\" + 0.011*\"flavor\" + 0.009*\"sugar\" + 0.009*\"good\" + 0.008*\"try\" + 0.008*\"sweet\" + 0.007*\"think\"\n",
      "2021-08-24 16:16:57,788 : INFO : topic #41 (0.020): 0.023*\"drink\" + 0.021*\"good\" + 0.015*\"coffee\" + 0.015*\"love\" + 0.014*\"try\" + 0.014*\"taste\" + 0.013*\"flavor\" + 0.012*\"great\" + 0.011*\"energy\" + 0.010*\"like\"\n",
      "2021-08-24 16:16:57,789 : INFO : topic #49 (0.020): 0.017*\"honey\" + 0.016*\"flavor\" + 0.016*\"taste\" + 0.014*\"like\" + 0.013*\"tea\" + 0.013*\"sauce\" + 0.012*\"good\" + 0.011*\"product\" + 0.011*\"use\" + 0.008*\"sweet\"\n",
      "2021-08-24 16:16:57,790 : INFO : topic #19 (0.020): 0.023*\"like\" + 0.022*\"taste\" + 0.022*\"bar\" + 0.020*\"flavor\" + 0.018*\"good\" + 0.014*\"snack\" + 0.011*\"eat\" + 0.011*\"peanut\" + 0.009*\"great\" + 0.008*\"try\"\n",
      "2021-08-24 16:16:57,792 : INFO : topic diff=0.582593, rho=0.235702\n",
      "2021-08-24 16:16:58,863 : INFO : -7.764 per-word bound, 217.4 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:16:58,864 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:16:58,874 : INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:16:58,875 : INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:16:58,876 : INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:16:58,876 : INFO : PROGRESS: pass 1, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:16:58,883 : INFO : PROGRESS: pass 1, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:16:58,887 : INFO : PROGRESS: pass 1, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:16:58,888 : INFO : PROGRESS: pass 1, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:16:58,889 : INFO : PROGRESS: pass 1, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:16:58,890 : INFO : PROGRESS: pass 1, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:16:58,891 : INFO : PROGRESS: pass 1, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:16:58,902 : INFO : PROGRESS: pass 1, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:16:58,903 : INFO : PROGRESS: pass 1, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:16:58,905 : INFO : PROGRESS: pass 1, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:16:58,906 : INFO : PROGRESS: pass 1, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:16:58,906 : INFO : PROGRESS: pass 1, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:16:58,925 : INFO : PROGRESS: pass 1, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:16:58,927 : INFO : PROGRESS: pass 1, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:16:58,929 : INFO : PROGRESS: pass 1, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:16:58,941 : INFO : PROGRESS: pass 1, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:16:58,962 : INFO : PROGRESS: pass 1, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:16:59,000 : INFO : PROGRESS: pass 1, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:16:59,027 : INFO : PROGRESS: pass 1, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:16:59,048 : INFO : PROGRESS: pass 1, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:01,415 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:01,450 : INFO : topic #20 (0.020): 0.024*\"milk\" + 0.015*\"taste\" + 0.015*\"use\" + 0.015*\"like\" + 0.013*\"tea\" + 0.011*\"sugar\" + 0.010*\"good\" + 0.009*\"little\" + 0.009*\"drink\" + 0.009*\"try\"\n",
      "2021-08-24 16:17:01,452 : INFO : topic #42 (0.020): 0.021*\"taste\" + 0.015*\"like\" + 0.014*\"flavor\" + 0.013*\"oil\" + 0.013*\"good\" + 0.010*\"water\" + 0.010*\"coconut\" + 0.010*\"use\" + 0.008*\"product\" + 0.007*\"add\"\n",
      "2021-08-24 16:17:01,454 : INFO : topic #17 (0.020): 0.019*\"good\" + 0.017*\"chocolate\" + 0.012*\"love\" + 0.011*\"flavor\" + 0.011*\"like\" + 0.010*\"bar\" + 0.009*\"buy\" + 0.009*\"taste\" + 0.009*\"use\" + 0.009*\"eat\"\n",
      "2021-08-24 16:17:01,456 : INFO : topic #13 (0.020): 0.022*\"taste\" + 0.021*\"like\" + 0.016*\"cereal\" + 0.014*\"good\" + 0.011*\"product\" + 0.010*\"flavor\" + 0.010*\"sugar\" + 0.008*\"eat\" + 0.008*\"free\" + 0.008*\"calorie\"\n",
      "2021-08-24 16:17:01,458 : INFO : topic #46 (0.020): 0.025*\"like\" + 0.016*\"flavor\" + 0.015*\"product\" + 0.014*\"taste\" + 0.013*\"good\" + 0.010*\"sugar\" + 0.009*\"try\" + 0.008*\"use\" + 0.007*\"drink\" + 0.007*\"price\"\n",
      "2021-08-24 16:17:01,460 : INFO : topic diff=0.488503, rho=0.196544\n",
      "2021-08-24 16:17:04,373 : INFO : -7.756 per-word bound, 216.2 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:04,473 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:04,519 : INFO : topic #14 (0.020): 0.022*\"taste\" + 0.022*\"good\" + 0.020*\"like\" + 0.019*\"chocolate\" + 0.017*\"flavor\" + 0.015*\"use\" + 0.008*\"coffee\" + 0.008*\"think\" + 0.008*\"sweet\" + 0.007*\"drink\"\n",
      "2021-08-24 16:17:04,521 : INFO : topic #8 (0.020): 0.018*\"good\" + 0.016*\"like\" + 0.016*\"flavor\" + 0.015*\"jerky\" + 0.013*\"taste\" + 0.012*\"product\" + 0.011*\"buy\" + 0.011*\"beef\" + 0.011*\"use\" + 0.011*\"soup\"\n",
      "2021-08-24 16:17:04,522 : INFO : topic #44 (0.020): 0.038*\"chocolate\" + 0.026*\"like\" + 0.013*\"tea\" + 0.012*\"use\" + 0.011*\"love\" + 0.011*\"taste\" + 0.011*\"bag\" + 0.011*\"caramel\" + 0.010*\"good\" + 0.009*\"box\"\n",
      "2021-08-24 16:17:04,523 : INFO : topic #7 (0.020): 0.031*\"good\" + 0.015*\"like\" + 0.014*\"eat\" + 0.012*\"amazon\" + 0.012*\"taste\" + 0.012*\"price\" + 0.011*\"product\" + 0.011*\"love\" + 0.011*\"use\" + 0.011*\"purchase\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:17:04,525 : INFO : topic #42 (0.020): 0.021*\"taste\" + 0.016*\"oil\" + 0.015*\"like\" + 0.014*\"flavor\" + 0.012*\"good\" + 0.011*\"water\" + 0.010*\"coconut\" + 0.010*\"use\" + 0.008*\"fat\" + 0.007*\"product\"\n",
      "2021-08-24 16:17:04,527 : INFO : topic diff=0.507813, rho=0.196544\n",
      "2021-08-24 16:17:06,928 : INFO : -7.693 per-word bound, 206.9 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:06,994 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:07,017 : INFO : topic #48 (0.020): 0.028*\"like\" + 0.025*\"taste\" + 0.019*\"drink\" + 0.014*\"good\" + 0.012*\"sugar\" + 0.011*\"use\" + 0.011*\"flavor\" + 0.010*\"product\" + 0.009*\"water\" + 0.009*\"try\"\n",
      "2021-08-24 16:17:07,018 : INFO : topic #49 (0.020): 0.036*\"honey\" + 0.016*\"sauce\" + 0.016*\"flavor\" + 0.016*\"taste\" + 0.013*\"like\" + 0.013*\"use\" + 0.011*\"good\" + 0.011*\"mango\" + 0.011*\"product\" + 0.010*\"pork\"\n",
      "2021-08-24 16:17:07,019 : INFO : topic #18 (0.020): 0.020*\"good\" + 0.018*\"taste\" + 0.014*\"great\" + 0.014*\"use\" + 0.014*\"like\" + 0.012*\"chip\" + 0.011*\"flavor\" + 0.010*\"add\" + 0.010*\"try\" + 0.009*\"product\"\n",
      "2021-08-24 16:17:07,019 : INFO : topic #6 (0.020): 0.032*\"product\" + 0.024*\"taste\" + 0.017*\"cheese\" + 0.014*\"butter\" + 0.013*\"cracker\" + 0.013*\"like\" + 0.010*\"peanut\" + 0.009*\"good\" + 0.008*\"great\" + 0.007*\"try\"\n",
      "2021-08-24 16:17:07,020 : INFO : topic #29 (0.020): 0.022*\"good\" + 0.016*\"like\" + 0.014*\"buy\" + 0.012*\"use\" + 0.012*\"product\" + 0.012*\"taste\" + 0.010*\"flavor\" + 0.009*\"tea\" + 0.009*\"price\" + 0.008*\"great\"\n",
      "2021-08-24 16:17:07,022 : INFO : topic diff=0.528322, rho=0.196544\n",
      "2021-08-24 16:17:08,084 : INFO : -7.588 per-word bound, 192.5 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:08,084 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:17:08,093 : INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:17:08,094 : INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:17:08,095 : INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:17:08,096 : INFO : PROGRESS: pass 2, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:17:08,106 : INFO : PROGRESS: pass 2, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:17:08,107 : INFO : PROGRESS: pass 2, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:17:08,108 : INFO : PROGRESS: pass 2, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:17:08,109 : INFO : PROGRESS: pass 2, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:17:08,110 : INFO : PROGRESS: pass 2, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:17:08,111 : INFO : PROGRESS: pass 2, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:17:08,123 : INFO : PROGRESS: pass 2, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:17:08,124 : INFO : PROGRESS: pass 2, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:17:08,125 : INFO : PROGRESS: pass 2, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:17:08,127 : INFO : PROGRESS: pass 2, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:17:08,144 : INFO : PROGRESS: pass 2, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:17:08,146 : INFO : PROGRESS: pass 2, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:17:08,147 : INFO : PROGRESS: pass 2, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:17:08,162 : INFO : PROGRESS: pass 2, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:17:08,164 : INFO : PROGRESS: pass 2, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:17:08,180 : INFO : PROGRESS: pass 2, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:17:08,211 : INFO : PROGRESS: pass 2, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:17:08,268 : INFO : PROGRESS: pass 2, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:17:08,308 : INFO : PROGRESS: pass 2, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:10,446 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:10,500 : INFO : topic #17 (0.020): 0.024*\"chocolate\" + 0.018*\"good\" + 0.013*\"bar\" + 0.012*\"love\" + 0.011*\"flavor\" + 0.011*\"like\" + 0.009*\"caramel\" + 0.009*\"taste\" + 0.009*\"buy\" + 0.009*\"eat\"\n",
      "2021-08-24 16:17:10,501 : INFO : topic #34 (0.020): 0.017*\"taste\" + 0.015*\"fat\" + 0.014*\"seed\" + 0.012*\"use\" + 0.012*\"calorie\" + 0.011*\"like\" + 0.010*\"high\" + 0.010*\"try\" + 0.009*\"good\" + 0.008*\"great\"\n",
      "2021-08-24 16:17:10,503 : INFO : topic #19 (0.020): 0.037*\"bar\" + 0.025*\"like\" + 0.022*\"taste\" + 0.020*\"snack\" + 0.020*\"flavor\" + 0.020*\"good\" + 0.017*\"peanut\" + 0.014*\"eat\" + 0.010*\"great\" + 0.009*\"butter\"\n",
      "2021-08-24 16:17:10,504 : INFO : topic #29 (0.020): 0.022*\"good\" + 0.016*\"like\" + 0.014*\"buy\" + 0.012*\"use\" + 0.012*\"product\" + 0.011*\"taste\" + 0.010*\"price\" + 0.009*\"flavor\" + 0.008*\"tea\" + 0.008*\"great\"\n",
      "2021-08-24 16:17:10,506 : INFO : topic #26 (0.020): 0.030*\"good\" + 0.018*\"cheese\" + 0.018*\"like\" + 0.015*\"olive\" + 0.014*\"flavor\" + 0.012*\"love\" + 0.011*\"taste\" + 0.011*\"mix\" + 0.011*\"use\" + 0.010*\"great\"\n",
      "2021-08-24 16:17:10,507 : INFO : topic diff=0.551817, rho=0.192854\n",
      "2021-08-24 16:17:13,506 : INFO : -7.582 per-word bound, 191.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:13,930 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:13,971 : INFO : topic #46 (0.020): 0.024*\"like\" + 0.018*\"product\" + 0.016*\"flavor\" + 0.014*\"taste\" + 0.012*\"good\" + 0.011*\"sugar\" + 0.009*\"organic\" + 0.008*\"try\" + 0.008*\"price\" + 0.007*\"amazon\"\n",
      "2021-08-24 16:17:13,972 : INFO : topic #7 (0.020): 0.032*\"good\" + 0.021*\"amazon\" + 0.019*\"price\" + 0.015*\"purchase\" + 0.014*\"like\" + 0.013*\"product\" + 0.013*\"eat\" + 0.013*\"love\" + 0.011*\"taste\" + 0.011*\"use\"\n",
      "2021-08-24 16:17:13,974 : INFO : topic #3 (0.020): 0.017*\"oreo\" + 0.017*\"product\" + 0.013*\"flavor\" + 0.011*\"like\" + 0.009*\"creme\" + 0.009*\"taste\" + 0.008*\"buy\" + 0.008*\"great\" + 0.008*\"use\" + 0.007*\"try\"\n",
      "2021-08-24 16:17:13,976 : INFO : topic #43 (0.020): 0.021*\"product\" + 0.021*\"seed\" + 0.011*\"eat\" + 0.010*\"good\" + 0.009*\"taste\" + 0.009*\"like\" + 0.009*\"buy\" + 0.008*\"try\" + 0.008*\"add\" + 0.007*\"small\"\n",
      "2021-08-24 16:17:13,977 : INFO : topic #20 (0.020): 0.046*\"milk\" + 0.016*\"use\" + 0.015*\"taste\" + 0.014*\"like\" + 0.013*\"sugar\" + 0.010*\"good\" + 0.009*\"tea\" + 0.009*\"little\" + 0.009*\"drink\" + 0.009*\"try\"\n",
      "2021-08-24 16:17:13,979 : INFO : topic diff=0.562100, rho=0.192854\n",
      "2021-08-24 16:17:16,584 : INFO : -7.560 per-word bound, 188.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:16,655 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:16,679 : INFO : topic #46 (0.020): 0.024*\"like\" + 0.019*\"product\" + 0.016*\"flavor\" + 0.014*\"taste\" + 0.012*\"good\" + 0.012*\"sugar\" + 0.008*\"try\" + 0.008*\"organic\" + 0.008*\"price\" + 0.007*\"brand\"\n",
      "2021-08-24 16:17:16,680 : INFO : topic #39 (0.020): 0.037*\"love\" + 0.028*\"great\" + 0.027*\"good\" + 0.023*\"taste\" + 0.018*\"like\" + 0.016*\"flavor\" + 0.015*\"couscous\" + 0.013*\"product\" + 0.013*\"soup\" + 0.012*\"try\"\n",
      "2021-08-24 16:17:16,681 : INFO : topic #34 (0.020): 0.018*\"fat\" + 0.017*\"seed\" + 0.015*\"taste\" + 0.014*\"calorie\" + 0.012*\"high\" + 0.011*\"use\" + 0.010*\"like\" + 0.009*\"good\" + 0.008*\"try\" + 0.008*\"food\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:17:16,682 : INFO : topic #13 (0.020): 0.031*\"cereal\" + 0.021*\"like\" + 0.021*\"taste\" + 0.015*\"sugar\" + 0.015*\"good\" + 0.011*\"eat\" + 0.011*\"fiber\" + 0.011*\"flavor\" + 0.009*\"cinnamon\" + 0.009*\"calorie\"\n",
      "2021-08-24 16:17:16,683 : INFO : topic #20 (0.020): 0.051*\"milk\" + 0.016*\"use\" + 0.015*\"taste\" + 0.014*\"like\" + 0.013*\"sugar\" + 0.010*\"good\" + 0.009*\"try\" + 0.009*\"little\" + 0.009*\"drink\" + 0.008*\"tea\"\n",
      "2021-08-24 16:17:16,684 : INFO : topic diff=0.585516, rho=0.192854\n",
      "2021-08-24 16:17:17,776 : INFO : -7.485 per-word bound, 179.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:17,778 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:17:17,787 : INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:17:17,788 : INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:17:17,789 : INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:17:17,800 : INFO : PROGRESS: pass 3, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:17:17,801 : INFO : PROGRESS: pass 3, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:17:17,803 : INFO : PROGRESS: pass 3, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:17:17,804 : INFO : PROGRESS: pass 3, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:17:17,805 : INFO : PROGRESS: pass 3, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:17:17,822 : INFO : PROGRESS: pass 3, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:17:17,824 : INFO : PROGRESS: pass 3, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:17:17,825 : INFO : PROGRESS: pass 3, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:17:17,827 : INFO : PROGRESS: pass 3, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:17:17,828 : INFO : PROGRESS: pass 3, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:17:17,843 : INFO : PROGRESS: pass 3, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:17:17,846 : INFO : PROGRESS: pass 3, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:17:17,847 : INFO : PROGRESS: pass 3, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:17:17,849 : INFO : PROGRESS: pass 3, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:17:17,865 : INFO : PROGRESS: pass 3, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:17:17,867 : INFO : PROGRESS: pass 3, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:17:17,889 : INFO : PROGRESS: pass 3, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:17:17,903 : INFO : PROGRESS: pass 3, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:17:17,962 : INFO : PROGRESS: pass 3, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:17:17,998 : INFO : PROGRESS: pass 3, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:20,107 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:20,141 : INFO : topic #34 (0.020): 0.019*\"fat\" + 0.017*\"seed\" + 0.015*\"taste\" + 0.015*\"calorie\" + 0.013*\"high\" + 0.010*\"use\" + 0.009*\"food\" + 0.009*\"like\" + 0.009*\"protein\" + 0.009*\"consume\"\n",
      "2021-08-24 16:17:20,143 : INFO : topic #13 (0.020): 0.031*\"cereal\" + 0.021*\"like\" + 0.021*\"taste\" + 0.015*\"sugar\" + 0.015*\"good\" + 0.012*\"eat\" + 0.011*\"fiber\" + 0.011*\"flavor\" + 0.009*\"calorie\" + 0.009*\"cinnamon\"\n",
      "2021-08-24 16:17:20,144 : INFO : topic #45 (0.020): 0.027*\"snack\" + 0.015*\"like\" + 0.014*\"good\" + 0.013*\"flavor\" + 0.012*\"time\" + 0.011*\"love\" + 0.011*\"pasta\" + 0.010*\"eat\" + 0.010*\"great\" + 0.009*\"spaghetti\"\n",
      "2021-08-24 16:17:20,145 : INFO : topic #1 (0.020): 0.027*\"add\" + 0.013*\"soup\" + 0.012*\"minute\" + 0.012*\"chicken\" + 0.011*\"water\" + 0.010*\"good\" + 0.009*\"pasta\" + 0.009*\"use\" + 0.009*\"bit\" + 0.009*\"cook\"\n",
      "2021-08-24 16:17:20,147 : INFO : topic #31 (0.020): 0.048*\"chocolate\" + 0.028*\"cooky\" + 0.020*\"like\" + 0.020*\"taste\" + 0.016*\"good\" + 0.015*\"cookie\" + 0.014*\"eat\" + 0.010*\"snack\" + 0.010*\"sweet\" + 0.010*\"calorie\"\n",
      "2021-08-24 16:17:20,149 : INFO : topic diff=0.603988, rho=0.189365\n",
      "2021-08-24 16:17:23,375 : INFO : -7.482 per-word bound, 178.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:23,480 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:23,519 : INFO : topic #46 (0.020): 0.023*\"like\" + 0.020*\"product\" + 0.017*\"flavor\" + 0.014*\"taste\" + 0.012*\"good\" + 0.011*\"sugar\" + 0.010*\"organic\" + 0.008*\"try\" + 0.008*\"price\" + 0.007*\"brand\"\n",
      "2021-08-24 16:17:23,521 : INFO : topic #42 (0.020): 0.042*\"oil\" + 0.033*\"coconut\" + 0.017*\"taste\" + 0.014*\"water\" + 0.013*\"use\" + 0.012*\"fat\" + 0.012*\"like\" + 0.012*\"flavor\" + 0.009*\"good\" + 0.007*\"product\"\n",
      "2021-08-24 16:17:23,524 : INFO : topic #36 (0.020): 0.065*\"coffee\" + 0.047*\"vanilla\" + 0.025*\"flavor\" + 0.022*\"taste\" + 0.015*\"good\" + 0.014*\"like\" + 0.013*\"cup\" + 0.011*\"starbucks\" + 0.011*\"love\" + 0.008*\"great\"\n",
      "2021-08-24 16:17:23,528 : INFO : topic #31 (0.020): 0.053*\"chocolate\" + 0.026*\"cooky\" + 0.020*\"like\" + 0.020*\"taste\" + 0.016*\"good\" + 0.014*\"eat\" + 0.014*\"cookie\" + 0.011*\"dark\" + 0.011*\"sweet\" + 0.010*\"snack\"\n",
      "2021-08-24 16:17:23,530 : INFO : topic #35 (0.020): 0.024*\"cake\" + 0.018*\"good\" + 0.016*\"product\" + 0.015*\"price\" + 0.014*\"red\" + 0.013*\"great\" + 0.012*\"store\" + 0.012*\"crust\" + 0.010*\"taste\" + 0.009*\"bob\"\n",
      "2021-08-24 16:17:23,532 : INFO : topic diff=0.607753, rho=0.189365\n",
      "2021-08-24 16:17:26,006 : INFO : -7.475 per-word bound, 177.9 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:26,073 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:26,096 : INFO : topic #3 (0.020): 0.048*\"oreo\" + 0.022*\"creme\" + 0.017*\"product\" + 0.016*\"mio\" + 0.013*\"flavor\" + 0.011*\"like\" + 0.008*\"taste\" + 0.008*\"buy\" + 0.007*\"use\" + 0.007*\"try\"\n",
      "2021-08-24 16:17:26,097 : INFO : topic #36 (0.020): 0.063*\"coffee\" + 0.048*\"vanilla\" + 0.025*\"flavor\" + 0.022*\"taste\" + 0.015*\"good\" + 0.014*\"like\" + 0.014*\"cup\" + 0.011*\"love\" + 0.011*\"starbucks\" + 0.009*\"great\"\n",
      "2021-08-24 16:17:26,099 : INFO : topic #40 (0.020): 0.028*\"flavor\" + 0.021*\"good\" + 0.017*\"taste\" + 0.015*\"almond\" + 0.014*\"like\" + 0.013*\"try\" + 0.012*\"use\" + 0.012*\"product\" + 0.009*\"fruit\" + 0.008*\"great\"\n",
      "2021-08-24 16:17:26,100 : INFO : topic #24 (0.020): 0.014*\"box\" + 0.012*\"like\" + 0.012*\"ring\" + 0.010*\"good\" + 0.010*\"little\" + 0.010*\"eat\" + 0.009*\"taste\" + 0.008*\"use\" + 0.008*\"pop\" + 0.008*\"think\"\n",
      "2021-08-24 16:17:26,101 : INFO : topic #31 (0.020): 0.051*\"chocolate\" + 0.032*\"cooky\" + 0.021*\"like\" + 0.020*\"taste\" + 0.019*\"cookie\" + 0.016*\"good\" + 0.013*\"eat\" + 0.011*\"sweet\" + 0.010*\"calorie\" + 0.010*\"snack\"\n",
      "2021-08-24 16:17:26,102 : INFO : topic diff=0.624268, rho=0.189365\n",
      "2021-08-24 16:17:27,164 : INFO : -7.410 per-word bound, 170.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:27,165 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:17:27,173 : INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:17:27,174 : INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:17:27,175 : INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:17:27,176 : INFO : PROGRESS: pass 4, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:17:27,177 : INFO : PROGRESS: pass 4, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:17:27,185 : INFO : PROGRESS: pass 4, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:17:27,186 : INFO : PROGRESS: pass 4, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:17:27,187 : INFO : PROGRESS: pass 4, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:17:27,188 : INFO : PROGRESS: pass 4, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:17:27,197 : INFO : PROGRESS: pass 4, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:17:27,198 : INFO : PROGRESS: pass 4, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:17:27,199 : INFO : PROGRESS: pass 4, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:17:27,209 : INFO : PROGRESS: pass 4, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:17:27,211 : INFO : PROGRESS: pass 4, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:17:27,213 : INFO : PROGRESS: pass 4, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:17:27,214 : INFO : PROGRESS: pass 4, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:17:27,216 : INFO : PROGRESS: pass 4, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:17:27,217 : INFO : PROGRESS: pass 4, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:17:27,230 : INFO : PROGRESS: pass 4, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:17:27,252 : INFO : PROGRESS: pass 4, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:17:27,281 : INFO : PROGRESS: pass 4, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:17:27,306 : INFO : PROGRESS: pass 4, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:17:27,333 : INFO : PROGRESS: pass 4, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:29,327 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:29,367 : INFO : topic #28 (0.020): 0.051*\"coffee\" + 0.039*\"cup\" + 0.021*\"flavor\" + 0.020*\"good\" + 0.017*\"taste\" + 0.017*\"like\" + 0.017*\"try\" + 0.013*\"use\" + 0.011*\"great\" + 0.008*\"hot\"\n",
      "2021-08-24 16:17:29,369 : INFO : topic #15 (0.020): 0.049*\"rice\" + 0.023*\"cook\" + 0.020*\"use\" + 0.020*\"noodle\" + 0.018*\"mix\" + 0.016*\"bread\" + 0.012*\"gluten\" + 0.011*\"like\" + 0.011*\"try\" + 0.010*\"brown\"\n",
      "2021-08-24 16:17:29,370 : INFO : topic #5 (0.020): 0.070*\"salt\" + 0.044*\"popcorn\" + 0.021*\"taste\" + 0.019*\"good\" + 0.017*\"like\" + 0.016*\"great\" + 0.015*\"use\" + 0.015*\"flavor\" + 0.012*\"pop\" + 0.012*\"love\"\n",
      "2021-08-24 16:17:29,372 : INFO : topic #33 (0.020): 0.028*\"coffee\" + 0.023*\"taste\" + 0.020*\"like\" + 0.014*\"flavor\" + 0.013*\"use\" + 0.012*\"try\" + 0.012*\"product\" + 0.010*\"amazon\" + 0.008*\"love\" + 0.008*\"buy\"\n",
      "2021-08-24 16:17:29,374 : INFO : topic #36 (0.020): 0.061*\"coffee\" + 0.052*\"vanilla\" + 0.025*\"flavor\" + 0.021*\"taste\" + 0.015*\"good\" + 0.014*\"like\" + 0.014*\"cup\" + 0.011*\"love\" + 0.010*\"starbucks\" + 0.010*\"bean\"\n",
      "2021-08-24 16:17:29,376 : INFO : topic diff=0.633223, rho=0.186058\n",
      "2021-08-24 16:17:32,523 : INFO : -7.416 per-word bound, 170.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:32,713 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:32,770 : INFO : topic #9 (0.020): 0.028*\"good\" + 0.012*\"price\" + 0.012*\"taste\" + 0.011*\"product\" + 0.010*\"use\" + 0.010*\"buy\" + 0.009*\"flavor\" + 0.009*\"bag\" + 0.008*\"like\" + 0.008*\"eat\"\n",
      "2021-08-24 16:17:32,773 : INFO : topic #18 (0.020): 0.029*\"chip\" + 0.020*\"good\" + 0.018*\"taste\" + 0.018*\"potato\" + 0.017*\"like\" + 0.015*\"use\" + 0.014*\"great\" + 0.013*\"flavor\" + 0.011*\"try\" + 0.011*\"chili\"\n",
      "2021-08-24 16:17:32,795 : INFO : topic #0 (0.020): 0.021*\"box\" + 0.020*\"good\" + 0.015*\"like\" + 0.013*\"taste\" + 0.012*\"great\" + 0.011*\"day\" + 0.009*\"product\" + 0.008*\"packet\" + 0.007*\"open\" + 0.007*\"amazon\"\n",
      "2021-08-24 16:17:32,809 : INFO : topic #21 (0.020): 0.127*\"tea\" + 0.024*\"taste\" + 0.024*\"green\" + 0.017*\"flavor\" + 0.016*\"drink\" + 0.015*\"bag\" + 0.013*\"like\" + 0.011*\"good\" + 0.009*\"use\" + 0.008*\"cup\"\n",
      "2021-08-24 16:17:32,845 : INFO : topic #2 (0.020): 0.064*\"tea\" + 0.042*\"flavor\" + 0.042*\"like\" + 0.021*\"taste\" + 0.014*\"good\" + 0.014*\"try\" + 0.011*\"smell\" + 0.010*\"bag\" + 0.010*\"love\" + 0.009*\"strong\"\n",
      "2021-08-24 16:17:32,873 : INFO : topic diff=0.630551, rho=0.186058\n",
      "2021-08-24 16:17:34,994 : INFO : -7.408 per-word bound, 169.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:35,050 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:35,073 : INFO : topic #37 (0.020): 0.019*\"like\" + 0.014*\"taste\" + 0.014*\"good\" + 0.012*\"clean\" + 0.011*\"mustard\" + 0.010*\"candy\" + 0.010*\"fruit\" + 0.010*\"pad\" + 0.009*\"little\" + 0.009*\"flavor\"\n",
      "2021-08-24 16:17:35,074 : INFO : topic #10 (0.020): 0.052*\"free\" + 0.050*\"gluten\" + 0.025*\"good\" + 0.023*\"pasta\" + 0.021*\"tuna\" + 0.019*\"bread\" + 0.015*\"great\" + 0.015*\"taste\" + 0.014*\"like\" + 0.013*\"buy\"\n",
      "2021-08-24 16:17:35,074 : INFO : topic #31 (0.020): 0.052*\"chocolate\" + 0.035*\"cooky\" + 0.022*\"like\" + 0.022*\"cookie\" + 0.020*\"taste\" + 0.016*\"good\" + 0.013*\"eat\" + 0.011*\"sweet\" + 0.010*\"calorie\" + 0.010*\"dark\"\n",
      "2021-08-24 16:17:35,075 : INFO : topic #9 (0.020): 0.028*\"good\" + 0.011*\"taste\" + 0.011*\"price\" + 0.011*\"product\" + 0.010*\"use\" + 0.009*\"buy\" + 0.009*\"bag\" + 0.008*\"flavor\" + 0.008*\"like\" + 0.008*\"eat\"\n",
      "2021-08-24 16:17:35,076 : INFO : topic #19 (0.020): 0.051*\"bar\" + 0.027*\"like\" + 0.027*\"snack\" + 0.025*\"peanut\" + 0.023*\"taste\" + 0.021*\"good\" + 0.021*\"flavor\" + 0.016*\"eat\" + 0.013*\"butter\" + 0.012*\"granola\"\n",
      "2021-08-24 16:17:35,077 : INFO : topic diff=0.638227, rho=0.186058\n",
      "2021-08-24 16:17:36,141 : INFO : -7.359 per-word bound, 164.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:36,143 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:17:36,158 : INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:17:36,160 : INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:17:36,163 : INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:17:36,182 : INFO : PROGRESS: pass 5, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:17:36,184 : INFO : PROGRESS: pass 5, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:17:36,187 : INFO : PROGRESS: pass 5, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:17:36,191 : INFO : PROGRESS: pass 5, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:17:36,192 : INFO : PROGRESS: pass 5, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:17:36,209 : INFO : PROGRESS: pass 5, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:17:36,213 : INFO : PROGRESS: pass 5, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:17:36,215 : INFO : PROGRESS: pass 5, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:17:36,216 : INFO : PROGRESS: pass 5, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:17:36,217 : INFO : PROGRESS: pass 5, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:17:36,233 : INFO : PROGRESS: pass 5, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:17:36,236 : INFO : PROGRESS: pass 5, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:17:36,240 : INFO : PROGRESS: pass 5, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:17:36,242 : INFO : PROGRESS: pass 5, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:17:36,245 : INFO : PROGRESS: pass 5, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:17:36,273 : INFO : PROGRESS: pass 5, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:17:36,300 : INFO : PROGRESS: pass 5, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:17:36,319 : INFO : PROGRESS: pass 5, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:17:36,356 : INFO : PROGRESS: pass 5, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:17:36,387 : INFO : PROGRESS: pass 5, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:38,628 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:38,666 : INFO : topic #25 (0.020): 0.030*\"vitamin\" + 0.025*\"juice\" + 0.016*\"mg\" + 0.015*\"flavor\" + 0.013*\"product\" + 0.011*\"calorie\" + 0.011*\"protein\" + 0.011*\"jamba\" + 0.011*\"ingredient\" + 0.011*\"sodium\"\n",
      "2021-08-24 16:17:38,667 : INFO : topic #44 (0.020): 0.051*\"chocolate\" + 0.026*\"gift\" + 0.023*\"like\" + 0.023*\"box\" + 0.014*\"basket\" + 0.013*\"candy\" + 0.012*\"wrap\" + 0.011*\"love\" + 0.011*\"bag\" + 0.010*\"caramel\"\n",
      "2021-08-24 16:17:38,669 : INFO : topic #8 (0.020): 0.028*\"soup\" + 0.022*\"jerky\" + 0.021*\"like\" + 0.021*\"flavor\" + 0.021*\"good\" + 0.019*\"noodle\" + 0.019*\"beef\" + 0.016*\"spicy\" + 0.015*\"taste\" + 0.012*\"product\"\n",
      "2021-08-24 16:17:38,670 : INFO : topic #17 (0.020): 0.054*\"chocolate\" + 0.025*\"candy\" + 0.023*\"bar\" + 0.019*\"caramel\" + 0.016*\"good\" + 0.015*\"dark\" + 0.012*\"flavor\" + 0.011*\"like\" + 0.011*\"piece\" + 0.010*\"taste\"\n",
      "2021-08-24 16:17:38,672 : INFO : topic #12 (0.020): 0.025*\"like\" + 0.018*\"fruit\" + 0.017*\"bean\" + 0.016*\"great\" + 0.013*\"taste\" + 0.013*\"oatmeal\" + 0.013*\"use\" + 0.012*\"buy\" + 0.011*\"try\" + 0.011*\"add\"\n",
      "2021-08-24 16:17:38,675 : INFO : topic diff=0.634969, rho=0.182919\n",
      "2021-08-24 16:17:42,315 : INFO : -7.363 per-word bound, 164.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:42,409 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:42,449 : INFO : topic #9 (0.020): 0.028*\"good\" + 0.011*\"taste\" + 0.011*\"price\" + 0.010*\"product\" + 0.010*\"buy\" + 0.009*\"use\" + 0.009*\"bag\" + 0.009*\"star\" + 0.008*\"licorice\" + 0.008*\"flavor\"\n",
      "2021-08-24 16:17:42,452 : INFO : topic #39 (0.020): 0.058*\"love\" + 0.052*\"great\" + 0.034*\"good\" + 0.029*\"taste\" + 0.021*\"like\" + 0.018*\"easy\" + 0.018*\"soup\" + 0.017*\"flavor\" + 0.017*\"product\" + 0.017*\"quick\"\n",
      "2021-08-24 16:17:42,472 : INFO : topic #7 (0.020): 0.045*\"price\" + 0.042*\"amazon\" + 0.034*\"good\" + 0.027*\"store\" + 0.020*\"buy\" + 0.020*\"purchase\" + 0.017*\"product\" + 0.015*\"love\" + 0.015*\"order\" + 0.014*\"great\"\n",
      "2021-08-24 16:17:42,480 : INFO : topic #6 (0.020): 0.050*\"cheese\" + 0.046*\"cracker\" + 0.032*\"product\" + 0.028*\"butter\" + 0.026*\"taste\" + 0.018*\"peanut\" + 0.015*\"like\" + 0.012*\"cheddar\" + 0.010*\"good\" + 0.008*\"spread\"\n",
      "2021-08-24 16:17:42,493 : INFO : topic #31 (0.020): 0.054*\"chocolate\" + 0.035*\"cooky\" + 0.022*\"like\" + 0.021*\"cookie\" + 0.020*\"taste\" + 0.016*\"good\" + 0.014*\"eat\" + 0.012*\"sweet\" + 0.011*\"calorie\" + 0.010*\"dark\"\n",
      "2021-08-24 16:17:42,497 : INFO : topic diff=0.624639, rho=0.182919\n",
      "2021-08-24 16:17:44,753 : INFO : -7.363 per-word bound, 164.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:44,813 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:44,835 : INFO : topic #27 (0.020): 0.038*\"cherry\" + 0.026*\"mix\" + 0.024*\"pancake\" + 0.023*\"like\" + 0.018*\"taste\" + 0.013*\"tart\" + 0.013*\"great\" + 0.012*\"waffle\" + 0.012*\"use\" + 0.010*\"pop\"\n",
      "2021-08-24 16:17:44,836 : INFO : topic #40 (0.020): 0.033*\"flavor\" + 0.033*\"almond\" + 0.019*\"good\" + 0.017*\"taste\" + 0.014*\"try\" + 0.014*\"like\" + 0.011*\"product\" + 0.011*\"fruit\" + 0.010*\"use\" + 0.008*\"great\"\n",
      "2021-08-24 16:17:44,837 : INFO : topic #48 (0.020): 0.029*\"taste\" + 0.028*\"like\" + 0.018*\"water\" + 0.014*\"product\" + 0.013*\"drink\" + 0.012*\"good\" + 0.011*\"use\" + 0.010*\"bottle\" + 0.010*\"flavor\" + 0.009*\"try\"\n",
      "2021-08-24 16:17:44,838 : INFO : topic #9 (0.020): 0.028*\"good\" + 0.011*\"taste\" + 0.011*\"product\" + 0.011*\"price\" + 0.009*\"bag\" + 0.009*\"use\" + 0.009*\"buy\" + 0.009*\"star\" + 0.008*\"licorice\" + 0.008*\"flavor\"\n",
      "2021-08-24 16:17:44,839 : INFO : topic #10 (0.020): 0.065*\"free\" + 0.061*\"gluten\" + 0.025*\"good\" + 0.021*\"pasta\" + 0.021*\"tuna\" + 0.020*\"bread\" + 0.015*\"taste\" + 0.015*\"great\" + 0.015*\"like\" + 0.014*\"product\"\n",
      "2021-08-24 16:17:44,840 : INFO : topic diff=0.622294, rho=0.182919\n",
      "2021-08-24 16:17:45,815 : INFO : -7.320 per-word bound, 159.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:45,816 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:17:45,824 : INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:17:45,825 : INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:17:45,827 : INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:17:45,828 : INFO : PROGRESS: pass 6, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:17:45,838 : INFO : PROGRESS: pass 6, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:17:45,840 : INFO : PROGRESS: pass 6, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:17:45,841 : INFO : PROGRESS: pass 6, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:17:45,843 : INFO : PROGRESS: pass 6, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:17:45,853 : INFO : PROGRESS: pass 6, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:17:45,855 : INFO : PROGRESS: pass 6, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:17:45,857 : INFO : PROGRESS: pass 6, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:17:45,859 : INFO : PROGRESS: pass 6, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:17:45,860 : INFO : PROGRESS: pass 6, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:17:45,876 : INFO : PROGRESS: pass 6, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:17:45,877 : INFO : PROGRESS: pass 6, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:17:45,878 : INFO : PROGRESS: pass 6, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:17:45,879 : INFO : PROGRESS: pass 6, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:17:45,896 : INFO : PROGRESS: pass 6, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:17:45,899 : INFO : PROGRESS: pass 6, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:17:45,920 : INFO : PROGRESS: pass 6, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:17:45,946 : INFO : PROGRESS: pass 6, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:17:45,971 : INFO : PROGRESS: pass 6, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:17:45,990 : INFO : PROGRESS: pass 6, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:47,918 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:47,956 : INFO : topic #48 (0.020): 0.029*\"taste\" + 0.028*\"like\" + 0.020*\"water\" + 0.015*\"product\" + 0.013*\"drink\" + 0.012*\"good\" + 0.011*\"bottle\" + 0.011*\"use\" + 0.010*\"flavor\" + 0.009*\"try\"\n",
      "2021-08-24 16:17:47,957 : INFO : topic #17 (0.020): 0.070*\"chocolate\" + 0.028*\"candy\" + 0.025*\"bar\" + 0.022*\"caramel\" + 0.021*\"dark\" + 0.016*\"good\" + 0.012*\"flavor\" + 0.012*\"taste\" + 0.011*\"like\" + 0.011*\"piece\"\n",
      "2021-08-24 16:17:47,958 : INFO : topic #29 (0.020): 0.017*\"buy\" + 0.016*\"good\" + 0.016*\"product\" + 0.015*\"amazon\" + 0.012*\"order\" + 0.011*\"price\" + 0.011*\"like\" + 0.009*\"use\" + 0.009*\"store\" + 0.008*\"year\"\n",
      "2021-08-24 16:17:47,960 : INFO : topic #14 (0.020): 0.047*\"chocolate\" + 0.029*\"taste\" + 0.028*\"cream\" + 0.026*\"like\" + 0.026*\"good\" + 0.025*\"flavor\" + 0.021*\"ice\" + 0.013*\"use\" + 0.012*\"milk\" + 0.012*\"sweet\"\n",
      "2021-08-24 16:17:47,962 : INFO : topic #11 (0.020): 0.056*\"hot\" + 0.036*\"pepper\" + 0.036*\"sauce\" + 0.020*\"heat\" + 0.016*\"use\" + 0.015*\"taste\" + 0.013*\"product\" + 0.013*\"flavor\" + 0.011*\"like\" + 0.010*\"bottle\"\n",
      "2021-08-24 16:17:47,964 : INFO : topic diff=0.608254, rho=0.179934\n",
      "2021-08-24 16:17:50,729 : INFO : -7.326 per-word bound, 160.4 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:50,845 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:50,890 : INFO : topic #45 (0.020): 0.031*\"snack\" + 0.031*\"pasta\" + 0.018*\"spaghetti\" + 0.016*\"barilla\" + 0.016*\"good\" + 0.016*\"like\" + 0.013*\"maple\" + 0.013*\"eat\" + 0.012*\"love\" + 0.012*\"great\"\n",
      "2021-08-24 16:17:50,893 : INFO : topic #20 (0.020): 0.114*\"milk\" + 0.017*\"use\" + 0.015*\"taste\" + 0.012*\"like\" + 0.011*\"powder\" + 0.011*\"sugar\" + 0.009*\"add\" + 0.009*\"water\" + 0.008*\"little\" + 0.008*\"drink\"\n",
      "2021-08-24 16:17:50,905 : INFO : topic #9 (0.020): 0.027*\"good\" + 0.014*\"licorice\" + 0.011*\"taste\" + 0.010*\"product\" + 0.010*\"price\" + 0.010*\"star\" + 0.009*\"bag\" + 0.009*\"buy\" + 0.009*\"use\" + 0.008*\"flavor\"\n",
      "2021-08-24 16:17:50,926 : INFO : topic #1 (0.020): 0.038*\"add\" + 0.020*\"water\" + 0.018*\"minute\" + 0.016*\"chicken\" + 0.015*\"cook\" + 0.014*\"soup\" + 0.012*\"microwave\" + 0.012*\"pasta\" + 0.011*\"use\" + 0.011*\"stir\"\n",
      "2021-08-24 16:17:50,932 : INFO : topic #29 (0.020): 0.016*\"buy\" + 0.016*\"amazon\" + 0.016*\"product\" + 0.016*\"good\" + 0.012*\"order\" + 0.011*\"price\" + 0.011*\"like\" + 0.009*\"date\" + 0.009*\"use\" + 0.009*\"year\"\n",
      "2021-08-24 16:17:50,937 : INFO : topic diff=0.590648, rho=0.179934\n",
      "2021-08-24 16:17:52,954 : INFO : -7.329 per-word bound, 160.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:53,034 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:53,057 : INFO : topic #9 (0.020): 0.027*\"good\" + 0.013*\"licorice\" + 0.011*\"taste\" + 0.010*\"product\" + 0.010*\"star\" + 0.010*\"price\" + 0.010*\"bag\" + 0.009*\"buy\" + 0.009*\"use\" + 0.008*\"eat\"\n",
      "2021-08-24 16:17:53,058 : INFO : topic #1 (0.020): 0.038*\"add\" + 0.020*\"water\" + 0.019*\"minute\" + 0.017*\"chicken\" + 0.015*\"cook\" + 0.013*\"soup\" + 0.012*\"microwave\" + 0.012*\"pasta\" + 0.011*\"stir\" + 0.011*\"use\"\n",
      "2021-08-24 16:17:53,059 : INFO : topic #38 (0.020): 0.031*\"buy\" + 0.017*\"bag\" + 0.016*\"jar\" + 0.015*\"good\" + 0.014*\"ahoy\" + 0.014*\"container\" + 0.014*\"use\" + 0.012*\"package\" + 0.012*\"store\" + 0.012*\"open\"\n",
      "2021-08-24 16:17:53,060 : INFO : topic #35 (0.020): 0.037*\"cake\" + 0.023*\"red\" + 0.019*\"crust\" + 0.018*\"good\" + 0.018*\"pizza\" + 0.017*\"product\" + 0.016*\"bob\" + 0.012*\"mix\" + 0.012*\"price\" + 0.011*\"great\"\n",
      "2021-08-24 16:17:53,061 : INFO : topic #26 (0.020): 0.032*\"olive\" + 0.026*\"good\" + 0.021*\"salad\" + 0.019*\"cheese\" + 0.018*\"flavor\" + 0.018*\"like\" + 0.017*\"use\" + 0.017*\"mix\" + 0.016*\"oil\" + 0.015*\"garlic\"\n",
      "2021-08-24 16:17:53,062 : INFO : topic diff=0.582306, rho=0.179934\n",
      "2021-08-24 16:17:54,068 : INFO : -7.292 per-word bound, 156.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:54,069 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:17:54,077 : INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:17:54,078 : INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:17:54,079 : INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:17:54,080 : INFO : PROGRESS: pass 7, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:17:54,081 : INFO : PROGRESS: pass 7, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:17:54,082 : INFO : PROGRESS: pass 7, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:17:54,094 : INFO : PROGRESS: pass 7, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:17:54,096 : INFO : PROGRESS: pass 7, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:17:54,098 : INFO : PROGRESS: pass 7, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:17:54,099 : INFO : PROGRESS: pass 7, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:17:54,100 : INFO : PROGRESS: pass 7, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:17:54,110 : INFO : PROGRESS: pass 7, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:17:54,111 : INFO : PROGRESS: pass 7, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:17:54,112 : INFO : PROGRESS: pass 7, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:17:54,114 : INFO : PROGRESS: pass 7, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:17:54,124 : INFO : PROGRESS: pass 7, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:17:54,128 : INFO : PROGRESS: pass 7, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:17:54,130 : INFO : PROGRESS: pass 7, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:17:54,143 : INFO : PROGRESS: pass 7, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:17:54,162 : INFO : PROGRESS: pass 7, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:17:54,187 : INFO : PROGRESS: pass 7, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:17:54,224 : INFO : PROGRESS: pass 7, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:17:54,262 : INFO : PROGRESS: pass 7, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:17:56,405 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:56,442 : INFO : topic #40 (0.020): 0.044*\"almond\" + 0.037*\"flavor\" + 0.019*\"good\" + 0.017*\"taste\" + 0.014*\"try\" + 0.013*\"like\" + 0.011*\"fruit\" + 0.010*\"product\" + 0.009*\"use\" + 0.009*\"lemon\"\n",
      "2021-08-24 16:17:56,444 : INFO : topic #2 (0.020): 0.067*\"tea\" + 0.050*\"flavor\" + 0.037*\"like\" + 0.022*\"taste\" + 0.014*\"try\" + 0.013*\"smell\" + 0.013*\"good\" + 0.013*\"bag\" + 0.012*\"blackberry\" + 0.011*\"orange\"\n",
      "2021-08-24 16:17:56,445 : INFO : topic #39 (0.020): 0.071*\"love\" + 0.064*\"great\" + 0.037*\"good\" + 0.033*\"taste\" + 0.022*\"easy\" + 0.022*\"like\" + 0.019*\"quick\" + 0.018*\"product\" + 0.018*\"flavor\" + 0.015*\"soup\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:17:56,447 : INFO : topic #5 (0.020): 0.094*\"salt\" + 0.053*\"popcorn\" + 0.022*\"taste\" + 0.020*\"good\" + 0.017*\"pop\" + 0.017*\"like\" + 0.016*\"use\" + 0.016*\"flavor\" + 0.015*\"sea\" + 0.014*\"great\"\n",
      "2021-08-24 16:17:56,448 : INFO : topic #10 (0.020): 0.080*\"free\" + 0.074*\"gluten\" + 0.025*\"good\" + 0.024*\"bread\" + 0.020*\"tuna\" + 0.017*\"pasta\" + 0.016*\"taste\" + 0.016*\"like\" + 0.015*\"product\" + 0.015*\"eat\"\n",
      "2021-08-24 16:17:56,451 : INFO : topic diff=0.560817, rho=0.177090\n",
      "2021-08-24 16:17:59,482 : INFO : -7.298 per-word bound, 157.4 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:17:59,601 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:17:59,649 : INFO : topic #34 (0.020): 0.032*\"fat\" + 0.023*\"calorie\" + 0.019*\"high\" + 0.019*\"protein\" + 0.017*\"seed\" + 0.014*\"low\" + 0.014*\"consume\" + 0.014*\"food\" + 0.011*\"nutrient\" + 0.011*\"diet\"\n",
      "2021-08-24 16:17:59,654 : INFO : topic #43 (0.020): 0.055*\"seed\" + 0.022*\"product\" + 0.014*\"eat\" + 0.014*\"raw\" + 0.014*\"nut\" + 0.011*\"chia\" + 0.011*\"bag\" + 0.011*\"add\" + 0.011*\"salmon\" + 0.011*\"fresh\"\n",
      "2021-08-24 16:17:59,658 : INFO : topic #42 (0.020): 0.084*\"oil\" + 0.068*\"coconut\" + 0.021*\"use\" + 0.018*\"fat\" + 0.012*\"taste\" + 0.011*\"water\" + 0.009*\"like\" + 0.008*\"natural\" + 0.008*\"flavor\" + 0.008*\"organic\"\n",
      "2021-08-24 16:17:59,671 : INFO : topic #10 (0.020): 0.082*\"free\" + 0.074*\"gluten\" + 0.025*\"good\" + 0.024*\"bread\" + 0.023*\"tuna\" + 0.016*\"taste\" + 0.016*\"pasta\" + 0.016*\"like\" + 0.015*\"eat\" + 0.015*\"product\"\n",
      "2021-08-24 16:17:59,677 : INFO : topic #5 (0.020): 0.097*\"salt\" + 0.051*\"popcorn\" + 0.022*\"taste\" + 0.020*\"good\" + 0.017*\"pop\" + 0.017*\"like\" + 0.016*\"use\" + 0.016*\"sea\" + 0.016*\"flavor\" + 0.014*\"great\"\n",
      "2021-08-24 16:17:59,692 : INFO : topic diff=0.539283, rho=0.177090\n",
      "2021-08-24 16:18:01,650 : INFO : -7.303 per-word bound, 157.9 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:01,715 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:01,738 : INFO : topic #40 (0.020): 0.053*\"almond\" + 0.039*\"flavor\" + 0.018*\"good\" + 0.017*\"taste\" + 0.014*\"try\" + 0.014*\"like\" + 0.010*\"fruit\" + 0.010*\"lemon\" + 0.010*\"product\" + 0.008*\"use\"\n",
      "2021-08-24 16:18:01,739 : INFO : topic #13 (0.020): 0.045*\"cereal\" + 0.022*\"like\" + 0.021*\"taste\" + 0.016*\"sugar\" + 0.016*\"good\" + 0.015*\"eat\" + 0.014*\"cinnamon\" + 0.014*\"fiber\" + 0.012*\"flavor\" + 0.011*\"sweet\"\n",
      "2021-08-24 16:18:01,740 : INFO : topic #42 (0.020): 0.087*\"oil\" + 0.071*\"coconut\" + 0.023*\"use\" + 0.018*\"fat\" + 0.011*\"taste\" + 0.010*\"water\" + 0.009*\"like\" + 0.008*\"palm\" + 0.008*\"natural\" + 0.008*\"product\"\n",
      "2021-08-24 16:18:01,740 : INFO : topic #27 (0.020): 0.042*\"cherry\" + 0.036*\"mix\" + 0.031*\"pancake\" + 0.023*\"like\" + 0.018*\"taste\" + 0.016*\"tart\" + 0.014*\"waffle\" + 0.013*\"muffin\" + 0.012*\"great\" + 0.012*\"use\"\n",
      "2021-08-24 16:18:01,742 : INFO : topic #17 (0.020): 0.097*\"chocolate\" + 0.029*\"dark\" + 0.028*\"candy\" + 0.027*\"bar\" + 0.026*\"caramel\" + 0.016*\"good\" + 0.014*\"taste\" + 0.013*\"like\" + 0.012*\"piece\" + 0.012*\"flavor\"\n",
      "2021-08-24 16:18:01,743 : INFO : topic diff=0.527015, rho=0.177090\n",
      "2021-08-24 16:18:02,713 : INFO : -7.269 per-word bound, 154.2 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:02,715 : INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:02,724 : INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:02,726 : INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:02,727 : INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:02,727 : INFO : PROGRESS: pass 8, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:02,739 : INFO : PROGRESS: pass 8, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:02,739 : INFO : PROGRESS: pass 8, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:02,741 : INFO : PROGRESS: pass 8, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:18:02,741 : INFO : PROGRESS: pass 8, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:02,742 : INFO : PROGRESS: pass 8, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:02,753 : INFO : PROGRESS: pass 8, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:02,754 : INFO : PROGRESS: pass 8, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:02,755 : INFO : PROGRESS: pass 8, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:02,756 : INFO : PROGRESS: pass 8, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:02,757 : INFO : PROGRESS: pass 8, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:02,758 : INFO : PROGRESS: pass 8, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:18:02,771 : INFO : PROGRESS: pass 8, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:02,772 : INFO : PROGRESS: pass 8, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:02,774 : INFO : PROGRESS: pass 8, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:02,775 : INFO : PROGRESS: pass 8, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:02,794 : INFO : PROGRESS: pass 8, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:02,832 : INFO : PROGRESS: pass 8, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:02,858 : INFO : PROGRESS: pass 8, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:02,906 : INFO : PROGRESS: pass 8, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:18:04,699 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:04,747 : INFO : topic #36 (0.020): 0.080*\"vanilla\" + 0.072*\"coffee\" + 0.040*\"flavor\" + 0.024*\"taste\" + 0.019*\"starbucks\" + 0.016*\"bean\" + 0.016*\"like\" + 0.014*\"flavored\" + 0.013*\"good\" + 0.011*\"smell\"\n",
      "2021-08-24 16:18:04,754 : INFO : topic #32 (0.020): 0.111*\"organic\" + 0.024*\"product\" + 0.023*\"use\" + 0.022*\"food\" + 0.016*\"buy\" + 0.016*\"company\" + 0.015*\"spice\" + 0.012*\"love\" + 0.011*\"great\" + 0.009*\"brand\"\n",
      "2021-08-24 16:18:04,756 : INFO : topic #25 (0.020): 0.030*\"vitamin\" + 0.024*\"juice\" + 0.021*\"mg\" + 0.017*\"sodium\" + 0.017*\"calorie\" + 0.016*\"gram\" + 0.016*\"ingredient\" + 0.015*\"contain\" + 0.014*\"sugar\" + 0.013*\"flavor\"\n",
      "2021-08-24 16:18:04,757 : INFO : topic #24 (0.020): 0.017*\"kid\" + 0.015*\"eat\" + 0.013*\"little\" + 0.013*\"box\" + 0.013*\"like\" + 0.012*\"pop\" + 0.011*\"old\" + 0.011*\"ring\" + 0.011*\"child\" + 0.010*\"think\"\n",
      "2021-08-24 16:18:04,759 : INFO : topic #15 (0.020): 0.079*\"rice\" + 0.034*\"cook\" + 0.019*\"use\" + 0.019*\"noodle\" + 0.018*\"brown\" + 0.014*\"mix\" + 0.013*\"like\" + 0.013*\"try\" + 0.011*\"bread\" + 0.010*\"oat\"\n",
      "2021-08-24 16:18:04,760 : INFO : topic diff=0.501948, rho=0.174376\n",
      "2021-08-24 16:18:07,283 : INFO : -7.277 per-word bound, 155.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:07,396 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:07,444 : INFO : topic #11 (0.020): 0.073*\"hot\" + 0.039*\"pepper\" + 0.039*\"sauce\" + 0.024*\"heat\" + 0.016*\"use\" + 0.013*\"flavor\" + 0.013*\"taste\" + 0.011*\"product\" + 0.011*\"like\" + 0.010*\"bottle\"\n",
      "2021-08-24 16:18:07,452 : INFO : topic #25 (0.020): 0.029*\"vitamin\" + 0.025*\"juice\" + 0.020*\"mg\" + 0.017*\"calorie\" + 0.017*\"gram\" + 0.017*\"sodium\" + 0.016*\"ingredient\" + 0.015*\"contain\" + 0.015*\"sugar\" + 0.013*\"protein\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:18:07,481 : INFO : topic #1 (0.020): 0.042*\"add\" + 0.024*\"water\" + 0.020*\"minute\" + 0.017*\"chicken\" + 0.016*\"cook\" + 0.014*\"microwave\" + 0.014*\"soup\" + 0.012*\"stir\" + 0.012*\"use\" + 0.011*\"meal\"\n",
      "2021-08-24 16:18:07,491 : INFO : topic #38 (0.020): 0.031*\"buy\" + 0.026*\"bag\" + 0.019*\"jar\" + 0.018*\"container\" + 0.015*\"open\" + 0.015*\"good\" + 0.015*\"use\" + 0.014*\"package\" + 0.013*\"plastic\" + 0.012*\"store\"\n",
      "2021-08-24 16:18:07,516 : INFO : topic #36 (0.020): 0.080*\"coffee\" + 0.078*\"vanilla\" + 0.043*\"flavor\" + 0.025*\"taste\" + 0.022*\"starbucks\" + 0.016*\"like\" + 0.015*\"flavored\" + 0.014*\"bean\" + 0.013*\"good\" + 0.011*\"smell\"\n",
      "2021-08-24 16:18:07,533 : INFO : topic diff=0.479213, rho=0.174376\n",
      "2021-08-24 16:18:09,420 : INFO : -7.282 per-word bound, 155.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:09,499 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:09,523 : INFO : topic #33 (0.020): 0.027*\"taste\" + 0.022*\"review\" + 0.020*\"like\" + 0.016*\"try\" + 0.016*\"product\" + 0.013*\"coffee\" + 0.012*\"use\" + 0.010*\"flavor\" + 0.008*\"amazon\" + 0.008*\"buy\"\n",
      "2021-08-24 16:18:09,525 : INFO : topic #40 (0.020): 0.060*\"almond\" + 0.041*\"flavor\" + 0.017*\"good\" + 0.017*\"taste\" + 0.014*\"try\" + 0.014*\"like\" + 0.012*\"lemon\" + 0.010*\"nut\" + 0.010*\"fruit\" + 0.009*\"product\"\n",
      "2021-08-24 16:18:09,526 : INFO : topic #11 (0.020): 0.074*\"hot\" + 0.039*\"pepper\" + 0.037*\"sauce\" + 0.024*\"heat\" + 0.016*\"use\" + 0.014*\"flavor\" + 0.013*\"taste\" + 0.011*\"like\" + 0.011*\"product\" + 0.010*\"bottle\"\n",
      "2021-08-24 16:18:09,527 : INFO : topic #27 (0.020): 0.044*\"cherry\" + 0.041*\"mix\" + 0.034*\"pancake\" + 0.023*\"like\" + 0.018*\"taste\" + 0.017*\"tart\" + 0.015*\"waffle\" + 0.014*\"muffin\" + 0.012*\"pumpkin\" + 0.012*\"pie\"\n",
      "2021-08-24 16:18:09,528 : INFO : topic #42 (0.020): 0.094*\"oil\" + 0.076*\"coconut\" + 0.025*\"use\" + 0.018*\"fat\" + 0.011*\"taste\" + 0.009*\"water\" + 0.009*\"palm\" + 0.008*\"like\" + 0.008*\"skin\" + 0.008*\"product\"\n",
      "2021-08-24 16:18:09,529 : INFO : topic diff=0.465859, rho=0.174376\n",
      "2021-08-24 16:18:10,525 : INFO : -7.250 per-word bound, 152.3 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:10,526 : INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:10,535 : INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:10,536 : INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:10,537 : INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:10,538 : INFO : PROGRESS: pass 9, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:10,539 : INFO : PROGRESS: pass 9, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:10,549 : INFO : PROGRESS: pass 9, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:10,550 : INFO : PROGRESS: pass 9, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:18:10,551 : INFO : PROGRESS: pass 9, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:10,552 : INFO : PROGRESS: pass 9, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:10,553 : INFO : PROGRESS: pass 9, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:10,565 : INFO : PROGRESS: pass 9, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:10,566 : INFO : PROGRESS: pass 9, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:10,567 : INFO : PROGRESS: pass 9, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:10,568 : INFO : PROGRESS: pass 9, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:10,569 : INFO : PROGRESS: pass 9, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:18:10,582 : INFO : PROGRESS: pass 9, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:10,584 : INFO : PROGRESS: pass 9, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:10,585 : INFO : PROGRESS: pass 9, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:10,601 : INFO : PROGRESS: pass 9, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:10,623 : INFO : PROGRESS: pass 9, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:10,645 : INFO : PROGRESS: pass 9, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:10,681 : INFO : PROGRESS: pass 9, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:10,711 : INFO : PROGRESS: pass 9, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:18:12,737 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:12,777 : INFO : topic #37 (0.020): 0.021*\"clean\" + 0.019*\"like\" + 0.014*\"mustard\" + 0.012*\"sardine\" + 0.012*\"good\" + 0.011*\"bear\" + 0.011*\"taste\" + 0.011*\"pad\" + 0.009*\"candy\" + 0.009*\"gummy\"\n",
      "2021-08-24 16:18:12,778 : INFO : topic #12 (0.020): 0.045*\"fruit\" + 0.035*\"oatmeal\" + 0.033*\"bean\" + 0.024*\"like\" + 0.017*\"dry\" + 0.016*\"dried\" + 0.014*\"great\" + 0.012*\"cranberry\" + 0.012*\"add\" + 0.012*\"taste\"\n",
      "2021-08-24 16:18:12,780 : INFO : topic #7 (0.020): 0.058*\"price\" + 0.044*\"amazon\" + 0.037*\"store\" + 0.035*\"good\" + 0.029*\"buy\" + 0.019*\"great\" + 0.019*\"purchase\" + 0.017*\"product\" + 0.017*\"order\" + 0.017*\"grocery\"\n",
      "2021-08-24 16:18:12,782 : INFO : topic #6 (0.020): 0.071*\"cheese\" + 0.064*\"cracker\" + 0.038*\"butter\" + 0.028*\"taste\" + 0.027*\"peanut\" + 0.026*\"product\" + 0.019*\"like\" + 0.015*\"cheddar\" + 0.011*\"mac\" + 0.011*\"good\"\n",
      "2021-08-24 16:18:12,783 : INFO : topic #9 (0.020): 0.029*\"licorice\" + 0.027*\"good\" + 0.013*\"star\" + 0.010*\"taste\" + 0.010*\"product\" + 0.009*\"bag\" + 0.008*\"buy\" + 0.008*\"clam\" + 0.008*\"price\" + 0.008*\"use\"\n",
      "2021-08-24 16:18:12,786 : INFO : topic diff=0.441110, rho=0.171784\n",
      "2021-08-24 16:18:15,552 : INFO : -7.259 per-word bound, 153.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:15,682 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:15,730 : INFO : topic #26 (0.020): 0.039*\"olive\" + 0.030*\"salad\" + 0.023*\"good\" + 0.021*\"use\" + 0.020*\"garlic\" + 0.020*\"oil\" + 0.019*\"flavor\" + 0.018*\"mix\" + 0.016*\"cheese\" + 0.016*\"like\"\n",
      "2021-08-24 16:18:15,733 : INFO : topic #32 (0.020): 0.130*\"organic\" + 0.025*\"product\" + 0.023*\"food\" + 0.023*\"use\" + 0.017*\"company\" + 0.016*\"spice\" + 0.015*\"buy\" + 0.011*\"love\" + 0.010*\"brand\" + 0.010*\"great\"\n",
      "2021-08-24 16:18:15,753 : INFO : topic #34 (0.020): 0.035*\"fat\" + 0.025*\"calorie\" + 0.021*\"high\" + 0.021*\"protein\" + 0.017*\"low\" + 0.016*\"seed\" + 0.015*\"consume\" + 0.015*\"food\" + 0.013*\"diet\" + 0.012*\"nutrient\"\n",
      "2021-08-24 16:18:15,772 : INFO : topic #40 (0.020): 0.069*\"almond\" + 0.040*\"flavor\" + 0.017*\"good\" + 0.017*\"taste\" + 0.014*\"try\" + 0.014*\"like\" + 0.014*\"nut\" + 0.012*\"lemon\" + 0.009*\"product\" + 0.009*\"fruit\"\n",
      "2021-08-24 16:18:15,774 : INFO : topic #0 (0.020): 0.042*\"box\" + 0.018*\"day\" + 0.018*\"good\" + 0.015*\"open\" + 0.013*\"packet\" + 0.012*\"time\" + 0.011*\"like\" + 0.010*\"arrive\" + 0.009*\"product\" + 0.008*\"taste\"\n",
      "2021-08-24 16:18:15,791 : INFO : topic diff=0.418981, rho=0.171784\n",
      "2021-08-24 16:18:17,651 : INFO : -7.264 per-word bound, 153.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:17,717 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:17,739 : INFO : topic #35 (0.020): 0.048*\"cake\" + 0.035*\"red\" + 0.026*\"pizza\" + 0.025*\"crust\" + 0.022*\"bob\" + 0.018*\"good\" + 0.016*\"product\" + 0.014*\"mix\" + 0.010*\"great\" + 0.009*\"dough\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:18:17,740 : INFO : topic #40 (0.020): 0.066*\"almond\" + 0.043*\"flavor\" + 0.017*\"taste\" + 0.017*\"good\" + 0.014*\"try\" + 0.014*\"like\" + 0.013*\"lemon\" + 0.012*\"nut\" + 0.009*\"product\" + 0.009*\"fruit\"\n",
      "2021-08-24 16:18:17,741 : INFO : topic #27 (0.020): 0.046*\"cherry\" + 0.046*\"mix\" + 0.036*\"pancake\" + 0.024*\"like\" + 0.018*\"tart\" + 0.017*\"taste\" + 0.015*\"muffin\" + 0.015*\"waffle\" + 0.014*\"pumpkin\" + 0.012*\"pie\"\n",
      "2021-08-24 16:18:17,742 : INFO : topic #32 (0.020): 0.133*\"organic\" + 0.025*\"product\" + 0.024*\"food\" + 0.022*\"use\" + 0.018*\"company\" + 0.016*\"spice\" + 0.015*\"buy\" + 0.010*\"love\" + 0.010*\"brand\" + 0.010*\"great\"\n",
      "2021-08-24 16:18:17,743 : INFO : topic #12 (0.020): 0.050*\"fruit\" + 0.042*\"oatmeal\" + 0.030*\"bean\" + 0.024*\"like\" + 0.018*\"dry\" + 0.017*\"dried\" + 0.013*\"cranberry\" + 0.013*\"great\" + 0.012*\"add\" + 0.012*\"taste\"\n",
      "2021-08-24 16:18:17,744 : INFO : topic diff=0.406959, rho=0.171784\n",
      "2021-08-24 16:18:18,709 : INFO : -7.237 per-word bound, 150.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:18,710 : INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:18,719 : INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:18,720 : INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:18,722 : INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:18,723 : INFO : PROGRESS: pass 10, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:18,732 : INFO : PROGRESS: pass 10, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:18,733 : INFO : PROGRESS: pass 10, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:18,735 : INFO : PROGRESS: pass 10, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:18:18,743 : INFO : PROGRESS: pass 10, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:18,746 : INFO : PROGRESS: pass 10, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:18,747 : INFO : PROGRESS: pass 10, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:18,748 : INFO : PROGRESS: pass 10, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:18,749 : INFO : PROGRESS: pass 10, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:18,761 : INFO : PROGRESS: pass 10, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:18,763 : INFO : PROGRESS: pass 10, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:18,764 : INFO : PROGRESS: pass 10, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:18:18,765 : INFO : PROGRESS: pass 10, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:18,766 : INFO : PROGRESS: pass 10, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:18,781 : INFO : PROGRESS: pass 10, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:18,782 : INFO : PROGRESS: pass 10, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:18,786 : INFO : PROGRESS: pass 10, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:18,827 : INFO : PROGRESS: pass 10, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:18,858 : INFO : PROGRESS: pass 10, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:18,881 : INFO : PROGRESS: pass 10, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:18:21,277 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:21,332 : INFO : topic #40 (0.020): 0.065*\"almond\" + 0.044*\"flavor\" + 0.017*\"good\" + 0.017*\"taste\" + 0.014*\"try\" + 0.014*\"lemon\" + 0.014*\"like\" + 0.012*\"nut\" + 0.009*\"fruit\" + 0.009*\"product\"\n",
      "2021-08-24 16:18:21,334 : INFO : topic #28 (0.020): 0.065*\"cup\" + 0.062*\"coffee\" + 0.018*\"flavor\" + 0.018*\"like\" + 0.017*\"good\" + 0.017*\"taste\" + 0.015*\"try\" + 0.014*\"instant\" + 0.014*\"use\" + 0.013*\"hot\"\n",
      "2021-08-24 16:18:21,336 : INFO : topic #43 (0.020): 0.065*\"seed\" + 0.020*\"product\" + 0.018*\"raw\" + 0.016*\"eat\" + 0.016*\"nut\" + 0.015*\"chia\" + 0.014*\"salmon\" + 0.013*\"add\" + 0.012*\"fresh\" + 0.011*\"good\"\n",
      "2021-08-24 16:18:21,338 : INFO : topic #37 (0.020): 0.022*\"clean\" + 0.019*\"like\" + 0.015*\"mustard\" + 0.013*\"sardine\" + 0.013*\"bear\" + 0.012*\"good\" + 0.011*\"pad\" + 0.010*\"taste\" + 0.010*\"gummy\" + 0.009*\"use\"\n",
      "2021-08-24 16:18:21,339 : INFO : topic #11 (0.020): 0.084*\"hot\" + 0.043*\"pepper\" + 0.042*\"sauce\" + 0.027*\"heat\" + 0.016*\"use\" + 0.014*\"flavor\" + 0.012*\"taste\" + 0.011*\"like\" + 0.010*\"bottle\" + 0.010*\"tabasco\"\n",
      "2021-08-24 16:18:21,341 : INFO : topic diff=0.383986, rho=0.169304\n",
      "2021-08-24 16:18:24,917 : INFO : -7.244 per-word bound, 151.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:25,576 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:25,639 : INFO : topic #46 (0.020): 0.032*\"product\" + 0.022*\"ingredient\" + 0.018*\"flavor\" + 0.017*\"like\" + 0.011*\"taste\" + 0.011*\"high\" + 0.009*\"list\" + 0.009*\"good\" + 0.009*\"natural\" + 0.008*\"syrup\"\n",
      "2021-08-24 16:18:25,641 : INFO : topic #11 (0.020): 0.084*\"hot\" + 0.042*\"pepper\" + 0.041*\"sauce\" + 0.027*\"heat\" + 0.016*\"use\" + 0.013*\"flavor\" + 0.012*\"taste\" + 0.011*\"like\" + 0.010*\"bottle\" + 0.010*\"tabasco\"\n",
      "2021-08-24 16:18:25,644 : INFO : topic #9 (0.020): 0.032*\"licorice\" + 0.026*\"good\" + 0.015*\"star\" + 0.009*\"taste\" + 0.009*\"product\" + 0.008*\"buy\" + 0.008*\"clam\" + 0.008*\"bag\" + 0.007*\"know\" + 0.007*\"use\"\n",
      "2021-08-24 16:18:25,648 : INFO : topic #22 (0.020): 0.123*\"coffee\" + 0.026*\"like\" + 0.024*\"cup\" + 0.020*\"roast\" + 0.019*\"flavor\" + 0.019*\"taste\" + 0.017*\"blend\" + 0.017*\"good\" + 0.015*\"strong\" + 0.012*\"bold\"\n",
      "2021-08-24 16:18:25,650 : INFO : topic #18 (0.020): 0.054*\"chip\" + 0.028*\"potato\" + 0.022*\"like\" + 0.020*\"good\" + 0.019*\"taste\" + 0.017*\"flavor\" + 0.015*\"chili\" + 0.013*\"use\" + 0.012*\"try\" + 0.011*\"food\"\n",
      "2021-08-24 16:18:25,654 : INFO : topic diff=0.363630, rho=0.169304\n",
      "2021-08-24 16:18:27,708 : INFO : -7.251 per-word bound, 152.3 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:27,813 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:27,845 : INFO : topic #13 (0.020): 0.052*\"cereal\" + 0.023*\"like\" + 0.021*\"taste\" + 0.017*\"cinnamon\" + 0.016*\"good\" + 0.016*\"eat\" + 0.016*\"sugar\" + 0.014*\"fiber\" + 0.012*\"sweet\" + 0.012*\"flavor\"\n",
      "2021-08-24 16:18:27,846 : INFO : topic #45 (0.020): 0.049*\"pasta\" + 0.036*\"snack\" + 0.019*\"good\" + 0.019*\"spaghetti\" + 0.017*\"like\" + 0.017*\"maple\" + 0.016*\"barilla\" + 0.015*\"grain\" + 0.015*\"syrup\" + 0.014*\"eat\"\n",
      "2021-08-24 16:18:27,847 : INFO : topic #42 (0.020): 0.105*\"oil\" + 0.085*\"coconut\" + 0.028*\"use\" + 0.017*\"fat\" + 0.010*\"palm\" + 0.009*\"taste\" + 0.009*\"skin\" + 0.008*\"hair\" + 0.008*\"product\" + 0.008*\"like\"\n",
      "2021-08-24 16:18:27,848 : INFO : topic #21 (0.020): 0.176*\"tea\" + 0.033*\"green\" + 0.019*\"taste\" + 0.017*\"bag\" + 0.015*\"flavor\" + 0.015*\"drink\" + 0.013*\"like\" + 0.011*\"cup\" + 0.011*\"good\" + 0.009*\"leaf\"\n",
      "2021-08-24 16:18:27,850 : INFO : topic #23 (0.020): 0.110*\"sauce\" + 0.025*\"like\" + 0.019*\"taste\" + 0.017*\"use\" + 0.017*\"flavor\" + 0.014*\"good\" + 0.012*\"try\" + 0.012*\"chicken\" + 0.011*\"pouch\" + 0.010*\"tomato\"\n",
      "2021-08-24 16:18:27,852 : INFO : topic diff=0.353873, rho=0.169304\n",
      "2021-08-24 16:18:29,186 : INFO : -7.225 per-word bound, 149.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:18:29,187 : INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:29,198 : INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:29,199 : INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:29,200 : INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:29,201 : INFO : PROGRESS: pass 11, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:29,202 : INFO : PROGRESS: pass 11, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:29,213 : INFO : PROGRESS: pass 11, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:29,215 : INFO : PROGRESS: pass 11, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:18:29,216 : INFO : PROGRESS: pass 11, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:29,231 : INFO : PROGRESS: pass 11, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:29,233 : INFO : PROGRESS: pass 11, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:29,234 : INFO : PROGRESS: pass 11, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:29,236 : INFO : PROGRESS: pass 11, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:29,238 : INFO : PROGRESS: pass 11, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:29,239 : INFO : PROGRESS: pass 11, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:29,252 : INFO : PROGRESS: pass 11, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:18:29,256 : INFO : PROGRESS: pass 11, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:29,257 : INFO : PROGRESS: pass 11, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:29,259 : INFO : PROGRESS: pass 11, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:29,278 : INFO : PROGRESS: pass 11, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:29,307 : INFO : PROGRESS: pass 11, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:29,335 : INFO : PROGRESS: pass 11, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:29,375 : INFO : PROGRESS: pass 11, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:29,407 : INFO : PROGRESS: pass 11, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:18:31,622 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:31,667 : INFO : topic #3 (0.020): 0.110*\"mint\" + 0.087*\"oreo\" + 0.031*\"creme\" + 0.019*\"mio\" + 0.018*\"scout\" + 0.011*\"flavor\" + 0.010*\"sandwich\" + 0.009*\"product\" + 0.008*\"like\" + 0.008*\"similar\"\n",
      "2021-08-24 16:18:31,669 : INFO : topic #8 (0.020): 0.045*\"soup\" + 0.029*\"noodle\" + 0.025*\"like\" + 0.025*\"flavor\" + 0.023*\"good\" + 0.022*\"jerky\" + 0.021*\"beef\" + 0.019*\"spicy\" + 0.016*\"taste\" + 0.012*\"eat\"\n",
      "2021-08-24 16:18:31,671 : INFO : topic #37 (0.020): 0.024*\"clean\" + 0.019*\"like\" + 0.015*\"mustard\" + 0.014*\"bear\" + 0.013*\"sardine\" + 0.012*\"pad\" + 0.011*\"good\" + 0.011*\"gummy\" + 0.010*\"use\" + 0.010*\"taste\"\n",
      "2021-08-24 16:18:31,673 : INFO : topic #7 (0.020): 0.063*\"price\" + 0.044*\"amazon\" + 0.039*\"store\" + 0.036*\"good\" + 0.033*\"buy\" + 0.020*\"great\" + 0.018*\"purchase\" + 0.018*\"grocery\" + 0.018*\"save\" + 0.017*\"order\"\n",
      "2021-08-24 16:18:31,674 : INFO : topic #33 (0.020): 0.032*\"review\" + 0.031*\"taste\" + 0.021*\"like\" + 0.019*\"try\" + 0.019*\"product\" + 0.011*\"use\" + 0.009*\"flavor\" + 0.008*\"read\" + 0.008*\"buy\" + 0.008*\"bad\"\n",
      "2021-08-24 16:18:31,676 : INFO : topic diff=0.333489, rho=0.166929\n",
      "2021-08-24 16:18:34,412 : INFO : -7.234 per-word bound, 150.5 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:34,537 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:34,593 : INFO : topic #45 (0.020): 0.053*\"pasta\" + 0.033*\"snack\" + 0.021*\"spaghetti\" + 0.019*\"good\" + 0.018*\"barilla\" + 0.017*\"maple\" + 0.017*\"like\" + 0.016*\"grain\" + 0.016*\"syrup\" + 0.014*\"eat\"\n",
      "2021-08-24 16:18:34,607 : INFO : topic #1 (0.020): 0.046*\"add\" + 0.028*\"water\" + 0.023*\"minute\" + 0.018*\"cook\" + 0.018*\"chicken\" + 0.015*\"microwave\" + 0.013*\"cup\" + 0.013*\"stir\" + 0.012*\"meal\" + 0.012*\"use\"\n",
      "2021-08-24 16:18:34,639 : INFO : topic #37 (0.020): 0.024*\"clean\" + 0.019*\"like\" + 0.018*\"mustard\" + 0.015*\"bear\" + 0.013*\"sardine\" + 0.011*\"gummy\" + 0.011*\"good\" + 0.011*\"pad\" + 0.010*\"dog\" + 0.010*\"taste\"\n",
      "2021-08-24 16:18:34,647 : INFO : topic #20 (0.020): 0.165*\"milk\" + 0.018*\"use\" + 0.017*\"powder\" + 0.014*\"taste\" + 0.012*\"add\" + 0.011*\"like\" + 0.011*\"soy\" + 0.010*\"water\" + 0.008*\"drink\" + 0.008*\"sugar\"\n",
      "2021-08-24 16:18:34,689 : INFO : topic #26 (0.020): 0.041*\"olive\" + 0.033*\"salad\" + 0.023*\"use\" + 0.023*\"garlic\" + 0.022*\"good\" + 0.022*\"oil\" + 0.019*\"flavor\" + 0.019*\"mix\" + 0.015*\"like\" + 0.015*\"cheese\"\n",
      "2021-08-24 16:18:34,699 : INFO : topic diff=0.315481, rho=0.166929\n",
      "2021-08-24 16:18:36,644 : INFO : -7.239 per-word bound, 151.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:36,732 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:36,762 : INFO : topic #27 (0.020): 0.056*\"mix\" + 0.050*\"cherry\" + 0.039*\"pancake\" + 0.024*\"like\" + 0.019*\"tart\" + 0.017*\"taste\" + 0.016*\"muffin\" + 0.016*\"pumpkin\" + 0.015*\"waffle\" + 0.013*\"pie\"\n",
      "2021-08-24 16:18:36,764 : INFO : topic #36 (0.020): 0.086*\"vanilla\" + 0.080*\"coffee\" + 0.051*\"flavor\" + 0.025*\"taste\" + 0.023*\"starbucks\" + 0.017*\"flavored\" + 0.017*\"like\" + 0.016*\"bean\" + 0.014*\"smell\" + 0.012*\"good\"\n",
      "2021-08-24 16:18:36,765 : INFO : topic #40 (0.020): 0.075*\"almond\" + 0.046*\"flavor\" + 0.016*\"taste\" + 0.016*\"nut\" + 0.016*\"good\" + 0.015*\"lemon\" + 0.014*\"like\" + 0.014*\"try\" + 0.009*\"aid\" + 0.008*\"product\"\n",
      "2021-08-24 16:18:36,766 : INFO : topic #10 (0.020): 0.118*\"free\" + 0.096*\"gluten\" + 0.028*\"bread\" + 0.025*\"good\" + 0.022*\"tuna\" + 0.018*\"product\" + 0.017*\"eat\" + 0.017*\"taste\" + 0.017*\"like\" + 0.014*\"try\"\n",
      "2021-08-24 16:18:36,767 : INFO : topic #22 (0.020): 0.125*\"coffee\" + 0.026*\"like\" + 0.025*\"cup\" + 0.021*\"roast\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.017*\"blend\" + 0.017*\"good\" + 0.016*\"strong\" + 0.012*\"bold\"\n",
      "2021-08-24 16:18:36,771 : INFO : topic diff=0.308409, rho=0.166929\n",
      "2021-08-24 16:18:38,031 : INFO : -7.216 per-word bound, 148.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:38,032 : INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:38,045 : INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:38,046 : INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:38,047 : INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:38,049 : INFO : PROGRESS: pass 12, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:38,063 : INFO : PROGRESS: pass 12, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:38,068 : INFO : PROGRESS: pass 12, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:38,071 : INFO : PROGRESS: pass 12, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:18:38,073 : INFO : PROGRESS: pass 12, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:38,075 : INFO : PROGRESS: pass 12, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:38,094 : INFO : PROGRESS: pass 12, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:38,095 : INFO : PROGRESS: pass 12, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:38,097 : INFO : PROGRESS: pass 12, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:38,099 : INFO : PROGRESS: pass 12, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:38,103 : INFO : PROGRESS: pass 12, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:38,105 : INFO : PROGRESS: pass 12, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:18:38,127 : INFO : PROGRESS: pass 12, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:38,128 : INFO : PROGRESS: pass 12, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:38,131 : INFO : PROGRESS: pass 12, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:38,136 : INFO : PROGRESS: pass 12, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:38,175 : INFO : PROGRESS: pass 12, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:38,196 : INFO : PROGRESS: pass 12, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:38,228 : INFO : PROGRESS: pass 12, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:38,270 : INFO : PROGRESS: pass 12, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:18:40,480 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:40,518 : INFO : topic #15 (0.020): 0.097*\"rice\" + 0.042*\"cook\" + 0.024*\"brown\" + 0.018*\"use\" + 0.018*\"noodle\" + 0.014*\"like\" + 0.013*\"try\" + 0.012*\"oat\" + 0.011*\"grain\" + 0.010*\"texture\"\n",
      "2021-08-24 16:18:40,520 : INFO : topic #18 (0.020): 0.057*\"chip\" + 0.029*\"potato\" + 0.023*\"like\" + 0.020*\"good\" + 0.019*\"taste\" + 0.017*\"flavor\" + 0.016*\"chili\" + 0.012*\"use\" + 0.012*\"food\" + 0.012*\"try\"\n",
      "2021-08-24 16:18:40,522 : INFO : topic #45 (0.020): 0.052*\"pasta\" + 0.036*\"snack\" + 0.020*\"good\" + 0.018*\"spaghetti\" + 0.017*\"maple\" + 0.017*\"like\" + 0.016*\"syrup\" + 0.015*\"barilla\" + 0.015*\"grain\" + 0.014*\"eat\"\n",
      "2021-08-24 16:18:40,524 : INFO : topic #3 (0.020): 0.119*\"mint\" + 0.089*\"oreo\" + 0.031*\"creme\" + 0.020*\"scout\" + 0.019*\"mio\" + 0.011*\"flavor\" + 0.010*\"sandwich\" + 0.009*\"peppermint\" + 0.009*\"similar\" + 0.008*\"product\"\n",
      "2021-08-24 16:18:40,525 : INFO : topic #29 (0.020): 0.022*\"amazon\" + 0.022*\"order\" + 0.021*\"product\" + 0.014*\"date\" + 0.014*\"buy\" + 0.012*\"year\" + 0.010*\"good\" + 0.010*\"time\" + 0.008*\"item\" + 0.008*\"box\"\n",
      "2021-08-24 16:18:40,527 : INFO : topic diff=0.290271, rho=0.164651\n",
      "2021-08-24 16:18:43,200 : INFO : -7.224 per-word bound, 149.5 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:43,314 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:43,362 : INFO : topic #7 (0.020): 0.065*\"price\" + 0.045*\"amazon\" + 0.040*\"store\" + 0.037*\"good\" + 0.035*\"buy\" + 0.021*\"great\" + 0.018*\"save\" + 0.018*\"purchase\" + 0.018*\"grocery\" + 0.017*\"local\"\n",
      "2021-08-24 16:18:43,379 : INFO : topic #49 (0.020): 0.136*\"honey\" + 0.048*\"ginger\" + 0.022*\"raw\" + 0.021*\"mango\" + 0.017*\"pork\" + 0.017*\"taste\" + 0.014*\"use\" + 0.014*\"sweet\" + 0.012*\"flavor\" + 0.011*\"like\"\n",
      "2021-08-24 16:18:43,384 : INFO : topic #43 (0.020): 0.070*\"seed\" + 0.020*\"raw\" + 0.020*\"nut\" + 0.018*\"product\" + 0.017*\"eat\" + 0.014*\"add\" + 0.014*\"chia\" + 0.014*\"salmon\" + 0.012*\"fresh\" + 0.012*\"good\"\n",
      "2021-08-24 16:18:43,388 : INFO : topic #37 (0.020): 0.025*\"clean\" + 0.019*\"like\" + 0.018*\"mustard\" + 0.017*\"bear\" + 0.013*\"sardine\" + 0.012*\"gummy\" + 0.011*\"dog\" + 0.011*\"pad\" + 0.010*\"good\" + 0.010*\"handle\"\n",
      "2021-08-24 16:18:43,393 : INFO : topic #26 (0.020): 0.042*\"olive\" + 0.034*\"salad\" + 0.024*\"use\" + 0.024*\"garlic\" + 0.023*\"oil\" + 0.022*\"good\" + 0.020*\"flavor\" + 0.019*\"mix\" + 0.015*\"like\" + 0.014*\"cheese\"\n",
      "2021-08-24 16:18:43,397 : INFO : topic diff=0.274660, rho=0.164651\n",
      "2021-08-24 16:18:45,526 : INFO : -7.231 per-word bound, 150.2 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:45,610 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:45,640 : INFO : topic #6 (0.020): 0.075*\"cracker\" + 0.072*\"cheese\" + 0.052*\"butter\" + 0.040*\"peanut\" + 0.030*\"taste\" + 0.022*\"like\" + 0.020*\"product\" + 0.016*\"cheddar\" + 0.012*\"spread\" + 0.012*\"good\"\n",
      "2021-08-24 16:18:45,641 : INFO : topic #12 (0.020): 0.064*\"fruit\" + 0.051*\"oatmeal\" + 0.036*\"bean\" + 0.024*\"like\" + 0.024*\"dry\" + 0.018*\"dried\" + 0.015*\"cranberry\" + 0.013*\"eat\" + 0.012*\"add\" + 0.012*\"quaker\"\n",
      "2021-08-24 16:18:45,642 : INFO : topic #28 (0.020): 0.075*\"cup\" + 0.064*\"coffee\" + 0.018*\"like\" + 0.017*\"flavor\" + 0.016*\"good\" + 0.016*\"taste\" + 0.014*\"use\" + 0.014*\"instant\" + 0.014*\"try\" + 0.013*\"hot\"\n",
      "2021-08-24 16:18:45,643 : INFO : topic #48 (0.020): 0.035*\"water\" + 0.031*\"taste\" + 0.026*\"like\" + 0.020*\"bottle\" + 0.019*\"product\" + 0.012*\"good\" + 0.011*\"use\" + 0.011*\"flavor\" + 0.009*\"try\" + 0.009*\"drink\"\n",
      "2021-08-24 16:18:45,645 : INFO : topic #39 (0.020): 0.103*\"love\" + 0.093*\"great\" + 0.041*\"good\" + 0.039*\"taste\" + 0.025*\"easy\" + 0.023*\"like\" + 0.021*\"product\" + 0.020*\"flavor\" + 0.018*\"quick\" + 0.016*\"recommend\"\n",
      "2021-08-24 16:18:45,648 : INFO : topic diff=0.269793, rho=0.164651\n",
      "2021-08-24 16:18:46,847 : INFO : -7.207 per-word bound, 147.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:46,849 : INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:46,859 : INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:46,860 : INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:46,862 : INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:46,863 : INFO : PROGRESS: pass 13, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:46,880 : INFO : PROGRESS: pass 13, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:46,882 : INFO : PROGRESS: pass 13, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:46,884 : INFO : PROGRESS: pass 13, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:18:46,885 : INFO : PROGRESS: pass 13, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:46,886 : INFO : PROGRESS: pass 13, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:46,901 : INFO : PROGRESS: pass 13, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:46,902 : INFO : PROGRESS: pass 13, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:46,904 : INFO : PROGRESS: pass 13, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:46,906 : INFO : PROGRESS: pass 13, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:46,907 : INFO : PROGRESS: pass 13, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:46,929 : INFO : PROGRESS: pass 13, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:18:46,932 : INFO : PROGRESS: pass 13, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:46,935 : INFO : PROGRESS: pass 13, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:46,938 : INFO : PROGRESS: pass 13, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:46,961 : INFO : PROGRESS: pass 13, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:46,974 : INFO : PROGRESS: pass 13, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:47,004 : INFO : PROGRESS: pass 13, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:47,044 : INFO : PROGRESS: pass 13, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:47,071 : INFO : PROGRESS: pass 13, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:18:48,984 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:49,021 : INFO : topic #1 (0.020): 0.049*\"add\" + 0.029*\"water\" + 0.024*\"minute\" + 0.018*\"cook\" + 0.018*\"chicken\" + 0.016*\"microwave\" + 0.013*\"cup\" + 0.013*\"stir\" + 0.013*\"meal\" + 0.012*\"use\"\n",
      "2021-08-24 16:18:49,024 : INFO : topic #31 (0.020): 0.061*\"cooky\" + 0.039*\"cookie\" + 0.038*\"chocolate\" + 0.027*\"like\" + 0.022*\"taste\" + 0.017*\"good\" + 0.015*\"chip\" + 0.013*\"sweet\" + 0.013*\"eat\" + 0.012*\"package\"\n",
      "2021-08-24 16:18:49,026 : INFO : topic #4 (0.020): 0.031*\"tea\" + 0.021*\"pu\" + 0.021*\"costco\" + 0.020*\"erh\" + 0.016*\"english\" + 0.014*\"breakfast\" + 0.012*\"try\" + 0.011*\"brand\" + 0.009*\"flavor\" + 0.009*\"good\"\n",
      "2021-08-24 16:18:49,028 : INFO : topic #38 (0.020): 0.052*\"bag\" + 0.027*\"buy\" + 0.022*\"container\" + 0.021*\"jar\" + 0.021*\"open\" + 0.018*\"plastic\" + 0.017*\"package\" + 0.016*\"fresh\" + 0.016*\"use\" + 0.014*\"good\"\n",
      "2021-08-24 16:18:49,029 : INFO : topic #28 (0.020): 0.074*\"cup\" + 0.065*\"coffee\" + 0.017*\"like\" + 0.017*\"flavor\" + 0.016*\"good\" + 0.016*\"taste\" + 0.016*\"instant\" + 0.014*\"use\" + 0.014*\"try\" + 0.013*\"hot\"\n",
      "2021-08-24 16:18:49,031 : INFO : topic diff=0.254111, rho=0.162463\n",
      "2021-08-24 16:18:51,636 : INFO : -7.217 per-word bound, 148.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:51,738 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:51,786 : INFO : topic #16 (0.020): 0.100*\"sugar\" + 0.039*\"use\" + 0.030*\"taste\" + 0.027*\"sweetener\" + 0.025*\"stevia\" + 0.018*\"sweet\" + 0.018*\"splenda\" + 0.018*\"like\" + 0.016*\"product\" + 0.013*\"good\"\n",
      "2021-08-24 16:18:51,789 : INFO : topic #23 (0.020): 0.118*\"sauce\" + 0.025*\"like\" + 0.019*\"taste\" + 0.018*\"use\" + 0.017*\"flavor\" + 0.015*\"good\" + 0.013*\"chicken\" + 0.013*\"try\" + 0.012*\"tomato\" + 0.012*\"pouch\"\n",
      "2021-08-24 16:18:51,794 : INFO : topic #20 (0.020): 0.177*\"milk\" + 0.020*\"powder\" + 0.018*\"use\" + 0.014*\"add\" + 0.013*\"taste\" + 0.013*\"soy\" + 0.011*\"like\" + 0.010*\"water\" + 0.009*\"mix\" + 0.008*\"drink\"\n",
      "2021-08-24 16:18:51,814 : INFO : topic #28 (0.020): 0.076*\"cup\" + 0.065*\"coffee\" + 0.017*\"like\" + 0.017*\"flavor\" + 0.016*\"good\" + 0.016*\"taste\" + 0.015*\"instant\" + 0.015*\"use\" + 0.014*\"try\" + 0.013*\"hot\"\n",
      "2021-08-24 16:18:51,825 : INFO : topic #46 (0.020): 0.037*\"product\" + 0.033*\"ingredient\" + 0.017*\"flavor\" + 0.015*\"like\" + 0.014*\"list\" + 0.014*\"high\" + 0.012*\"corn\" + 0.012*\"syrup\" + 0.011*\"taste\" + 0.011*\"label\"\n",
      "2021-08-24 16:18:51,840 : INFO : topic diff=0.240543, rho=0.162463\n",
      "2021-08-24 16:18:53,661 : INFO : -7.225 per-word bound, 149.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:53,728 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:53,756 : INFO : topic #35 (0.020): 0.058*\"cake\" + 0.049*\"red\" + 0.031*\"pizza\" + 0.029*\"crust\" + 0.028*\"bob\" + 0.017*\"mix\" + 0.016*\"good\" + 0.015*\"product\" + 0.011*\"dough\" + 0.010*\"crumb\"\n",
      "2021-08-24 16:18:53,758 : INFO : topic #40 (0.020): 0.080*\"almond\" + 0.049*\"flavor\" + 0.020*\"nut\" + 0.017*\"lemon\" + 0.016*\"taste\" + 0.015*\"good\" + 0.014*\"like\" + 0.014*\"try\" + 0.010*\"aid\" + 0.010*\"peach\"\n",
      "2021-08-24 16:18:53,759 : INFO : topic #15 (0.020): 0.101*\"rice\" + 0.045*\"cook\" + 0.027*\"brown\" + 0.018*\"use\" + 0.018*\"noodle\" + 0.014*\"like\" + 0.014*\"oat\" + 0.013*\"try\" + 0.011*\"grain\" + 0.011*\"texture\"\n",
      "2021-08-24 16:18:53,760 : INFO : topic #22 (0.020): 0.128*\"coffee\" + 0.027*\"like\" + 0.025*\"cup\" + 0.021*\"roast\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.018*\"blend\" + 0.017*\"good\" + 0.016*\"strong\" + 0.013*\"bold\"\n",
      "2021-08-24 16:18:53,761 : INFO : topic #6 (0.020): 0.076*\"cracker\" + 0.073*\"cheese\" + 0.054*\"butter\" + 0.043*\"peanut\" + 0.030*\"taste\" + 0.022*\"like\" + 0.019*\"product\" + 0.016*\"cheddar\" + 0.012*\"spread\" + 0.012*\"good\"\n",
      "2021-08-24 16:18:53,762 : INFO : topic diff=0.237568, rho=0.162463\n",
      "2021-08-24 16:18:54,919 : INFO : -7.202 per-word bound, 147.3 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:54,920 : INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:18:54,933 : INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:18:54,934 : INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:18:54,936 : INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:18:54,937 : INFO : PROGRESS: pass 14, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:18:54,938 : INFO : PROGRESS: pass 14, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:18:54,953 : INFO : PROGRESS: pass 14, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:18:54,955 : INFO : PROGRESS: pass 14, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:18:54,956 : INFO : PROGRESS: pass 14, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:18:54,958 : INFO : PROGRESS: pass 14, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:18:54,973 : INFO : PROGRESS: pass 14, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:18:54,974 : INFO : PROGRESS: pass 14, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:18:54,976 : INFO : PROGRESS: pass 14, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:18:54,977 : INFO : PROGRESS: pass 14, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:18:54,979 : INFO : PROGRESS: pass 14, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:18:55,000 : INFO : PROGRESS: pass 14, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:18:55,003 : INFO : PROGRESS: pass 14, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:18:55,005 : INFO : PROGRESS: pass 14, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:18:55,008 : INFO : PROGRESS: pass 14, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:18:55,030 : INFO : PROGRESS: pass 14, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:18:55,060 : INFO : PROGRESS: pass 14, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:18:55,068 : INFO : PROGRESS: pass 14, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:18:55,105 : INFO : PROGRESS: pass 14, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:18:55,136 : INFO : PROGRESS: pass 14, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:18:56,990 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:57,029 : INFO : topic #34 (0.020): 0.035*\"fat\" + 0.028*\"calorie\" + 0.022*\"high\" + 0.022*\"low\" + 0.022*\"protein\" + 0.017*\"consume\" + 0.016*\"food\" + 0.016*\"diet\" + 0.014*\"seed\" + 0.013*\"nutrient\"\n",
      "2021-08-24 16:18:57,030 : INFO : topic #26 (0.020): 0.043*\"olive\" + 0.035*\"salad\" + 0.025*\"use\" + 0.024*\"garlic\" + 0.023*\"oil\" + 0.021*\"good\" + 0.020*\"flavor\" + 0.018*\"mix\" + 0.014*\"like\" + 0.013*\"cheese\"\n",
      "2021-08-24 16:18:57,031 : INFO : topic #30 (0.020): 0.030*\"grey\" + 0.027*\"earl\" + 0.017*\"flavor\" + 0.015*\"bring\" + 0.014*\"like\" + 0.010*\"bergamot\" + 0.010*\"memory\" + 0.009*\"stash\" + 0.008*\"law\" + 0.008*\"lady\"\n",
      "2021-08-24 16:18:57,033 : INFO : topic #49 (0.020): 0.138*\"honey\" + 0.051*\"ginger\" + 0.023*\"raw\" + 0.022*\"mango\" + 0.019*\"pork\" + 0.017*\"taste\" + 0.014*\"sweet\" + 0.014*\"use\" + 0.011*\"flavor\" + 0.011*\"like\"\n",
      "2021-08-24 16:18:57,034 : INFO : topic #7 (0.020): 0.068*\"price\" + 0.044*\"amazon\" + 0.042*\"store\" + 0.038*\"good\" + 0.037*\"buy\" + 0.021*\"great\" + 0.019*\"grocery\" + 0.019*\"save\" + 0.018*\"purchase\" + 0.018*\"local\"\n",
      "2021-08-24 16:18:57,036 : INFO : topic diff=0.224049, rho=0.160361\n",
      "2021-08-24 16:18:59,521 : INFO : -7.211 per-word bound, 148.1 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:18:59,682 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:18:59,735 : INFO : topic #8 (0.020): 0.053*\"soup\" + 0.032*\"noodle\" + 0.026*\"like\" + 0.026*\"flavor\" + 0.024*\"good\" + 0.021*\"beef\" + 0.021*\"jerky\" + 0.019*\"spicy\" + 0.017*\"taste\" + 0.013*\"eat\"\n",
      "2021-08-24 16:18:59,741 : INFO : topic #28 (0.020): 0.078*\"cup\" + 0.066*\"coffee\" + 0.017*\"like\" + 0.016*\"flavor\" + 0.016*\"instant\" + 0.016*\"good\" + 0.015*\"taste\" + 0.015*\"use\" + 0.013*\"try\" + 0.013*\"hot\"\n",
      "2021-08-24 16:18:59,767 : INFO : topic #34 (0.020): 0.034*\"fat\" + 0.027*\"calorie\" + 0.023*\"high\" + 0.023*\"protein\" + 0.022*\"low\" + 0.017*\"consume\" + 0.017*\"food\" + 0.016*\"diet\" + 0.014*\"seed\" + 0.013*\"nutrient\"\n",
      "2021-08-24 16:18:59,776 : INFO : topic #0 (0.020): 0.060*\"box\" + 0.022*\"day\" + 0.018*\"packet\" + 0.017*\"open\" + 0.016*\"time\" + 0.016*\"good\" + 0.014*\"arrive\" + 0.010*\"pack\" + 0.010*\"inside\" + 0.010*\"package\"\n",
      "2021-08-24 16:18:59,779 : INFO : topic #17 (0.020): 0.142*\"chocolate\" + 0.039*\"dark\" + 0.028*\"caramel\" + 0.026*\"candy\" + 0.024*\"bar\" + 0.018*\"taste\" + 0.017*\"like\" + 0.016*\"good\" + 0.014*\"sweet\" + 0.014*\"cocoa\"\n",
      "2021-08-24 16:18:59,791 : INFO : topic diff=0.212397, rho=0.160361\n",
      "2021-08-24 16:19:01,725 : INFO : -7.220 per-word bound, 149.0 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:01,814 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:01,842 : INFO : topic #38 (0.020): 0.060*\"bag\" + 0.026*\"buy\" + 0.023*\"container\" + 0.022*\"open\" + 0.020*\"jar\" + 0.019*\"plastic\" + 0.018*\"package\" + 0.017*\"fresh\" + 0.017*\"use\" + 0.014*\"good\"\n",
      "2021-08-24 16:19:01,844 : INFO : topic #36 (0.020): 0.088*\"vanilla\" + 0.081*\"coffee\" + 0.056*\"flavor\" + 0.026*\"taste\" + 0.024*\"starbucks\" + 0.019*\"flavored\" + 0.018*\"like\" + 0.016*\"bean\" + 0.016*\"smell\" + 0.012*\"good\"\n",
      "2021-08-24 16:19:01,844 : INFO : topic #35 (0.020): 0.060*\"cake\" + 0.053*\"red\" + 0.032*\"pizza\" + 0.030*\"crust\" + 0.029*\"bob\" + 0.017*\"mix\" + 0.016*\"good\" + 0.015*\"product\" + 0.012*\"dough\" + 0.010*\"crumb\"\n",
      "2021-08-24 16:19:01,845 : INFO : topic #21 (0.020): 0.192*\"tea\" + 0.035*\"green\" + 0.018*\"taste\" + 0.017*\"bag\" + 0.016*\"drink\" + 0.015*\"flavor\" + 0.013*\"like\" + 0.013*\"cup\" + 0.012*\"good\" + 0.010*\"leaf\"\n",
      "2021-08-24 16:19:01,846 : INFO : topic #10 (0.020): 0.134*\"free\" + 0.103*\"gluten\" + 0.029*\"bread\" + 0.024*\"good\" + 0.022*\"tuna\" + 0.018*\"eat\" + 0.018*\"product\" + 0.018*\"like\" + 0.017*\"taste\" + 0.015*\"try\"\n",
      "2021-08-24 16:19:01,848 : INFO : topic diff=0.210825, rho=0.160361\n",
      "2021-08-24 16:19:03,056 : INFO : -7.198 per-word bound, 146.8 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:03,057 : INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:19:03,069 : INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:19:03,071 : INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:19:03,072 : INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:19:03,073 : INFO : PROGRESS: pass 15, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:19:03,074 : INFO : PROGRESS: pass 15, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:19:03,075 : INFO : PROGRESS: pass 15, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:19:03,090 : INFO : PROGRESS: pass 15, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:19:03,091 : INFO : PROGRESS: pass 15, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:19:03,092 : INFO : PROGRESS: pass 15, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:19:03,093 : INFO : PROGRESS: pass 15, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:19:03,094 : INFO : PROGRESS: pass 15, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:19:03,096 : INFO : PROGRESS: pass 15, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:19:03,116 : INFO : PROGRESS: pass 15, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:19:03,117 : INFO : PROGRESS: pass 15, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:19:03,119 : INFO : PROGRESS: pass 15, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:19:03,121 : INFO : PROGRESS: pass 15, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:19:03,122 : INFO : PROGRESS: pass 15, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:19:03,141 : INFO : PROGRESS: pass 15, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:19:03,168 : INFO : PROGRESS: pass 15, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:19:03,190 : INFO : PROGRESS: pass 15, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:19:03,219 : INFO : PROGRESS: pass 15, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:19:03,247 : INFO : PROGRESS: pass 15, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:19:03,276 : INFO : PROGRESS: pass 15, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:19:05,305 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:05,343 : INFO : topic #25 (0.020): 0.031*\"calorie\" + 0.029*\"fat\" + 0.028*\"gram\" + 0.025*\"vitamin\" + 0.022*\"sodium\" + 0.022*\"mg\" + 0.022*\"sugar\" + 0.021*\"ingredient\" + 0.020*\"contain\" + 0.016*\"fiber\"\n",
      "2021-08-24 16:19:05,345 : INFO : topic #31 (0.020): 0.064*\"cooky\" + 0.041*\"cookie\" + 0.036*\"chocolate\" + 0.028*\"like\" + 0.023*\"taste\" + 0.017*\"good\" + 0.015*\"chip\" + 0.013*\"sweet\" + 0.012*\"eat\" + 0.012*\"fudge\"\n",
      "2021-08-24 16:19:05,346 : INFO : topic #16 (0.020): 0.103*\"sugar\" + 0.039*\"use\" + 0.030*\"taste\" + 0.028*\"sweetener\" + 0.025*\"stevia\" + 0.019*\"splenda\" + 0.019*\"sweet\" + 0.018*\"like\" + 0.016*\"product\" + 0.013*\"good\"\n",
      "2021-08-24 16:19:05,348 : INFO : topic #8 (0.020): 0.054*\"soup\" + 0.033*\"noodle\" + 0.027*\"like\" + 0.026*\"flavor\" + 0.024*\"good\" + 0.022*\"jerky\" + 0.021*\"beef\" + 0.020*\"spicy\" + 0.017*\"taste\" + 0.013*\"eat\"\n",
      "2021-08-24 16:19:05,349 : INFO : topic #35 (0.020): 0.060*\"cake\" + 0.056*\"red\" + 0.033*\"bob\" + 0.031*\"pizza\" + 0.030*\"crust\" + 0.017*\"mix\" + 0.016*\"good\" + 0.015*\"product\" + 0.011*\"dough\" + 0.009*\"crumb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:05,351 : INFO : topic diff=0.199053, rho=0.158338\n",
      "2021-08-24 16:19:08,077 : INFO : -7.206 per-word bound, 147.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:08,223 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:08,279 : INFO : topic #5 (0.020): 0.122*\"salt\" + 0.058*\"popcorn\" + 0.023*\"taste\" + 0.022*\"pop\" + 0.021*\"salty\" + 0.020*\"sea\" + 0.020*\"good\" + 0.018*\"use\" + 0.017*\"like\" + 0.017*\"flavor\"\n",
      "2021-08-24 16:19:08,291 : INFO : topic #3 (0.020): 0.130*\"mint\" + 0.086*\"oreo\" + 0.032*\"creme\" + 0.021*\"scout\" + 0.018*\"mio\" + 0.015*\"peppermint\" + 0.011*\"flavor\" + 0.010*\"sandwich\" + 0.010*\"similar\" + 0.009*\"year\"\n",
      "2021-08-24 16:19:08,318 : INFO : topic #47 (0.020): 0.091*\"use\" + 0.047*\"recipe\" + 0.047*\"bake\" + 0.046*\"flour\" + 0.034*\"bread\" + 0.023*\"powder\" + 0.017*\"add\" + 0.016*\"mix\" + 0.014*\"work\" + 0.013*\"yeast\"\n",
      "2021-08-24 16:19:08,332 : INFO : topic #35 (0.020): 0.061*\"cake\" + 0.054*\"red\" + 0.035*\"pizza\" + 0.032*\"crust\" + 0.030*\"bob\" + 0.018*\"mix\" + 0.016*\"good\" + 0.015*\"product\" + 0.013*\"dough\" + 0.009*\"pan\"\n",
      "2021-08-24 16:19:08,363 : INFO : topic #31 (0.020): 0.064*\"cooky\" + 0.040*\"cookie\" + 0.036*\"chocolate\" + 0.028*\"like\" + 0.023*\"taste\" + 0.017*\"good\" + 0.015*\"chip\" + 0.013*\"sweet\" + 0.013*\"eat\" + 0.012*\"soft\"\n",
      "2021-08-24 16:19:08,381 : INFO : topic diff=0.188939, rho=0.158338\n",
      "2021-08-24 16:19:10,379 : INFO : -7.215 per-word bound, 148.5 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:10,467 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:10,498 : INFO : topic #28 (0.020): 0.082*\"cup\" + 0.066*\"coffee\" + 0.017*\"like\" + 0.016*\"flavor\" + 0.016*\"good\" + 0.015*\"instant\" + 0.015*\"taste\" + 0.015*\"use\" + 0.013*\"hot\" + 0.013*\"try\"\n",
      "2021-08-24 16:19:10,499 : INFO : topic #1 (0.020): 0.050*\"add\" + 0.032*\"water\" + 0.026*\"minute\" + 0.018*\"cook\" + 0.017*\"chicken\" + 0.016*\"microwave\" + 0.014*\"stir\" + 0.014*\"cup\" + 0.013*\"meal\" + 0.013*\"use\"\n",
      "2021-08-24 16:19:10,500 : INFO : topic #41 (0.020): 0.084*\"drink\" + 0.038*\"taste\" + 0.037*\"energy\" + 0.030*\"like\" + 0.024*\"juice\" + 0.023*\"flavor\" + 0.016*\"good\" + 0.014*\"caffeine\" + 0.012*\"try\" + 0.012*\"apple\"\n",
      "2021-08-24 16:19:10,501 : INFO : topic #37 (0.020): 0.032*\"clean\" + 0.018*\"like\" + 0.018*\"bear\" + 0.017*\"mustard\" + 0.014*\"pad\" + 0.013*\"dog\" + 0.013*\"sardine\" + 0.013*\"gummy\" + 0.012*\"handle\" + 0.011*\"use\"\n",
      "2021-08-24 16:19:10,503 : INFO : topic #5 (0.020): 0.117*\"salt\" + 0.065*\"popcorn\" + 0.023*\"taste\" + 0.022*\"pop\" + 0.021*\"salty\" + 0.020*\"sea\" + 0.020*\"good\" + 0.018*\"use\" + 0.017*\"flavor\" + 0.017*\"like\"\n",
      "2021-08-24 16:19:10,504 : INFO : topic diff=0.188451, rho=0.158338\n",
      "2021-08-24 16:19:11,758 : INFO : -7.194 per-word bound, 146.4 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:11,759 : INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:19:11,769 : INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:19:11,769 : INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:19:11,771 : INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:19:11,779 : INFO : PROGRESS: pass 16, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:19:11,783 : INFO : PROGRESS: pass 16, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:19:11,784 : INFO : PROGRESS: pass 16, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:19:11,786 : INFO : PROGRESS: pass 16, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:19:11,788 : INFO : PROGRESS: pass 16, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:19:11,808 : INFO : PROGRESS: pass 16, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:19:11,810 : INFO : PROGRESS: pass 16, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:19:11,812 : INFO : PROGRESS: pass 16, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:19:11,813 : INFO : PROGRESS: pass 16, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:19:11,815 : INFO : PROGRESS: pass 16, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:19:11,817 : INFO : PROGRESS: pass 16, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:19:11,842 : INFO : PROGRESS: pass 16, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:19:11,845 : INFO : PROGRESS: pass 16, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:19:11,849 : INFO : PROGRESS: pass 16, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:19:11,852 : INFO : PROGRESS: pass 16, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:19:11,876 : INFO : PROGRESS: pass 16, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:19:11,898 : INFO : PROGRESS: pass 16, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:19:11,914 : INFO : PROGRESS: pass 16, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:19:11,992 : INFO : PROGRESS: pass 16, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:19:12,023 : INFO : PROGRESS: pass 16, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:19:13,903 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:13,942 : INFO : topic #9 (0.020): 0.040*\"licorice\" + 0.033*\"star\" + 0.025*\"good\" + 0.010*\"black\" + 0.009*\"clam\" + 0.009*\"tasteless\" + 0.009*\"peppercorn\" + 0.008*\"assortment\" + 0.007*\"rating\" + 0.007*\"twist\"\n",
      "2021-08-24 16:19:13,945 : INFO : topic #7 (0.020): 0.071*\"price\" + 0.044*\"amazon\" + 0.044*\"store\" + 0.039*\"buy\" + 0.039*\"good\" + 0.021*\"great\" + 0.020*\"grocery\" + 0.019*\"save\" + 0.018*\"local\" + 0.018*\"purchase\"\n",
      "2021-08-24 16:19:13,947 : INFO : topic #43 (0.020): 0.074*\"seed\" + 0.022*\"raw\" + 0.020*\"nut\" + 0.019*\"eat\" + 0.017*\"add\" + 0.016*\"product\" + 0.016*\"chia\" + 0.015*\"salmon\" + 0.013*\"good\" + 0.013*\"flax\"\n",
      "2021-08-24 16:19:13,948 : INFO : topic #31 (0.020): 0.066*\"cooky\" + 0.042*\"cookie\" + 0.036*\"chocolate\" + 0.028*\"like\" + 0.023*\"taste\" + 0.017*\"good\" + 0.016*\"chip\" + 0.013*\"sweet\" + 0.013*\"fudge\" + 0.012*\"eat\"\n",
      "2021-08-24 16:19:13,950 : INFO : topic #18 (0.020): 0.064*\"chip\" + 0.032*\"potato\" + 0.025*\"like\" + 0.021*\"good\" + 0.020*\"taste\" + 0.018*\"flavor\" + 0.017*\"chili\" + 0.013*\"food\" + 0.012*\"taco\" + 0.012*\"try\"\n",
      "2021-08-24 16:19:13,952 : INFO : topic diff=0.178365, rho=0.156389\n",
      "2021-08-24 16:19:16,695 : INFO : -7.202 per-word bound, 147.3 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:16,865 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:16,918 : INFO : topic #37 (0.020): 0.031*\"clean\" + 0.020*\"bear\" + 0.019*\"mustard\" + 0.018*\"like\" + 0.014*\"dog\" + 0.014*\"gummy\" + 0.013*\"sardine\" + 0.012*\"pad\" + 0.011*\"handle\" + 0.010*\"use\"\n",
      "2021-08-24 16:19:16,940 : INFO : topic #5 (0.020): 0.124*\"salt\" + 0.058*\"popcorn\" + 0.023*\"taste\" + 0.022*\"pop\" + 0.022*\"salty\" + 0.020*\"sea\" + 0.020*\"good\" + 0.018*\"use\" + 0.018*\"like\" + 0.017*\"flavor\"\n",
      "2021-08-24 16:19:16,968 : INFO : topic #12 (0.020): 0.073*\"fruit\" + 0.055*\"oatmeal\" + 0.041*\"bean\" + 0.028*\"dry\" + 0.022*\"like\" + 0.019*\"dried\" + 0.015*\"cranberry\" + 0.014*\"eat\" + 0.012*\"raisin\" + 0.012*\"add\"\n",
      "2021-08-24 16:19:16,978 : INFO : topic #22 (0.020): 0.131*\"coffee\" + 0.027*\"like\" + 0.024*\"cup\" + 0.021*\"roast\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.018*\"blend\" + 0.017*\"good\" + 0.017*\"strong\" + 0.013*\"bold\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:16,989 : INFO : topic #40 (0.020): 0.087*\"almond\" + 0.050*\"flavor\" + 0.029*\"nut\" + 0.017*\"lemon\" + 0.016*\"taste\" + 0.014*\"good\" + 0.014*\"like\" + 0.013*\"try\" + 0.011*\"peach\" + 0.011*\"roast\"\n",
      "2021-08-24 16:19:16,992 : INFO : topic diff=0.169256, rho=0.156389\n",
      "2021-08-24 16:19:19,096 : INFO : -7.212 per-word bound, 148.2 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:19,188 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:19,217 : INFO : topic #47 (0.020): 0.092*\"use\" + 0.051*\"bake\" + 0.048*\"flour\" + 0.048*\"recipe\" + 0.035*\"bread\" + 0.022*\"powder\" + 0.017*\"add\" + 0.016*\"mix\" + 0.015*\"shake\" + 0.014*\"work\"\n",
      "2021-08-24 16:19:19,218 : INFO : topic #10 (0.020): 0.142*\"free\" + 0.107*\"gluten\" + 0.028*\"bread\" + 0.024*\"good\" + 0.023*\"tuna\" + 0.019*\"eat\" + 0.018*\"product\" + 0.018*\"like\" + 0.017*\"taste\" + 0.016*\"try\"\n",
      "2021-08-24 16:19:19,219 : INFO : topic #41 (0.020): 0.085*\"drink\" + 0.038*\"taste\" + 0.038*\"energy\" + 0.030*\"like\" + 0.024*\"juice\" + 0.023*\"flavor\" + 0.017*\"good\" + 0.014*\"caffeine\" + 0.012*\"try\" + 0.012*\"apple\"\n",
      "2021-08-24 16:19:19,220 : INFO : topic #32 (0.020): 0.185*\"organic\" + 0.030*\"food\" + 0.027*\"product\" + 0.022*\"company\" + 0.021*\"use\" + 0.018*\"spice\" + 0.016*\"brand\" + 0.013*\"non\" + 0.013*\"gmo\" + 0.011*\"certify\"\n",
      "2021-08-24 16:19:19,221 : INFO : topic #30 (0.020): 0.028*\"grey\" + 0.026*\"earl\" + 0.018*\"bring\" + 0.016*\"flavor\" + 0.012*\"like\" + 0.011*\"memory\" + 0.010*\"law\" + 0.010*\"bergamot\" + 0.009*\"mother\" + 0.009*\"sister\"\n",
      "2021-08-24 16:19:19,222 : INFO : topic diff=0.169565, rho=0.156389\n",
      "2021-08-24 16:19:20,585 : INFO : -7.192 per-word bound, 146.2 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:20,586 : INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:19:20,598 : INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:19:20,600 : INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:19:20,601 : INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:19:20,602 : INFO : PROGRESS: pass 17, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:19:20,614 : INFO : PROGRESS: pass 17, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:19:20,615 : INFO : PROGRESS: pass 17, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:19:20,616 : INFO : PROGRESS: pass 17, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:19:20,628 : INFO : PROGRESS: pass 17, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:19:20,636 : INFO : PROGRESS: pass 17, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:19:20,639 : INFO : PROGRESS: pass 17, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:19:20,640 : INFO : PROGRESS: pass 17, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:19:20,661 : INFO : PROGRESS: pass 17, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:19:20,667 : INFO : PROGRESS: pass 17, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:19:20,668 : INFO : PROGRESS: pass 17, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:19:20,672 : INFO : PROGRESS: pass 17, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:19:20,675 : INFO : PROGRESS: pass 17, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:19:20,693 : INFO : PROGRESS: pass 17, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:19:20,698 : INFO : PROGRESS: pass 17, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:19:20,700 : INFO : PROGRESS: pass 17, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:19:20,714 : INFO : PROGRESS: pass 17, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:19:20,774 : INFO : PROGRESS: pass 17, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:19:20,810 : INFO : PROGRESS: pass 17, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:19:20,819 : INFO : PROGRESS: pass 17, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:19:23,170 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:23,210 : INFO : topic #3 (0.020): 0.136*\"mint\" + 0.093*\"oreo\" + 0.032*\"creme\" + 0.023*\"scout\" + 0.019*\"mio\" + 0.018*\"peppermint\" + 0.011*\"flavor\" + 0.010*\"similar\" + 0.010*\"year\" + 0.010*\"sandwich\"\n",
      "2021-08-24 16:19:23,212 : INFO : topic #38 (0.020): 0.070*\"bag\" + 0.025*\"buy\" + 0.024*\"container\" + 0.023*\"open\" + 0.021*\"jar\" + 0.020*\"plastic\" + 0.019*\"fresh\" + 0.018*\"package\" + 0.017*\"use\" + 0.014*\"good\"\n",
      "2021-08-24 16:19:23,214 : INFO : topic #41 (0.020): 0.086*\"drink\" + 0.038*\"taste\" + 0.037*\"energy\" + 0.030*\"like\" + 0.024*\"juice\" + 0.023*\"flavor\" + 0.017*\"good\" + 0.014*\"caffeine\" + 0.012*\"try\" + 0.011*\"apple\"\n",
      "2021-08-24 16:19:23,216 : INFO : topic #26 (0.020): 0.044*\"olive\" + 0.037*\"salad\" + 0.028*\"use\" + 0.026*\"garlic\" + 0.024*\"oil\" + 0.021*\"flavor\" + 0.020*\"good\" + 0.018*\"mix\" + 0.013*\"like\" + 0.013*\"fresh\"\n",
      "2021-08-24 16:19:23,218 : INFO : topic #19 (0.020): 0.062*\"bar\" + 0.050*\"snack\" + 0.028*\"like\" + 0.023*\"good\" + 0.021*\"taste\" + 0.021*\"eat\" + 0.019*\"nut\" + 0.018*\"flavor\" + 0.017*\"peanut\" + 0.015*\"sweet\"\n",
      "2021-08-24 16:19:23,219 : INFO : topic diff=0.160663, rho=0.154511\n",
      "2021-08-24 16:19:26,159 : INFO : -7.199 per-word bound, 147.0 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:26,319 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:26,381 : INFO : topic #22 (0.020): 0.132*\"coffee\" + 0.027*\"like\" + 0.024*\"cup\" + 0.021*\"roast\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.019*\"blend\" + 0.017*\"good\" + 0.017*\"strong\" + 0.013*\"bold\"\n",
      "2021-08-24 16:19:26,385 : INFO : topic #18 (0.020): 0.067*\"chip\" + 0.034*\"potato\" + 0.026*\"like\" + 0.021*\"good\" + 0.020*\"taste\" + 0.018*\"flavor\" + 0.016*\"chili\" + 0.014*\"food\" + 0.012*\"eat\" + 0.012*\"dip\"\n",
      "2021-08-24 16:19:26,422 : INFO : topic #33 (0.020): 0.044*\"taste\" + 0.040*\"review\" + 0.029*\"try\" + 0.026*\"like\" + 0.023*\"product\" + 0.015*\"bad\" + 0.013*\"think\" + 0.012*\"read\" + 0.011*\"buy\" + 0.011*\"know\"\n",
      "2021-08-24 16:19:26,458 : INFO : topic #7 (0.020): 0.072*\"price\" + 0.044*\"amazon\" + 0.044*\"store\" + 0.040*\"buy\" + 0.039*\"good\" + 0.022*\"great\" + 0.020*\"save\" + 0.019*\"grocery\" + 0.018*\"local\" + 0.017*\"purchase\"\n",
      "2021-08-24 16:19:26,496 : INFO : topic #38 (0.020): 0.070*\"bag\" + 0.025*\"container\" + 0.025*\"buy\" + 0.023*\"open\" + 0.021*\"jar\" + 0.019*\"plastic\" + 0.019*\"fresh\" + 0.018*\"package\" + 0.017*\"use\" + 0.014*\"good\"\n",
      "2021-08-24 16:19:26,504 : INFO : topic diff=0.152765, rho=0.154511\n",
      "2021-08-24 16:19:28,398 : INFO : -7.208 per-word bound, 147.9 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:28,472 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:28,499 : INFO : topic #16 (0.020): 0.108*\"sugar\" + 0.041*\"use\" + 0.029*\"sweetener\" + 0.029*\"taste\" + 0.027*\"stevia\" + 0.020*\"splenda\" + 0.020*\"sweet\" + 0.018*\"like\" + 0.016*\"product\" + 0.013*\"good\"\n",
      "2021-08-24 16:19:28,500 : INFO : topic #25 (0.020): 0.038*\"fat\" + 0.035*\"calorie\" + 0.030*\"gram\" + 0.025*\"vitamin\" + 0.025*\"sugar\" + 0.022*\"sodium\" + 0.022*\"mg\" + 0.020*\"contain\" + 0.020*\"ingredient\" + 0.018*\"fiber\"\n",
      "2021-08-24 16:19:28,501 : INFO : topic #26 (0.020): 0.043*\"olive\" + 0.037*\"salad\" + 0.027*\"use\" + 0.026*\"garlic\" + 0.024*\"oil\" + 0.021*\"flavor\" + 0.020*\"good\" + 0.019*\"mix\" + 0.013*\"like\" + 0.013*\"dressing\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:28,502 : INFO : topic #21 (0.020): 0.199*\"tea\" + 0.036*\"green\" + 0.018*\"taste\" + 0.017*\"drink\" + 0.017*\"bag\" + 0.015*\"flavor\" + 0.013*\"like\" + 0.013*\"cup\" + 0.012*\"good\" + 0.010*\"leaf\"\n",
      "2021-08-24 16:19:28,503 : INFO : topic #9 (0.020): 0.042*\"star\" + 0.036*\"licorice\" + 0.025*\"good\" + 0.011*\"black\" + 0.010*\"rating\" + 0.010*\"tasteless\" + 0.008*\"assortment\" + 0.008*\"peppercorn\" + 0.008*\"twist\" + 0.007*\"clam\"\n",
      "2021-08-24 16:19:28,504 : INFO : topic diff=0.153651, rho=0.154511\n",
      "2021-08-24 16:19:29,793 : INFO : -7.189 per-word bound, 145.9 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:29,794 : INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:19:29,805 : INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:19:29,806 : INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-24 16:19:29,807 : INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:19:29,808 : INFO : PROGRESS: pass 18, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:19:29,820 : INFO : PROGRESS: pass 18, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:19:29,822 : INFO : PROGRESS: pass 18, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:19:29,824 : INFO : PROGRESS: pass 18, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:19:29,825 : INFO : PROGRESS: pass 18, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:19:29,837 : INFO : PROGRESS: pass 18, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:19:29,840 : INFO : PROGRESS: pass 18, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:19:29,841 : INFO : PROGRESS: pass 18, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:19:29,843 : INFO : PROGRESS: pass 18, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:19:29,845 : INFO : PROGRESS: pass 18, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:19:29,846 : INFO : PROGRESS: pass 18, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:19:29,863 : INFO : PROGRESS: pass 18, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:19:29,865 : INFO : PROGRESS: pass 18, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:19:29,873 : INFO : PROGRESS: pass 18, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:19:29,876 : INFO : PROGRESS: pass 18, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:19:29,893 : INFO : PROGRESS: pass 18, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:19:29,927 : INFO : PROGRESS: pass 18, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:19:29,957 : INFO : PROGRESS: pass 18, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:19:29,989 : INFO : PROGRESS: pass 18, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:19:30,015 : INFO : PROGRESS: pass 18, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:19:31,860 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:31,897 : INFO : topic #20 (0.020): 0.192*\"milk\" + 0.028*\"powder\" + 0.018*\"use\" + 0.017*\"soy\" + 0.016*\"add\" + 0.012*\"taste\" + 0.012*\"mix\" + 0.011*\"water\" + 0.009*\"like\" + 0.008*\"drink\"\n",
      "2021-08-24 16:19:31,899 : INFO : topic #17 (0.020): 0.155*\"chocolate\" + 0.042*\"dark\" + 0.028*\"caramel\" + 0.024*\"bar\" + 0.024*\"candy\" + 0.019*\"taste\" + 0.018*\"like\" + 0.017*\"good\" + 0.015*\"cocoa\" + 0.015*\"sweet\"\n",
      "2021-08-24 16:19:31,901 : INFO : topic #44 (0.020): 0.044*\"gift\" + 0.042*\"box\" + 0.031*\"wrap\" + 0.020*\"basket\" + 0.019*\"individually\" + 0.014*\"chocolate\" + 0.014*\"look\" + 0.014*\"nice\" + 0.014*\"item\" + 0.013*\"like\"\n",
      "2021-08-24 16:19:31,902 : INFO : topic #29 (0.020): 0.029*\"order\" + 0.026*\"amazon\" + 0.023*\"product\" + 0.015*\"date\" + 0.013*\"year\" + 0.011*\"buy\" + 0.011*\"time\" + 0.009*\"item\" + 0.009*\"month\" + 0.009*\"receive\"\n",
      "2021-08-24 16:19:31,905 : INFO : topic #37 (0.020): 0.034*\"clean\" + 0.020*\"bear\" + 0.018*\"like\" + 0.017*\"mustard\" + 0.015*\"dog\" + 0.015*\"sardine\" + 0.014*\"gummy\" + 0.013*\"pad\" + 0.011*\"handle\" + 0.011*\"use\"\n",
      "2021-08-24 16:19:31,906 : INFO : topic diff=0.145776, rho=0.152699\n",
      "2021-08-24 16:19:34,501 : INFO : -7.197 per-word bound, 146.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:34,611 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:34,659 : INFO : topic #29 (0.020): 0.029*\"order\" + 0.026*\"amazon\" + 0.023*\"product\" + 0.016*\"date\" + 0.014*\"year\" + 0.011*\"buy\" + 0.011*\"time\" + 0.009*\"item\" + 0.009*\"month\" + 0.009*\"receive\"\n",
      "2021-08-24 16:19:34,661 : INFO : topic #18 (0.020): 0.068*\"chip\" + 0.035*\"potato\" + 0.027*\"like\" + 0.021*\"good\" + 0.020*\"taste\" + 0.018*\"flavor\" + 0.017*\"chili\" + 0.014*\"food\" + 0.013*\"eat\" + 0.012*\"dip\"\n",
      "2021-08-24 16:19:34,665 : INFO : topic #5 (0.020): 0.127*\"salt\" + 0.059*\"popcorn\" + 0.023*\"taste\" + 0.023*\"pop\" + 0.022*\"salty\" + 0.021*\"sea\" + 0.020*\"good\" + 0.018*\"use\" + 0.018*\"like\" + 0.018*\"flavor\"\n",
      "2021-08-24 16:19:34,691 : INFO : topic #43 (0.020): 0.075*\"seed\" + 0.023*\"raw\" + 0.021*\"nut\" + 0.019*\"eat\" + 0.018*\"add\" + 0.015*\"product\" + 0.015*\"chia\" + 0.015*\"salmon\" + 0.014*\"good\" + 0.013*\"flax\"\n",
      "2021-08-24 16:19:34,716 : INFO : topic #48 (0.020): 0.045*\"water\" + 0.031*\"taste\" + 0.027*\"bottle\" + 0.026*\"like\" + 0.020*\"product\" + 0.012*\"use\" + 0.012*\"good\" + 0.011*\"flavor\" + 0.010*\"squeeze\" + 0.009*\"try\"\n",
      "2021-08-24 16:19:34,739 : INFO : topic diff=0.138692, rho=0.152699\n",
      "2021-08-24 16:19:36,601 : INFO : -7.205 per-word bound, 147.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:36,680 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:36,708 : INFO : topic #3 (0.020): 0.146*\"mint\" + 0.099*\"oreo\" + 0.034*\"creme\" + 0.025*\"scout\" + 0.021*\"mio\" + 0.021*\"peppermint\" + 0.011*\"flavor\" + 0.011*\"year\" + 0.011*\"similar\" + 0.010*\"sandwich\"\n",
      "2021-08-24 16:19:36,710 : INFO : topic #4 (0.020): 0.025*\"pu\" + 0.024*\"costco\" + 0.023*\"erh\" + 0.018*\"tea\" + 0.016*\"english\" + 0.016*\"breakfast\" + 0.011*\"try\" + 0.010*\"cardamom\" + 0.010*\"brand\" + 0.009*\"numi\"\n",
      "2021-08-24 16:19:36,711 : INFO : topic #21 (0.020): 0.201*\"tea\" + 0.036*\"green\" + 0.018*\"taste\" + 0.017*\"drink\" + 0.016*\"bag\" + 0.015*\"flavor\" + 0.014*\"like\" + 0.013*\"cup\" + 0.012*\"good\" + 0.010*\"leaf\"\n",
      "2021-08-24 16:19:36,712 : INFO : topic #44 (0.020): 0.045*\"gift\" + 0.042*\"box\" + 0.031*\"wrap\" + 0.022*\"basket\" + 0.020*\"individually\" + 0.014*\"item\" + 0.014*\"nice\" + 0.014*\"look\" + 0.014*\"chocolate\" + 0.013*\"like\"\n",
      "2021-08-24 16:19:36,713 : INFO : topic #8 (0.020): 0.059*\"soup\" + 0.037*\"noodle\" + 0.027*\"flavor\" + 0.027*\"like\" + 0.025*\"good\" + 0.022*\"beef\" + 0.020*\"jerky\" + 0.020*\"spicy\" + 0.017*\"taste\" + 0.014*\"eat\"\n",
      "2021-08-24 16:19:36,715 : INFO : topic diff=0.140023, rho=0.152699\n",
      "2021-08-24 16:19:37,931 : INFO : -7.187 per-word bound, 145.7 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:37,932 : INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-24 16:19:37,942 : INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-24 16:19:37,944 : INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:37,945 : INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-24 16:19:37,946 : INFO : PROGRESS: pass 19, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-24 16:19:37,954 : INFO : PROGRESS: pass 19, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-24 16:19:37,958 : INFO : PROGRESS: pass 19, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-24 16:19:37,959 : INFO : PROGRESS: pass 19, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-24 16:19:37,960 : INFO : PROGRESS: pass 19, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-24 16:19:37,961 : INFO : PROGRESS: pass 19, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-24 16:19:37,974 : INFO : PROGRESS: pass 19, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-24 16:19:37,976 : INFO : PROGRESS: pass 19, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-24 16:19:37,978 : INFO : PROGRESS: pass 19, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-24 16:19:37,994 : INFO : PROGRESS: pass 19, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-24 16:19:37,995 : INFO : PROGRESS: pass 19, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-24 16:19:37,996 : INFO : PROGRESS: pass 19, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-24 16:19:37,999 : INFO : PROGRESS: pass 19, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-24 16:19:38,001 : INFO : PROGRESS: pass 19, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-24 16:19:38,002 : INFO : PROGRESS: pass 19, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-24 16:19:38,027 : INFO : PROGRESS: pass 19, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-24 16:19:38,038 : INFO : PROGRESS: pass 19, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-24 16:19:38,093 : INFO : PROGRESS: pass 19, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-24 16:19:38,153 : INFO : PROGRESS: pass 19, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-24 16:19:38,212 : INFO : PROGRESS: pass 19, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-24 16:19:40,499 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:40,536 : INFO : topic #8 (0.020): 0.060*\"soup\" + 0.035*\"noodle\" + 0.027*\"flavor\" + 0.027*\"like\" + 0.025*\"good\" + 0.022*\"jerky\" + 0.022*\"beef\" + 0.020*\"spicy\" + 0.017*\"taste\" + 0.014*\"eat\"\n",
      "2021-08-24 16:19:40,538 : INFO : topic #9 (0.020): 0.048*\"star\" + 0.041*\"licorice\" + 0.024*\"good\" + 0.012*\"rating\" + 0.012*\"black\" + 0.010*\"tasteless\" + 0.009*\"clam\" + 0.009*\"assortment\" + 0.009*\"peppercorn\" + 0.009*\"twist\"\n",
      "2021-08-24 16:19:40,539 : INFO : topic #15 (0.020): 0.114*\"rice\" + 0.053*\"cook\" + 0.031*\"brown\" + 0.018*\"use\" + 0.016*\"noodle\" + 0.014*\"like\" + 0.013*\"oat\" + 0.013*\"grain\" + 0.012*\"try\" + 0.012*\"quinoa\"\n",
      "2021-08-24 16:19:40,540 : INFO : topic #17 (0.020): 0.157*\"chocolate\" + 0.042*\"dark\" + 0.028*\"caramel\" + 0.024*\"bar\" + 0.023*\"candy\" + 0.019*\"taste\" + 0.018*\"like\" + 0.017*\"good\" + 0.016*\"cocoa\" + 0.015*\"sweet\"\n",
      "2021-08-24 16:19:40,542 : INFO : topic #10 (0.020): 0.147*\"free\" + 0.110*\"gluten\" + 0.030*\"bread\" + 0.024*\"good\" + 0.023*\"tuna\" + 0.020*\"eat\" + 0.018*\"product\" + 0.018*\"like\" + 0.017*\"taste\" + 0.017*\"try\"\n",
      "2021-08-24 16:19:40,544 : INFO : topic diff=0.133150, rho=0.150950\n",
      "2021-08-24 16:19:42,988 : INFO : -7.195 per-word bound, 146.6 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:43,113 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:43,162 : INFO : topic #31 (0.020): 0.070*\"cooky\" + 0.044*\"cookie\" + 0.034*\"chocolate\" + 0.029*\"like\" + 0.024*\"taste\" + 0.017*\"good\" + 0.016*\"chip\" + 0.013*\"soft\" + 0.013*\"sweet\" + 0.013*\"fudge\"\n",
      "2021-08-24 16:19:43,165 : INFO : topic #10 (0.020): 0.148*\"free\" + 0.108*\"gluten\" + 0.029*\"bread\" + 0.025*\"tuna\" + 0.024*\"good\" + 0.020*\"eat\" + 0.018*\"product\" + 0.018*\"like\" + 0.017*\"taste\" + 0.016*\"try\"\n",
      "2021-08-24 16:19:43,169 : INFO : topic #16 (0.020): 0.113*\"sugar\" + 0.042*\"use\" + 0.029*\"sweetener\" + 0.029*\"taste\" + 0.027*\"stevia\" + 0.020*\"sweet\" + 0.019*\"splenda\" + 0.018*\"like\" + 0.016*\"product\" + 0.013*\"good\"\n",
      "2021-08-24 16:19:43,176 : INFO : topic #45 (0.020): 0.078*\"pasta\" + 0.024*\"spaghetti\" + 0.022*\"grain\" + 0.022*\"maple\" + 0.022*\"good\" + 0.022*\"barilla\" + 0.021*\"syrup\" + 0.019*\"like\" + 0.016*\"taste\" + 0.016*\"snack\"\n",
      "2021-08-24 16:19:43,183 : INFO : topic #29 (0.020): 0.031*\"order\" + 0.027*\"amazon\" + 0.023*\"product\" + 0.016*\"date\" + 0.014*\"year\" + 0.011*\"buy\" + 0.011*\"time\" + 0.009*\"item\" + 0.009*\"month\" + 0.009*\"receive\"\n",
      "2021-08-24 16:19:43,190 : INFO : topic diff=0.126596, rho=0.150950\n",
      "2021-08-24 16:19:44,832 : INFO : -7.203 per-word bound, 147.4 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:44,904 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-24 16:19:44,934 : INFO : topic #35 (0.020): 0.066*\"red\" + 0.065*\"cake\" + 0.035*\"pizza\" + 0.033*\"bob\" + 0.033*\"crust\" + 0.018*\"mix\" + 0.015*\"good\" + 0.014*\"product\" + 0.013*\"dough\" + 0.011*\"crumb\"\n",
      "2021-08-24 16:19:44,936 : INFO : topic #36 (0.020): 0.087*\"vanilla\" + 0.082*\"coffee\" + 0.063*\"flavor\" + 0.027*\"taste\" + 0.024*\"starbucks\" + 0.020*\"flavored\" + 0.020*\"smell\" + 0.019*\"like\" + 0.016*\"bean\" + 0.012*\"good\"\n",
      "2021-08-24 16:19:44,937 : INFO : topic #23 (0.020): 0.122*\"sauce\" + 0.024*\"like\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.019*\"use\" + 0.017*\"good\" + 0.017*\"chicken\" + 0.016*\"tomato\" + 0.014*\"try\" + 0.013*\"pouch\"\n",
      "2021-08-24 16:19:44,938 : INFO : topic #18 (0.020): 0.070*\"chip\" + 0.035*\"potato\" + 0.027*\"like\" + 0.021*\"good\" + 0.021*\"taste\" + 0.019*\"flavor\" + 0.016*\"chili\" + 0.014*\"food\" + 0.014*\"taco\" + 0.013*\"eat\"\n",
      "2021-08-24 16:19:44,939 : INFO : topic #5 (0.020): 0.124*\"salt\" + 0.066*\"popcorn\" + 0.023*\"pop\" + 0.023*\"salty\" + 0.023*\"taste\" + 0.021*\"sea\" + 0.020*\"good\" + 0.019*\"use\" + 0.018*\"flavor\" + 0.018*\"like\"\n",
      "2021-08-24 16:19:44,941 : INFO : topic diff=0.128372, rho=0.150950\n",
      "2021-08-24 16:19:46,263 : INFO : -7.185 per-word bound, 145.5 perplexity estimate based on a held-out corpus of 1774 documents with 80239 words\n",
      "2021-08-24 16:19:46,281 : INFO : LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=10055, num_topics=50, decay=0.5, chunksize=2000) in 181.61s', 'datetime': '2021-08-24T16:19:46.281030', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=50, id2word=dictionary, passes=20, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "099c932c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:46,288 : INFO : topic #0 (0.020): 0.073*\"box\" + 0.022*\"day\" + 0.021*\"packet\" + 0.019*\"time\" + 0.018*\"open\" + 0.016*\"arrive\" + 0.015*\"good\" + 0.015*\"package\" + 0.014*\"pack\" + 0.011*\"inside\"\n",
      "2021-08-24 16:19:46,289 : INFO : topic #1 (0.020): 0.052*\"add\" + 0.034*\"water\" + 0.028*\"minute\" + 0.019*\"cook\" + 0.017*\"microwave\" + 0.016*\"chicken\" + 0.015*\"cup\" + 0.014*\"stir\" + 0.014*\"meal\" + 0.013*\"use\"\n",
      "2021-08-24 16:19:46,290 : INFO : topic #2 (0.020): 0.065*\"flavor\" + 0.060*\"tea\" + 0.032*\"like\" + 0.025*\"taste\" + 0.017*\"orange\" + 0.017*\"bag\" + 0.016*\"blackberry\" + 0.015*\"vanilla\" + 0.013*\"chai\" + 0.013*\"try\"\n",
      "2021-08-24 16:19:46,292 : INFO : topic #3 (0.020): 0.146*\"mint\" + 0.099*\"oreo\" + 0.034*\"creme\" + 0.026*\"scout\" + 0.023*\"peppermint\" + 0.021*\"mio\" + 0.011*\"flavor\" + 0.011*\"year\" + 0.011*\"similar\" + 0.010*\"sandwich\"\n",
      "2021-08-24 16:19:46,293 : INFO : topic #4 (0.020): 0.025*\"pu\" + 0.024*\"costco\" + 0.023*\"erh\" + 0.017*\"english\" + 0.016*\"tea\" + 0.016*\"breakfast\" + 0.011*\"try\" + 0.010*\"cardamom\" + 0.010*\"brand\" + 0.009*\"american\"\n",
      "2021-08-24 16:19:46,294 : INFO : topic #5 (0.020): 0.124*\"salt\" + 0.066*\"popcorn\" + 0.023*\"pop\" + 0.023*\"salty\" + 0.023*\"taste\" + 0.021*\"sea\" + 0.020*\"good\" + 0.019*\"use\" + 0.018*\"flavor\" + 0.018*\"like\"\n",
      "2021-08-24 16:19:46,294 : INFO : topic #6 (0.020): 0.079*\"cracker\" + 0.078*\"cheese\" + 0.064*\"butter\" + 0.054*\"peanut\" + 0.031*\"taste\" + 0.026*\"like\" + 0.017*\"cheddar\" + 0.015*\"product\" + 0.014*\"good\" + 0.013*\"spread\"\n",
      "2021-08-24 16:19:46,295 : INFO : topic #7 (0.020): 0.076*\"price\" + 0.045*\"store\" + 0.043*\"amazon\" + 0.042*\"buy\" + 0.040*\"good\" + 0.022*\"great\" + 0.020*\"grocery\" + 0.020*\"save\" + 0.019*\"local\" + 0.018*\"brand\"\n",
      "2021-08-24 16:19:46,296 : INFO : topic #8 (0.020): 0.061*\"soup\" + 0.037*\"noodle\" + 0.028*\"flavor\" + 0.027*\"like\" + 0.025*\"good\" + 0.022*\"beef\" + 0.020*\"jerky\" + 0.020*\"spicy\" + 0.017*\"taste\" + 0.014*\"eat\"\n",
      "2021-08-24 16:19:46,297 : INFO : topic #9 (0.020): 0.053*\"star\" + 0.037*\"licorice\" + 0.024*\"good\" + 0.014*\"rating\" + 0.012*\"black\" + 0.010*\"tasteless\" + 0.009*\"assortment\" + 0.008*\"twist\" + 0.008*\"peppercorn\" + 0.007*\"clam\"\n",
      "2021-08-24 16:19:46,298 : INFO : topic #10 (0.020): 0.153*\"free\" + 0.111*\"gluten\" + 0.028*\"bread\" + 0.024*\"good\" + 0.024*\"tuna\" + 0.020*\"eat\" + 0.019*\"product\" + 0.018*\"like\" + 0.017*\"taste\" + 0.016*\"try\"\n",
      "2021-08-24 16:19:46,300 : INFO : topic #11 (0.020): 0.113*\"hot\" + 0.045*\"pepper\" + 0.039*\"sauce\" + 0.035*\"heat\" + 0.016*\"use\" + 0.013*\"flavor\" + 0.011*\"like\" + 0.010*\"add\" + 0.010*\"kick\" + 0.010*\"spicy\"\n",
      "2021-08-24 16:19:46,301 : INFO : topic #12 (0.020): 0.082*\"fruit\" + 0.058*\"oatmeal\" + 0.041*\"bean\" + 0.030*\"dry\" + 0.022*\"like\" + 0.019*\"dried\" + 0.018*\"cranberry\" + 0.015*\"raisin\" + 0.014*\"eat\" + 0.014*\"quaker\"\n",
      "2021-08-24 16:19:46,302 : INFO : topic #13 (0.020): 0.064*\"cereal\" + 0.026*\"like\" + 0.022*\"taste\" + 0.021*\"cinnamon\" + 0.018*\"eat\" + 0.017*\"good\" + 0.015*\"sugar\" + 0.015*\"sweet\" + 0.013*\"flavor\" + 0.013*\"crunchy\"\n",
      "2021-08-24 16:19:46,303 : INFO : topic #14 (0.020): 0.056*\"cream\" + 0.042*\"flavor\" + 0.041*\"ice\" + 0.037*\"like\" + 0.033*\"good\" + 0.033*\"taste\" + 0.030*\"chocolate\" + 0.019*\"sweet\" + 0.018*\"mix\" + 0.016*\"add\"\n",
      "2021-08-24 16:19:46,303 : INFO : topic #15 (0.020): 0.114*\"rice\" + 0.053*\"cook\" + 0.032*\"brown\" + 0.018*\"use\" + 0.017*\"noodle\" + 0.015*\"oat\" + 0.014*\"like\" + 0.013*\"grain\" + 0.013*\"try\" + 0.012*\"white\"\n",
      "2021-08-24 16:19:46,305 : INFO : topic #16 (0.020): 0.112*\"sugar\" + 0.042*\"use\" + 0.030*\"sweetener\" + 0.029*\"taste\" + 0.027*\"stevia\" + 0.021*\"sweet\" + 0.020*\"splenda\" + 0.018*\"like\" + 0.016*\"product\" + 0.013*\"sweeten\"\n",
      "2021-08-24 16:19:46,306 : INFO : topic #17 (0.020): 0.159*\"chocolate\" + 0.042*\"dark\" + 0.029*\"caramel\" + 0.025*\"bar\" + 0.023*\"candy\" + 0.019*\"taste\" + 0.018*\"like\" + 0.017*\"good\" + 0.015*\"cocoa\" + 0.015*\"sweet\"\n",
      "2021-08-24 16:19:46,307 : INFO : topic #18 (0.020): 0.070*\"chip\" + 0.035*\"potato\" + 0.027*\"like\" + 0.021*\"good\" + 0.021*\"taste\" + 0.019*\"flavor\" + 0.016*\"chili\" + 0.014*\"food\" + 0.014*\"taco\" + 0.013*\"eat\"\n",
      "2021-08-24 16:19:46,308 : INFO : topic #19 (0.020): 0.064*\"bar\" + 0.054*\"snack\" + 0.028*\"like\" + 0.023*\"good\" + 0.021*\"eat\" + 0.021*\"taste\" + 0.018*\"nut\" + 0.017*\"flavor\" + 0.016*\"peanut\" + 0.016*\"sweet\"\n",
      "2021-08-24 16:19:46,310 : INFO : topic #20 (0.020): 0.197*\"milk\" + 0.032*\"powder\" + 0.019*\"use\" + 0.017*\"soy\" + 0.017*\"add\" + 0.013*\"mix\" + 0.012*\"taste\" + 0.011*\"water\" + 0.009*\"like\" + 0.008*\"drink\"\n",
      "2021-08-24 16:19:46,311 : INFO : topic #21 (0.020): 0.203*\"tea\" + 0.036*\"green\" + 0.018*\"taste\" + 0.017*\"drink\" + 0.016*\"bag\" + 0.015*\"flavor\" + 0.014*\"like\" + 0.014*\"cup\" + 0.012*\"good\" + 0.010*\"leaf\"\n",
      "2021-08-24 16:19:46,312 : INFO : topic #22 (0.020): 0.134*\"coffee\" + 0.028*\"like\" + 0.024*\"cup\" + 0.022*\"roast\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.019*\"blend\" + 0.017*\"good\" + 0.017*\"strong\" + 0.013*\"bold\"\n",
      "2021-08-24 16:19:46,313 : INFO : topic #23 (0.020): 0.122*\"sauce\" + 0.024*\"like\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.019*\"use\" + 0.017*\"good\" + 0.017*\"chicken\" + 0.016*\"tomato\" + 0.014*\"try\" + 0.013*\"pouch\"\n",
      "2021-08-24 16:19:46,314 : INFO : topic #24 (0.020): 0.042*\"kid\" + 0.030*\"old\" + 0.025*\"eat\" + 0.022*\"candy\" + 0.019*\"like\" + 0.019*\"year\" + 0.017*\"little\" + 0.017*\"child\" + 0.014*\"treat\" + 0.013*\"think\"\n",
      "2021-08-24 16:19:46,315 : INFO : topic #25 (0.020): 0.043*\"fat\" + 0.038*\"calorie\" + 0.032*\"gram\" + 0.026*\"sugar\" + 0.024*\"vitamin\" + 0.023*\"sodium\" + 0.022*\"mg\" + 0.020*\"contain\" + 0.020*\"fiber\" + 0.019*\"ingredient\"\n",
      "2021-08-24 16:19:46,316 : INFO : topic #26 (0.020): 0.043*\"olive\" + 0.038*\"salad\" + 0.028*\"use\" + 0.027*\"garlic\" + 0.025*\"oil\" + 0.021*\"flavor\" + 0.019*\"good\" + 0.019*\"mix\" + 0.013*\"like\" + 0.013*\"fresh\"\n",
      "2021-08-24 16:19:46,317 : INFO : topic #27 (0.020): 0.098*\"mix\" + 0.061*\"cherry\" + 0.043*\"pancake\" + 0.024*\"like\" + 0.023*\"tart\" + 0.019*\"pumpkin\" + 0.018*\"muffin\" + 0.018*\"blueberry\" + 0.016*\"waffle\" + 0.015*\"taste\"\n",
      "2021-08-24 16:19:46,318 : INFO : topic #28 (0.020): 0.090*\"cup\" + 0.068*\"coffee\" + 0.017*\"like\" + 0.016*\"instant\" + 0.016*\"use\" + 0.015*\"good\" + 0.015*\"flavor\" + 0.014*\"taste\" + 0.014*\"hot\" + 0.012*\"try\"\n",
      "2021-08-24 16:19:46,319 : INFO : topic #29 (0.020): 0.031*\"order\" + 0.027*\"amazon\" + 0.024*\"product\" + 0.015*\"date\" + 0.013*\"year\" + 0.011*\"buy\" + 0.011*\"time\" + 0.009*\"item\" + 0.009*\"receive\" + 0.009*\"month\"\n",
      "2021-08-24 16:19:46,320 : INFO : topic #30 (0.020): 0.028*\"grey\" + 0.026*\"earl\" + 0.021*\"bring\" + 0.015*\"flavor\" + 0.012*\"memory\" + 0.011*\"sister\" + 0.011*\"law\" + 0.011*\"mother\" + 0.010*\"like\" + 0.010*\"bergamot\"\n",
      "2021-08-24 16:19:46,321 : INFO : topic #31 (0.020): 0.071*\"cooky\" + 0.046*\"cookie\" + 0.034*\"chocolate\" + 0.030*\"like\" + 0.024*\"taste\" + 0.017*\"good\" + 0.017*\"chip\" + 0.015*\"fudge\" + 0.014*\"soft\" + 0.013*\"sweet\"\n",
      "2021-08-24 16:19:46,322 : INFO : topic #32 (0.020): 0.197*\"organic\" + 0.030*\"food\" + 0.027*\"product\" + 0.024*\"company\" + 0.021*\"use\" + 0.018*\"spice\" + 0.017*\"brand\" + 0.014*\"non\" + 0.014*\"gmo\" + 0.012*\"certify\"\n",
      "2021-08-24 16:19:46,323 : INFO : topic #33 (0.020): 0.048*\"taste\" + 0.038*\"review\" + 0.032*\"try\" + 0.028*\"like\" + 0.024*\"product\" + 0.017*\"bad\" + 0.015*\"think\" + 0.012*\"buy\" + 0.012*\"know\" + 0.011*\"read\"\n",
      "2021-08-24 16:19:46,325 : INFO : topic #34 (0.020): 0.027*\"fat\" + 0.025*\"calorie\" + 0.023*\"low\" + 0.022*\"high\" + 0.021*\"protein\" + 0.019*\"consume\" + 0.017*\"diet\" + 0.017*\"food\" + 0.015*\"weight\" + 0.014*\"nutrient\"\n",
      "2021-08-24 16:19:46,326 : INFO : topic #35 (0.020): 0.066*\"red\" + 0.065*\"cake\" + 0.035*\"pizza\" + 0.033*\"bob\" + 0.033*\"crust\" + 0.018*\"mix\" + 0.015*\"good\" + 0.014*\"product\" + 0.013*\"dough\" + 0.011*\"crumb\"\n",
      "2021-08-24 16:19:46,327 : INFO : topic #36 (0.020): 0.087*\"vanilla\" + 0.082*\"coffee\" + 0.063*\"flavor\" + 0.027*\"taste\" + 0.024*\"starbucks\" + 0.020*\"flavored\" + 0.020*\"smell\" + 0.019*\"like\" + 0.016*\"bean\" + 0.012*\"good\"\n",
      "2021-08-24 16:19:46,328 : INFO : topic #37 (0.020): 0.037*\"clean\" + 0.020*\"bear\" + 0.017*\"mustard\" + 0.017*\"like\" + 0.015*\"dog\" + 0.014*\"pad\" + 0.014*\"gummy\" + 0.014*\"sardine\" + 0.012*\"handle\" + 0.012*\"use\"\n",
      "2021-08-24 16:19:46,329 : INFO : topic #38 (0.020): 0.079*\"bag\" + 0.024*\"container\" + 0.024*\"open\" + 0.023*\"buy\" + 0.021*\"plastic\" + 0.020*\"jar\" + 0.019*\"fresh\" + 0.019*\"package\" + 0.017*\"use\" + 0.014*\"small\"\n",
      "2021-08-24 16:19:46,330 : INFO : topic #39 (0.020): 0.115*\"love\" + 0.106*\"great\" + 0.042*\"taste\" + 0.041*\"good\" + 0.024*\"recommend\" + 0.023*\"product\" + 0.022*\"like\" + 0.021*\"easy\" + 0.020*\"flavor\" + 0.018*\"buy\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:46,331 : INFO : topic #40 (0.020): 0.086*\"almond\" + 0.055*\"flavor\" + 0.034*\"nut\" + 0.019*\"lemon\" + 0.015*\"taste\" + 0.014*\"peach\" + 0.014*\"like\" + 0.013*\"good\" + 0.013*\"aid\" + 0.012*\"try\"\n",
      "2021-08-24 16:19:46,332 : INFO : topic #41 (0.020): 0.087*\"drink\" + 0.039*\"energy\" + 0.038*\"taste\" + 0.030*\"like\" + 0.027*\"juice\" + 0.024*\"flavor\" + 0.017*\"good\" + 0.015*\"caffeine\" + 0.012*\"apple\" + 0.012*\"try\"\n",
      "2021-08-24 16:19:46,333 : INFO : topic #42 (0.020): 0.126*\"oil\" + 0.104*\"coconut\" + 0.036*\"use\" + 0.012*\"skin\" + 0.012*\"palm\" + 0.011*\"fat\" + 0.010*\"hair\" + 0.009*\"cook\" + 0.008*\"food\" + 0.008*\"product\"\n",
      "2021-08-24 16:19:46,334 : INFO : topic #43 (0.020): 0.078*\"seed\" + 0.022*\"raw\" + 0.020*\"eat\" + 0.019*\"nut\" + 0.019*\"chia\" + 0.019*\"add\" + 0.015*\"product\" + 0.014*\"flax\" + 0.014*\"salmon\" + 0.014*\"good\"\n",
      "2021-08-24 16:19:46,334 : INFO : topic #44 (0.020): 0.045*\"gift\" + 0.043*\"box\" + 0.031*\"wrap\" + 0.022*\"basket\" + 0.020*\"individually\" + 0.015*\"item\" + 0.015*\"nice\" + 0.014*\"look\" + 0.013*\"like\" + 0.012*\"chocolate\"\n",
      "2021-08-24 16:19:46,335 : INFO : topic #45 (0.020): 0.078*\"pasta\" + 0.023*\"spaghetti\" + 0.022*\"grain\" + 0.022*\"maple\" + 0.022*\"good\" + 0.021*\"syrup\" + 0.020*\"barilla\" + 0.019*\"like\" + 0.016*\"taste\" + 0.016*\"snack\"\n",
      "2021-08-24 16:19:46,336 : INFO : topic #46 (0.020): 0.055*\"ingredient\" + 0.045*\"product\" + 0.024*\"list\" + 0.021*\"corn\" + 0.016*\"high\" + 0.016*\"natural\" + 0.016*\"syrup\" + 0.016*\"flavor\" + 0.014*\"label\" + 0.010*\"like\"\n",
      "2021-08-24 16:19:46,337 : INFO : topic #47 (0.020): 0.095*\"use\" + 0.053*\"bake\" + 0.050*\"recipe\" + 0.049*\"flour\" + 0.039*\"bread\" + 0.020*\"powder\" + 0.017*\"add\" + 0.015*\"mix\" + 0.015*\"shake\" + 0.014*\"work\"\n",
      "2021-08-24 16:19:46,338 : INFO : topic #48 (0.020): 0.048*\"water\" + 0.031*\"taste\" + 0.029*\"bottle\" + 0.026*\"like\" + 0.020*\"product\" + 0.013*\"squeeze\" + 0.013*\"use\" + 0.012*\"flavor\" + 0.012*\"good\" + 0.009*\"try\"\n",
      "2021-08-24 16:19:46,340 : INFO : topic #49 (0.020): 0.164*\"honey\" + 0.057*\"ginger\" + 0.026*\"raw\" + 0.023*\"pork\" + 0.018*\"mango\" + 0.016*\"taste\" + 0.014*\"chop\" + 0.014*\"sweet\" + 0.013*\"use\" + 0.010*\"like\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0, Words: 0.073*\"box\" + 0.022*\"day\" + 0.021*\"packet\" + 0.019*\"time\" + 0.018*\"open\" + 0.016*\"arrive\" + 0.015*\"good\" + 0.015*\"package\" + 0.014*\"pack\" + 0.011*\"inside\"\n",
      "Topic: 1, Words: 0.052*\"add\" + 0.034*\"water\" + 0.028*\"minute\" + 0.019*\"cook\" + 0.017*\"microwave\" + 0.016*\"chicken\" + 0.015*\"cup\" + 0.014*\"stir\" + 0.014*\"meal\" + 0.013*\"use\"\n",
      "Topic: 2, Words: 0.065*\"flavor\" + 0.060*\"tea\" + 0.032*\"like\" + 0.025*\"taste\" + 0.017*\"orange\" + 0.017*\"bag\" + 0.016*\"blackberry\" + 0.015*\"vanilla\" + 0.013*\"chai\" + 0.013*\"try\"\n",
      "Topic: 3, Words: 0.146*\"mint\" + 0.099*\"oreo\" + 0.034*\"creme\" + 0.026*\"scout\" + 0.023*\"peppermint\" + 0.021*\"mio\" + 0.011*\"flavor\" + 0.011*\"year\" + 0.011*\"similar\" + 0.010*\"sandwich\"\n",
      "Topic: 4, Words: 0.025*\"pu\" + 0.024*\"costco\" + 0.023*\"erh\" + 0.017*\"english\" + 0.016*\"tea\" + 0.016*\"breakfast\" + 0.011*\"try\" + 0.010*\"cardamom\" + 0.010*\"brand\" + 0.009*\"american\"\n",
      "Topic: 5, Words: 0.124*\"salt\" + 0.066*\"popcorn\" + 0.023*\"pop\" + 0.023*\"salty\" + 0.023*\"taste\" + 0.021*\"sea\" + 0.020*\"good\" + 0.019*\"use\" + 0.018*\"flavor\" + 0.018*\"like\"\n",
      "Topic: 6, Words: 0.079*\"cracker\" + 0.078*\"cheese\" + 0.064*\"butter\" + 0.054*\"peanut\" + 0.031*\"taste\" + 0.026*\"like\" + 0.017*\"cheddar\" + 0.015*\"product\" + 0.014*\"good\" + 0.013*\"spread\"\n",
      "Topic: 7, Words: 0.076*\"price\" + 0.045*\"store\" + 0.043*\"amazon\" + 0.042*\"buy\" + 0.040*\"good\" + 0.022*\"great\" + 0.020*\"grocery\" + 0.020*\"save\" + 0.019*\"local\" + 0.018*\"brand\"\n",
      "Topic: 8, Words: 0.061*\"soup\" + 0.037*\"noodle\" + 0.028*\"flavor\" + 0.027*\"like\" + 0.025*\"good\" + 0.022*\"beef\" + 0.020*\"jerky\" + 0.020*\"spicy\" + 0.017*\"taste\" + 0.014*\"eat\"\n",
      "Topic: 9, Words: 0.053*\"star\" + 0.037*\"licorice\" + 0.024*\"good\" + 0.014*\"rating\" + 0.012*\"black\" + 0.010*\"tasteless\" + 0.009*\"assortment\" + 0.008*\"twist\" + 0.008*\"peppercorn\" + 0.007*\"clam\"\n",
      "Topic: 10, Words: 0.153*\"free\" + 0.111*\"gluten\" + 0.028*\"bread\" + 0.024*\"good\" + 0.024*\"tuna\" + 0.020*\"eat\" + 0.019*\"product\" + 0.018*\"like\" + 0.017*\"taste\" + 0.016*\"try\"\n",
      "Topic: 11, Words: 0.113*\"hot\" + 0.045*\"pepper\" + 0.039*\"sauce\" + 0.035*\"heat\" + 0.016*\"use\" + 0.013*\"flavor\" + 0.011*\"like\" + 0.010*\"add\" + 0.010*\"kick\" + 0.010*\"spicy\"\n",
      "Topic: 12, Words: 0.082*\"fruit\" + 0.058*\"oatmeal\" + 0.041*\"bean\" + 0.030*\"dry\" + 0.022*\"like\" + 0.019*\"dried\" + 0.018*\"cranberry\" + 0.015*\"raisin\" + 0.014*\"eat\" + 0.014*\"quaker\"\n",
      "Topic: 13, Words: 0.064*\"cereal\" + 0.026*\"like\" + 0.022*\"taste\" + 0.021*\"cinnamon\" + 0.018*\"eat\" + 0.017*\"good\" + 0.015*\"sugar\" + 0.015*\"sweet\" + 0.013*\"flavor\" + 0.013*\"crunchy\"\n",
      "Topic: 14, Words: 0.056*\"cream\" + 0.042*\"flavor\" + 0.041*\"ice\" + 0.037*\"like\" + 0.033*\"good\" + 0.033*\"taste\" + 0.030*\"chocolate\" + 0.019*\"sweet\" + 0.018*\"mix\" + 0.016*\"add\"\n",
      "Topic: 15, Words: 0.114*\"rice\" + 0.053*\"cook\" + 0.032*\"brown\" + 0.018*\"use\" + 0.017*\"noodle\" + 0.015*\"oat\" + 0.014*\"like\" + 0.013*\"grain\" + 0.013*\"try\" + 0.012*\"white\"\n",
      "Topic: 16, Words: 0.112*\"sugar\" + 0.042*\"use\" + 0.030*\"sweetener\" + 0.029*\"taste\" + 0.027*\"stevia\" + 0.021*\"sweet\" + 0.020*\"splenda\" + 0.018*\"like\" + 0.016*\"product\" + 0.013*\"sweeten\"\n",
      "Topic: 17, Words: 0.159*\"chocolate\" + 0.042*\"dark\" + 0.029*\"caramel\" + 0.025*\"bar\" + 0.023*\"candy\" + 0.019*\"taste\" + 0.018*\"like\" + 0.017*\"good\" + 0.015*\"cocoa\" + 0.015*\"sweet\"\n",
      "Topic: 18, Words: 0.070*\"chip\" + 0.035*\"potato\" + 0.027*\"like\" + 0.021*\"good\" + 0.021*\"taste\" + 0.019*\"flavor\" + 0.016*\"chili\" + 0.014*\"food\" + 0.014*\"taco\" + 0.013*\"eat\"\n",
      "Topic: 19, Words: 0.064*\"bar\" + 0.054*\"snack\" + 0.028*\"like\" + 0.023*\"good\" + 0.021*\"eat\" + 0.021*\"taste\" + 0.018*\"nut\" + 0.017*\"flavor\" + 0.016*\"peanut\" + 0.016*\"sweet\"\n",
      "Topic: 20, Words: 0.197*\"milk\" + 0.032*\"powder\" + 0.019*\"use\" + 0.017*\"soy\" + 0.017*\"add\" + 0.013*\"mix\" + 0.012*\"taste\" + 0.011*\"water\" + 0.009*\"like\" + 0.008*\"drink\"\n",
      "Topic: 21, Words: 0.203*\"tea\" + 0.036*\"green\" + 0.018*\"taste\" + 0.017*\"drink\" + 0.016*\"bag\" + 0.015*\"flavor\" + 0.014*\"like\" + 0.014*\"cup\" + 0.012*\"good\" + 0.010*\"leaf\"\n",
      "Topic: 22, Words: 0.134*\"coffee\" + 0.028*\"like\" + 0.024*\"cup\" + 0.022*\"roast\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.019*\"blend\" + 0.017*\"good\" + 0.017*\"strong\" + 0.013*\"bold\"\n",
      "Topic: 23, Words: 0.122*\"sauce\" + 0.024*\"like\" + 0.020*\"flavor\" + 0.019*\"taste\" + 0.019*\"use\" + 0.017*\"good\" + 0.017*\"chicken\" + 0.016*\"tomato\" + 0.014*\"try\" + 0.013*\"pouch\"\n",
      "Topic: 24, Words: 0.042*\"kid\" + 0.030*\"old\" + 0.025*\"eat\" + 0.022*\"candy\" + 0.019*\"like\" + 0.019*\"year\" + 0.017*\"little\" + 0.017*\"child\" + 0.014*\"treat\" + 0.013*\"think\"\n",
      "Topic: 25, Words: 0.043*\"fat\" + 0.038*\"calorie\" + 0.032*\"gram\" + 0.026*\"sugar\" + 0.024*\"vitamin\" + 0.023*\"sodium\" + 0.022*\"mg\" + 0.020*\"contain\" + 0.020*\"fiber\" + 0.019*\"ingredient\"\n",
      "Topic: 26, Words: 0.043*\"olive\" + 0.038*\"salad\" + 0.028*\"use\" + 0.027*\"garlic\" + 0.025*\"oil\" + 0.021*\"flavor\" + 0.019*\"good\" + 0.019*\"mix\" + 0.013*\"like\" + 0.013*\"fresh\"\n",
      "Topic: 27, Words: 0.098*\"mix\" + 0.061*\"cherry\" + 0.043*\"pancake\" + 0.024*\"like\" + 0.023*\"tart\" + 0.019*\"pumpkin\" + 0.018*\"muffin\" + 0.018*\"blueberry\" + 0.016*\"waffle\" + 0.015*\"taste\"\n",
      "Topic: 28, Words: 0.090*\"cup\" + 0.068*\"coffee\" + 0.017*\"like\" + 0.016*\"instant\" + 0.016*\"use\" + 0.015*\"good\" + 0.015*\"flavor\" + 0.014*\"taste\" + 0.014*\"hot\" + 0.012*\"try\"\n",
      "Topic: 29, Words: 0.031*\"order\" + 0.027*\"amazon\" + 0.024*\"product\" + 0.015*\"date\" + 0.013*\"year\" + 0.011*\"buy\" + 0.011*\"time\" + 0.009*\"item\" + 0.009*\"receive\" + 0.009*\"month\"\n",
      "Topic: 30, Words: 0.028*\"grey\" + 0.026*\"earl\" + 0.021*\"bring\" + 0.015*\"flavor\" + 0.012*\"memory\" + 0.011*\"sister\" + 0.011*\"law\" + 0.011*\"mother\" + 0.010*\"like\" + 0.010*\"bergamot\"\n",
      "Topic: 31, Words: 0.071*\"cooky\" + 0.046*\"cookie\" + 0.034*\"chocolate\" + 0.030*\"like\" + 0.024*\"taste\" + 0.017*\"good\" + 0.017*\"chip\" + 0.015*\"fudge\" + 0.014*\"soft\" + 0.013*\"sweet\"\n",
      "Topic: 32, Words: 0.197*\"organic\" + 0.030*\"food\" + 0.027*\"product\" + 0.024*\"company\" + 0.021*\"use\" + 0.018*\"spice\" + 0.017*\"brand\" + 0.014*\"non\" + 0.014*\"gmo\" + 0.012*\"certify\"\n",
      "Topic: 33, Words: 0.048*\"taste\" + 0.038*\"review\" + 0.032*\"try\" + 0.028*\"like\" + 0.024*\"product\" + 0.017*\"bad\" + 0.015*\"think\" + 0.012*\"buy\" + 0.012*\"know\" + 0.011*\"read\"\n",
      "Topic: 34, Words: 0.027*\"fat\" + 0.025*\"calorie\" + 0.023*\"low\" + 0.022*\"high\" + 0.021*\"protein\" + 0.019*\"consume\" + 0.017*\"diet\" + 0.017*\"food\" + 0.015*\"weight\" + 0.014*\"nutrient\"\n",
      "Topic: 35, Words: 0.066*\"red\" + 0.065*\"cake\" + 0.035*\"pizza\" + 0.033*\"bob\" + 0.033*\"crust\" + 0.018*\"mix\" + 0.015*\"good\" + 0.014*\"product\" + 0.013*\"dough\" + 0.011*\"crumb\"\n",
      "Topic: 36, Words: 0.087*\"vanilla\" + 0.082*\"coffee\" + 0.063*\"flavor\" + 0.027*\"taste\" + 0.024*\"starbucks\" + 0.020*\"flavored\" + 0.020*\"smell\" + 0.019*\"like\" + 0.016*\"bean\" + 0.012*\"good\"\n",
      "Topic: 37, Words: 0.037*\"clean\" + 0.020*\"bear\" + 0.017*\"mustard\" + 0.017*\"like\" + 0.015*\"dog\" + 0.014*\"pad\" + 0.014*\"gummy\" + 0.014*\"sardine\" + 0.012*\"handle\" + 0.012*\"use\"\n",
      "Topic: 38, Words: 0.079*\"bag\" + 0.024*\"container\" + 0.024*\"open\" + 0.023*\"buy\" + 0.021*\"plastic\" + 0.020*\"jar\" + 0.019*\"fresh\" + 0.019*\"package\" + 0.017*\"use\" + 0.014*\"small\"\n",
      "Topic: 39, Words: 0.115*\"love\" + 0.106*\"great\" + 0.042*\"taste\" + 0.041*\"good\" + 0.024*\"recommend\" + 0.023*\"product\" + 0.022*\"like\" + 0.021*\"easy\" + 0.020*\"flavor\" + 0.018*\"buy\"\n",
      "Topic: 40, Words: 0.086*\"almond\" + 0.055*\"flavor\" + 0.034*\"nut\" + 0.019*\"lemon\" + 0.015*\"taste\" + 0.014*\"peach\" + 0.014*\"like\" + 0.013*\"good\" + 0.013*\"aid\" + 0.012*\"try\"\n",
      "Topic: 41, Words: 0.087*\"drink\" + 0.039*\"energy\" + 0.038*\"taste\" + 0.030*\"like\" + 0.027*\"juice\" + 0.024*\"flavor\" + 0.017*\"good\" + 0.015*\"caffeine\" + 0.012*\"apple\" + 0.012*\"try\"\n",
      "Topic: 42, Words: 0.126*\"oil\" + 0.104*\"coconut\" + 0.036*\"use\" + 0.012*\"skin\" + 0.012*\"palm\" + 0.011*\"fat\" + 0.010*\"hair\" + 0.009*\"cook\" + 0.008*\"food\" + 0.008*\"product\"\n",
      "Topic: 43, Words: 0.078*\"seed\" + 0.022*\"raw\" + 0.020*\"eat\" + 0.019*\"nut\" + 0.019*\"chia\" + 0.019*\"add\" + 0.015*\"product\" + 0.014*\"flax\" + 0.014*\"salmon\" + 0.014*\"good\"\n",
      "Topic: 44, Words: 0.045*\"gift\" + 0.043*\"box\" + 0.031*\"wrap\" + 0.022*\"basket\" + 0.020*\"individually\" + 0.015*\"item\" + 0.015*\"nice\" + 0.014*\"look\" + 0.013*\"like\" + 0.012*\"chocolate\"\n",
      "Topic: 45, Words: 0.078*\"pasta\" + 0.023*\"spaghetti\" + 0.022*\"grain\" + 0.022*\"maple\" + 0.022*\"good\" + 0.021*\"syrup\" + 0.020*\"barilla\" + 0.019*\"like\" + 0.016*\"taste\" + 0.016*\"snack\"\n",
      "Topic: 46, Words: 0.055*\"ingredient\" + 0.045*\"product\" + 0.024*\"list\" + 0.021*\"corn\" + 0.016*\"high\" + 0.016*\"natural\" + 0.016*\"syrup\" + 0.016*\"flavor\" + 0.014*\"label\" + 0.010*\"like\"\n",
      "Topic: 47, Words: 0.095*\"use\" + 0.053*\"bake\" + 0.050*\"recipe\" + 0.049*\"flour\" + 0.039*\"bread\" + 0.020*\"powder\" + 0.017*\"add\" + 0.015*\"mix\" + 0.015*\"shake\" + 0.014*\"work\"\n",
      "Topic: 48, Words: 0.048*\"water\" + 0.031*\"taste\" + 0.029*\"bottle\" + 0.026*\"like\" + 0.020*\"product\" + 0.013*\"squeeze\" + 0.013*\"use\" + 0.012*\"flavor\" + 0.012*\"good\" + 0.009*\"try\"\n",
      "Topic: 49, Words: 0.164*\"honey\" + 0.057*\"ginger\" + 0.026*\"raw\" + 0.023*\"pork\" + 0.018*\"mango\" + 0.016*\"taste\" + 0.014*\"chop\" + 0.014*\"sweet\" + 0.013*\"use\" + 0.010*\"like\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic: {idx}, Words: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d7f26ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-24 16:19:46,395 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "2021-08-24 16:19:46,412 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "2021-08-24 16:19:46,434 : INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "2021-08-24 16:19:46,453 : INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "2021-08-24 16:19:46,478 : INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "2021-08-24 16:19:46,497 : INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "2021-08-24 16:19:46,516 : INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "2021-08-24 16:19:46,538 : INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "2021-08-24 16:19:46,560 : INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "2021-08-24 16:19:46,579 : INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "2021-08-24 16:19:46,596 : INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "2021-08-24 16:19:46,615 : INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "2021-08-24 16:19:46,634 : INFO : CorpusAccumulator accumulated stats from 13000 documents\n",
      "2021-08-24 16:19:46,654 : INFO : CorpusAccumulator accumulated stats from 14000 documents\n",
      "2021-08-24 16:19:46,679 : INFO : CorpusAccumulator accumulated stats from 15000 documents\n",
      "2021-08-24 16:19:46,701 : INFO : CorpusAccumulator accumulated stats from 16000 documents\n",
      "2021-08-24 16:19:46,721 : INFO : CorpusAccumulator accumulated stats from 17000 documents\n",
      "2021-08-24 16:19:46,741 : INFO : CorpusAccumulator accumulated stats from 18000 documents\n",
      "2021-08-24 16:19:46,761 : INFO : CorpusAccumulator accumulated stats from 19000 documents\n",
      "2021-08-24 16:19:46,783 : INFO : CorpusAccumulator accumulated stats from 20000 documents\n",
      "2021-08-24 16:19:46,804 : INFO : CorpusAccumulator accumulated stats from 21000 documents\n",
      "2021-08-24 16:19:46,826 : INFO : CorpusAccumulator accumulated stats from 22000 documents\n",
      "2021-08-24 16:19:46,849 : INFO : CorpusAccumulator accumulated stats from 23000 documents\n",
      "2021-08-24 16:19:46,869 : INFO : CorpusAccumulator accumulated stats from 24000 documents\n",
      "2021-08-24 16:19:46,890 : INFO : CorpusAccumulator accumulated stats from 25000 documents\n",
      "2021-08-24 16:19:46,909 : INFO : CorpusAccumulator accumulated stats from 26000 documents\n",
      "2021-08-24 16:19:46,930 : INFO : CorpusAccumulator accumulated stats from 27000 documents\n",
      "2021-08-24 16:19:46,951 : INFO : CorpusAccumulator accumulated stats from 28000 documents\n",
      "2021-08-24 16:19:46,968 : INFO : CorpusAccumulator accumulated stats from 29000 documents\n",
      "2021-08-24 16:19:46,990 : INFO : CorpusAccumulator accumulated stats from 30000 documents\n",
      "2021-08-24 16:19:47,009 : INFO : CorpusAccumulator accumulated stats from 31000 documents\n",
      "2021-08-24 16:19:47,032 : INFO : CorpusAccumulator accumulated stats from 32000 documents\n",
      "2021-08-24 16:19:47,051 : INFO : CorpusAccumulator accumulated stats from 33000 documents\n",
      "2021-08-24 16:19:47,071 : INFO : CorpusAccumulator accumulated stats from 34000 documents\n",
      "2021-08-24 16:19:47,091 : INFO : CorpusAccumulator accumulated stats from 35000 documents\n",
      "2021-08-24 16:19:47,115 : INFO : CorpusAccumulator accumulated stats from 36000 documents\n",
      "2021-08-24 16:19:47,139 : INFO : CorpusAccumulator accumulated stats from 37000 documents\n",
      "2021-08-24 16:19:47,161 : INFO : CorpusAccumulator accumulated stats from 38000 documents\n",
      "2021-08-24 16:19:47,181 : INFO : CorpusAccumulator accumulated stats from 39000 documents\n",
      "2021-08-24 16:19:47,203 : INFO : CorpusAccumulator accumulated stats from 40000 documents\n",
      "2021-08-24 16:19:47,226 : INFO : CorpusAccumulator accumulated stats from 41000 documents\n",
      "2021-08-24 16:19:47,245 : INFO : CorpusAccumulator accumulated stats from 42000 documents\n",
      "2021-08-24 16:19:47,267 : INFO : CorpusAccumulator accumulated stats from 43000 documents\n",
      "2021-08-24 16:19:47,289 : INFO : CorpusAccumulator accumulated stats from 44000 documents\n",
      "2021-08-24 16:19:47,312 : INFO : CorpusAccumulator accumulated stats from 45000 documents\n",
      "2021-08-24 16:19:47,334 : INFO : CorpusAccumulator accumulated stats from 46000 documents\n",
      "2021-08-24 16:19:47,354 : INFO : CorpusAccumulator accumulated stats from 47000 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -2.773395173084744\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e2951",
   "metadata": {},
   "source": [
    "# Retrieving User/Item Topic Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c94bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews = train.groupby([\"reviewerID\"])['processedReviewText'].apply(lambda x: ' '.join(x))\n",
    "item_reviews = train.groupby([\"asin\"])[\"processedReviewText\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# get unique users and items\n",
    "unique_users = user_reviews.index.tolist()\n",
    "unique_items = item_reviews.index.tolist()\n",
    "\n",
    "# tokenize reviews\n",
    "user_reviews_list = user_reviews.apply(lambda x: x.split()).tolist()\n",
    "item_reviews_list = item_reviews.apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df5a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random user:\n",
      "happy amazon com store area buy year come price right peanut addict love product lightly salt ounce jar cheap big discount store handy way sparkling water ups man product truly delicious taste like plain carbonated water add flavor thoroughly mix little serve package wyler crystal light miro little plain water pour talkingrain orange lemon calorie light soda shipment package properly damage leak amazon care send replacement shipment right away arrive thoroughly bubble wrapped proper size box reorder fine product\n",
      "\n",
      "Random item:\n",
      "start love annie chun udon soup march amazon grocery list month read bad review guy know great order chun soup noodle bowl order future annie chun cute talented woman st asian female admire read story soup noodle second time amazon com normally like udon noodle noodle annie chun kim chi soup noodle bowl good broth sour spicy taste like kim chi great udon noodle noodle dehydrate like instant soup pretty good consider bowl require refrigeration hotness meter medium hot flavor easy open package place bowl add water stick microwave minute probably order finish batch annie chun kimchi soup noodle bowl delicious taste korea convenient organic turn annie chun korean like raw foodist ani phyo comedienne margaret cho instant meal nod korean upbringing soup warm delicious noodle good drawback kimchi kind blah add kimchi dehydrate straight jar kimchi soup noodle bowl fun fast good soup bowl good flavor job sit afghanistan think far bad convenient food actually yummy tangy bit plenty noodle easy prepare adequate veggie reason eat spicy good tasting instant soup bowl vegetarian easy bowl add cup boil water delicious meal minute instant udon taste okay add thing red pepper flake meat mushroom decent fan instant noodle cup ramen try tom yum want try enjoy flavor hint lime nice spicy expect like hot spicy food want stay away good level spicyness unbearable like spicyness try rat star spicy enjoyable mass produce instant udon probably good instant easy prepare self contain excellent healthy quick fix pinch taste pretty good guilt free natural cholesterol free virtually fat free measly vegan traditional udon fish seafood extract base broth worry sodium restriction high blood pressure salt content serving daily sodium intake respectable comparison instant noodle product like ramen typically rdi people drink ramen noodle water know good product deliver japanese authenticity quality claim udon fairly standard issue material factory totally ordinary come clear vacuum seal pouch like asian supermarket udon brand worth comment white flavorless like rest seasoning product stand dozen try year include time japan bag liquid soup base freeze dried block vegetable impress veggie block low quality brand use soup powder salt msg maybe fleck scallion carrot soup taste bit shiitake spinach scallion ingredient sort dissolve soup notice fried tofu age dofu taste taste oil bit like old unlike reviewer taste bland issue product japanese cuisine typically lean neutral muted compare world cuisine like thai korean mexican udon suppose pungent spicy certainly add liking preparation direction needlessly complex skip step achieve result bowl pour boil water loosen noodle utensil let sit mins need drain mess reviewer complain awkward cover microwave water mug dump mug lastly feel good support company believe environmental responsibility sustainable consumerism box recycled paper bowl kind biodegradable cornstarch reuse bowl time thing reuse enviro friendly recycle reason product star instead serve economy pack filling adult male average weight noodle portion bit skimpy need time noodle volume meal big eater suppose price right high quality ingredient hurry want prepare udon cheaply buy pack ofmyojo udon japanese style noodle soup base oriental flavor ounce bag pack andkikkoman tsuyu add shrimp tempura chop scallion raw egg quail egg popular kansai region japan goshoku natural cut fueru wakame seaweed favorite choice topping literally thousand way enjoy udon thing sure slurp noodle consider normal japan box encourage favorite like green olive marinate artichoke heart extra mince garlic good spicey hot pantry like soup tasty convenient cheap buy amazon send daughter quick work lunch son liikes school snack sodium bit high good instant noodle good earthquake emergency kit need water rehydrate love soup low salt hard good soup hand great sick add little hot sauce amp heat highly recommend korean think try kimchi bowl lieu traditional ramen load preservative msg bowl ok taste like gochujang red hot chili paste kimchi pretty spicy finish broth share fine spice level buy eat delicious order high hop flavor reminiscent thai tom yum enjoy taste freeze dry veggie stringy bowl reorder opinion tastebud hop refine recipe like idea bit strange mix kimchi japanese udon noodles noodle ok break section dosage hot water try avoid breakage little success overall taste ok recommend purchase kimchi flavor ramen style noodle instead order great taste love texture udon noodle add fresh slice crimini mushroom bowl microwave soup dimension great flavor navy like send care package noodle lightweight inexpensive ship experience annie chun noodle bowl kimchi awesome highly recommend recently annie chun product sale buy miso amazon kimchi love miso figure good kimchi spicy wrong kikkoman instant miso soup good miso flavor eat plain add spinach tofu touch sliced mushroom annie ok noodle fun opinion like miso lacking purchase miso soup restaurant actually good love fact environmentally concern product buy product know care throw away biodegradable thing crazy noodle prefer thinner noodle bulky typical asian dish like spicy hot food pas compare mexican food salsa medium hotif like little spice love good mix flavor toss noddle use spice packet water instant rice great dish dinner waypurchased expiration date package vegetarian adopt healthier lifestyle girl friend pretty ramen grow hawaii saimen ramen instant noodle soup animal product msg bad head ache try natural ramen like soup annie chun korean kimihi noodle soup probably best try koyo soken good grant expensive good reason flavor eat ramen high sodium content okay usually ad veggie tofu home kimchi organic eggland best egg human certify soup hearty kudo annie best msg vegan instant kimchi soup right size lunch cold day easy great taste buy soup bowl work usually work lunch provide fairly healthy light lunch fairly little salty dry tofu usually reconstitute fine complaint biodegradable marketing gimic nice idea think people feel rot landfill try bowl compost heap year later kick backyard rot paper wrapper plastic wrapper certainly compostable purchase amazon base nutrition information provide lie packaging state serve package calorie mg sodium lot sodium nutrition information website state calorie mg sodium serving actual case actually try soup know soup actally taste good prove unhealthy choice provide accurate actual information customer informed decision waste time money actual nutrition fact carton calorie total fat sodium mg total carbs dietary fiber sugar protien consume half day sodium depend diet lot carbs little nutritional value information available amazon purchase workday lunch thid excellent easy instant soup live street korean restaurant soup similar like good udon noodle cheap instant soup good complaint coupon box expire soup fine till hope annie fix problem dollar coupon good expire love quick satisfy taste product feel like kitchen table home thanks prompt shipping support love product good quick lunch mg sodium similar type soup great flavor love great meal diet calorie good good star udon noodle soup bowl awesome love like ramen noodle like good flavor good like veggie include add fresh csae emergency food stash work case snow happen way work late case home emergency food eat actually couple occasion camping cookware grill power storm come plastic bowl course fine great product come cooking bowl convenient environmentally safe bio degradable cooking time ready second noodle tasty vacuum pack freshness perfect quick lunch time cook regular meal recommend add chopped onion red pepper little flavor annie chun brand noodle variety choose annie chun soup look taste pretty way picture kimchi noodle bowl spicy colorful tasty compare instant soup choice store shelf warm prepare accord easy instruction like add veggie cook meat meal rat star little veggie opinion recommend add chopped cabbage family green bit shredded carrot color crunch btw observe case annie chun soup good asian restaurant manhattan mid town nyc stuff good great starter oh far good ramen like ramen plemty sodium add dash hot pepper sauce tamari cook sherry remove package cook ceramic toaster calphalon type skillet squeeze fresh oranic lime emjoy cheap tasty hot lunch tax tip reordered price slightly beat employee discount health food store add shrimp fresh cilantro nicely spiced dice fresh slice cayenne need store try annie chun product happen kind impression hell brick dehydrated crap refer veges look awful soup veges sauce bowl noodles pour boiling water instantly impress vegetable actually look like veges instead vegetable flake noodle tasty sauce pretty spot miso good product price ease hungry eat definitely away bite filling lunch veges meat mixed maybe salad perfect instead felt like broth little bolder flavor wrong definitely order annie chun product probably start pho kimchi right spice spicy texture noodle great delicious wish cheap entire family love problem carbs salt fat huge low package noodle soup bowl brand buy great food storage item deal love noodle think fast filling lunch delicious miso noodle bit weak tsp soy sauce fix issue guess want hold sodium noodle refresh hot water microwave freeze dry cube scallion seaweed soup base packet white miso shiro miso water drain hot water use refresh udon minute total restriction salt save packet soy sauce chinese takeout doll noodle suit taste like texture slurpy chewy good leave drop soup buy soup roommate addict spicy food love try flavor terrific spicy product bland edible use minimum water recommend plus packet miso taste plus annie chun product try look like picture box nice green noodle definitely buy like thing kick probably great buy trip japan crave miso soup store ahead buy pack amazon excited arrive disappointed try taste good annie chun product love unpleasantly surprise purchase finish entire bowl fact bowl sit cupboard good idea poor execution intend try bowl case bad feeling case reason star noodle fine general like annie chun product new thai soup soup sooo good add favorite meat good love anne chun donate portion fee people fortunate fast add water microwave product taste texture soup bowl pretty good good snack depend main course complaint noodle tend bit rubbery surprisingly impress flavor add shrimp frozen stir fry veggie plump dish highly recommend product little rat convenience factor taste think add ginger chicken soup pleasantly tasty bit bland wish ginger flavor msg salt add vegetable pretty hard cook add boiling water wait minute small piece vegetable think actual slice mushroom increase perceived value greatly noodle reconstitute nicely version soup nice serving like maybe slightly noodle mean vegetable optional spice flavor packet nice think bad impress probably improve little soy sauce spice know try limit salt soup mg sodium soup claim serving joke deceive people taste cook use water specify cup substantially dilute taste recommend try think repeat saw local publix whop certainly worth price annie chun partly pay gimmick cornstarch recyclable packaging charity donation organic ingredient msg contain yeast extract free glutimates believe recommendation pick sale add extra maybe ginger able diced chicken improve soup add chicken breast shelf stable think overall consensus try annie chun soup try udon weak dish kind bland absorb flavor okay dish near homemade kimchi jigge alright snack buy annie soup wonderful taste great low calorie packaging soup outstanding great soup price big high quality value bowl biodegradable paper cover bowl recycle environmental friendly food product market help environment away taste taste mild consider ideal japanese cuisine dilute taste taste depend water ideal water instruct add water water brown pictured veggie picture noodle soft delicious great meal work office heat cup water microwave pour large male leave bit want child serving average leave feel right annie chun udon soup quick meal large traditional soup cup reconstituted texture soup bowl hold cup soup nice size lunch natural vegetarian consisting noodle flavorful soy soup dried mushroom onion bok choy herb spice ingredient come package bag noodle dry liquid soup base packet dry soup topping add boil water actually instruction package unnecessarily complicate tell add water loosen noodle drain add ingredient add water necessary maybe need loosen noodle microwave soup suggest stir noodle minute microwave kettle handy package soup bowl add boil water half inch bowl let sit cover minute faster easy use water instruction recommend soup come perfectly annie chun suggest add spinach snow pea broccoli mushroom shrimp tofu soup complete meal thing need cook add fresh mushroom frozen pea excellent addition require pre cook slice dice mushroom soup add boiling water partially cook sit minute acquire nice dense texture raw limp ingredient noodles wheat flour water tapioca starch lactic acid salt soup base soy sauce water wheat soybean salt shiitake mushroom sea vegetable evaporate cane juice rice wine yeast extract topping green onion maltodextrin bok choy tofu red pepper shiitake mushroom guar gum product manufacture facility use peanuts soup bowl corn product biodegradable degrades landfill bowl toxic staple office worker sort easy heat soup unfortunately soup cup pretty poor terrible taste like paste annie chun exception noodle great comparison ramen noodle nice consistency flavor thicker comparison plus soup contain nearly sodium ramen mean bit healthy miso soup variety wife favorite enjoy sour variety love annie chun udon noodle bowl product good noodle different seasoning completely control heat udon noodle bowl somewhat spicy hot mesh taste wise try time good kimchi soup like kimchi regularly eat asian soup home restaurant surprise kimchi major element spicy hot soup small reconstitute piece amid noodle negative enjoy taste noodle plenty hearty addition extra meat tofu good order annie chun udon soup favorite package meal noodle good dried udon noodle purchase attempt recreate soup usually need eat fast udon kimchi miso good soup udon definitely favorite bunch dish teriyaki good vegetarian fish chicken broth appreciate veggie vegan friendly complaint price grocery store amazon subscription trader joe best price far serve size list nutritional panel bowl realistic opinion add item serve appetizer calorie serving bowl diet friendly bowl lunch try add sliced mushroom cook help satisfy lunch fruit annie chun sexy noodle cover wish lady like good look healthy style cooking good beauty supermarket come house buy bulk product autograph lolyou special lady thank healthy time comsuming product love health product second time order product tasty quick lunch add left veges strip sunday roast intend try annie chun product taste like spicy cardboard overrated product buy period recommend use intend pot noodle soup use shrimp bag frozen japanese vegetable green onion pack soup included seasoning packet add extra water like brothy soup great dinner husband lot fuss great flavor use use ramen noodle soup way salty use add low sodium soy want dab hot chili paste tasty overly salty compare brand instant soup cup annie chun hot sour soup bowl pretty darn good compare flavor annie chun soup bowl major disappointment noodle fabulous veggie reconstitute annie chun soup bowl unfortunately flavor lack finger exactly miss basically taste like extremely water hot sour soup annie chun big fan pain leave negative review hot sour definitely order rotation okay need look context instant noodle compare udon cute little noodle shop osaka firstly vegan ingredient include yeast extract eating yeast extract problem pass vegan think plus good secondly cardboard outer plastic bowl recyclable decomposable agree reviewer point decomposes landfill corn potato petroleum good styrofoam cup cup noodle brand use little sauce packet probably recyclable little thirdly veggie nice shiitake mushroom bok choy improvement dried pea carrot crappy brand piece tofu weird spongy type silky type fourth msg additionally noodle nice texture contain natural ingredient chicken flavoring think annie chun noodle bowl pretty tasty comment like plenty food lunch high calorie easy good hand day run time lunch bowl biodegradable plus pretty darn tasty bit expensive like amazon good price compare super market lovely soup spicy annie chun soup like food hot great biodegradable microwaveable bowl serving total calorie count calorie great diet thing nice udon noodle ready minute good noodle cup grocery store shipping free grocery order husband love soup tasty love calorie smell heavenly heat people work constantly comment good smell desk drawer need microwave water try soup line far favorite subscribe save eat save try pick target try yesterday like flavor sure review low love spinach try flavor spinach tofu surprise prefer chicken flavor like mushroom flavor texture repulsive past shittake chinese stir fry stomach worried able handle mushroom slice soup turn bother bit mushroomy flavor texture eat problem thing lacking soup veggie heck lot expect guess wish veggie instant noodle soup matter brand recently buy bag freeze dry peas corn throw instant soup prove great investment great control add beef soup lot corn peas choose plan carrot add little extra corn soup prepare great like hot sour soup restaurant usually lighter bit black pepper taste salty use sauce packet use like suppose love miso soup love udon soup thought perfect combination bowl able finish hard explain gross process try annie chun noodle bowl soup noodle bowl try night think pretty good big noodle reconstituted veggie bit desire awful exactly broth good flavor add little salt little bland little spicy overly great flavor surely buy perfect thing light supper great lunch husband drag vegan world health great meat potato kind guy love pasta noodle kind able entice great product amazon sell like quick easy cook cook big fan little bland add vegetable spice liven annie chung product horrid grossly sticky salty picture vegetable eat crap starve try annie chun flavor like kimchi soup unbelievably delicious best package soup product kind try usually dislike package soup product good favorite brunswick stew love long moderately spicy mind bit spice good pass practically live stuff thank annie chun package meal worth eat leftover sandwich meat delicious convenient option low fat delicious highly recommend annie chun rest manufacturer hot sour bandwagon understand hot sour soup completely different animal maybe discover love hot sour soup local chinese restaurant think try store brand hot sour big mistake hot sour soup use flavorful robust soup chunk tofu pork meat bamboo shoot egg dry mushroom lace slightly tangy affair bit spicy palette contrast oh dear annie chun fall pitfalls try store brand prepackaged hot sour soup admit interested saw noodle fresh dry add hot water flavor packet hot oil sachet ugh taste like strain head garlic chilli sieve bowl boil water dry veggie noticeably green onion godawful consistency akin bad calamari taste closely resemble cardboard ask know cardboard taste like awful favor near chinese restaurant order like serving hot sour soup usually pop portion individual freezer safe tub sandwich bag freeze extract time freezer craving happy\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random user:\\n{user_reviews[np.random.randint(0, user_reviews.shape[0])]}\")\n",
    "print(f\"\\nRandom item:\\n{item_reviews[np.random.randint(0, item_reviews.shape[0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0665ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_corpus = [dictionary.doc2bow(doc) for doc in user_reviews_list]\n",
    "item_corpus = [dictionary.doc2bow(doc) for doc in item_reviews_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec6f1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_vectors(model, corpus, n_topics=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    topic_vecs = []\n",
    "    for i in tqdm(range(len(corpus))):\n",
    "        top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "        topic_vecs.append([top_topics[i][1] for i in range(n_topics)])\n",
    "        \n",
    "    return topic_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655ec479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 13397/13397 [00:10<00:00, 1281.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 4729/4729 [00:05<00:00, 832.46it/s]\n"
     ]
    }
   ],
   "source": [
    "user_vecs = get_topic_vectors(lda_model, user_corpus)\n",
    "item_vecs = get_topic_vectors(lda_model, item_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4ede2a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.412026e-05,\n",
      "  0.037068404,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.01118332,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.056985307,\n",
      "  0.37342215,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.011684398,\n",
      "  0.0029754133,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.015933922,\n",
      "  0.03278494,\n",
      "  4.412026e-05,\n",
      "  0.018550407,\n",
      "  4.412026e-05,\n",
      "  0.021376897,\n",
      "  0.05969913,\n",
      "  4.412026e-05,\n",
      "  0.041945748,\n",
      "  0.013643295,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.040703386,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.17367385,\n",
      "  0.0230405,\n",
      "  4.412026e-05,\n",
      "  4.412026e-05,\n",
      "  0.016442873,\n",
      "  4.412026e-05,\n",
      "  0.0057348763,\n",
      "  4.412026e-05,\n",
      "  0.012069327,\n",
      "  0.019473264,\n",
      "  0.010329086,\n",
      "  4.412026e-05]]\n"
     ]
    }
   ],
   "source": [
    "# checking topic vector\n",
    "pprint(item_vecs[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabfeed",
   "metadata": {},
   "source": [
    "# Create Topic Vector Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c3656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_map = {k: unique_users[k] for k in range(len(unique_users))}\n",
    "item_idx_map = {k: unique_items[k] for k in range(len(unique_items))}\n",
    "\n",
    "user_vec_map = {k: v for k, v in zip(unique_users, user_vecs)}\n",
    "item_vec_map = {k: v for k, v in zip(unique_items, item_vecs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b9dded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading user topic vectors into DF\n",
    "user_vecs = pd.DataFrame.from_dict(user_vec_map, orient='index')\n",
    "user_vecs.index.name = 'reviewerID'\n",
    "# loading item topic vectors into DF\n",
    "item_vecs = pd.DataFrame.from_dict(item_vec_map, orient='index')\n",
    "item_vecs.index.name = 'asin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec6b6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00177463W0XWB16A9O05</th>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.321427</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A022899328A0QROR32DCT</th>\n",
       "      <td>0.150856</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.079691</td>\n",
       "      <td>0.024830</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.011307</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A068255029AHTHDXZURNU</th>\n",
       "      <td>0.099152</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.149055</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.236662</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A06944662TFWOKKV4GJKX</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.246271</td>\n",
       "      <td>0.166885</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1004703RC79J9</th>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.532996</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.059955</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZWRZZAMX90VT</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.224511</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.008113</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.014185</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.183947</td>\n",
       "      <td>0.086676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.026617</td>\n",
       "      <td>0.018546</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.050363</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>0.047481</td>\n",
       "      <td>0.000080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZXKAH2DE6C8A</th>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.040951</td>\n",
       "      <td>0.190155</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.010761</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.058788</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZXON596A1VXC</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.029897</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.012432</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.104411</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.022724</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.111096</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.143816</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZYXC63SS008M</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.111081</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.195631</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZZ5ASC403N74</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13397 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4   \\\n",
       "reviewerID                                                                \n",
       "A00177463W0XWB16A9O05  0.001334  0.001334  0.001334  0.001334  0.001334   \n",
       "A022899328A0QROR32DCT  0.150856  0.000239  0.000239  0.013963  0.000239   \n",
       "A068255029AHTHDXZURNU  0.099152  0.000572  0.000572  0.000572  0.000572   \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.246271  0.166885  0.000800  0.000800   \n",
       "A1004703RC79J9         0.001429  0.001429  0.001429  0.001429  0.001429   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "AZWRZZAMX90VT          0.000080  0.224511  0.000080  0.000080  0.008113   \n",
       "AZXKAH2DE6C8A          0.000147  0.000147  0.000147  0.000147  0.000147   \n",
       "AZXON596A1VXC          0.000173  0.029897  0.000173  0.012432  0.000173   \n",
       "AZYXC63SS008M          0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714   \n",
       "\n",
       "                             5         6         7         8         9   ...  \\\n",
       "reviewerID                                                               ...   \n",
       "A00177463W0XWB16A9O05  0.321427  0.001334  0.001334  0.001334  0.001334  ...   \n",
       "A022899328A0QROR32DCT  0.000239  0.000239  0.079691  0.024830  0.000239  ...   \n",
       "A068255029AHTHDXZURNU  0.000572  0.000572  0.000572  0.000572  0.000572  ...   \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.000800  0.000800  0.000800  0.000800  ...   \n",
       "A1004703RC79J9         0.001429  0.001429  0.532996  0.001429  0.001429  ...   \n",
       "...                         ...       ...       ...       ...       ...  ...   \n",
       "AZWRZZAMX90VT          0.000080  0.014185  0.000080  0.183947  0.086676  ...   \n",
       "AZXKAH2DE6C8A          0.000147  0.040951  0.190155  0.000147  0.009686  ...   \n",
       "AZXON596A1VXC          0.000173  0.000173  0.000173  0.104411  0.000173  ...   \n",
       "AZYXC63SS008M          0.001667  0.001667  0.001667  0.111081  0.001667  ...   \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714  ...   \n",
       "\n",
       "                             40        41        42        43        44  \\\n",
       "reviewerID                                                                \n",
       "A00177463W0XWB16A9O05  0.001334  0.001334  0.001334  0.001334  0.001334   \n",
       "A022899328A0QROR32DCT  0.019680  0.000239  0.000239  0.000239  0.000239   \n",
       "A068255029AHTHDXZURNU  0.000572  0.000572  0.000572  0.000572  0.149055   \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.000800  0.000800  0.000800  0.000800   \n",
       "A1004703RC79J9         0.001429  0.059955  0.001429  0.001429  0.001429   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "AZWRZZAMX90VT          0.000080  0.026617  0.018546  0.000080  0.000080   \n",
       "AZXKAH2DE6C8A          0.000147  0.000147  0.010761  0.000147  0.000147   \n",
       "AZXON596A1VXC          0.000173  0.022724  0.000173  0.111096  0.000173   \n",
       "AZYXC63SS008M          0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714   \n",
       "\n",
       "                             45        46        47        48        49  \n",
       "reviewerID                                                               \n",
       "A00177463W0XWB16A9O05  0.001334  0.001334  0.001334  0.001334  0.001334  \n",
       "A022899328A0QROR32DCT  0.000239  0.011307  0.000239  0.000239  0.000239  \n",
       "A068255029AHTHDXZURNU  0.000572  0.000572  0.000572  0.236662  0.000572  \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.000800  0.000800  0.000800  0.000800  \n",
       "A1004703RC79J9         0.001429  0.001429  0.001429  0.001429  0.001429  \n",
       "...                         ...       ...       ...       ...       ...  \n",
       "AZWRZZAMX90VT          0.000080  0.050363  0.010761  0.047481  0.000080  \n",
       "AZXKAH2DE6C8A          0.073099  0.000147  0.058788  0.000147  0.000147  \n",
       "AZXON596A1VXC          0.000173  0.000173  0.143816  0.000173  0.000173  \n",
       "AZYXC63SS008M          0.001667  0.195631  0.001667  0.001667  0.001667  \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714  \n",
       "\n",
       "[13397 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6b5167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9742356831</th>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.037068</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.011183</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.056985</td>\n",
       "      <td>0.373422</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.005735</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.012069</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.010329</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004S1C5</th>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.017596</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.221324</td>\n",
       "      <td>0.275595</td>\n",
       "      <td>0.166724</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005344V</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.310664</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.018822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.018308</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.018326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0000CDEPD</th>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.270056</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.021182</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.100708</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0000CFPI2</th>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.067632</td>\n",
       "      <td>0.491923</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.067539</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.097631</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.018163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00I08JNWU</th>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.196998</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00I33696K</th>\n",
       "      <td>0.118955</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.127053</td>\n",
       "      <td>0.188531</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.155561</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00ID9VSOM</th>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.106754</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.302539</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00IRL93SY</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00ISVHJ3Y</th>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.079890</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.157596</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4729 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "asin                                                                     \n",
       "9742356831  0.000044  0.037068  0.000044  0.000044  0.011183  0.000044   \n",
       "B00004S1C5  0.000056  0.000056  0.000056  0.000056  0.000056  0.016450   \n",
       "B00005344V  0.000076  0.000076  0.310664  0.000076  0.000076  0.000076   \n",
       "B0000CDEPD  0.000128  0.000128  0.000128  0.000128  0.000128  0.000128   \n",
       "B0000CFPI2  0.000082  0.000082  0.000082  0.000082  0.000082  0.053972   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "B00I08JNWU  0.000455  0.000455  0.000455  0.000455  0.000455  0.000455   \n",
       "B00I33696K  0.118955  0.000303  0.000303  0.000303  0.000303  0.000303   \n",
       "B00ID9VSOM  0.000370  0.068766  0.000370  0.000370  0.000370  0.000370   \n",
       "B00IRL93SY  0.001667  0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "B00ISVHJ3Y  0.001111  0.001111  0.001111  0.079890  0.001111  0.001111   \n",
       "\n",
       "                  6         7         8         9   ...        40        41  \\\n",
       "asin                                                ...                       \n",
       "9742356831  0.000044  0.056985  0.373422  0.000044  ...  0.000044  0.000044   \n",
       "B00004S1C5  0.000056  0.000056  0.000056  0.000056  ...  0.000056  0.000056   \n",
       "B00005344V  0.000076  0.000076  0.000076  0.018822  ...  0.000076  0.000076   \n",
       "B0000CDEPD  0.000128  0.270056  0.000128  0.000128  ...  0.000128  0.000128   \n",
       "B0000CFPI2  0.000082  0.067632  0.491923  0.000082  ...  0.000082  0.000082   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "B00I08JNWU  0.000455  0.000455  0.000455  0.000455  ...  0.000455  0.196998   \n",
       "B00I33696K  0.127053  0.188531  0.000303  0.000303  ...  0.000303  0.000303   \n",
       "B00ID9VSOM  0.000370  0.000370  0.000370  0.039394  ...  0.000370  0.000370   \n",
       "B00IRL93SY  0.001667  0.001667  0.001667  0.001667  ...  0.001667  0.001667   \n",
       "B00ISVHJ3Y  0.001111  0.001111  0.001111  0.001111  ...  0.001111  0.001111   \n",
       "\n",
       "                  42        43        44        45        46        47  \\\n",
       "asin                                                                     \n",
       "9742356831  0.016443  0.000044  0.005735  0.000044  0.012069  0.019473   \n",
       "B00004S1C5  0.000056  0.000056  0.017596  0.000056  0.221324  0.275595   \n",
       "B00005344V  0.000076  0.000076  0.000076  0.000076  0.012768  0.018308   \n",
       "B0000CDEPD  0.000128  0.021182  0.000128  0.000128  0.000128  0.000128   \n",
       "B0000CFPI2  0.000082  0.000082  0.067539  0.000082  0.000082  0.097631   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "B00I08JNWU  0.000455  0.000455  0.000455  0.000455  0.000455  0.000455   \n",
       "B00I33696K  0.000303  0.000303  0.155561  0.000303  0.000303  0.000303   \n",
       "B00ID9VSOM  0.033863  0.106754  0.000370  0.000370  0.000370  0.302539   \n",
       "B00IRL93SY  0.001667  0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "B00ISVHJ3Y  0.001111  0.001111  0.001111  0.001111  0.001111  0.157596   \n",
       "\n",
       "                  48        49  \n",
       "asin                            \n",
       "9742356831  0.010329  0.000044  \n",
       "B00004S1C5  0.166724  0.000056  \n",
       "B00005344V  0.000076  0.018326  \n",
       "B0000CDEPD  0.100708  0.000128  \n",
       "B0000CFPI2  0.000348  0.018163  \n",
       "...              ...       ...  \n",
       "B00I08JNWU  0.000455  0.000455  \n",
       "B00I33696K  0.000303  0.000303  \n",
       "B00ID9VSOM  0.000370  0.000370  \n",
       "B00IRL93SY  0.001667  0.001667  \n",
       "B00ISVHJ3Y  0.001111  0.001111  \n",
       "\n",
       "[4729 rows x 50 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f41ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting factors into numpy obj\n",
    "user_factors = user_vecs.to_numpy()\n",
    "item_factors = item_vecs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31cbeccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.3214275 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.53154725, 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.08434129, 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ,\n",
       "       0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 , 0.0013337 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd79bc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.4120261e-05, 3.7068404e-02, 4.4120261e-05, 4.4120261e-05,\n",
       "       1.1183320e-02, 4.4120261e-05, 4.4120261e-05, 5.6985307e-02,\n",
       "       3.7342215e-01, 4.4120261e-05, 4.4120261e-05, 1.1684398e-02,\n",
       "       2.9754133e-03, 4.4120261e-05, 4.4120261e-05, 1.5933922e-02,\n",
       "       3.2784939e-02, 4.4120261e-05, 1.8550407e-02, 4.4120261e-05,\n",
       "       2.1376897e-02, 5.9699129e-02, 4.4120261e-05, 4.1945748e-02,\n",
       "       1.3643295e-02, 4.4120261e-05, 4.4120261e-05, 4.4120261e-05,\n",
       "       4.4120261e-05, 4.4120261e-05, 4.4120261e-05, 4.4120261e-05,\n",
       "       4.4120261e-05, 4.4120261e-05, 4.4120261e-05, 4.0703386e-02,\n",
       "       4.4120261e-05, 4.4120261e-05, 1.7367385e-01, 2.3040500e-02,\n",
       "       4.4120261e-05, 4.4120261e-05, 1.6442873e-02, 4.4120261e-05,\n",
       "       5.7348763e-03, 4.4120261e-05, 1.2069327e-02, 1.9473264e-02,\n",
       "       1.0329086e-02, 4.4120261e-05], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5903a6c",
   "metadata": {},
   "source": [
    "# Train `EmbeddedMF` Class w/ Initialized Topic Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7ba16818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import emf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f1fb009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_mf = emf.EmbeddedMF(user_map=user_idx_map,\n",
    "                       item_map=item_idx_map,\n",
    "                       user_factor=user_factors,\n",
    "                       item_factor=item_factors,\n",
    "                       learning_rate=.01,\n",
    "                       beta=.02,\n",
    "                       num_epochs=20,\n",
    "                       num_factors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4f214fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data required for surprise\n",
    "\n",
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[['reviewerID', 'asin', 'overall']], reader)\n",
    "# generating training set\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a14405fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 20/20 [08:11<00:00, 24.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 7s, sys: 1.7 s, total: 8min 9s\n",
      "Wall time: 8min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fitting algo to training set\n",
    "ti_mf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2d8f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 s, sys: 11.5 s, total: 45.1 s\n",
      "Wall time: 54.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate candidate items for user to predict rating\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ecb38503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 36s, sys: 6min 18s, total: 14min 55s\n",
      "Wall time: 18min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "predictions = ti_mf.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ebf2e",
   "metadata": {},
   "source": [
    "# Evaluate Top-N Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfc060",
   "metadata": {},
   "source": [
    "### Defining Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "58335bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating precision@K - relevant / total recommended\n",
    "    precision_at_k = num_relevant / k\n",
    "    \n",
    "    return precision_at_k\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "386ce9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "91208e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")\n",
    "\n",
    "# generating test rating history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7e8b34e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "62cb82bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: AWY8ZY16DPTVE:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "19630  B001E6K6B2  Kellogg's Raisin Bran Crunch, Breakfast Cereal...\n",
      "33274  B0040J01KQ  Pop-Tarts Toaster Pastries Variety Pack, 48-Co...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "             asin                                              title\n",
      "344    B00014HS2S  Prince of Peace Oolong Tea - 100 Tea Bags net ...\n",
      "1336   B00028PVA4  Tazo Refresh Mint Herbal Tea Filterbags (20 co...\n",
      "2542   B000CMD64S  Yogi Rejuvenation Green Tea, 16 Tea Bags (Pack...\n",
      "14852  B0013L0C6W                      Soda Stream Tonic Syrup 440ml\n",
      "19011  B001E5E10K   White Gold Honey, 23-Ounce Container (Pack of 2)\n",
      "19038  B001E5E12I   Maine Coast Sea Vegetables Kombu, Wild Atlant...\n",
      "21967  B001EQ5IPQ  O.N.E. 100% Natural Coconut Water, 33.8 Ounce ...\n",
      "21970  B001EQ5IBU  NOW Foods Macadamia Nuts Roasted-salted, 12-Ou...\n",
      "25988  B001TNXSZG   Guayaki Traditional Organic Yerba Mate, Loose...\n",
      "27609  B00286KM8E  Lipton Black Tea Bags, America's Favorite Tea,...\n",
      "\n",
      "[('B001EQ5IBU', 4.986607575497755), ('B001E5E12I', 4.971116804552838), ('B00286KM8E', 4.9673949208960355), ('B001E5E10K', 4.953984658162144), ('B001TNXSZG', 4.952940704659588), ('B00014HS2S', 4.934830493846837), ('B000CMD64S', 4.932316648621569), ('B001EQ5IPQ', 4.8958082163282475), ('B0013L0C6W', 4.8905366218455235), ('B00028PVA4', 4.883185915068609)]\n"
     ]
    }
   ],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "print(f\"For user: {random_user}:\")\n",
    "print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "# find the recommendations\n",
    "# NOTE: This is not sorted in ranking\n",
    "print(f\"\\nRecommending:\\n\")\n",
    "print(f\"{train[train['asin'].isin([i[0] for i in top_ns[random_user]])][['asin', 'title']].drop_duplicates(subset='asin')}\")\n",
    "print(f\"\\n{top_ns[random_user]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d01182",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd6c4fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 41617.66it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 48716.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@10: 0.00060, average recall@10: 0.00321.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074081e0",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d7af19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 45502.25it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 45615.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@25: 0.00061, average recall@25: 0.00789.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69f1ce",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc9a8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 32080.60it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 28881.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@30: 0.00059, average recall@30: 0.00911.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895cbcd",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b79dcff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 37503.26it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 39617.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@45: 0.00061, average recall@45: 0.01380.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29a08b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>pred_asin</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A10BD0288TGRVS</td>\n",
       "      <td>[B00017LEXE, B00017LEXE, B001D3K2GA, B0029XLH4Y]</td>\n",
       "      <td>[B000JMAXMY, B000EDG4V2, B001G2F5R4, B0029JHHO...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>A10UIIZS7YW78Y</td>\n",
       "      <td>[B005C3IVN8]</td>\n",
       "      <td>[B000EDG4V2, B000EDM6PA, B000H1195C, B000HVX6N...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>A11WS6V544IWEM</td>\n",
       "      <td>[B0033HGLTG, B005K4Q1YA]</td>\n",
       "      <td>[B000CQ01GU, B000E123H8, B000E1BL5S, B000E1FXR...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>A11YOTONCPRQ9S</td>\n",
       "      <td>[B000CQBZQK, B000EVLZCW, B001SB4OV6, B002YR7A7...</td>\n",
       "      <td>[B001PEWJWC, B00271OPVU, B000EDG4V2, B000JMAXM...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>A12KUNIKXGX3U1</td>\n",
       "      <td>[B005HGAVD8]</td>\n",
       "      <td>[B001E5E12I, B001E5E10A, B002859GAU, B00286KM8...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>AXVNVV5VH5XZY</td>\n",
       "      <td>[B000EIZ8FA, B000LKV2KQ, B000O3QD2C]</td>\n",
       "      <td>[B001ET5XVW, B001PF1846, B001PEWJWC, B003VTG7R...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13144</th>\n",
       "      <td>AYB4ELCS5AM8P</td>\n",
       "      <td>[B005GNXIYQ, B009M516HU, B009M515HQ, B00BNR7I1...</td>\n",
       "      <td>[B000GAT6NG, B003OGKCDC, B000F4D5GC, B00DS842H...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13236</th>\n",
       "      <td>AZFHSPEZUPGD2</td>\n",
       "      <td>[B002DM62BY, B00A64NLOM, B00BHIS6MI, B00FPNVTU...</td>\n",
       "      <td>[B0013L0C6W, B0014ET2MI, B000UXDHGQ, B001LO37P...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13255</th>\n",
       "      <td>AZOTVJHNSAQXG</td>\n",
       "      <td>[B001EQ4RWQ, B005CULMWI]</td>\n",
       "      <td>[B000216O16, B000DZDJ0K, B000DZKKKC, B000ED9LS...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13270</th>\n",
       "      <td>AZVJHW8TARWV9</td>\n",
       "      <td>[B001PEWJWC]</td>\n",
       "      <td>[B001E55ZQO, B0029JASWA, B0029JHHO2, B002DMFSS...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "42     A10BD0288TGRVS   [B00017LEXE, B00017LEXE, B001D3K2GA, B0029XLH4Y]   \n",
       "94     A10UIIZS7YW78Y                                       [B005C3IVN8]   \n",
       "195    A11WS6V544IWEM                           [B0033HGLTG, B005K4Q1YA]   \n",
       "202    A11YOTONCPRQ9S  [B000CQBZQK, B000EVLZCW, B001SB4OV6, B002YR7A7...   \n",
       "251    A12KUNIKXGX3U1                                       [B005HGAVD8]   \n",
       "...               ...                                                ...   \n",
       "13093   AXVNVV5VH5XZY               [B000EIZ8FA, B000LKV2KQ, B000O3QD2C]   \n",
       "13144   AYB4ELCS5AM8P  [B005GNXIYQ, B009M516HU, B009M515HQ, B00BNR7I1...   \n",
       "13236   AZFHSPEZUPGD2  [B002DM62BY, B00A64NLOM, B00BHIS6MI, B00FPNVTU...   \n",
       "13255   AZOTVJHNSAQXG                           [B001EQ4RWQ, B005CULMWI]   \n",
       "13270   AZVJHW8TARWV9                                       [B001PEWJWC]   \n",
       "\n",
       "                                               pred_asin  precision@k  \\\n",
       "42     [B000JMAXMY, B000EDG4V2, B001G2F5R4, B0029JHHO...     0.022222   \n",
       "94     [B000EDG4V2, B000EDM6PA, B000H1195C, B000HVX6N...     0.022222   \n",
       "195    [B000CQ01GU, B000E123H8, B000E1BL5S, B000E1FXR...     0.022222   \n",
       "202    [B001PEWJWC, B00271OPVU, B000EDG4V2, B000JMAXM...     0.022222   \n",
       "251    [B001E5E12I, B001E5E10A, B002859GAU, B00286KM8...     0.022222   \n",
       "...                                                  ...          ...   \n",
       "13093  [B001ET5XVW, B001PF1846, B001PEWJWC, B003VTG7R...     0.022222   \n",
       "13144  [B000GAT6NG, B003OGKCDC, B000F4D5GC, B00DS842H...     0.022222   \n",
       "13236  [B0013L0C6W, B0014ET2MI, B000UXDHGQ, B001LO37P...     0.022222   \n",
       "13255  [B000216O16, B000DZDJ0K, B000DZKKKC, B000ED9LS...     0.022222   \n",
       "13270  [B001E55ZQO, B0029JASWA, B0029JHHO2, B002DMFSS...     0.022222   \n",
       "\n",
       "       recall@k  \n",
       "42     0.250000  \n",
       "94     1.000000  \n",
       "195    0.500000  \n",
       "202    0.166667  \n",
       "251    1.000000  \n",
       "...         ...  \n",
       "13093  0.333333  \n",
       "13144  0.090909  \n",
       "13236  0.200000  \n",
       "13255  0.500000  \n",
       "13270  1.000000  \n",
       "\n",
       "[358 rows x 5 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at how many get correct\n",
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3fa88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
