{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa7e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from pandarallel import pandarallel\n",
    "from src.models import cf\n",
    "from tqdm import tqdm \n",
    "\n",
    "pandarallel.initialize()\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fa3cef",
   "metadata": {},
   "source": [
    "# Load Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158d1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = 'data/evaluation'\n",
    "MODEL_PATH = 'models/d2v'\n",
    "CATEGORY = \"Clothing_Shoes_and_Jewelry\"\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")\n",
    "model = Doc2Vec.load(f\"{MODEL_PATH}/{CATEGORY}_50_d2v.model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ec2f7c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>2011-02-12</td>\n",
       "      <td>great tutu great price look cheap glad look am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>2013-01-19</td>\n",
       "      <td>buy yr old daughter dance class wear today tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>daughter orange black white pink think buy fuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>buy tutu high review sturdy seemingly girl wea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>2014-03-15</td>\n",
       "      <td>thank halo heaven great product little girls g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176500</th>\n",
       "      <td>278257</td>\n",
       "      <td>B00JULS24Q</td>\n",
       "      <td>Buyinhouse Feeling Adorable Cute Pink Bowknot ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Novelty, Costu...</td>\n",
       "      <td>A2IQT5AFFXA1OM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This item is exactly as described but for some...</td>\n",
       "      <td>2014-05-21</td>\n",
       "      <td>item exactly described reason like person like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176501</th>\n",
       "      <td>278290</td>\n",
       "      <td>B00K035Y08</td>\n",
       "      <td>Sakkas 197 Oasis Gauzy Crepe Sleeveless Blouse...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Women', 'Cloth...</td>\n",
       "      <td>A1XWMGHBAPKOV3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Put on and it fit great easy care also.Would t...</td>\n",
       "      <td>2014-06-15</td>\n",
       "      <td>fit great easy care tell friend buy thank hawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176502</th>\n",
       "      <td>278297</td>\n",
       "      <td>B00K0352PU</td>\n",
       "      <td>Sakkas Paradise Embroidered Relaxed Fit Blouse</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Women', 'Cloth...</td>\n",
       "      <td>A3VTQB69FYGQDU</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Before I washed the top it was extremely large...</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>wash extremely large fit perfectly wash embroi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176503</th>\n",
       "      <td>278316</td>\n",
       "      <td>B00K8J06CK</td>\n",
       "      <td>TrendzArt Azules Poly Span Floral Print Full L...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Women', 'Cloth...</td>\n",
       "      <td>A241BLSJL8AGY</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This maxi skirt was very nice material it fit ...</td>\n",
       "      <td>2014-06-20</td>\n",
       "      <td>maxi skirt nice material fit nicely color pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176504</th>\n",
       "      <td>278345</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>[2 PACK] Multi-Purpose Sports Balaclava - For ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Men', 'Accesso...</td>\n",
       "      <td>A2YKWYC3WQJX5J</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is truly a year round product. Here in th...</td>\n",
       "      <td>2014-06-21</td>\n",
       "      <td>truly year round product midwest summer use ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         index        asin                                              title  \\\n",
       "0            0  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "1            1  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "2            2  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "3            3  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "4            4  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "176500  278257  B00JULS24Q  Buyinhouse Feeling Adorable Cute Pink Bowknot ...   \n",
       "176501  278290  B00K035Y08  Sakkas 197 Oasis Gauzy Crepe Sleeveless Blouse...   \n",
       "176502  278297  B00K0352PU     Sakkas Paradise Embroidered Relaxed Fit Blouse   \n",
       "176503  278316  B00K8J06CK  TrendzArt Azules Poly Span Floral Print Full L...   \n",
       "176504  278345  B00KF9180W  [2 PACK] Multi-Purpose Sports Balaclava - For ...   \n",
       "\n",
       "                                               categories      reviewerID  \\\n",
       "0       [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...  A1KLRMWW2FWPL4   \n",
       "1       [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...  A2G5TCU2WDFZ65   \n",
       "2       [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...  A1RLQXYNCMWRWN   \n",
       "3       [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...   A8U3FAMSJVHS5   \n",
       "4       [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...  A3GEOILWLK86XM   \n",
       "176500  [['Clothing, Shoes & Jewelry', 'Novelty, Costu...  A2IQT5AFFXA1OM   \n",
       "176501  [['Clothing, Shoes & Jewelry', 'Women', 'Cloth...  A1XWMGHBAPKOV3   \n",
       "176502  [['Clothing, Shoes & Jewelry', 'Women', 'Cloth...  A3VTQB69FYGQDU   \n",
       "176503  [['Clothing, Shoes & Jewelry', 'Women', 'Cloth...   A241BLSJL8AGY   \n",
       "176504  [['Clothing, Shoes & Jewelry', 'Men', 'Accesso...  A2YKWYC3WQJX5J   \n",
       "\n",
       "        overall                                         reviewText  \\\n",
       "0           5.0  This is a great tutu and at a really great pri...   \n",
       "1           5.0  I bought this for my 4 yr old daughter for dan...   \n",
       "2           5.0  What can I say... my daughters have it in oran...   \n",
       "3           5.0  We bought several tutus at once, and they are ...   \n",
       "4           5.0  Thank you Halo Heaven great product for Little...   \n",
       "176500      4.0  This item is exactly as described but for some...   \n",
       "176501      5.0  Put on and it fit great easy care also.Would t...   \n",
       "176502      3.0  Before I washed the top it was extremely large...   \n",
       "176503      4.0  This maxi skirt was very nice material it fit ...   \n",
       "176504      5.0  This is truly a year round product. Here in th...   \n",
       "\n",
       "        reviewTime                                processedReviewText  \n",
       "0       2011-02-12  great tutu great price look cheap glad look am...  \n",
       "1       2013-01-19  buy yr old daughter dance class wear today tim...  \n",
       "2       2013-01-04  daughter orange black white pink think buy fuc...  \n",
       "3       2014-04-27  buy tutu high review sturdy seemingly girl wea...  \n",
       "4       2014-03-15  thank halo heaven great product little girls g...  \n",
       "176500  2014-05-21  item exactly described reason like person like...  \n",
       "176501  2014-06-15  fit great easy care tell friend buy thank hawa...  \n",
       "176502  2014-06-06  wash extremely large fit perfectly wash embroi...  \n",
       "176503  2014-06-20  maxi skirt nice material fit nicely color pret...  \n",
       "176504  2014-06-21  truly year round product midwest summer use ba...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d33dd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18483885,  0.13683623,  0.431223  ,  0.46865723, -0.6673366 ,\n",
       "       -0.26540083,  0.67599654, -0.6965546 , -0.95767546,  0.2404644 ,\n",
       "       -0.08230511, -0.07275622, -1.5187771 , -0.17228617, -1.4812549 ,\n",
       "        0.33527163,  0.79808766, -0.38892385, -0.09236064, -0.3225281 ,\n",
       "       -0.41883117,  0.2977529 ,  1.0714364 ,  1.6929846 ,  2.6893625 ,\n",
       "        1.4981884 , -0.35175997, -0.7717815 ,  0.5517118 , -0.00497056,\n",
       "        0.11664307,  0.9710174 , -0.16621333,  0.29962972, -0.52694905,\n",
       "        1.5606344 ,  1.441607  ,  1.0353522 ,  0.37510684,  1.9985726 ,\n",
       "        1.0185841 , -0.2807343 , -0.41933128, -0.34082264,  1.9616672 ,\n",
       "       -0.6369609 , -0.09271178, -0.6820405 , -0.9024493 ,  0.6379632 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing model\n",
    "model.dv[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807272ed",
   "metadata": {},
   "source": [
    "# Generate User Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3423f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewerID\n",
      "A001114613O3F18Q5NVR6     [B0016JNS44, B001T54XA8, B004AZXO1I, B004QJWKLS]\n",
      "A00146182PNM90WNNAZ5Q     [B000JJX7C0, B000MX3SH2, B003CO205E, B008JXDFCU]\n",
      "A00165422B2GAUE3EL6Z0     [B007WADN4G, B007WAEBPQ, B007WAT3I6, B008G51WHQ]\n",
      "A00338282E99B8OR2JYTZ                 [B002FA5B8O, B003F06XQW, B00768LFYY]\n",
      "A00354001GE099Q1FL0TU                 [B00387EEYA, B003RYZY8E, B0058XN9ZC]\n",
      "                                               ...                        \n",
      "AZZMQ85DPFEG3            [B0007KPPAI, B005EYUQ7E, B005VEMVI4, B007LOTZ5...\n",
      "AZZNK89PXD006                         [B000KGOHLM, B005C3DH00, B005PQPLLC]\n",
      "AZZT1ERHBSNQ8            [B000UANLGU, B002ATSG8C, B002UTJVMM, B007P83XJ...\n",
      "AZZTOUKVTUMVM             [B000196UJ0, B009GE3XQ4, B00C2DJ66C, B00C4NV6LS]\n",
      "AZZYW4YOE1B6E                         [B003V4AKTS, B004G8GOW0, B007LTV82W]\n",
      "Name: asin, Length: 39386, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# get user rating history\n",
    "user_rating_history = train.groupby(['reviewerID'])['asin'].apply(list)\n",
    "\n",
    "print(user_rating_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e19899fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:01<00:00, 34101.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# getting unique users\n",
    "unique_users = user_rating_history.reset_index()['reviewerID'].tolist()\n",
    "\n",
    "# generating user embeddings for all unique users\n",
    "user_embeddings = {}\n",
    "\n",
    "for user in tqdm(unique_users):\n",
    "    user_embedding = np.zeros(50)\n",
    "    for item in user_rating_history[user]:\n",
    "        user_embedding += model.dv[item]\n",
    "        \n",
    "    # mean aggregation\n",
    "    user_embedding /= len(user_rating_history[user])\n",
    "    user_embeddings[user] = user_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac96cc",
   "metadata": {},
   "source": [
    "# Generate Top-N Recommendations (N=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62046bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(d2v, user_embeddings, n=10):\n",
    "    \"\"\"Return the top-N recommendations for each user based on cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "        d2v ([Doc2Vec]): Doc2Vec of item representations based on reviews.\n",
    "        user_embeddings ([dict]): User representations based on mean aggregation of item\n",
    "            representations within the d2v vector dimension space.\n",
    "    \n",
    "    Returns:\n",
    "        ([dict]): A dictionary of top-N recommendations for each unique user, sorted by\n",
    "            cosine similarties.\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve a 200 items candidate list based on similarities\n",
    "    top_ns = {}\n",
    "    for user in tqdm(user_embeddings.items()):\n",
    "        candidate_items = [i[0] for i in d2v.dv.most_similar([user[1]], topn=200)]\n",
    "        unrated_items = set(candidate_items) - set(user_rating_history[user[0]])\n",
    "        \n",
    "        user_top_n = []\n",
    "        idx = 0\n",
    "        while len(user_top_n) < n:\n",
    "            if candidate_items[idx] in unrated_items:\n",
    "                user_top_n.append(candidate_items[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                idx += 1\n",
    "        \n",
    "        top_ns[user[0]] = user_top_n\n",
    "        \n",
    "    return top_ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3739f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(model, user_embeddings, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28300635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "print(f\"For user: {random_user}:\")\n",
    "print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "# find the recommendations\n",
    "print(f\"\\nRecommending:\\n\")\n",
    "print(f\"{train[train['asin'].isin(top_ns[random_user])][['asin', 'title']].drop_duplicates(subset='asin')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c6b9ad",
   "metadata": {},
   "source": [
    "# Evaluate Top-N Recommendations (N=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cca96",
   "metadata": {},
   "source": [
    "### Defining Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "567b3cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating precision@K - relevant / total recommended\n",
    "    precision_at_k = num_relevant / k\n",
    "    \n",
    "    return precision_at_k\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab3c7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "446daced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A16GFPNVF4Y816</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bought this as a backup to the regular ballet ...</td>\n",
       "      <td>2014-05-03</td>\n",
       "      <td>bought backup regular ballet outfit daughter w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Ballet Dress-Up Fairy Tutu</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Girls', 'Cloth...</td>\n",
       "      <td>A2XJ13PIXVJFJH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Never GOT this item - but gave a 1 STAR becaus...</td>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>item star reply supplier great try send item r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>0123456479</td>\n",
       "      <td>SHINING IMAGE HUGE PINK LEATHER JEWELRY BOX / ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Novelty, Costu...</td>\n",
       "      <td>A2WNN1DQVL4LH5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The minute I saw this my heart skipped a beat....</td>\n",
       "      <td>2013-11-07</td>\n",
       "      <td>minute saw heart skip beat nice case sort coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>0123456479</td>\n",
       "      <td>SHINING IMAGE HUGE PINK LEATHER JEWELRY BOX / ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Novelty, Costu...</td>\n",
       "      <td>A1ZPOCG2ST2CY3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Love this Jewelry Box  so well put together ho...</td>\n",
       "      <td>2014-01-19</td>\n",
       "      <td>love jewelry box hold plendy love pink look ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0123456479</td>\n",
       "      <td>SHINING IMAGE HUGE PINK LEATHER JEWELRY BOX / ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Novelty, Costu...</td>\n",
       "      <td>A1JC50F14SLAEV</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I wanted to have the title summarize my though...</td>\n",
       "      <td>2014-05-12</td>\n",
       "      <td>want title summarize thought decide read entir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99497</th>\n",
       "      <td>278341</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>[2 PACK] Multi-Purpose Sports Balaclava - For ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Men', 'Accesso...</td>\n",
       "      <td>A1EVV74UQYVKRY</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I go walking a lot in all kinds of weather and...</td>\n",
       "      <td>2014-06-16</td>\n",
       "      <td>walk lot kind weather know lot like block cold...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99498</th>\n",
       "      <td>278342</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>[2 PACK] Multi-Purpose Sports Balaclava - For ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Men', 'Accesso...</td>\n",
       "      <td>ABUE0ALHKWKHC</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This two pack of Balaclavas makes for a very n...</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>pack balaclava nice purchase balaclava fit snu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99499</th>\n",
       "      <td>278343</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>[2 PACK] Multi-Purpose Sports Balaclava - For ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Men', 'Accesso...</td>\n",
       "      <td>A1PI8VBCXXSGC7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Well, the first thing I did was try the balacl...</td>\n",
       "      <td>2014-06-13</td>\n",
       "      <td>thing try balaclava hubby try fit average size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99500</th>\n",
       "      <td>278344</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>[2 PACK] Multi-Purpose Sports Balaclava - For ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Men', 'Accesso...</td>\n",
       "      <td>A2XX2A4OJCDNLZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>While balaclavas can be used for a variety of ...</td>\n",
       "      <td>2014-06-13</td>\n",
       "      <td>balaclava use variety thing use mainly late fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99501</th>\n",
       "      <td>278346</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>[2 PACK] Multi-Purpose Sports Balaclava - For ...</td>\n",
       "      <td>[['Clothing, Shoes &amp; Jewelry', 'Men', 'Accesso...</td>\n",
       "      <td>A3UJRNI8UR4871</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Nice material, but not as nice as  silk or mer...</td>\n",
       "      <td>2014-06-09</td>\n",
       "      <td>nice material nice silk merino wool course mat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        asin                                              title  \\\n",
       "0           6  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "1          17  0000031887                         Ballet Dress-Up Fairy Tutu   \n",
       "2          23  0123456479  SHINING IMAGE HUGE PINK LEATHER JEWELRY BOX / ...   \n",
       "3          24  0123456479  SHINING IMAGE HUGE PINK LEATHER JEWELRY BOX / ...   \n",
       "4          27  0123456479  SHINING IMAGE HUGE PINK LEATHER JEWELRY BOX / ...   \n",
       "99497  278341  B00KF9180W  [2 PACK] Multi-Purpose Sports Balaclava - For ...   \n",
       "99498  278342  B00KF9180W  [2 PACK] Multi-Purpose Sports Balaclava - For ...   \n",
       "99499  278343  B00KF9180W  [2 PACK] Multi-Purpose Sports Balaclava - For ...   \n",
       "99500  278344  B00KF9180W  [2 PACK] Multi-Purpose Sports Balaclava - For ...   \n",
       "99501  278346  B00KF9180W  [2 PACK] Multi-Purpose Sports Balaclava - For ...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0      [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...  A16GFPNVF4Y816   \n",
       "1      [['Clothing, Shoes & Jewelry', 'Girls', 'Cloth...  A2XJ13PIXVJFJH   \n",
       "2      [['Clothing, Shoes & Jewelry', 'Novelty, Costu...  A2WNN1DQVL4LH5   \n",
       "3      [['Clothing, Shoes & Jewelry', 'Novelty, Costu...  A1ZPOCG2ST2CY3   \n",
       "4      [['Clothing, Shoes & Jewelry', 'Novelty, Costu...  A1JC50F14SLAEV   \n",
       "99497  [['Clothing, Shoes & Jewelry', 'Men', 'Accesso...  A1EVV74UQYVKRY   \n",
       "99498  [['Clothing, Shoes & Jewelry', 'Men', 'Accesso...   ABUE0ALHKWKHC   \n",
       "99499  [['Clothing, Shoes & Jewelry', 'Men', 'Accesso...  A1PI8VBCXXSGC7   \n",
       "99500  [['Clothing, Shoes & Jewelry', 'Men', 'Accesso...  A2XX2A4OJCDNLZ   \n",
       "99501  [['Clothing, Shoes & Jewelry', 'Men', 'Accesso...  A3UJRNI8UR4871   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          5.0  Bought this as a backup to the regular ballet ...  2014-05-03   \n",
       "1          1.0  Never GOT this item - but gave a 1 STAR becaus...  2014-05-12   \n",
       "2          5.0  The minute I saw this my heart skipped a beat....  2013-11-07   \n",
       "3          5.0  Love this Jewelry Box  so well put together ho...  2014-01-19   \n",
       "4          3.0  I wanted to have the title summarize my though...  2014-05-12   \n",
       "99497      4.0  I go walking a lot in all kinds of weather and...  2014-06-16   \n",
       "99498      5.0  This two pack of Balaclavas makes for a very n...  2014-06-09   \n",
       "99499      5.0  Well, the first thing I did was try the balacl...  2014-06-13   \n",
       "99500      5.0  While balaclavas can be used for a variety of ...  2014-06-13   \n",
       "99501      4.0  Nice material, but not as nice as  silk or mer...  2014-06-09   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      bought backup regular ballet outfit daughter w...  \n",
       "1      item star reply supplier great try send item r...  \n",
       "2      minute saw heart skip beat nice case sort coll...  \n",
       "3      love jewelry box hold plendy love pink look ni...  \n",
       "4      want title summarize thought decide read entir...  \n",
       "99497  walk lot kind weather know lot like block cold...  \n",
       "99498  pack balaclava nice purchase balaclava fit snu...  \n",
       "99499  thing try balaclava hubby try fit average size...  \n",
       "99500  balaclava use variety thing use mainly late fa...  \n",
       "99501  nice material nice silk merino wool course mat...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65ad49bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating test rating history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e3be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f24cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d373dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069090e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0097cfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd610b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66306cbe",
   "metadata": {},
   "source": [
    "# Looking at Relevant Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c60b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ceaebf",
   "metadata": {},
   "source": [
    "# Generating Top-N Recommendations (N=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd50dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(model, user_embeddings, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2f3fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcf9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=25), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=25), axis=1)\n",
    "\n",
    "k = 25\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc6872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d728ae1b",
   "metadata": {},
   "source": [
    "# Generating Top-N Recommendations (N=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(model, user_embeddings, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc090a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4f03ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=30), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=30), axis=1)\n",
    "\n",
    "k = 30\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c680d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0c6f7d",
   "metadata": {},
   "source": [
    "# Generating Top-N Recommendations (N=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17253fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(model, user_embeddings, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e69ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=45), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=45), axis=1)\n",
    "\n",
    "k = 45\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa1bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98418d3",
   "metadata": {},
   "source": [
    "# Evaluating `EmbeddedCF` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aea8cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedCF():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, d2v):\n",
    "        self.d2v = d2v\n",
    "        self.user_rating_history = None\n",
    "        self.user_embeddings = None\n",
    "        \n",
    "    def fit(self, train, dimension=50):\n",
    "        # get user rating history\n",
    "        user_rating_history = train.groupby(['reviewerID'])['asin'].apply(list)\n",
    "        # getting unique users\n",
    "        unique_users = user_rating_history.reset_index()['reviewerID'].tolist()\n",
    "\n",
    "        # generating user embeddings for all unique users\n",
    "        user_embeddings = {}\n",
    "\n",
    "        for user in tqdm(unique_users):\n",
    "            user_embedding = np.zeros(dimension)\n",
    "            for item in user_rating_history[user]:\n",
    "                user_embedding += self.d2v.dv[item]\n",
    "\n",
    "            # mean aggregation\n",
    "            user_embedding /= len(user_rating_history[user])\n",
    "            user_embeddings[user] = user_embedding\n",
    "        \n",
    "        self.user_rating_history = user_rating_history\n",
    "        self.user_embeddings = user_embeddings\n",
    "        \n",
    "    def predict(self, n=200):\n",
    "        \"\"\"Generate a list of n-number of candidates items.\n",
    "\n",
    "        This only generates a generic candidate list of items which do not factor\n",
    "        in existing rated items and also top-N items required for recommendations.\n",
    "\n",
    "        \"\"\"\n",
    "        candidate_items = {}\n",
    "        for user in tqdm(self.user_embeddings.items()):\n",
    "            candidate_items[user[0]] = [i for i in self.d2v.dv.most_similar([user[1]], topn=n)]\n",
    "\n",
    "        return candidate_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83c1e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_ecf = EmbeddedCF(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "781a31bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:01<00:00, 36545.57it/s]\n"
     ]
    }
   ],
   "source": [
    "mem_ecf.fit(train, dimension=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "782dfa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID\n",
       "A001114613O3F18Q5NVR6     [B0016JNS44, B001T54XA8, B004AZXO1I, B004QJWKLS]\n",
       "A00146182PNM90WNNAZ5Q     [B000JJX7C0, B000MX3SH2, B003CO205E, B008JXDFCU]\n",
       "A00165422B2GAUE3EL6Z0     [B007WADN4G, B007WAEBPQ, B007WAT3I6, B008G51WHQ]\n",
       "A00338282E99B8OR2JYTZ                 [B002FA5B8O, B003F06XQW, B00768LFYY]\n",
       "A00354001GE099Q1FL0TU                 [B00387EEYA, B003RYZY8E, B0058XN9ZC]\n",
       "                                               ...                        \n",
       "AZZMQ85DPFEG3            [B0007KPPAI, B005EYUQ7E, B005VEMVI4, B007LOTZ5...\n",
       "AZZNK89PXD006                         [B000KGOHLM, B005C3DH00, B005PQPLLC]\n",
       "AZZT1ERHBSNQ8            [B000UANLGU, B002ATSG8C, B002UTJVMM, B007P83XJ...\n",
       "AZZTOUKVTUMVM             [B000196UJ0, B009GE3XQ4, B00C2DJ66C, B00C4NV6LS]\n",
       "AZZYW4YOE1B6E                         [B003V4AKTS, B004G8GOW0, B007LTV82W]\n",
       "Name: asin, Length: 39386, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_ecf.user_rating_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "648ceaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:28<00:00, 1368.28it/s]\n"
     ]
    }
   ],
   "source": [
    "predictions = mem_ecf.predict(n=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f05c188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B0016JNS44', 0.8733696341514587),\n",
       " ('B004AZXO1I', 0.8602843284606934),\n",
       " ('B0022JV0ZG', 0.8170426487922668),\n",
       " ('B002RZQIDO', 0.8118180632591248),\n",
       " ('B004QJWKLS', 0.8106290102005005)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check predictions\n",
    "predictions['A001114613O3F18Q5NVR6'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b51f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, user_rating_history, n=10):\n",
    "    \"\"\"Return the top-N recommendations for each user based on cosine similarity.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "    Returns:\n",
    "        ([dict]): A dictionary of top-N recommendations for each unique user, sorted by\n",
    "            cosine similarties.\n",
    "    \"\"\"\n",
    "    \n",
    "    # retrieve a 200 items candidate list based on similarities\n",
    "    top_ns = {}\n",
    "    for user in tqdm(predictions):\n",
    "        rated_items = user_rating_history[user]\n",
    "        candidate_items = [i[0] for i in predictions[user]]\n",
    "        unrated_items = set(candidate_items) - set(rated_items)\n",
    "        \n",
    "        user_top_n = []\n",
    "        idx = 0\n",
    "        while len(user_top_n) < n:\n",
    "            if candidate_items[idx] in unrated_items:\n",
    "                user_top_n.append(candidate_items[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                idx += 1\n",
    "        \n",
    "        top_ns[user] = user_top_n\n",
    "        \n",
    "    return top_ns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5dc4f1",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "036076ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:01<00:00, 30964.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 50576.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 52982.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@10: 0.00277, average recall@10: 0.01173.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, mem_ecf.user_rating_history, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8be5d58",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "402a5233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:01<00:00, 26816.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 48438.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 45829.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@25: 0.00224, average recall@25: 0.02344.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, mem_ecf.user_rating_history, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa6d28",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb88ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:01<00:00, 22943.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 47655.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 48280.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@30: 0.00215, average recall@30: 0.02710.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, mem_ecf.user_rating_history, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a16d98",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cd8cf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39386/39386 [00:01<00:00, 20836.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 44207.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 39363/39363 [00:00<00:00, 46873.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@45: 0.00191, average recall@45: 0.03592.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, mem_ecf.user_rating_history, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3e93d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
