{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "215181c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2cfa4d",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8729351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable\n",
    "CATEGORY = \"Grocery_and_Gourmet_Food\"\n",
    "DATA_PATH = \"data/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f77c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32f53641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A23RYWDS884TUL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This curry paste makes a delicious curry.  I j...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>curry paste delicious curry fry chicken vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A945RBQWGZXCK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've purchased different curries in the grocer...</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>purchase different curry grocery store complet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3AMNY44OP8AOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I started a new diet restricting all added sug...</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>start new diet restrict added sugar brand suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3IB4CQ2QEJLJ8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>So many flavors. I can't begin to tell you how...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>flavor begin tell love mae ploy curry ask reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>AQA5DF3RWKETQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've used this a lot recently in some of my ch...</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>use lot recently chicken dish use lot like spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        asin                              title  \\\n",
       "0      0  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1      1  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2      3  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "3      4  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "4      5  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "\n",
       "                                          categories      reviewerID  overall  \\\n",
       "0  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A23RYWDS884TUL      5.0   \n",
       "1  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   A945RBQWGZXCK      5.0   \n",
       "2  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3AMNY44OP8AOU      4.0   \n",
       "3  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3IB4CQ2QEJLJ8      5.0   \n",
       "4  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   AQA5DF3RWKETQ      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  \\\n",
       "0  This curry paste makes a delicious curry.  I j...  2013-05-28   \n",
       "1  I've purchased different curries in the grocer...  2012-09-17   \n",
       "2  I started a new diet restricting all added sug...  2014-01-23   \n",
       "3  So many flavors. I can't begin to tell you how...  2014-04-27   \n",
       "4  I've used this a lot recently in some of my ch...  2012-11-27   \n",
       "\n",
       "                                 processedReviewText  \n",
       "0  curry paste delicious curry fry chicken vegeta...  \n",
       "1  purchase different curry grocery store complet...  \n",
       "2  start new diet restrict added sugar brand suga...  \n",
       "3  flavor begin tell love mae ploy curry ask reci...  \n",
       "4  use lot recently chicken dish use lot like spi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06d5ca8",
   "metadata": {},
   "source": [
    "# Preparing Review Text for LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d938b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 47774/47774 [00:00<00:00, 120004.19it/s]\n",
      "2021-08-23 22:45:55,002 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2021-08-23 22:45:55,399 : INFO : adding document #10000 to Dictionary(14898 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-23 22:45:55,827 : INFO : adding document #20000 to Dictionary(21785 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-23 22:45:56,278 : INFO : adding document #30000 to Dictionary(27143 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-23 22:45:56,883 : INFO : adding document #40000 to Dictionary(31844 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n",
      "2021-08-23 22:45:57,268 : INFO : built Dictionary(34875 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...) from 47774 documents (total 1942617 corpus positions)\n",
      "2021-08-23 22:45:57,309 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary(34875 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...) from 47774 documents (total 1942617 corpus positions)\", 'datetime': '2021-08-23T22:45:57.268773', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'created'}\n",
      "2021-08-23 22:45:57,371 : INFO : discarding 29213 tokens: [('lidded', 9), ('scrambled', 4), ('yogurts', 1), ('chaokoh', 5), ('icer', 2), ('newbie', 11), ('whomever', 6), ('curris', 1), ('eggnog', 13), ('exclude', 12)]...\n",
      "2021-08-23 22:45:57,371 : INFO : keeping 5662 tokens which were in no less than 15 and no more than 35830 (=75.0%) documents\n",
      "2021-08-23 22:45:57,386 : INFO : resulting dictionary: Dictionary(5662 unique tokens: ['add', 'chicken', 'coconut', 'curry', 'delicious']...)\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "processed_reviews = train[\"processedReviewText\"].progress_apply(lambda x: x.split())\n",
    "\n",
    "# creating a bag-of-words\n",
    "dictionary = gensim.corpora.Dictionary(processed_reviews)\n",
    "\n",
    "# filtering out tokens that appear in less than 15 reviews\n",
    "# or more than 0.5 of the corpus\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.75)\n",
    "\n",
    "# creating dict how many words and time the word appear\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc400a",
   "metadata": {},
   "source": [
    "# Training LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d0b109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:45:58,834 : INFO : using symmetric alpha at 0.02\n",
      "2021-08-23 22:45:58,835 : INFO : using symmetric eta at 0.02\n",
      "2021-08-23 22:45:58,837 : INFO : using serial LDA version on this node\n",
      "2021-08-23 22:45:58,862 : INFO : running online LDA training, 50 topics, 20 passes over the supplied corpus of 47774 documents, updating every 16000 documents, evaluating every ~47774 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "2021-08-23 22:45:58,865 : INFO : training LDA model using 8 processes\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "2021-08-23 22:46:04,068 : INFO : PROGRESS: pass 0, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:46:04,080 : INFO : PROGRESS: pass 0, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:46:04,082 : INFO : PROGRESS: pass 0, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:46:04,092 : INFO : PROGRESS: pass 0, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:46:04,094 : INFO : PROGRESS: pass 0, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:46:04,105 : INFO : PROGRESS: pass 0, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:46:04,107 : INFO : PROGRESS: pass 0, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:46:04,121 : INFO : PROGRESS: pass 0, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:46:04,125 : INFO : PROGRESS: pass 0, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:46:04,145 : INFO : PROGRESS: pass 0, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:46:04,152 : INFO : PROGRESS: pass 0, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:46:04,179 : INFO : PROGRESS: pass 0, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:46:04,184 : INFO : PROGRESS: pass 0, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:46:04,232 : INFO : PROGRESS: pass 0, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:46:04,246 : INFO : PROGRESS: pass 0, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:46:04,254 : INFO : PROGRESS: pass 0, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:46:04,275 : INFO : PROGRESS: pass 0, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:46:04,278 : INFO : PROGRESS: pass 0, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:46:04,280 : INFO : PROGRESS: pass 0, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:46:04,283 : INFO : PROGRESS: pass 0, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:46:04,310 : INFO : PROGRESS: pass 0, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:46:04,313 : INFO : PROGRESS: pass 0, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:46:04,316 : INFO : PROGRESS: pass 0, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:46:04,318 : INFO : PROGRESS: pass 0, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:46:07,629 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:07,660 : INFO : topic #39 (0.020): 0.024*\"good\" + 0.019*\"flavor\" + 0.017*\"love\" + 0.012*\"like\" + 0.012*\"buy\" + 0.010*\"mix\" + 0.010*\"try\" + 0.008*\"eat\" + 0.008*\"bag\" + 0.007*\"taste\"\n",
      "2021-08-23 22:46:07,662 : INFO : topic #33 (0.020): 0.019*\"good\" + 0.018*\"like\" + 0.015*\"tea\" + 0.013*\"love\" + 0.010*\"product\" + 0.010*\"eat\" + 0.010*\"taste\" + 0.009*\"bag\" + 0.009*\"buy\" + 0.008*\"soup\"\n",
      "2021-08-23 22:46:07,664 : INFO : topic #1 (0.020): 0.024*\"like\" + 0.022*\"taste\" + 0.014*\"good\" + 0.014*\"coffee\" + 0.014*\"sauce\" + 0.012*\"flavor\" + 0.011*\"use\" + 0.011*\"great\" + 0.008*\"try\" + 0.008*\"add\"\n",
      "2021-08-23 22:46:07,665 : INFO : topic #9 (0.020): 0.014*\"product\" + 0.011*\"taste\" + 0.011*\"good\" + 0.011*\"like\" + 0.009*\"great\" + 0.009*\"use\" + 0.008*\"try\" + 0.007*\"flavor\" + 0.006*\"fresh\" + 0.006*\"come\"\n",
      "2021-08-23 22:46:07,666 : INFO : topic #3 (0.020): 0.019*\"like\" + 0.015*\"good\" + 0.015*\"taste\" + 0.014*\"great\" + 0.011*\"flavor\" + 0.010*\"tea\" + 0.010*\"try\" + 0.009*\"chocolate\" + 0.008*\"product\" + 0.007*\"organic\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:46:07,668 : INFO : topic diff=20.570000, rho=1.000000\n",
      "2021-08-23 22:46:11,335 : INFO : -7.644 per-word bound, 200.1 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:11,399 : INFO : merging changes from 18000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:11,421 : INFO : topic #43 (0.020): 0.018*\"use\" + 0.016*\"good\" + 0.016*\"like\" + 0.014*\"great\" + 0.012*\"taste\" + 0.011*\"love\" + 0.011*\"tea\" + 0.011*\"price\" + 0.010*\"product\" + 0.009*\"coffee\"\n",
      "2021-08-23 22:46:11,423 : INFO : topic #42 (0.020): 0.019*\"good\" + 0.013*\"taste\" + 0.013*\"buy\" + 0.012*\"tea\" + 0.010*\"chocolate\" + 0.010*\"soup\" + 0.010*\"like\" + 0.009*\"flavor\" + 0.009*\"try\" + 0.008*\"use\"\n",
      "2021-08-23 22:46:11,425 : INFO : topic #44 (0.020): 0.019*\"good\" + 0.016*\"taste\" + 0.014*\"product\" + 0.013*\"tea\" + 0.012*\"like\" + 0.012*\"use\" + 0.011*\"flavor\" + 0.009*\"buy\" + 0.008*\"try\" + 0.007*\"chocolate\"\n",
      "2021-08-23 22:46:11,427 : INFO : topic #6 (0.020): 0.023*\"use\" + 0.018*\"good\" + 0.016*\"taste\" + 0.012*\"flavor\" + 0.011*\"like\" + 0.009*\"product\" + 0.008*\"try\" + 0.006*\"honey\" + 0.006*\"free\" + 0.006*\"great\"\n",
      "2021-08-23 22:46:11,430 : INFO : topic #11 (0.020): 0.024*\"like\" + 0.019*\"taste\" + 0.014*\"use\" + 0.013*\"flavor\" + 0.012*\"love\" + 0.011*\"coconut\" + 0.010*\"buy\" + 0.010*\"water\" + 0.010*\"good\" + 0.009*\"chocolate\"\n",
      "2021-08-23 22:46:11,432 : INFO : topic diff=7.214655, rho=0.333333\n",
      "2021-08-23 22:46:14,077 : INFO : -7.599 per-word bound, 193.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:14,110 : INFO : merging changes from 13774 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:14,123 : INFO : topic #2 (0.020): 0.016*\"use\" + 0.016*\"try\" + 0.015*\"sugar\" + 0.014*\"product\" + 0.014*\"like\" + 0.013*\"pasta\" + 0.012*\"good\" + 0.012*\"taste\" + 0.012*\"oil\" + 0.008*\"olive\"\n",
      "2021-08-23 22:46:14,124 : INFO : topic #31 (0.020): 0.025*\"taste\" + 0.021*\"like\" + 0.020*\"good\" + 0.016*\"coffee\" + 0.013*\"flavor\" + 0.010*\"love\" + 0.008*\"great\" + 0.008*\"tea\" + 0.008*\"little\" + 0.007*\"add\"\n",
      "2021-08-23 22:46:14,125 : INFO : topic #27 (0.020): 0.014*\"chocolate\" + 0.012*\"eat\" + 0.012*\"taste\" + 0.011*\"good\" + 0.010*\"like\" + 0.010*\"sauce\" + 0.009*\"try\" + 0.009*\"product\" + 0.008*\"buy\" + 0.007*\"flavor\"\n",
      "2021-08-23 22:46:14,126 : INFO : topic #25 (0.020): 0.022*\"tea\" + 0.018*\"good\" + 0.016*\"coffee\" + 0.016*\"try\" + 0.015*\"love\" + 0.014*\"chocolate\" + 0.013*\"like\" + 0.013*\"cup\" + 0.010*\"taste\" + 0.008*\"great\"\n",
      "2021-08-23 22:46:14,127 : INFO : topic #29 (0.020): 0.013*\"use\" + 0.012*\"taste\" + 0.012*\"product\" + 0.011*\"water\" + 0.011*\"good\" + 0.011*\"add\" + 0.010*\"like\" + 0.009*\"sugar\" + 0.009*\"honey\" + 0.008*\"flavor\"\n",
      "2021-08-23 22:46:14,128 : INFO : topic diff=0.620148, rho=0.235702\n",
      "2021-08-23 22:46:15,262 : INFO : -7.411 per-word bound, 170.1 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:15,263 : INFO : PROGRESS: pass 1, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:46:15,271 : INFO : PROGRESS: pass 1, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:46:15,271 : INFO : PROGRESS: pass 1, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:46:15,272 : INFO : PROGRESS: pass 1, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:46:15,280 : INFO : PROGRESS: pass 1, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:46:15,281 : INFO : PROGRESS: pass 1, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:46:15,282 : INFO : PROGRESS: pass 1, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:46:15,283 : INFO : PROGRESS: pass 1, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:46:15,292 : INFO : PROGRESS: pass 1, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:46:15,293 : INFO : PROGRESS: pass 1, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:46:15,294 : INFO : PROGRESS: pass 1, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:46:15,304 : INFO : PROGRESS: pass 1, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:46:15,305 : INFO : PROGRESS: pass 1, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:46:15,307 : INFO : PROGRESS: pass 1, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:46:15,318 : INFO : PROGRESS: pass 1, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:46:15,321 : INFO : PROGRESS: pass 1, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:46:15,324 : INFO : PROGRESS: pass 1, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:46:15,338 : INFO : PROGRESS: pass 1, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:46:15,346 : INFO : PROGRESS: pass 1, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:46:15,351 : INFO : PROGRESS: pass 1, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:46:15,356 : INFO : PROGRESS: pass 1, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:46:15,397 : INFO : PROGRESS: pass 1, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:46:15,416 : INFO : PROGRESS: pass 1, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:46:15,454 : INFO : PROGRESS: pass 1, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:46:17,889 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:17,912 : INFO : topic #21 (0.020): 0.022*\"good\" + 0.019*\"like\" + 0.016*\"coffee\" + 0.015*\"chocolate\" + 0.013*\"flavor\" + 0.013*\"drink\" + 0.012*\"buy\" + 0.010*\"love\" + 0.009*\"taste\" + 0.008*\"honey\"\n",
      "2021-08-23 22:46:17,913 : INFO : topic #24 (0.020): 0.078*\"tea\" + 0.026*\"flavor\" + 0.016*\"taste\" + 0.015*\"like\" + 0.012*\"bag\" + 0.011*\"drink\" + 0.011*\"good\" + 0.008*\"try\" + 0.008*\"green\" + 0.008*\"great\"\n",
      "2021-08-23 22:46:17,915 : INFO : topic #13 (0.020): 0.026*\"good\" + 0.015*\"use\" + 0.015*\"taste\" + 0.015*\"flavor\" + 0.014*\"like\" + 0.013*\"love\" + 0.013*\"great\" + 0.011*\"buy\" + 0.010*\"product\" + 0.010*\"sauce\"\n",
      "2021-08-23 22:46:17,920 : INFO : topic #45 (0.020): 0.026*\"like\" + 0.023*\"cereal\" + 0.021*\"taste\" + 0.017*\"bar\" + 0.014*\"sugar\" + 0.013*\"chocolate\" + 0.013*\"good\" + 0.011*\"flavor\" + 0.010*\"sweet\" + 0.009*\"cocoa\"\n",
      "2021-08-23 22:46:17,921 : INFO : topic #6 (0.020): 0.027*\"use\" + 0.017*\"good\" + 0.015*\"taste\" + 0.011*\"like\" + 0.011*\"flavor\" + 0.010*\"product\" + 0.008*\"try\" + 0.008*\"honey\" + 0.007*\"syrup\" + 0.006*\"oil\"\n",
      "2021-08-23 22:46:17,922 : INFO : topic diff=0.500137, rho=0.196544\n",
      "2021-08-23 22:46:21,826 : INFO : -7.389 per-word bound, 167.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:21,901 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:21,934 : INFO : topic #41 (0.020): 0.028*\"like\" + 0.021*\"good\" + 0.014*\"flavor\" + 0.012*\"taste\" + 0.011*\"try\" + 0.011*\"eat\" + 0.009*\"use\" + 0.009*\"chocolate\" + 0.008*\"love\" + 0.008*\"think\"\n",
      "2021-08-23 22:46:21,936 : INFO : topic #27 (0.020): 0.013*\"chocolate\" + 0.013*\"eat\" + 0.012*\"taste\" + 0.011*\"sauce\" + 0.011*\"good\" + 0.010*\"like\" + 0.009*\"product\" + 0.009*\"try\" + 0.008*\"buy\" + 0.007*\"flavor\"\n",
      "2021-08-23 22:46:21,938 : INFO : topic #24 (0.020): 0.085*\"tea\" + 0.026*\"flavor\" + 0.017*\"taste\" + 0.016*\"like\" + 0.012*\"bag\" + 0.011*\"drink\" + 0.011*\"good\" + 0.009*\"try\" + 0.007*\"green\" + 0.007*\"great\"\n",
      "2021-08-23 22:46:21,940 : INFO : topic #16 (0.020): 0.026*\"coffee\" + 0.023*\"flavor\" + 0.021*\"good\" + 0.016*\"great\" + 0.015*\"like\" + 0.014*\"price\" + 0.013*\"amazon\" + 0.013*\"love\" + 0.013*\"taste\" + 0.011*\"buy\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:46:21,942 : INFO : topic #7 (0.020): 0.028*\"like\" + 0.026*\"good\" + 0.019*\"taste\" + 0.017*\"cheese\" + 0.016*\"flavor\" + 0.012*\"chip\" + 0.011*\"sauce\" + 0.011*\"cracker\" + 0.009*\"little\" + 0.009*\"love\"\n",
      "2021-08-23 22:46:21,943 : INFO : topic diff=0.526771, rho=0.196544\n",
      "2021-08-23 22:46:24,608 : INFO : -7.346 per-word bound, 162.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:24,646 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:24,659 : INFO : topic #15 (0.020): 0.040*\"sugar\" + 0.019*\"like\" + 0.019*\"taste\" + 0.016*\"sweet\" + 0.015*\"flavor\" + 0.015*\"use\" + 0.012*\"good\" + 0.011*\"drink\" + 0.011*\"product\" + 0.007*\"cooky\"\n",
      "2021-08-23 22:46:24,660 : INFO : topic #49 (0.020): 0.072*\"coffee\" + 0.022*\"taste\" + 0.019*\"like\" + 0.018*\"flavor\" + 0.015*\"good\" + 0.014*\"cup\" + 0.014*\"vanilla\" + 0.011*\"try\" + 0.010*\"use\" + 0.010*\"roast\"\n",
      "2021-08-23 22:46:24,661 : INFO : topic #17 (0.020): 0.023*\"taste\" + 0.019*\"product\" + 0.013*\"like\" + 0.012*\"try\" + 0.010*\"caramel\" + 0.009*\"use\" + 0.009*\"good\" + 0.008*\"think\" + 0.008*\"flavor\" + 0.008*\"buy\"\n",
      "2021-08-23 22:46:24,661 : INFO : topic #48 (0.020): 0.019*\"like\" + 0.015*\"good\" + 0.013*\"time\" + 0.012*\"taste\" + 0.010*\"eat\" + 0.010*\"flavor\" + 0.008*\"try\" + 0.007*\"bean\" + 0.007*\"nut\" + 0.007*\"product\"\n",
      "2021-08-23 22:46:24,663 : INFO : topic #16 (0.020): 0.027*\"coffee\" + 0.024*\"flavor\" + 0.021*\"good\" + 0.017*\"great\" + 0.016*\"price\" + 0.015*\"like\" + 0.014*\"amazon\" + 0.013*\"love\" + 0.012*\"taste\" + 0.011*\"buy\"\n",
      "2021-08-23 22:46:24,664 : INFO : topic diff=0.556301, rho=0.196544\n",
      "2021-08-23 22:46:25,915 : INFO : -7.253 per-word bound, 152.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:25,916 : INFO : PROGRESS: pass 2, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:46:25,925 : INFO : PROGRESS: pass 2, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:46:25,927 : INFO : PROGRESS: pass 2, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:46:25,928 : INFO : PROGRESS: pass 2, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:46:25,937 : INFO : PROGRESS: pass 2, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:46:25,938 : INFO : PROGRESS: pass 2, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:46:25,939 : INFO : PROGRESS: pass 2, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:46:25,951 : INFO : PROGRESS: pass 2, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:46:25,952 : INFO : PROGRESS: pass 2, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:46:25,964 : INFO : PROGRESS: pass 2, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:46:25,966 : INFO : PROGRESS: pass 2, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:46:25,980 : INFO : PROGRESS: pass 2, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:46:25,982 : INFO : PROGRESS: pass 2, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:46:25,985 : INFO : PROGRESS: pass 2, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:46:25,989 : INFO : PROGRESS: pass 2, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:46:26,011 : INFO : PROGRESS: pass 2, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:46:26,017 : INFO : PROGRESS: pass 2, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:46:26,020 : INFO : PROGRESS: pass 2, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:46:26,053 : INFO : PROGRESS: pass 2, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:46:26,061 : INFO : PROGRESS: pass 2, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:46:26,065 : INFO : PROGRESS: pass 2, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:46:26,082 : INFO : PROGRESS: pass 2, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:46:26,083 : INFO : PROGRESS: pass 2, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:46:26,101 : INFO : PROGRESS: pass 2, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:46:28,456 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:28,478 : INFO : topic #5 (0.020): 0.040*\"coffee\" + 0.033*\"cup\" + 0.029*\"cookie\" + 0.029*\"like\" + 0.025*\"flavor\" + 0.018*\"good\" + 0.015*\"chocolate\" + 0.013*\"cooky\" + 0.012*\"use\" + 0.011*\"taste\"\n",
      "2021-08-23 22:46:28,479 : INFO : topic #25 (0.020): 0.020*\"good\" + 0.018*\"love\" + 0.017*\"try\" + 0.017*\"cup\" + 0.017*\"coffee\" + 0.017*\"tea\" + 0.014*\"chocolate\" + 0.013*\"like\" + 0.010*\"great\" + 0.009*\"taste\"\n",
      "2021-08-23 22:46:28,481 : INFO : topic #43 (0.020): 0.020*\"snack\" + 0.019*\"great\" + 0.017*\"good\" + 0.015*\"like\" + 0.015*\"use\" + 0.014*\"love\" + 0.012*\"price\" + 0.012*\"taste\" + 0.011*\"product\" + 0.009*\"bar\"\n",
      "2021-08-23 22:46:28,482 : INFO : topic #23 (0.020): 0.020*\"use\" + 0.015*\"love\" + 0.012*\"great\" + 0.012*\"brand\" + 0.011*\"oil\" + 0.010*\"good\" + 0.009*\"pad\" + 0.008*\"flavor\" + 0.008*\"product\" + 0.008*\"try\"\n",
      "2021-08-23 22:46:28,484 : INFO : topic #26 (0.020): 0.038*\"free\" + 0.034*\"gluten\" + 0.024*\"good\" + 0.020*\"like\" + 0.018*\"taste\" + 0.015*\"great\" + 0.015*\"snack\" + 0.014*\"product\" + 0.013*\"flavor\" + 0.011*\"try\"\n",
      "2021-08-23 22:46:28,485 : INFO : topic diff=0.574260, rho=0.192854\n",
      "2021-08-23 22:46:31,561 : INFO : -7.247 per-word bound, 151.9 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:31,617 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:31,644 : INFO : topic #24 (0.020): 0.100*\"tea\" + 0.028*\"flavor\" + 0.018*\"taste\" + 0.017*\"like\" + 0.013*\"bag\" + 0.012*\"drink\" + 0.011*\"good\" + 0.009*\"try\" + 0.008*\"cup\" + 0.008*\"green\"\n",
      "2021-08-23 22:46:31,646 : INFO : topic #9 (0.020): 0.020*\"product\" + 0.012*\"cake\" + 0.011*\"like\" + 0.010*\"good\" + 0.009*\"use\" + 0.009*\"taste\" + 0.009*\"great\" + 0.009*\"come\" + 0.007*\"package\" + 0.007*\"fresh\"\n",
      "2021-08-23 22:46:31,649 : INFO : topic #25 (0.020): 0.020*\"good\" + 0.018*\"cup\" + 0.018*\"love\" + 0.018*\"try\" + 0.017*\"coffee\" + 0.015*\"tea\" + 0.013*\"chocolate\" + 0.013*\"like\" + 0.012*\"oatmeal\" + 0.010*\"great\"\n",
      "2021-08-23 22:46:31,651 : INFO : topic #41 (0.020): 0.033*\"like\" + 0.021*\"good\" + 0.016*\"flavor\" + 0.013*\"taste\" + 0.013*\"try\" + 0.012*\"eat\" + 0.011*\"spicy\" + 0.009*\"think\" + 0.009*\"love\" + 0.008*\"little\"\n",
      "2021-08-23 22:46:31,652 : INFO : topic #44 (0.020): 0.019*\"fat\" + 0.016*\"good\" + 0.015*\"calorie\" + 0.013*\"high\" + 0.013*\"taste\" + 0.013*\"product\" + 0.010*\"like\" + 0.008*\"snack\" + 0.008*\"food\" + 0.007*\"healthy\"\n",
      "2021-08-23 22:46:31,654 : INFO : topic diff=0.597652, rho=0.192854\n",
      "2021-08-23 22:46:33,853 : INFO : -7.231 per-word bound, 150.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:33,887 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:33,900 : INFO : topic #4 (0.020): 0.030*\"apple\" + 0.023*\"fruit\" + 0.021*\"flavor\" + 0.021*\"like\" + 0.020*\"product\" + 0.018*\"taste\" + 0.014*\"good\" + 0.011*\"juice\" + 0.011*\"organic\" + 0.010*\"add\"\n",
      "2021-08-23 22:46:33,901 : INFO : topic #1 (0.020): 0.041*\"drink\" + 0.029*\"taste\" + 0.026*\"like\" + 0.020*\"energy\" + 0.017*\"flavor\" + 0.014*\"coffee\" + 0.014*\"good\" + 0.013*\"juice\" + 0.010*\"try\" + 0.009*\"caffeine\"\n",
      "2021-08-23 22:46:33,902 : INFO : topic #43 (0.020): 0.026*\"snack\" + 0.021*\"great\" + 0.017*\"good\" + 0.015*\"like\" + 0.014*\"love\" + 0.014*\"use\" + 0.012*\"price\" + 0.012*\"taste\" + 0.011*\"product\" + 0.011*\"granola\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:46:33,902 : INFO : topic #8 (0.020): 0.025*\"flavor\" + 0.025*\"salt\" + 0.024*\"chocolate\" + 0.020*\"taste\" + 0.017*\"like\" + 0.017*\"bar\" + 0.016*\"good\" + 0.014*\"dark\" + 0.012*\"little\" + 0.011*\"great\"\n",
      "2021-08-23 22:46:33,903 : INFO : topic #33 (0.020): 0.028*\"good\" + 0.021*\"tuna\" + 0.020*\"like\" + 0.019*\"love\" + 0.019*\"eat\" + 0.014*\"buy\" + 0.013*\"taste\" + 0.012*\"great\" + 0.012*\"popcorn\" + 0.012*\"bag\"\n",
      "2021-08-23 22:46:33,904 : INFO : topic diff=0.634059, rho=0.192854\n",
      "2021-08-23 22:46:34,941 : INFO : -7.164 per-word bound, 143.4 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:34,942 : INFO : PROGRESS: pass 3, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:46:34,951 : INFO : PROGRESS: pass 3, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:46:34,952 : INFO : PROGRESS: pass 3, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:46:34,960 : INFO : PROGRESS: pass 3, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:46:34,961 : INFO : PROGRESS: pass 3, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:46:34,962 : INFO : PROGRESS: pass 3, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:46:34,963 : INFO : PROGRESS: pass 3, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:46:34,973 : INFO : PROGRESS: pass 3, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:46:34,976 : INFO : PROGRESS: pass 3, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:46:34,977 : INFO : PROGRESS: pass 3, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:46:34,989 : INFO : PROGRESS: pass 3, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:46:34,991 : INFO : PROGRESS: pass 3, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:46:34,993 : INFO : PROGRESS: pass 3, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:46:35,008 : INFO : PROGRESS: pass 3, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:46:35,010 : INFO : PROGRESS: pass 3, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:46:35,016 : INFO : PROGRESS: pass 3, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:46:35,032 : INFO : PROGRESS: pass 3, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:46:35,037 : INFO : PROGRESS: pass 3, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:46:35,046 : INFO : PROGRESS: pass 3, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:46:35,051 : INFO : PROGRESS: pass 3, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:46:35,079 : INFO : PROGRESS: pass 3, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:46:35,080 : INFO : PROGRESS: pass 3, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:46:35,085 : INFO : PROGRESS: pass 3, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:46:35,121 : INFO : PROGRESS: pass 3, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:46:37,167 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:37,189 : INFO : topic #38 (0.020): 0.024*\"bread\" + 0.023*\"taste\" + 0.023*\"like\" + 0.016*\"good\" + 0.013*\"great\" + 0.012*\"butter\" + 0.011*\"buy\" + 0.011*\"love\" + 0.010*\"use\" + 0.010*\"eat\"\n",
      "2021-08-23 22:46:37,190 : INFO : topic #28 (0.020): 0.108*\"chocolate\" + 0.034*\"taste\" + 0.032*\"milk\" + 0.020*\"cooky\" + 0.019*\"good\" + 0.016*\"like\" + 0.014*\"dark\" + 0.013*\"sweet\" + 0.011*\"cookie\" + 0.010*\"chip\"\n",
      "2021-08-23 22:46:37,192 : INFO : topic #12 (0.020): 0.015*\"bar\" + 0.014*\"flavor\" + 0.014*\"good\" + 0.014*\"peanut\" + 0.013*\"like\" + 0.012*\"taste\" + 0.012*\"oat\" + 0.010*\"ingredient\" + 0.010*\"syrup\" + 0.009*\"buy\"\n",
      "2021-08-23 22:46:37,193 : INFO : topic #42 (0.020): 0.024*\"store\" + 0.023*\"buy\" + 0.020*\"good\" + 0.020*\"amazon\" + 0.016*\"price\" + 0.016*\"order\" + 0.012*\"grocery\" + 0.012*\"taste\" + 0.011*\"soup\" + 0.010*\"local\"\n",
      "2021-08-23 22:46:37,195 : INFO : topic #16 (0.020): 0.028*\"price\" + 0.024*\"amazon\" + 0.023*\"good\" + 0.022*\"flavor\" + 0.021*\"great\" + 0.020*\"coffee\" + 0.015*\"order\" + 0.014*\"love\" + 0.014*\"buy\" + 0.013*\"like\"\n",
      "2021-08-23 22:46:37,197 : INFO : topic diff=0.649484, rho=0.189365\n",
      "2021-08-23 22:46:40,176 : INFO : -7.164 per-word bound, 143.4 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:40,241 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:40,270 : INFO : topic #34 (0.020): 0.041*\"taste\" + 0.028*\"good\" + 0.017*\"drink\" + 0.013*\"coffee\" + 0.013*\"try\" + 0.013*\"great\" + 0.012*\"product\" + 0.009*\"red\" + 0.009*\"bit\" + 0.009*\"love\"\n",
      "2021-08-23 22:46:40,274 : INFO : topic #24 (0.020): 0.110*\"tea\" + 0.029*\"flavor\" + 0.019*\"taste\" + 0.018*\"like\" + 0.014*\"bag\" + 0.012*\"drink\" + 0.011*\"good\" + 0.010*\"try\" + 0.008*\"cup\" + 0.008*\"green\"\n",
      "2021-08-23 22:46:40,294 : INFO : topic #38 (0.020): 0.025*\"bread\" + 0.023*\"taste\" + 0.023*\"like\" + 0.016*\"good\" + 0.013*\"great\" + 0.012*\"butter\" + 0.011*\"eat\" + 0.011*\"buy\" + 0.011*\"love\" + 0.011*\"use\"\n",
      "2021-08-23 22:46:40,305 : INFO : topic #28 (0.020): 0.119*\"chocolate\" + 0.033*\"taste\" + 0.032*\"milk\" + 0.019*\"good\" + 0.017*\"like\" + 0.016*\"dark\" + 0.016*\"cooky\" + 0.013*\"sweet\" + 0.009*\"love\" + 0.009*\"cookie\"\n",
      "2021-08-23 22:46:40,326 : INFO : topic #33 (0.020): 0.030*\"good\" + 0.028*\"tuna\" + 0.022*\"eat\" + 0.020*\"love\" + 0.020*\"like\" + 0.016*\"buy\" + 0.014*\"great\" + 0.013*\"taste\" + 0.012*\"price\" + 0.012*\"product\"\n",
      "2021-08-23 22:46:40,347 : INFO : topic diff=0.668293, rho=0.189365\n",
      "2021-08-23 22:46:42,382 : INFO : -7.157 per-word bound, 142.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:42,420 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:42,433 : INFO : topic #41 (0.020): 0.038*\"like\" + 0.022*\"good\" + 0.019*\"flavor\" + 0.018*\"spicy\" + 0.015*\"biscuit\" + 0.015*\"taste\" + 0.014*\"try\" + 0.011*\"eat\" + 0.010*\"truffle\" + 0.010*\"think\"\n",
      "2021-08-23 22:46:42,434 : INFO : topic #28 (0.020): 0.122*\"chocolate\" + 0.032*\"taste\" + 0.031*\"milk\" + 0.022*\"cooky\" + 0.018*\"good\" + 0.018*\"like\" + 0.017*\"dark\" + 0.014*\"sweet\" + 0.012*\"cookie\" + 0.010*\"chip\"\n",
      "2021-08-23 22:46:42,434 : INFO : topic #9 (0.020): 0.024*\"product\" + 0.015*\"cake\" + 0.011*\"package\" + 0.011*\"like\" + 0.010*\"good\" + 0.010*\"come\" + 0.009*\"use\" + 0.008*\"great\" + 0.008*\"taste\" + 0.008*\"fresh\"\n",
      "2021-08-23 22:46:42,435 : INFO : topic #3 (0.020): 0.028*\"organic\" + 0.020*\"like\" + 0.018*\"taste\" + 0.015*\"spice\" + 0.014*\"ring\" + 0.014*\"good\" + 0.014*\"flavor\" + 0.012*\"great\" + 0.010*\"chocolate\" + 0.008*\"try\"\n",
      "2021-08-23 22:46:42,436 : INFO : topic #43 (0.020): 0.039*\"snack\" + 0.025*\"great\" + 0.017*\"good\" + 0.016*\"love\" + 0.015*\"like\" + 0.012*\"granola\" + 0.012*\"taste\" + 0.012*\"use\" + 0.011*\"product\" + 0.011*\"price\"\n",
      "2021-08-23 22:46:42,437 : INFO : topic diff=0.702451, rho=0.189365\n",
      "2021-08-23 22:46:43,463 : INFO : -7.104 per-word bound, 137.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:43,464 : INFO : PROGRESS: pass 4, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:46:43,472 : INFO : PROGRESS: pass 4, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:46:43,473 : INFO : PROGRESS: pass 4, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:46:43,474 : INFO : PROGRESS: pass 4, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:46:43,483 : INFO : PROGRESS: pass 4, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:46:43,484 : INFO : PROGRESS: pass 4, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:46:43,485 : INFO : PROGRESS: pass 4, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:46:43,496 : INFO : PROGRESS: pass 4, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:46:43,499 : INFO : PROGRESS: pass 4, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:46:43,500 : INFO : PROGRESS: pass 4, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:46:43,501 : INFO : PROGRESS: pass 4, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:46:43,524 : INFO : PROGRESS: pass 4, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:46:43,528 : INFO : PROGRESS: pass 4, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:46:43,532 : INFO : PROGRESS: pass 4, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:46:43,534 : INFO : PROGRESS: pass 4, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:46:43,550 : INFO : PROGRESS: pass 4, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:46:43,552 : INFO : PROGRESS: pass 4, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:46:43,554 : INFO : PROGRESS: pass 4, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:46:43,572 : INFO : PROGRESS: pass 4, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:46:43,577 : INFO : PROGRESS: pass 4, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:46:43,582 : INFO : PROGRESS: pass 4, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:46:43,606 : INFO : PROGRESS: pass 4, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:46:43,631 : INFO : PROGRESS: pass 4, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:46:43,653 : INFO : PROGRESS: pass 4, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:46:45,715 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:45,737 : INFO : topic #13 (0.020): 0.034*\"good\" + 0.020*\"great\" + 0.020*\"love\" + 0.017*\"taste\" + 0.016*\"use\" + 0.016*\"like\" + 0.016*\"buy\" + 0.015*\"stuff\" + 0.015*\"hot\" + 0.013*\"flavor\"\n",
      "2021-08-23 22:46:45,739 : INFO : topic #15 (0.020): 0.073*\"sugar\" + 0.025*\"use\" + 0.022*\"taste\" + 0.020*\"like\" + 0.019*\"sweet\" + 0.017*\"sweetener\" + 0.016*\"stevia\" + 0.014*\"splenda\" + 0.013*\"flavor\" + 0.013*\"product\"\n",
      "2021-08-23 22:46:45,740 : INFO : topic #8 (0.020): 0.048*\"salt\" + 0.026*\"flavor\" + 0.021*\"chocolate\" + 0.020*\"taste\" + 0.018*\"bar\" + 0.017*\"like\" + 0.016*\"good\" + 0.014*\"dark\" + 0.014*\"bean\" + 0.012*\"little\"\n",
      "2021-08-23 22:46:45,742 : INFO : topic #26 (0.020): 0.062*\"free\" + 0.055*\"gluten\" + 0.025*\"good\" + 0.020*\"like\" + 0.019*\"taste\" + 0.016*\"product\" + 0.016*\"great\" + 0.015*\"mix\" + 0.012*\"try\" + 0.011*\"flavor\"\n",
      "2021-08-23 22:46:45,743 : INFO : topic #23 (0.020): 0.026*\"use\" + 0.016*\"brand\" + 0.014*\"love\" + 0.013*\"great\" + 0.013*\"pad\" + 0.012*\"clean\" + 0.011*\"garlic\" + 0.010*\"oil\" + 0.009*\"good\" + 0.009*\"tomato\"\n",
      "2021-08-23 22:46:45,745 : INFO : topic diff=0.710076, rho=0.186058\n",
      "2021-08-23 22:46:48,643 : INFO : -7.107 per-word bound, 137.9 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:48,739 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:48,764 : INFO : topic #14 (0.020): 0.031*\"taste\" + 0.019*\"like\" + 0.017*\"aloe\" + 0.015*\"good\" + 0.013*\"product\" + 0.012*\"flavor\" + 0.010*\"order\" + 0.009*\"know\" + 0.009*\"drink\" + 0.007*\"pumpkin\"\n",
      "2021-08-23 22:46:48,765 : INFO : topic #49 (0.020): 0.105*\"coffee\" + 0.023*\"flavor\" + 0.023*\"taste\" + 0.022*\"like\" + 0.021*\"cup\" + 0.016*\"good\" + 0.015*\"vanilla\" + 0.012*\"roast\" + 0.012*\"strong\" + 0.011*\"try\"\n",
      "2021-08-23 22:46:48,766 : INFO : topic #24 (0.020): 0.117*\"tea\" + 0.030*\"flavor\" + 0.020*\"taste\" + 0.019*\"like\" + 0.015*\"bag\" + 0.012*\"drink\" + 0.011*\"good\" + 0.010*\"try\" + 0.009*\"cup\" + 0.007*\"strong\"\n",
      "2021-08-23 22:46:48,769 : INFO : topic #22 (0.020): 0.093*\"tea\" + 0.040*\"green\" + 0.013*\"good\" + 0.011*\"taste\" + 0.010*\"like\" + 0.010*\"water\" + 0.010*\"bag\" + 0.010*\"use\" + 0.009*\"organic\" + 0.009*\"try\"\n",
      "2021-08-23 22:46:48,770 : INFO : topic #41 (0.020): 0.040*\"like\" + 0.022*\"good\" + 0.022*\"spicy\" + 0.020*\"flavor\" + 0.015*\"try\" + 0.015*\"taste\" + 0.014*\"biscuit\" + 0.013*\"truffle\" + 0.012*\"eat\" + 0.010*\"think\"\n",
      "2021-08-23 22:46:48,772 : INFO : topic diff=0.719981, rho=0.186058\n",
      "2021-08-23 22:46:50,915 : INFO : -7.106 per-word bound, 137.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:50,956 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:50,969 : INFO : topic #35 (0.020): 0.053*\"love\" + 0.034*\"flavor\" + 0.032*\"try\" + 0.025*\"like\" + 0.021*\"taste\" + 0.019*\"buy\" + 0.015*\"great\" + 0.012*\"cashew\" + 0.011*\"good\" + 0.011*\"think\"\n",
      "2021-08-23 22:46:50,970 : INFO : topic #10 (0.020): 0.077*\"peanut\" + 0.074*\"butter\" + 0.022*\"popcorn\" + 0.021*\"product\" + 0.019*\"like\" + 0.016*\"taste\" + 0.014*\"try\" + 0.014*\"flavor\" + 0.012*\"nut\" + 0.011*\"great\"\n",
      "2021-08-23 22:46:50,971 : INFO : topic #23 (0.020): 0.028*\"use\" + 0.016*\"clean\" + 0.016*\"brand\" + 0.015*\"pad\" + 0.013*\"love\" + 0.013*\"garlic\" + 0.012*\"great\" + 0.009*\"oil\" + 0.009*\"good\" + 0.009*\"cook\"\n",
      "2021-08-23 22:46:50,971 : INFO : topic #4 (0.020): 0.042*\"apple\" + 0.037*\"fruit\" + 0.022*\"flavor\" + 0.020*\"like\" + 0.019*\"product\" + 0.018*\"taste\" + 0.017*\"organic\" + 0.016*\"juice\" + 0.015*\"ingredient\" + 0.012*\"good\"\n",
      "2021-08-23 22:46:50,972 : INFO : topic #18 (0.020): 0.045*\"bag\" + 0.016*\"use\" + 0.014*\"bread\" + 0.014*\"good\" + 0.013*\"box\" + 0.011*\"bake\" + 0.010*\"mix\" + 0.010*\"time\" + 0.009*\"great\" + 0.009*\"easy\"\n",
      "2021-08-23 22:46:50,973 : INFO : topic diff=0.748342, rho=0.186058\n",
      "2021-08-23 22:46:51,970 : INFO : -7.062 per-word bound, 133.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:51,971 : INFO : PROGRESS: pass 5, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:46:51,980 : INFO : PROGRESS: pass 5, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:46:51,981 : INFO : PROGRESS: pass 5, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:46:51,982 : INFO : PROGRESS: pass 5, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:46:51,990 : INFO : PROGRESS: pass 5, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:46:51,991 : INFO : PROGRESS: pass 5, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:46:51,992 : INFO : PROGRESS: pass 5, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:46:52,000 : INFO : PROGRESS: pass 5, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:46:52,003 : INFO : PROGRESS: pass 5, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:46:52,004 : INFO : PROGRESS: pass 5, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:46:52,005 : INFO : PROGRESS: pass 5, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:46:52,019 : INFO : PROGRESS: pass 5, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:46:52,020 : INFO : PROGRESS: pass 5, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:46:52,021 : INFO : PROGRESS: pass 5, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:46:52,036 : INFO : PROGRESS: pass 5, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:46:52,038 : INFO : PROGRESS: pass 5, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:46:52,039 : INFO : PROGRESS: pass 5, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:46:52,042 : INFO : PROGRESS: pass 5, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:46:52,062 : INFO : PROGRESS: pass 5, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:46:52,066 : INFO : PROGRESS: pass 5, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:46:52,071 : INFO : PROGRESS: pass 5, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:46:52,098 : INFO : PROGRESS: pass 5, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:46:52,137 : INFO : PROGRESS: pass 5, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:46:52,155 : INFO : PROGRESS: pass 5, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:46:54,177 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:54,198 : INFO : topic #46 (0.020): 0.031*\"rice\" + 0.026*\"soup\" + 0.025*\"add\" + 0.023*\"noodle\" + 0.017*\"cook\" + 0.016*\"water\" + 0.013*\"use\" + 0.012*\"minute\" + 0.011*\"like\" + 0.011*\"good\"\n",
      "2021-08-23 22:46:54,199 : INFO : topic #0 (0.020): 0.034*\"like\" + 0.021*\"gum\" + 0.020*\"piece\" + 0.019*\"flavor\" + 0.019*\"taste\" + 0.018*\"eat\" + 0.018*\"sweet\" + 0.015*\"cinnamon\" + 0.013*\"try\" + 0.013*\"candy\"\n",
      "2021-08-23 22:46:54,201 : INFO : topic #41 (0.020): 0.042*\"like\" + 0.028*\"spicy\" + 0.023*\"good\" + 0.023*\"flavor\" + 0.017*\"biscuit\" + 0.016*\"taste\" + 0.016*\"try\" + 0.012*\"truffle\" + 0.011*\"eat\" + 0.010*\"think\"\n",
      "2021-08-23 22:46:54,203 : INFO : topic #48 (0.020): 0.016*\"like\" + 0.016*\"time\" + 0.015*\"good\" + 0.013*\"eat\" + 0.011*\"work\" + 0.009*\"day\" + 0.009*\"bean\" + 0.009*\"taste\" + 0.008*\"nut\" + 0.007*\"know\"\n",
      "2021-08-23 22:46:54,204 : INFO : topic #10 (0.020): 0.076*\"peanut\" + 0.073*\"butter\" + 0.026*\"popcorn\" + 0.021*\"product\" + 0.019*\"like\" + 0.016*\"taste\" + 0.014*\"try\" + 0.013*\"flavor\" + 0.013*\"nut\" + 0.011*\"great\"\n",
      "2021-08-23 22:46:54,206 : INFO : topic diff=0.744169, rho=0.182919\n",
      "2021-08-23 22:46:57,083 : INFO : -7.068 per-word bound, 134.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:57,149 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:57,180 : INFO : topic #35 (0.020): 0.061*\"love\" + 0.036*\"flavor\" + 0.035*\"try\" + 0.027*\"like\" + 0.023*\"taste\" + 0.021*\"buy\" + 0.017*\"great\" + 0.014*\"cashew\" + 0.012*\"good\" + 0.011*\"think\"\n",
      "2021-08-23 22:46:57,187 : INFO : topic #1 (0.020): 0.057*\"drink\" + 0.031*\"taste\" + 0.025*\"like\" + 0.025*\"energy\" + 0.020*\"flavor\" + 0.019*\"juice\" + 0.014*\"good\" + 0.011*\"caffeine\" + 0.010*\"try\" + 0.009*\"soda\"\n",
      "2021-08-23 22:46:57,199 : INFO : topic #4 (0.020): 0.044*\"fruit\" + 0.039*\"apple\" + 0.022*\"flavor\" + 0.019*\"like\" + 0.019*\"product\" + 0.018*\"organic\" + 0.018*\"taste\" + 0.017*\"juice\" + 0.015*\"ingredient\" + 0.013*\"natural\"\n",
      "2021-08-23 22:46:57,224 : INFO : topic #8 (0.020): 0.061*\"salt\" + 0.027*\"flavor\" + 0.023*\"bar\" + 0.020*\"taste\" + 0.019*\"chocolate\" + 0.017*\"dark\" + 0.017*\"like\" + 0.016*\"good\" + 0.015*\"bean\" + 0.013*\"sea\"\n",
      "2021-08-23 22:46:57,238 : INFO : topic #15 (0.020): 0.084*\"sugar\" + 0.031*\"use\" + 0.024*\"taste\" + 0.020*\"sweetener\" + 0.020*\"like\" + 0.020*\"sweet\" + 0.020*\"stevia\" + 0.015*\"splenda\" + 0.014*\"product\" + 0.012*\"flavor\"\n",
      "2021-08-23 22:46:57,242 : INFO : topic diff=0.743525, rho=0.182919\n",
      "2021-08-23 22:46:59,674 : INFO : -7.069 per-word bound, 134.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:46:59,716 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:46:59,730 : INFO : topic #34 (0.020): 0.056*\"taste\" + 0.033*\"good\" + 0.016*\"try\" + 0.015*\"product\" + 0.014*\"drink\" + 0.013*\"bad\" + 0.013*\"great\" + 0.012*\"bitter\" + 0.012*\"red\" + 0.010*\"like\"\n",
      "2021-08-23 22:46:59,732 : INFO : topic #6 (0.020): 0.043*\"use\" + 0.036*\"syrup\" + 0.021*\"maple\" + 0.018*\"oil\" + 0.015*\"skin\" + 0.014*\"good\" + 0.012*\"taste\" + 0.011*\"product\" + 0.010*\"hair\" + 0.010*\"like\"\n",
      "2021-08-23 22:46:59,733 : INFO : topic #4 (0.020): 0.046*\"apple\" + 0.043*\"fruit\" + 0.022*\"flavor\" + 0.020*\"like\" + 0.019*\"organic\" + 0.018*\"product\" + 0.018*\"taste\" + 0.017*\"juice\" + 0.017*\"ingredient\" + 0.014*\"natural\"\n",
      "2021-08-23 22:46:59,734 : INFO : topic #12 (0.020): 0.029*\"oat\" + 0.023*\"ingredient\" + 0.017*\"corn\" + 0.017*\"syrup\" + 0.015*\"oil\" + 0.012*\"flavor\" + 0.012*\"bar\" + 0.012*\"good\" + 0.011*\"raisin\" + 0.011*\"taste\"\n",
      "2021-08-23 22:46:59,735 : INFO : topic #25 (0.020): 0.037*\"oatmeal\" + 0.022*\"love\" + 0.021*\"cup\" + 0.019*\"hot\" + 0.019*\"good\" + 0.019*\"try\" + 0.017*\"instant\" + 0.014*\"great\" + 0.014*\"day\" + 0.012*\"like\"\n",
      "2021-08-23 22:46:59,736 : INFO : topic diff=0.762152, rho=0.182919\n",
      "2021-08-23 22:47:00,929 : INFO : -7.031 per-word bound, 130.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:00,930 : INFO : PROGRESS: pass 6, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:00,939 : INFO : PROGRESS: pass 6, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:00,940 : INFO : PROGRESS: pass 6, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:00,941 : INFO : PROGRESS: pass 6, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:47:00,950 : INFO : PROGRESS: pass 6, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:47:00,951 : INFO : PROGRESS: pass 6, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:47:00,952 : INFO : PROGRESS: pass 6, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:47:00,965 : INFO : PROGRESS: pass 6, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:47:00,966 : INFO : PROGRESS: pass 6, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:47:00,968 : INFO : PROGRESS: pass 6, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:47:00,987 : INFO : PROGRESS: pass 6, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:47:00,989 : INFO : PROGRESS: pass 6, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:47:01,014 : INFO : PROGRESS: pass 6, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:47:01,019 : INFO : PROGRESS: pass 6, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:47:01,025 : INFO : PROGRESS: pass 6, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:47:01,041 : INFO : PROGRESS: pass 6, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:47:01,044 : INFO : PROGRESS: pass 6, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:47:01,045 : INFO : PROGRESS: pass 6, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:47:01,047 : INFO : PROGRESS: pass 6, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:47:01,048 : INFO : PROGRESS: pass 6, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:47:01,049 : INFO : PROGRESS: pass 6, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:47:01,051 : INFO : PROGRESS: pass 6, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:47:01,094 : INFO : PROGRESS: pass 6, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:47:01,110 : INFO : PROGRESS: pass 6, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:47:03,562 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:03,584 : INFO : topic #3 (0.020): 0.060*\"organic\" + 0.036*\"spice\" + 0.018*\"taste\" + 0.017*\"like\" + 0.015*\"ring\" + 0.015*\"curry\" + 0.014*\"good\" + 0.014*\"flavor\" + 0.013*\"great\" + 0.008*\"food\"\n",
      "2021-08-23 22:47:03,586 : INFO : topic #18 (0.020): 0.052*\"bag\" + 0.018*\"use\" + 0.014*\"bread\" + 0.013*\"good\" + 0.013*\"box\" + 0.012*\"bake\" + 0.011*\"mix\" + 0.010*\"time\" + 0.010*\"crust\" + 0.009*\"easy\"\n",
      "2021-08-23 22:47:03,587 : INFO : topic #2 (0.020): 0.057*\"pasta\" + 0.050*\"oil\" + 0.033*\"olive\" + 0.021*\"use\" + 0.016*\"taste\" + 0.016*\"good\" + 0.014*\"like\" + 0.013*\"barilla\" + 0.013*\"spaghetti\" + 0.013*\"try\"\n",
      "2021-08-23 22:47:03,589 : INFO : topic #20 (0.020): 0.069*\"sauce\" + 0.019*\"use\" + 0.018*\"flavor\" + 0.017*\"like\" + 0.017*\"hot\" + 0.016*\"taste\" + 0.012*\"add\" + 0.012*\"heat\" + 0.011*\"good\" + 0.010*\"chicken\"\n",
      "2021-08-23 22:47:03,591 : INFO : topic #41 (0.020): 0.046*\"like\" + 0.032*\"spicy\" + 0.025*\"flavor\" + 0.023*\"good\" + 0.018*\"biscuit\" + 0.018*\"try\" + 0.017*\"taste\" + 0.014*\"truffle\" + 0.011*\"eat\" + 0.011*\"think\"\n",
      "2021-08-23 22:47:03,592 : INFO : topic diff=0.746329, rho=0.179934\n",
      "2021-08-23 22:47:06,850 : INFO : -7.037 per-word bound, 131.4 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:06,922 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:06,987 : INFO : topic #11 (0.020): 0.072*\"water\" + 0.062*\"coconut\" + 0.036*\"bottle\" + 0.033*\"taste\" + 0.031*\"like\" + 0.019*\"flavor\" + 0.014*\"drink\" + 0.013*\"use\" + 0.012*\"try\" + 0.012*\"squeeze\"\n",
      "2021-08-23 22:47:07,021 : INFO : topic #8 (0.020): 0.072*\"salt\" + 0.027*\"flavor\" + 0.025*\"bar\" + 0.020*\"taste\" + 0.017*\"bean\" + 0.017*\"like\" + 0.016*\"dark\" + 0.016*\"chocolate\" + 0.016*\"good\" + 0.015*\"sea\"\n",
      "2021-08-23 22:47:07,023 : INFO : topic #21 (0.020): 0.020*\"like\" + 0.020*\"peppermint\" + 0.019*\"good\" + 0.014*\"buy\" + 0.012*\"coffee\" + 0.011*\"flavor\" + 0.010*\"chocolate\" + 0.009*\"hot\" + 0.009*\"drink\" + 0.009*\"price\"\n",
      "2021-08-23 22:47:07,027 : INFO : topic #19 (0.020): 0.041*\"cooky\" + 0.024*\"cookie\" + 0.024*\"like\" + 0.021*\"taste\" + 0.018*\"flavor\" + 0.015*\"good\" + 0.014*\"mint\" + 0.013*\"oreo\" + 0.012*\"fig\" + 0.012*\"fudge\"\n",
      "2021-08-23 22:47:07,030 : INFO : topic #10 (0.020): 0.095*\"peanut\" + 0.087*\"butter\" + 0.027*\"popcorn\" + 0.020*\"like\" + 0.018*\"taste\" + 0.017*\"product\" + 0.016*\"nut\" + 0.014*\"try\" + 0.013*\"flavor\" + 0.010*\"great\"\n",
      "2021-08-23 22:47:07,032 : INFO : topic diff=0.736134, rho=0.179934\n",
      "2021-08-23 22:47:09,166 : INFO : -7.041 per-word bound, 131.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:09,203 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:09,216 : INFO : topic #13 (0.020): 0.037*\"good\" + 0.027*\"stuff\" + 0.024*\"great\" + 0.023*\"love\" + 0.018*\"buy\" + 0.018*\"taste\" + 0.018*\"like\" + 0.017*\"use\" + 0.016*\"eat\" + 0.015*\"hot\"\n",
      "2021-08-23 22:47:09,217 : INFO : topic #3 (0.020): 0.068*\"organic\" + 0.039*\"spice\" + 0.020*\"ring\" + 0.018*\"taste\" + 0.017*\"like\" + 0.014*\"good\" + 0.013*\"flavor\" + 0.013*\"great\" + 0.013*\"curry\" + 0.008*\"food\"\n",
      "2021-08-23 22:47:09,218 : INFO : topic #26 (0.020): 0.086*\"free\" + 0.071*\"gluten\" + 0.024*\"good\" + 0.020*\"taste\" + 0.019*\"like\" + 0.018*\"product\" + 0.017*\"mix\" + 0.015*\"great\" + 0.013*\"try\" + 0.011*\"bake\"\n",
      "2021-08-23 22:47:09,219 : INFO : topic #5 (0.020): 0.084*\"cup\" + 0.037*\"coffee\" + 0.030*\"like\" + 0.029*\"keurig\" + 0.027*\"flavor\" + 0.024*\"cream\" + 0.024*\"cookie\" + 0.017*\"good\" + 0.017*\"ice\" + 0.012*\"mint\"\n",
      "2021-08-23 22:47:09,220 : INFO : topic #19 (0.020): 0.046*\"cooky\" + 0.030*\"cookie\" + 0.025*\"like\" + 0.021*\"taste\" + 0.017*\"flavor\" + 0.016*\"mint\" + 0.015*\"good\" + 0.015*\"oreo\" + 0.014*\"fudge\" + 0.012*\"fig\"\n",
      "2021-08-23 22:47:09,221 : INFO : topic diff=0.744822, rho=0.179934\n",
      "2021-08-23 22:47:10,241 : INFO : -7.007 per-word bound, 128.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:10,242 : INFO : PROGRESS: pass 7, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:10,251 : INFO : PROGRESS: pass 7, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:10,252 : INFO : PROGRESS: pass 7, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:10,253 : INFO : PROGRESS: pass 7, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:47:10,254 : INFO : PROGRESS: pass 7, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:47:10,264 : INFO : PROGRESS: pass 7, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:47:10,265 : INFO : PROGRESS: pass 7, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:47:10,266 : INFO : PROGRESS: pass 7, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:47:10,277 : INFO : PROGRESS: pass 7, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:47:10,278 : INFO : PROGRESS: pass 7, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:47:10,280 : INFO : PROGRESS: pass 7, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:47:10,293 : INFO : PROGRESS: pass 7, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:47:10,295 : INFO : PROGRESS: pass 7, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:47:10,297 : INFO : PROGRESS: pass 7, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:47:10,309 : INFO : PROGRESS: pass 7, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:47:10,313 : INFO : PROGRESS: pass 7, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:47:10,316 : INFO : PROGRESS: pass 7, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:47:10,317 : INFO : PROGRESS: pass 7, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:47:10,345 : INFO : PROGRESS: pass 7, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:47:10,355 : INFO : PROGRESS: pass 7, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:47:10,368 : INFO : PROGRESS: pass 7, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:47:10,404 : INFO : PROGRESS: pass 7, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:47:10,434 : INFO : PROGRESS: pass 7, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:47:10,449 : INFO : PROGRESS: pass 7, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:47:12,334 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:12,357 : INFO : topic #3 (0.020): 0.076*\"organic\" + 0.043*\"spice\" + 0.018*\"taste\" + 0.016*\"like\" + 0.016*\"ring\" + 0.015*\"curry\" + 0.014*\"good\" + 0.013*\"great\" + 0.013*\"flavor\" + 0.009*\"food\"\n",
      "2021-08-23 22:47:12,359 : INFO : topic #4 (0.020): 0.050*\"fruit\" + 0.045*\"apple\" + 0.023*\"flavor\" + 0.020*\"organic\" + 0.019*\"like\" + 0.019*\"ingredient\" + 0.018*\"juice\" + 0.017*\"taste\" + 0.017*\"product\" + 0.015*\"natural\"\n",
      "2021-08-23 22:47:12,361 : INFO : topic #42 (0.020): 0.042*\"store\" + 0.033*\"buy\" + 0.028*\"amazon\" + 0.021*\"order\" + 0.021*\"grocery\" + 0.020*\"price\" + 0.019*\"good\" + 0.018*\"local\" + 0.013*\"box\" + 0.012*\"product\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:47:12,363 : INFO : topic #33 (0.020): 0.037*\"good\" + 0.032*\"tuna\" + 0.032*\"eat\" + 0.023*\"love\" + 0.022*\"like\" + 0.020*\"buy\" + 0.018*\"great\" + 0.015*\"taste\" + 0.014*\"product\" + 0.012*\"kid\"\n",
      "2021-08-23 22:47:12,364 : INFO : topic #47 (0.020): 0.056*\"use\" + 0.045*\"flour\" + 0.028*\"recipe\" + 0.028*\"mix\" + 0.015*\"bake\" + 0.015*\"pancake\" + 0.014*\"product\" + 0.013*\"add\" + 0.012*\"gluten\" + 0.012*\"bob\"\n",
      "2021-08-23 22:47:12,366 : INFO : topic diff=0.719308, rho=0.177090\n",
      "2021-08-23 22:47:14,984 : INFO : -7.013 per-word bound, 129.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:15,051 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:15,083 : INFO : topic #2 (0.020): 0.065*\"pasta\" + 0.052*\"oil\" + 0.032*\"olive\" + 0.019*\"use\" + 0.018*\"spaghetti\" + 0.018*\"barilla\" + 0.017*\"good\" + 0.017*\"taste\" + 0.015*\"like\" + 0.015*\"cook\"\n",
      "2021-08-23 22:47:15,087 : INFO : topic #16 (0.020): 0.062*\"price\" + 0.040*\"amazon\" + 0.031*\"great\" + 0.029*\"good\" + 0.023*\"save\" + 0.020*\"buy\" + 0.019*\"order\" + 0.017*\"subscribe\" + 0.015*\"love\" + 0.013*\"flavor\"\n",
      "2021-08-23 22:47:15,107 : INFO : topic #22 (0.020): 0.106*\"tea\" + 0.053*\"green\" + 0.015*\"ginger\" + 0.012*\"good\" + 0.011*\"taste\" + 0.010*\"drink\" + 0.010*\"leaf\" + 0.010*\"organic\" + 0.009*\"like\" + 0.009*\"use\"\n",
      "2021-08-23 22:47:15,120 : INFO : topic #15 (0.020): 0.094*\"sugar\" + 0.036*\"use\" + 0.025*\"taste\" + 0.023*\"sweetener\" + 0.022*\"stevia\" + 0.021*\"sweet\" + 0.020*\"like\" + 0.017*\"splenda\" + 0.015*\"product\" + 0.011*\"sweeten\"\n",
      "2021-08-23 22:47:15,137 : INFO : topic #40 (0.020): 0.046*\"gift\" + 0.027*\"basket\" + 0.020*\"item\" + 0.020*\"calorie\" + 0.020*\"good\" + 0.020*\"size\" + 0.020*\"low\" + 0.014*\"nice\" + 0.013*\"carb\" + 0.011*\"great\"\n",
      "2021-08-23 22:47:15,154 : INFO : topic diff=0.701388, rho=0.177090\n",
      "2021-08-23 22:47:17,084 : INFO : -7.019 per-word bound, 129.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:17,121 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:17,134 : INFO : topic #12 (0.020): 0.037*\"ingredient\" + 0.035*\"oat\" + 0.031*\"corn\" + 0.023*\"syrup\" + 0.019*\"oil\" + 0.015*\"list\" + 0.014*\"fructose\" + 0.013*\"raisin\" + 0.012*\"natural\" + 0.011*\"flavor\"\n",
      "2021-08-23 22:47:17,135 : INFO : topic #22 (0.020): 0.106*\"tea\" + 0.060*\"green\" + 0.015*\"ginger\" + 0.012*\"good\" + 0.011*\"taste\" + 0.010*\"drink\" + 0.010*\"leaf\" + 0.009*\"like\" + 0.009*\"organic\" + 0.009*\"use\"\n",
      "2021-08-23 22:47:17,136 : INFO : topic #18 (0.020): 0.063*\"bag\" + 0.019*\"use\" + 0.013*\"bake\" + 0.013*\"good\" + 0.012*\"mix\" + 0.012*\"crust\" + 0.011*\"box\" + 0.011*\"pizza\" + 0.011*\"bread\" + 0.011*\"time\"\n",
      "2021-08-23 22:47:17,137 : INFO : topic #17 (0.020): 0.048*\"caramel\" + 0.026*\"product\" + 0.020*\"taste\" + 0.012*\"like\" + 0.012*\"werther\" + 0.011*\"try\" + 0.011*\"original\" + 0.010*\"think\" + 0.010*\"candy\" + 0.007*\"flavor\"\n",
      "2021-08-23 22:47:17,137 : INFO : topic #9 (0.020): 0.027*\"product\" + 0.018*\"package\" + 0.017*\"packaging\" + 0.016*\"container\" + 0.015*\"cake\" + 0.015*\"open\" + 0.015*\"plastic\" + 0.014*\"come\" + 0.013*\"wrap\" + 0.012*\"box\"\n",
      "2021-08-23 22:47:17,138 : INFO : topic diff=0.702978, rho=0.177090\n",
      "2021-08-23 22:47:18,323 : INFO : -6.988 per-word bound, 127.0 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:18,324 : INFO : PROGRESS: pass 8, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:18,336 : INFO : PROGRESS: pass 8, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:18,337 : INFO : PROGRESS: pass 8, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:18,338 : INFO : PROGRESS: pass 8, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:47:18,350 : INFO : PROGRESS: pass 8, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:47:18,351 : INFO : PROGRESS: pass 8, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:47:18,352 : INFO : PROGRESS: pass 8, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:47:18,364 : INFO : PROGRESS: pass 8, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:47:18,366 : INFO : PROGRESS: pass 8, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:47:18,367 : INFO : PROGRESS: pass 8, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:47:18,368 : INFO : PROGRESS: pass 8, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:47:18,383 : INFO : PROGRESS: pass 8, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:47:18,385 : INFO : PROGRESS: pass 8, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:47:18,387 : INFO : PROGRESS: pass 8, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:47:18,401 : INFO : PROGRESS: pass 8, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:47:18,403 : INFO : PROGRESS: pass 8, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:47:18,404 : INFO : PROGRESS: pass 8, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:47:18,427 : INFO : PROGRESS: pass 8, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:47:18,430 : INFO : PROGRESS: pass 8, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:47:18,433 : INFO : PROGRESS: pass 8, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:47:18,449 : INFO : PROGRESS: pass 8, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:47:18,452 : INFO : PROGRESS: pass 8, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:47:18,454 : INFO : PROGRESS: pass 8, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:47:18,499 : INFO : PROGRESS: pass 8, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:47:21,053 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:21,079 : INFO : topic #42 (0.020): 0.045*\"store\" + 0.035*\"buy\" + 0.029*\"amazon\" + 0.022*\"grocery\" + 0.021*\"order\" + 0.019*\"price\" + 0.019*\"good\" + 0.019*\"local\" + 0.013*\"box\" + 0.012*\"date\"\n",
      "2021-08-23 22:47:21,081 : INFO : topic #13 (0.020): 0.040*\"good\" + 0.035*\"stuff\" + 0.025*\"great\" + 0.024*\"love\" + 0.019*\"buy\" + 0.019*\"taste\" + 0.019*\"like\" + 0.018*\"use\" + 0.018*\"eat\" + 0.014*\"hot\"\n",
      "2021-08-23 22:47:21,084 : INFO : topic #29 (0.020): 0.100*\"honey\" + 0.033*\"raw\" + 0.018*\"use\" + 0.016*\"jar\" + 0.011*\"organic\" + 0.010*\"taste\" + 0.009*\"yeast\" + 0.009*\"product\" + 0.008*\"good\" + 0.008*\"lid\"\n",
      "2021-08-23 22:47:21,086 : INFO : topic #40 (0.020): 0.048*\"gift\" + 0.027*\"basket\" + 0.022*\"item\" + 0.021*\"low\" + 0.021*\"size\" + 0.020*\"calorie\" + 0.019*\"good\" + 0.014*\"carb\" + 0.014*\"nice\" + 0.011*\"small\"\n",
      "2021-08-23 22:47:21,090 : INFO : topic #25 (0.020): 0.041*\"oatmeal\" + 0.030*\"hot\" + 0.024*\"instant\" + 0.021*\"love\" + 0.021*\"cup\" + 0.019*\"day\" + 0.018*\"good\" + 0.018*\"try\" + 0.018*\"breakfast\" + 0.017*\"cold\"\n",
      "2021-08-23 22:47:21,091 : INFO : topic diff=0.670684, rho=0.174376\n",
      "2021-08-23 22:47:25,074 : INFO : -6.995 per-word bound, 127.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:25,439 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:25,463 : INFO : topic #15 (0.020): 0.098*\"sugar\" + 0.037*\"use\" + 0.025*\"taste\" + 0.024*\"sweetener\" + 0.023*\"stevia\" + 0.021*\"sweet\" + 0.020*\"like\" + 0.017*\"splenda\" + 0.016*\"product\" + 0.012*\"sweeten\"\n",
      "2021-08-23 22:47:25,466 : INFO : topic #2 (0.020): 0.069*\"pasta\" + 0.055*\"oil\" + 0.034*\"olive\" + 0.019*\"spaghetti\" + 0.019*\"use\" + 0.018*\"barilla\" + 0.017*\"good\" + 0.017*\"taste\" + 0.016*\"cook\" + 0.015*\"like\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:47:25,469 : INFO : topic #26 (0.020): 0.099*\"free\" + 0.079*\"gluten\" + 0.024*\"good\" + 0.020*\"mix\" + 0.020*\"taste\" + 0.019*\"product\" + 0.019*\"like\" + 0.015*\"great\" + 0.013*\"try\" + 0.012*\"eat\"\n",
      "2021-08-23 22:47:25,474 : INFO : topic #41 (0.020): 0.052*\"like\" + 0.038*\"spicy\" + 0.029*\"flavor\" + 0.025*\"good\" + 0.020*\"try\" + 0.019*\"truffle\" + 0.019*\"taste\" + 0.018*\"biscuit\" + 0.012*\"think\" + 0.011*\"bit\"\n",
      "2021-08-23 22:47:25,480 : INFO : topic #27 (0.020): 0.045*\"jerky\" + 0.034*\"beef\" + 0.025*\"fish\" + 0.015*\"salmon\" + 0.014*\"taste\" + 0.012*\"flavor\" + 0.012*\"good\" + 0.011*\"product\" + 0.011*\"eat\" + 0.011*\"like\"\n",
      "2021-08-23 22:47:25,486 : INFO : topic diff=0.648490, rho=0.174376\n",
      "2021-08-23 22:47:28,084 : INFO : -7.002 per-word bound, 128.1 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:28,134 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:28,151 : INFO : topic #39 (0.020): 0.052*\"candy\" + 0.040*\"love\" + 0.030*\"flavor\" + 0.027*\"good\" + 0.025*\"pop\" + 0.020*\"like\" + 0.019*\"eat\" + 0.017*\"kid\" + 0.016*\"buy\" + 0.014*\"soft\"\n",
      "2021-08-23 22:47:28,152 : INFO : topic #23 (0.020): 0.036*\"use\" + 0.031*\"clean\" + 0.019*\"garlic\" + 0.018*\"brand\" + 0.017*\"pad\" + 0.012*\"lemon\" + 0.012*\"cook\" + 0.012*\"tomato\" + 0.011*\"great\" + 0.010*\"fresh\"\n",
      "2021-08-23 22:47:28,153 : INFO : topic #27 (0.020): 0.043*\"jerky\" + 0.034*\"beef\" + 0.027*\"fish\" + 0.016*\"salmon\" + 0.014*\"taste\" + 0.012*\"flavor\" + 0.012*\"good\" + 0.011*\"like\" + 0.011*\"product\" + 0.011*\"eat\"\n",
      "2021-08-23 22:47:28,154 : INFO : topic #33 (0.020): 0.038*\"good\" + 0.034*\"eat\" + 0.034*\"tuna\" + 0.023*\"love\" + 0.022*\"like\" + 0.021*\"buy\" + 0.017*\"great\" + 0.016*\"taste\" + 0.014*\"product\" + 0.012*\"kid\"\n",
      "2021-08-23 22:47:28,156 : INFO : topic #22 (0.020): 0.109*\"tea\" + 0.064*\"green\" + 0.017*\"ginger\" + 0.012*\"good\" + 0.011*\"leaf\" + 0.011*\"taste\" + 0.011*\"drink\" + 0.009*\"like\" + 0.009*\"organic\" + 0.009*\"use\"\n",
      "2021-08-23 22:47:28,157 : INFO : topic diff=0.645299, rho=0.174376\n",
      "2021-08-23 22:47:29,791 : INFO : -6.975 per-word bound, 125.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:29,792 : INFO : PROGRESS: pass 9, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:29,805 : INFO : PROGRESS: pass 9, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:29,806 : INFO : PROGRESS: pass 9, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:29,808 : INFO : PROGRESS: pass 9, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:47:29,821 : INFO : PROGRESS: pass 9, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:47:29,824 : INFO : PROGRESS: pass 9, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:47:29,830 : INFO : PROGRESS: pass 9, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:47:29,832 : INFO : PROGRESS: pass 9, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:47:29,851 : INFO : PROGRESS: pass 9, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:47:29,854 : INFO : PROGRESS: pass 9, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:47:29,877 : INFO : PROGRESS: pass 9, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:47:29,887 : INFO : PROGRESS: pass 9, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:47:29,905 : INFO : PROGRESS: pass 9, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:47:29,940 : INFO : PROGRESS: pass 9, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:47:29,945 : INFO : PROGRESS: pass 9, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:47:29,963 : INFO : PROGRESS: pass 9, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:47:29,964 : INFO : PROGRESS: pass 9, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:47:29,970 : INFO : PROGRESS: pass 9, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:47:29,971 : INFO : PROGRESS: pass 9, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:47:29,973 : INFO : PROGRESS: pass 9, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:47:29,974 : INFO : PROGRESS: pass 9, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:47:29,998 : INFO : PROGRESS: pass 9, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:47:30,032 : INFO : PROGRESS: pass 9, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:47:30,074 : INFO : PROGRESS: pass 9, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:47:32,809 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:32,831 : INFO : topic #19 (0.020): 0.062*\"cooky\" + 0.043*\"cookie\" + 0.026*\"like\" + 0.022*\"taste\" + 0.018*\"mint\" + 0.016*\"oreo\" + 0.016*\"flavor\" + 0.015*\"good\" + 0.015*\"fudge\" + 0.012*\"fig\"\n",
      "2021-08-23 22:47:32,833 : INFO : topic #29 (0.020): 0.107*\"honey\" + 0.036*\"raw\" + 0.018*\"use\" + 0.017*\"jar\" + 0.011*\"organic\" + 0.010*\"taste\" + 0.010*\"yeast\" + 0.009*\"product\" + 0.009*\"lid\" + 0.008*\"good\"\n",
      "2021-08-23 22:47:32,835 : INFO : topic #30 (0.020): 0.072*\"chip\" + 0.038*\"package\" + 0.025*\"small\" + 0.019*\"bag\" + 0.017*\"size\" + 0.015*\"ahoy\" + 0.014*\"open\" + 0.014*\"like\" + 0.013*\"taste\" + 0.013*\"good\"\n",
      "2021-08-23 22:47:32,836 : INFO : topic #2 (0.020): 0.071*\"pasta\" + 0.061*\"oil\" + 0.038*\"olive\" + 0.019*\"use\" + 0.017*\"spaghetti\" + 0.017*\"taste\" + 0.017*\"good\" + 0.016*\"cook\" + 0.015*\"barilla\" + 0.015*\"like\"\n",
      "2021-08-23 22:47:32,837 : INFO : topic #26 (0.020): 0.104*\"free\" + 0.083*\"gluten\" + 0.023*\"good\" + 0.020*\"mix\" + 0.020*\"taste\" + 0.019*\"product\" + 0.018*\"like\" + 0.015*\"great\" + 0.014*\"try\" + 0.012*\"bake\"\n",
      "2021-08-23 22:47:32,839 : INFO : topic diff=0.610265, rho=0.171784\n",
      "2021-08-23 22:47:35,910 : INFO : -6.981 per-word bound, 126.3 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:35,993 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:36,029 : INFO : topic #30 (0.020): 0.072*\"chip\" + 0.039*\"package\" + 0.025*\"small\" + 0.020*\"bag\" + 0.018*\"size\" + 0.014*\"open\" + 0.014*\"like\" + 0.013*\"good\" + 0.013*\"taste\" + 0.013*\"ahoy\"\n",
      "2021-08-23 22:47:36,039 : INFO : topic #34 (0.020): 0.083*\"taste\" + 0.042*\"good\" + 0.024*\"bad\" + 0.022*\"try\" + 0.022*\"bitter\" + 0.016*\"aftertaste\" + 0.015*\"product\" + 0.014*\"ok\" + 0.013*\"like\" + 0.012*\"great\"\n",
      "2021-08-23 22:47:36,064 : INFO : topic #36 (0.020): 0.074*\"seed\" + 0.018*\"consume\" + 0.017*\"sesame\" + 0.017*\"food\" + 0.017*\"flax\" + 0.016*\"chia\" + 0.016*\"nutrient\" + 0.012*\"oil\" + 0.011*\"high\" + 0.010*\"quinoa\"\n",
      "2021-08-23 22:47:36,070 : INFO : topic #33 (0.020): 0.038*\"good\" + 0.038*\"tuna\" + 0.036*\"eat\" + 0.023*\"love\" + 0.023*\"like\" + 0.021*\"buy\" + 0.017*\"great\" + 0.016*\"taste\" + 0.014*\"product\" + 0.012*\"kid\"\n",
      "2021-08-23 22:47:36,072 : INFO : topic #7 (0.020): 0.066*\"cheese\" + 0.056*\"cracker\" + 0.029*\"taste\" + 0.029*\"like\" + 0.023*\"good\" + 0.020*\"flavor\" + 0.017*\"chip\" + 0.013*\"cheddar\" + 0.012*\"snack\" + 0.012*\"eat\"\n",
      "2021-08-23 22:47:36,075 : INFO : topic diff=0.586139, rho=0.171784\n",
      "2021-08-23 22:47:38,690 : INFO : -6.989 per-word bound, 127.0 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:38,740 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:38,758 : INFO : topic #43 (0.020): 0.096*\"snack\" + 0.036*\"great\" + 0.022*\"healthy\" + 0.021*\"good\" + 0.017*\"eat\" + 0.015*\"love\" + 0.014*\"like\" + 0.014*\"lunch\" + 0.013*\"tasty\" + 0.012*\"pack\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:47:38,759 : INFO : topic #0 (0.020): 0.039*\"like\" + 0.029*\"piece\" + 0.022*\"sweet\" + 0.022*\"gum\" + 0.022*\"flavor\" + 0.020*\"taste\" + 0.019*\"eat\" + 0.018*\"cinnamon\" + 0.017*\"chew\" + 0.015*\"hard\"\n",
      "2021-08-23 22:47:38,760 : INFO : topic #40 (0.020): 0.055*\"gift\" + 0.031*\"basket\" + 0.026*\"item\" + 0.024*\"low\" + 0.024*\"size\" + 0.019*\"calorie\" + 0.018*\"good\" + 0.015*\"carb\" + 0.015*\"nice\" + 0.013*\"small\"\n",
      "2021-08-23 22:47:38,761 : INFO : topic #20 (0.020): 0.073*\"sauce\" + 0.021*\"use\" + 0.019*\"flavor\" + 0.017*\"hot\" + 0.017*\"like\" + 0.015*\"taste\" + 0.014*\"add\" + 0.012*\"good\" + 0.012*\"chicken\" + 0.012*\"heat\"\n",
      "2021-08-23 22:47:38,762 : INFO : topic #49 (0.020): 0.126*\"coffee\" + 0.026*\"flavor\" + 0.024*\"like\" + 0.023*\"cup\" + 0.023*\"taste\" + 0.016*\"good\" + 0.014*\"roast\" + 0.014*\"strong\" + 0.013*\"vanilla\" + 0.012*\"blend\"\n",
      "2021-08-23 22:47:38,764 : INFO : topic diff=0.581152, rho=0.171784\n",
      "2021-08-23 22:47:40,093 : INFO : -6.962 per-word bound, 124.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:40,094 : INFO : PROGRESS: pass 10, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:40,105 : INFO : PROGRESS: pass 10, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:40,107 : INFO : PROGRESS: pass 10, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:40,108 : INFO : PROGRESS: pass 10, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:47:40,118 : INFO : PROGRESS: pass 10, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:47:40,119 : INFO : PROGRESS: pass 10, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:47:40,120 : INFO : PROGRESS: pass 10, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:47:40,121 : INFO : PROGRESS: pass 10, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:47:40,135 : INFO : PROGRESS: pass 10, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:47:40,137 : INFO : PROGRESS: pass 10, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:47:40,138 : INFO : PROGRESS: pass 10, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:47:40,153 : INFO : PROGRESS: pass 10, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:47:40,155 : INFO : PROGRESS: pass 10, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:47:40,156 : INFO : PROGRESS: pass 10, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:47:40,158 : INFO : PROGRESS: pass 10, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:47:40,162 : INFO : PROGRESS: pass 10, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:47:40,184 : INFO : PROGRESS: pass 10, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:47:40,199 : INFO : PROGRESS: pass 10, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:47:40,205 : INFO : PROGRESS: pass 10, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:47:40,213 : INFO : PROGRESS: pass 10, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:47:40,217 : INFO : PROGRESS: pass 10, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:47:40,235 : INFO : PROGRESS: pass 10, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:47:40,255 : INFO : PROGRESS: pass 10, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:47:40,291 : INFO : PROGRESS: pass 10, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:47:42,269 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:42,335 : INFO : topic #0 (0.020): 0.039*\"like\" + 0.029*\"piece\" + 0.023*\"gum\" + 0.023*\"sweet\" + 0.022*\"flavor\" + 0.020*\"taste\" + 0.019*\"eat\" + 0.018*\"chew\" + 0.018*\"cinnamon\" + 0.016*\"hard\"\n",
      "2021-08-23 22:47:42,337 : INFO : topic #5 (0.020): 0.131*\"cup\" + 0.041*\"coffee\" + 0.038*\"cream\" + 0.032*\"keurig\" + 0.028*\"ice\" + 0.027*\"flavor\" + 0.027*\"like\" + 0.016*\"good\" + 0.013*\"use\" + 0.012*\"box\"\n",
      "2021-08-23 22:47:42,338 : INFO : topic #11 (0.020): 0.090*\"water\" + 0.063*\"coconut\" + 0.044*\"bottle\" + 0.034*\"taste\" + 0.030*\"like\" + 0.021*\"flavor\" + 0.016*\"drink\" + 0.016*\"squeeze\" + 0.014*\"use\" + 0.012*\"try\"\n",
      "2021-08-23 22:47:42,340 : INFO : topic #39 (0.020): 0.054*\"candy\" + 0.039*\"love\" + 0.030*\"flavor\" + 0.026*\"good\" + 0.025*\"pop\" + 0.020*\"like\" + 0.020*\"eat\" + 0.018*\"kid\" + 0.016*\"buy\" + 0.015*\"licorice\"\n",
      "2021-08-23 22:47:42,341 : INFO : topic #22 (0.020): 0.116*\"tea\" + 0.068*\"green\" + 0.020*\"ginger\" + 0.012*\"good\" + 0.012*\"leaf\" + 0.011*\"drink\" + 0.010*\"taste\" + 0.009*\"jasmine\" + 0.009*\"organic\" + 0.009*\"like\"\n",
      "2021-08-23 22:47:42,343 : INFO : topic diff=0.545731, rho=0.169304\n",
      "2021-08-23 22:47:45,774 : INFO : -6.970 per-word bound, 125.4 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:45,860 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:45,909 : INFO : topic #49 (0.020): 0.128*\"coffee\" + 0.026*\"flavor\" + 0.024*\"like\" + 0.023*\"taste\" + 0.022*\"cup\" + 0.016*\"good\" + 0.014*\"roast\" + 0.014*\"vanilla\" + 0.014*\"strong\" + 0.012*\"blend\"\n",
      "2021-08-23 22:47:45,919 : INFO : topic #42 (0.020): 0.052*\"store\" + 0.038*\"buy\" + 0.030*\"amazon\" + 0.024*\"grocery\" + 0.021*\"order\" + 0.021*\"local\" + 0.019*\"good\" + 0.018*\"price\" + 0.014*\"date\" + 0.014*\"box\"\n",
      "2021-08-23 22:47:45,962 : INFO : topic #7 (0.020): 0.069*\"cheese\" + 0.059*\"cracker\" + 0.029*\"taste\" + 0.029*\"like\" + 0.022*\"good\" + 0.020*\"flavor\" + 0.016*\"chip\" + 0.013*\"cheddar\" + 0.012*\"snack\" + 0.012*\"eat\"\n",
      "2021-08-23 22:47:45,968 : INFO : topic #45 (0.020): 0.059*\"cereal\" + 0.041*\"bar\" + 0.028*\"like\" + 0.023*\"taste\" + 0.019*\"good\" + 0.018*\"eat\" + 0.018*\"granola\" + 0.016*\"sweet\" + 0.014*\"flavor\" + 0.013*\"box\"\n",
      "2021-08-23 22:47:45,971 : INFO : topic #13 (0.020): 0.045*\"stuff\" + 0.041*\"good\" + 0.026*\"great\" + 0.025*\"love\" + 0.020*\"like\" + 0.020*\"eat\" + 0.020*\"buy\" + 0.019*\"use\" + 0.018*\"taste\" + 0.015*\"family\"\n",
      "2021-08-23 22:47:45,975 : INFO : topic diff=0.521872, rho=0.169304\n",
      "2021-08-23 22:47:48,483 : INFO : -6.978 per-word bound, 126.0 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:48,528 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:48,544 : INFO : topic #33 (0.020): 0.039*\"good\" + 0.038*\"eat\" + 0.036*\"tuna\" + 0.023*\"like\" + 0.023*\"love\" + 0.021*\"buy\" + 0.017*\"taste\" + 0.017*\"great\" + 0.014*\"product\" + 0.011*\"kid\"\n",
      "2021-08-23 22:47:48,545 : INFO : topic #44 (0.020): 0.053*\"fat\" + 0.040*\"calorie\" + 0.023*\"gram\" + 0.021*\"fiber\" + 0.017*\"high\" + 0.016*\"protein\" + 0.016*\"sodium\" + 0.013*\"low\" + 0.013*\"serving\" + 0.013*\"mg\"\n",
      "2021-08-23 22:47:48,547 : INFO : topic #12 (0.020): 0.058*\"ingredient\" + 0.048*\"corn\" + 0.036*\"oat\" + 0.030*\"syrup\" + 0.024*\"list\" + 0.023*\"oil\" + 0.018*\"fructose\" + 0.016*\"sugar\" + 0.016*\"natural\" + 0.014*\"contain\"\n",
      "2021-08-23 22:47:48,548 : INFO : topic #21 (0.020): 0.034*\"peppermint\" + 0.019*\"like\" + 0.016*\"mocha\" + 0.016*\"good\" + 0.015*\"hot\" + 0.014*\"flavor\" + 0.012*\"latte\" + 0.011*\"buy\" + 0.010*\"coffee\" + 0.010*\"house\"\n",
      "2021-08-23 22:47:48,550 : INFO : topic #27 (0.020): 0.044*\"jerky\" + 0.038*\"beef\" + 0.028*\"fish\" + 0.018*\"salmon\" + 0.014*\"taste\" + 0.014*\"flavor\" + 0.014*\"meat\" + 0.013*\"good\" + 0.012*\"sardine\" + 0.011*\"like\"\n",
      "2021-08-23 22:47:48,551 : INFO : topic diff=0.517305, rho=0.169304\n",
      "2021-08-23 22:47:50,097 : INFO : -6.952 per-word bound, 123.9 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:47:50,099 : INFO : PROGRESS: pass 11, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:50,111 : INFO : PROGRESS: pass 11, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:50,112 : INFO : PROGRESS: pass 11, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:50,114 : INFO : PROGRESS: pass 11, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:47:50,115 : INFO : PROGRESS: pass 11, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:47:50,129 : INFO : PROGRESS: pass 11, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:47:50,131 : INFO : PROGRESS: pass 11, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:47:50,133 : INFO : PROGRESS: pass 11, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:47:50,150 : INFO : PROGRESS: pass 11, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:47:50,152 : INFO : PROGRESS: pass 11, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:47:50,154 : INFO : PROGRESS: pass 11, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:47:50,156 : INFO : PROGRESS: pass 11, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:47:50,185 : INFO : PROGRESS: pass 11, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:47:50,189 : INFO : PROGRESS: pass 11, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:47:50,208 : INFO : PROGRESS: pass 11, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:47:50,246 : INFO : PROGRESS: pass 11, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:47:50,248 : INFO : PROGRESS: pass 11, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:47:50,249 : INFO : PROGRESS: pass 11, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:47:50,252 : INFO : PROGRESS: pass 11, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:47:50,254 : INFO : PROGRESS: pass 11, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:47:50,288 : INFO : PROGRESS: pass 11, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:47:50,318 : INFO : PROGRESS: pass 11, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:47:50,358 : INFO : PROGRESS: pass 11, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:47:50,386 : INFO : PROGRESS: pass 11, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:47:53,034 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:53,063 : INFO : topic #39 (0.020): 0.056*\"candy\" + 0.038*\"love\" + 0.030*\"flavor\" + 0.025*\"good\" + 0.025*\"pop\" + 0.020*\"like\" + 0.020*\"eat\" + 0.019*\"kid\" + 0.016*\"buy\" + 0.016*\"licorice\"\n",
      "2021-08-23 22:47:53,064 : INFO : topic #11 (0.020): 0.093*\"water\" + 0.062*\"coconut\" + 0.045*\"bottle\" + 0.034*\"taste\" + 0.030*\"like\" + 0.021*\"flavor\" + 0.017*\"drink\" + 0.017*\"squeeze\" + 0.015*\"use\" + 0.012*\"add\"\n",
      "2021-08-23 22:47:53,068 : INFO : topic #41 (0.020): 0.057*\"like\" + 0.045*\"spicy\" + 0.035*\"flavor\" + 0.027*\"good\" + 0.022*\"try\" + 0.021*\"taste\" + 0.020*\"biscuit\" + 0.017*\"truffle\" + 0.013*\"bit\" + 0.012*\"think\"\n",
      "2021-08-23 22:47:53,070 : INFO : topic #42 (0.020): 0.054*\"store\" + 0.039*\"buy\" + 0.029*\"amazon\" + 0.026*\"grocery\" + 0.022*\"order\" + 0.021*\"local\" + 0.018*\"good\" + 0.018*\"price\" + 0.014*\"date\" + 0.014*\"box\"\n",
      "2021-08-23 22:47:53,076 : INFO : topic #23 (0.020): 0.038*\"use\" + 0.036*\"clean\" + 0.020*\"garlic\" + 0.019*\"brand\" + 0.016*\"lemon\" + 0.016*\"pad\" + 0.016*\"tomato\" + 0.012*\"cook\" + 0.011*\"fresh\" + 0.010*\"great\"\n",
      "2021-08-23 22:47:53,079 : INFO : topic diff=0.483019, rho=0.166929\n",
      "2021-08-23 22:47:56,460 : INFO : -6.960 per-word bound, 124.5 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:56,530 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:56,559 : INFO : topic #49 (0.020): 0.131*\"coffee\" + 0.027*\"flavor\" + 0.024*\"like\" + 0.022*\"taste\" + 0.021*\"cup\" + 0.016*\"good\" + 0.014*\"roast\" + 0.014*\"strong\" + 0.014*\"vanilla\" + 0.013*\"blend\"\n",
      "2021-08-23 22:47:56,565 : INFO : topic #26 (0.020): 0.117*\"free\" + 0.090*\"gluten\" + 0.023*\"good\" + 0.021*\"mix\" + 0.019*\"product\" + 0.019*\"taste\" + 0.017*\"like\" + 0.014*\"great\" + 0.014*\"try\" + 0.013*\"eat\"\n",
      "2021-08-23 22:47:56,567 : INFO : topic #42 (0.020): 0.054*\"store\" + 0.039*\"buy\" + 0.030*\"amazon\" + 0.025*\"grocery\" + 0.022*\"order\" + 0.021*\"local\" + 0.018*\"good\" + 0.018*\"price\" + 0.015*\"date\" + 0.014*\"box\"\n",
      "2021-08-23 22:47:56,569 : INFO : topic #25 (0.020): 0.049*\"oatmeal\" + 0.039*\"hot\" + 0.031*\"instant\" + 0.024*\"cold\" + 0.024*\"breakfast\" + 0.023*\"day\" + 0.019*\"love\" + 0.018*\"morning\" + 0.018*\"cup\" + 0.017*\"good\"\n",
      "2021-08-23 22:47:56,571 : INFO : topic #13 (0.020): 0.049*\"stuff\" + 0.042*\"good\" + 0.026*\"great\" + 0.025*\"love\" + 0.021*\"like\" + 0.020*\"eat\" + 0.019*\"buy\" + 0.019*\"use\" + 0.018*\"taste\" + 0.016*\"family\"\n",
      "2021-08-23 22:47:56,573 : INFO : topic diff=0.460658, rho=0.166929\n",
      "2021-08-23 22:47:58,707 : INFO : -6.968 per-word bound, 125.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:58,753 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:47:58,768 : INFO : topic #1 (0.020): 0.076*\"drink\" + 0.037*\"energy\" + 0.033*\"taste\" + 0.026*\"like\" + 0.022*\"juice\" + 0.021*\"flavor\" + 0.014*\"caffeine\" + 0.014*\"good\" + 0.011*\"soda\" + 0.011*\"vitamin\"\n",
      "2021-08-23 22:47:58,769 : INFO : topic #15 (0.020): 0.106*\"sugar\" + 0.041*\"use\" + 0.028*\"sweetener\" + 0.025*\"taste\" + 0.025*\"stevia\" + 0.022*\"sweet\" + 0.019*\"splenda\" + 0.019*\"like\" + 0.016*\"product\" + 0.014*\"sweeten\"\n",
      "2021-08-23 22:47:58,770 : INFO : topic #27 (0.020): 0.044*\"jerky\" + 0.039*\"beef\" + 0.029*\"fish\" + 0.019*\"salmon\" + 0.016*\"meat\" + 0.015*\"flavor\" + 0.014*\"taste\" + 0.013*\"sardine\" + 0.013*\"good\" + 0.012*\"like\"\n",
      "2021-08-23 22:47:58,771 : INFO : topic #11 (0.020): 0.094*\"water\" + 0.056*\"coconut\" + 0.047*\"bottle\" + 0.033*\"taste\" + 0.030*\"like\" + 0.022*\"flavor\" + 0.019*\"squeeze\" + 0.018*\"drink\" + 0.015*\"use\" + 0.013*\"add\"\n",
      "2021-08-23 22:47:58,772 : INFO : topic #14 (0.020): 0.042*\"taste\" + 0.026*\"like\" + 0.022*\"aloe\" + 0.017*\"review\" + 0.016*\"bad\" + 0.016*\"know\" + 0.015*\"product\" + 0.012*\"good\" + 0.011*\"think\" + 0.010*\"star\"\n",
      "2021-08-23 22:47:58,773 : INFO : topic diff=0.457170, rho=0.166929\n",
      "2021-08-23 22:47:59,979 : INFO : -6.944 per-word bound, 123.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:47:59,980 : INFO : PROGRESS: pass 12, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:47:59,991 : INFO : PROGRESS: pass 12, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:47:59,992 : INFO : PROGRESS: pass 12, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:47:59,993 : INFO : PROGRESS: pass 12, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:00,003 : INFO : PROGRESS: pass 12, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:00,005 : INFO : PROGRESS: pass 12, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:00,006 : INFO : PROGRESS: pass 12, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:00,008 : INFO : PROGRESS: pass 12, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:48:00,021 : INFO : PROGRESS: pass 12, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:00,022 : INFO : PROGRESS: pass 12, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:00,023 : INFO : PROGRESS: pass 12, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:00,038 : INFO : PROGRESS: pass 12, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:00,041 : INFO : PROGRESS: pass 12, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:00,043 : INFO : PROGRESS: pass 12, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:00,057 : INFO : PROGRESS: pass 12, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:00,061 : INFO : PROGRESS: pass 12, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:48:00,063 : INFO : PROGRESS: pass 12, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:00,071 : INFO : PROGRESS: pass 12, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:00,090 : INFO : PROGRESS: pass 12, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:00,102 : INFO : PROGRESS: pass 12, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:00,126 : INFO : PROGRESS: pass 12, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:00,127 : INFO : PROGRESS: pass 12, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:00,154 : INFO : PROGRESS: pass 12, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:00,188 : INFO : PROGRESS: pass 12, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:48:02,268 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:02,292 : INFO : topic #27 (0.020): 0.050*\"jerky\" + 0.041*\"beef\" + 0.027*\"fish\" + 0.018*\"salmon\" + 0.016*\"meat\" + 0.016*\"flavor\" + 0.014*\"taste\" + 0.013*\"good\" + 0.013*\"sardine\" + 0.012*\"like\"\n",
      "2021-08-23 22:48:02,293 : INFO : topic #30 (0.020): 0.088*\"chip\" + 0.044*\"package\" + 0.029*\"small\" + 0.022*\"bag\" + 0.019*\"size\" + 0.015*\"ahoy\" + 0.014*\"open\" + 0.014*\"like\" + 0.014*\"good\" + 0.013*\"gooey\"\n",
      "2021-08-23 22:48:02,295 : INFO : topic #32 (0.020): 0.089*\"almond\" + 0.045*\"bean\" + 0.039*\"vanilla\" + 0.025*\"nut\" + 0.025*\"chili\" + 0.019*\"good\" + 0.019*\"use\" + 0.017*\"extract\" + 0.015*\"paste\" + 0.011*\"roast\"\n",
      "2021-08-23 22:48:02,297 : INFO : topic #8 (0.020): 0.116*\"salt\" + 0.030*\"flavor\" + 0.022*\"sea\" + 0.021*\"taste\" + 0.019*\"bar\" + 0.018*\"bean\" + 0.016*\"use\" + 0.016*\"like\" + 0.015*\"good\" + 0.013*\"salty\"\n",
      "2021-08-23 22:48:02,298 : INFO : topic #45 (0.020): 0.058*\"cereal\" + 0.043*\"bar\" + 0.029*\"like\" + 0.024*\"taste\" + 0.020*\"granola\" + 0.019*\"eat\" + 0.019*\"good\" + 0.016*\"sweet\" + 0.015*\"flavor\" + 0.013*\"milk\"\n",
      "2021-08-23 22:48:02,300 : INFO : topic diff=0.425332, rho=0.164651\n",
      "2021-08-23 22:48:05,044 : INFO : -6.952 per-word bound, 123.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:05,109 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:05,141 : INFO : topic #24 (0.020): 0.148*\"tea\" + 0.033*\"flavor\" + 0.020*\"like\" + 0.020*\"taste\" + 0.018*\"bag\" + 0.013*\"drink\" + 0.011*\"try\" + 0.011*\"good\" + 0.009*\"cup\" + 0.009*\"strong\"\n",
      "2021-08-23 22:48:05,148 : INFO : topic #43 (0.020): 0.099*\"snack\" + 0.037*\"great\" + 0.025*\"healthy\" + 0.023*\"good\" + 0.020*\"eat\" + 0.016*\"lunch\" + 0.014*\"tasty\" + 0.014*\"like\" + 0.014*\"love\" + 0.014*\"pack\"\n",
      "2021-08-23 22:48:05,156 : INFO : topic #49 (0.020): 0.134*\"coffee\" + 0.027*\"flavor\" + 0.025*\"like\" + 0.022*\"taste\" + 0.021*\"cup\" + 0.015*\"good\" + 0.015*\"roast\" + 0.014*\"strong\" + 0.014*\"vanilla\" + 0.013*\"blend\"\n",
      "2021-08-23 22:48:05,164 : INFO : topic #26 (0.020): 0.122*\"free\" + 0.092*\"gluten\" + 0.023*\"good\" + 0.021*\"mix\" + 0.019*\"product\" + 0.019*\"taste\" + 0.017*\"like\" + 0.014*\"great\" + 0.014*\"try\" + 0.013*\"shake\"\n",
      "2021-08-23 22:48:05,191 : INFO : topic #37 (0.020): 0.091*\"product\" + 0.027*\"company\" + 0.022*\"amazon\" + 0.020*\"review\" + 0.018*\"receive\" + 0.017*\"order\" + 0.012*\"good\" + 0.012*\"quality\" + 0.010*\"send\" + 0.009*\"use\"\n",
      "2021-08-23 22:48:05,220 : INFO : topic diff=0.404946, rho=0.164651\n",
      "2021-08-23 22:48:07,620 : INFO : -6.960 per-word bound, 124.5 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:07,660 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:07,676 : INFO : topic #2 (0.020): 0.080*\"pasta\" + 0.062*\"oil\" + 0.038*\"olive\" + 0.021*\"spaghetti\" + 0.019*\"cook\" + 0.018*\"taste\" + 0.018*\"good\" + 0.018*\"barilla\" + 0.017*\"use\" + 0.016*\"like\"\n",
      "2021-08-23 22:48:07,678 : INFO : topic #46 (0.020): 0.037*\"rice\" + 0.033*\"soup\" + 0.028*\"add\" + 0.026*\"noodle\" + 0.023*\"cook\" + 0.020*\"water\" + 0.015*\"minute\" + 0.014*\"use\" + 0.013*\"like\" + 0.012*\"chicken\"\n",
      "2021-08-23 22:48:07,679 : INFO : topic #44 (0.020): 0.056*\"fat\" + 0.043*\"calorie\" + 0.025*\"gram\" + 0.023*\"fiber\" + 0.018*\"high\" + 0.018*\"protein\" + 0.017*\"sodium\" + 0.014*\"low\" + 0.014*\"serving\" + 0.014*\"serve\"\n",
      "2021-08-23 22:48:07,680 : INFO : topic #18 (0.020): 0.088*\"bag\" + 0.023*\"use\" + 0.014*\"bake\" + 0.014*\"pizza\" + 0.014*\"crust\" + 0.012*\"time\" + 0.011*\"mix\" + 0.010*\"good\" + 0.010*\"easy\" + 0.009*\"fresh\"\n",
      "2021-08-23 22:48:07,681 : INFO : topic #28 (0.020): 0.206*\"chocolate\" + 0.039*\"dark\" + 0.033*\"milk\" + 0.024*\"taste\" + 0.021*\"like\" + 0.021*\"cocoa\" + 0.020*\"bar\" + 0.018*\"good\" + 0.018*\"sweet\" + 0.011*\"flavor\"\n",
      "2021-08-23 22:48:07,682 : INFO : topic diff=0.402985, rho=0.164651\n",
      "2021-08-23 22:48:09,006 : INFO : -6.939 per-word bound, 122.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:09,007 : INFO : PROGRESS: pass 13, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:48:09,019 : INFO : PROGRESS: pass 13, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:48:09,020 : INFO : PROGRESS: pass 13, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:48:09,021 : INFO : PROGRESS: pass 13, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:09,032 : INFO : PROGRESS: pass 13, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:09,034 : INFO : PROGRESS: pass 13, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:09,036 : INFO : PROGRESS: pass 13, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:09,048 : INFO : PROGRESS: pass 13, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:48:09,049 : INFO : PROGRESS: pass 13, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:09,050 : INFO : PROGRESS: pass 13, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:09,066 : INFO : PROGRESS: pass 13, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:09,068 : INFO : PROGRESS: pass 13, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:09,069 : INFO : PROGRESS: pass 13, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:09,071 : INFO : PROGRESS: pass 13, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:09,088 : INFO : PROGRESS: pass 13, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:09,092 : INFO : PROGRESS: pass 13, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:48:09,120 : INFO : PROGRESS: pass 13, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:09,131 : INFO : PROGRESS: pass 13, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:09,153 : INFO : PROGRESS: pass 13, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:09,172 : INFO : PROGRESS: pass 13, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:09,176 : INFO : PROGRESS: pass 13, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:09,178 : INFO : PROGRESS: pass 13, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:09,207 : INFO : PROGRESS: pass 13, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:09,226 : INFO : PROGRESS: pass 13, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:48:11,930 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:11,953 : INFO : topic #27 (0.020): 0.050*\"jerky\" + 0.042*\"beef\" + 0.028*\"fish\" + 0.019*\"salmon\" + 0.018*\"meat\" + 0.016*\"flavor\" + 0.014*\"taste\" + 0.014*\"sardine\" + 0.014*\"good\" + 0.012*\"like\"\n",
      "2021-08-23 22:48:11,956 : INFO : topic #31 (0.020): 0.065*\"cherry\" + 0.055*\"pepper\" + 0.030*\"aid\" + 0.027*\"flavor\" + 0.026*\"peach\" + 0.023*\"kool\" + 0.023*\"mango\" + 0.022*\"taste\" + 0.021*\"like\" + 0.015*\"black\"\n",
      "2021-08-23 22:48:11,959 : INFO : topic #46 (0.020): 0.036*\"rice\" + 0.035*\"soup\" + 0.029*\"add\" + 0.026*\"noodle\" + 0.022*\"cook\" + 0.019*\"water\" + 0.014*\"minute\" + 0.014*\"use\" + 0.013*\"like\" + 0.012*\"chicken\"\n",
      "2021-08-23 22:48:11,962 : INFO : topic #37 (0.020): 0.095*\"product\" + 0.028*\"company\" + 0.022*\"amazon\" + 0.021*\"review\" + 0.019*\"receive\" + 0.018*\"order\" + 0.012*\"good\" + 0.012*\"quality\" + 0.010*\"send\" + 0.009*\"vine\"\n",
      "2021-08-23 22:48:11,966 : INFO : topic #36 (0.020): 0.080*\"seed\" + 0.019*\"food\" + 0.019*\"consume\" + 0.019*\"chia\" + 0.018*\"flax\" + 0.018*\"sesame\" + 0.017*\"nutrient\" + 0.013*\"quinoa\" + 0.013*\"high\" + 0.011*\"oil\"\n",
      "2021-08-23 22:48:11,967 : INFO : topic diff=0.374054, rho=0.162463\n",
      "2021-08-23 22:48:15,175 : INFO : -6.947 per-word bound, 123.3 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:15,279 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:15,309 : INFO : topic #5 (0.020): 0.162*\"cup\" + 0.048*\"coffee\" + 0.039*\"cream\" + 0.035*\"keurig\" + 0.029*\"ice\" + 0.025*\"flavor\" + 0.024*\"like\" + 0.015*\"use\" + 0.015*\"good\" + 0.012*\"box\"\n",
      "2021-08-23 22:48:15,319 : INFO : topic #36 (0.020): 0.080*\"seed\" + 0.019*\"consume\" + 0.019*\"food\" + 0.019*\"sesame\" + 0.018*\"flax\" + 0.017*\"chia\" + 0.017*\"nutrient\" + 0.013*\"quinoa\" + 0.013*\"high\" + 0.011*\"oil\"\n",
      "2021-08-23 22:48:15,329 : INFO : topic #10 (0.020): 0.118*\"peanut\" + 0.111*\"butter\" + 0.053*\"popcorn\" + 0.021*\"taste\" + 0.021*\"like\" + 0.021*\"nut\" + 0.013*\"pop\" + 0.012*\"flavor\" + 0.012*\"try\" + 0.011*\"jar\"\n",
      "2021-08-23 22:48:15,352 : INFO : topic #14 (0.020): 0.043*\"taste\" + 0.027*\"like\" + 0.019*\"review\" + 0.017*\"bad\" + 0.017*\"know\" + 0.015*\"aloe\" + 0.015*\"product\" + 0.013*\"think\" + 0.012*\"good\" + 0.011*\"star\"\n",
      "2021-08-23 22:48:15,362 : INFO : topic #44 (0.020): 0.057*\"fat\" + 0.043*\"calorie\" + 0.025*\"gram\" + 0.023*\"fiber\" + 0.019*\"protein\" + 0.019*\"high\" + 0.018*\"sodium\" + 0.015*\"low\" + 0.014*\"serving\" + 0.014*\"serve\"\n",
      "2021-08-23 22:48:15,371 : INFO : topic diff=0.355731, rho=0.162463\n",
      "2021-08-23 22:48:17,259 : INFO : -6.955 per-word bound, 124.1 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:17,299 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:17,314 : INFO : topic #5 (0.020): 0.168*\"cup\" + 0.049*\"coffee\" + 0.039*\"cream\" + 0.035*\"keurig\" + 0.029*\"ice\" + 0.025*\"flavor\" + 0.024*\"like\" + 0.015*\"use\" + 0.015*\"good\" + 0.012*\"box\"\n",
      "2021-08-23 22:48:17,315 : INFO : topic #8 (0.020): 0.120*\"salt\" + 0.031*\"flavor\" + 0.024*\"sea\" + 0.021*\"taste\" + 0.017*\"bar\" + 0.016*\"use\" + 0.016*\"like\" + 0.015*\"salty\" + 0.015*\"bean\" + 0.014*\"good\"\n",
      "2021-08-23 22:48:17,316 : INFO : topic #34 (0.020): 0.116*\"taste\" + 0.054*\"good\" + 0.040*\"bad\" + 0.027*\"try\" + 0.023*\"aftertaste\" + 0.022*\"bitter\" + 0.021*\"ok\" + 0.019*\"like\" + 0.016*\"smell\" + 0.015*\"product\"\n",
      "2021-08-23 22:48:17,317 : INFO : topic #29 (0.020): 0.132*\"honey\" + 0.043*\"raw\" + 0.025*\"jar\" + 0.019*\"use\" + 0.011*\"lid\" + 0.009*\"organic\" + 0.009*\"process\" + 0.008*\"taste\" + 0.008*\"yeast\" + 0.007*\"leak\"\n",
      "2021-08-23 22:48:17,318 : INFO : topic #4 (0.020): 0.074*\"fruit\" + 0.055*\"apple\" + 0.027*\"flavor\" + 0.024*\"juice\" + 0.022*\"ingredient\" + 0.021*\"natural\" + 0.019*\"organic\" + 0.017*\"like\" + 0.016*\"dried\" + 0.016*\"dry\"\n",
      "2021-08-23 22:48:17,319 : INFO : topic diff=0.355483, rho=0.162463\n",
      "2021-08-23 22:48:18,490 : INFO : -6.933 per-word bound, 122.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:18,491 : INFO : PROGRESS: pass 14, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:48:18,503 : INFO : PROGRESS: pass 14, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:48:18,504 : INFO : PROGRESS: pass 14, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:48:18,505 : INFO : PROGRESS: pass 14, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:18,517 : INFO : PROGRESS: pass 14, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:18,518 : INFO : PROGRESS: pass 14, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:18,519 : INFO : PROGRESS: pass 14, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:18,532 : INFO : PROGRESS: pass 14, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:48:18,533 : INFO : PROGRESS: pass 14, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:18,534 : INFO : PROGRESS: pass 14, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:18,548 : INFO : PROGRESS: pass 14, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:18,549 : INFO : PROGRESS: pass 14, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:18,551 : INFO : PROGRESS: pass 14, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:18,568 : INFO : PROGRESS: pass 14, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:18,570 : INFO : PROGRESS: pass 14, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:18,571 : INFO : PROGRESS: pass 14, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:48:18,575 : INFO : PROGRESS: pass 14, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:18,603 : INFO : PROGRESS: pass 14, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:18,610 : INFO : PROGRESS: pass 14, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:18,628 : INFO : PROGRESS: pass 14, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:18,689 : INFO : PROGRESS: pass 14, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:18,715 : INFO : PROGRESS: pass 14, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:18,753 : INFO : PROGRESS: pass 14, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:18,793 : INFO : PROGRESS: pass 14, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:48:20,768 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:20,790 : INFO : topic #21 (0.020): 0.034*\"peppermint\" + 0.018*\"mocha\" + 0.018*\"hot\" + 0.018*\"like\" + 0.015*\"flavor\" + 0.014*\"latte\" + 0.014*\"good\" + 0.013*\"house\" + 0.011*\"powder\" + 0.010*\"drink\"\n",
      "2021-08-23 22:48:20,792 : INFO : topic #43 (0.020): 0.102*\"snack\" + 0.036*\"great\" + 0.027*\"healthy\" + 0.023*\"good\" + 0.021*\"eat\" + 0.017*\"lunch\" + 0.016*\"tasty\" + 0.014*\"pack\" + 0.014*\"like\" + 0.014*\"little\"\n",
      "2021-08-23 22:48:20,794 : INFO : topic #17 (0.020): 0.057*\"caramel\" + 0.024*\"product\" + 0.021*\"original\" + 0.017*\"taste\" + 0.013*\"werther\" + 0.012*\"candy\" + 0.010*\"think\" + 0.010*\"like\" + 0.009*\"try\" + 0.009*\"hard\"\n",
      "2021-08-23 22:48:20,795 : INFO : topic #37 (0.020): 0.099*\"product\" + 0.028*\"company\" + 0.022*\"review\" + 0.022*\"amazon\" + 0.019*\"receive\" + 0.019*\"order\" + 0.012*\"quality\" + 0.011*\"good\" + 0.010*\"send\" + 0.009*\"vine\"\n",
      "2021-08-23 22:48:20,797 : INFO : topic #35 (0.020): 0.135*\"love\" + 0.062*\"try\" + 0.062*\"flavor\" + 0.044*\"like\" + 0.042*\"taste\" + 0.039*\"great\" + 0.038*\"buy\" + 0.024*\"husband\" + 0.016*\"good\" + 0.014*\"different\"\n",
      "2021-08-23 22:48:20,798 : INFO : topic diff=0.329452, rho=0.160361\n",
      "2021-08-23 22:48:23,501 : INFO : -6.941 per-word bound, 122.9 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:23,593 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:23,624 : INFO : topic #23 (0.020): 0.042*\"clean\" + 0.041*\"use\" + 0.023*\"garlic\" + 0.021*\"lemon\" + 0.018*\"brand\" + 0.016*\"tomato\" + 0.014*\"pad\" + 0.013*\"cook\" + 0.012*\"fresh\" + 0.010*\"prune\"\n",
      "2021-08-23 22:48:23,629 : INFO : topic #47 (0.020): 0.070*\"use\" + 0.048*\"mix\" + 0.043*\"flour\" + 0.039*\"recipe\" + 0.021*\"add\" + 0.018*\"bake\" + 0.017*\"powder\" + 0.016*\"pancake\" + 0.016*\"product\" + 0.015*\"milk\"\n",
      "2021-08-23 22:48:23,637 : INFO : topic #3 (0.020): 0.159*\"organic\" + 0.061*\"spice\" + 0.017*\"pumpkin\" + 0.016*\"taste\" + 0.014*\"ring\" + 0.013*\"curry\" + 0.013*\"certify\" + 0.013*\"food\" + 0.012*\"great\" + 0.012*\"good\"\n",
      "2021-08-23 22:48:23,654 : INFO : topic #0 (0.020): 0.041*\"like\" + 0.033*\"piece\" + 0.026*\"sweet\" + 0.024*\"flavor\" + 0.022*\"gum\" + 0.020*\"hard\" + 0.020*\"taste\" + 0.020*\"chew\" + 0.019*\"eat\" + 0.018*\"mouth\"\n",
      "2021-08-23 22:48:23,656 : INFO : topic #30 (0.020): 0.097*\"chip\" + 0.047*\"package\" + 0.032*\"small\" + 0.024*\"bag\" + 0.021*\"size\" + 0.015*\"open\" + 0.015*\"like\" + 0.014*\"good\" + 0.013*\"gooey\" + 0.013*\"ahoy\"\n",
      "2021-08-23 22:48:23,657 : INFO : topic diff=0.313052, rho=0.160361\n",
      "2021-08-23 22:48:25,483 : INFO : -6.949 per-word bound, 123.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:25,526 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:25,542 : INFO : topic #7 (0.020): 0.078*\"cheese\" + 0.073*\"cracker\" + 0.030*\"taste\" + 0.029*\"like\" + 0.021*\"good\" + 0.021*\"flavor\" + 0.016*\"cheddar\" + 0.014*\"snack\" + 0.012*\"eat\" + 0.011*\"box\"\n",
      "2021-08-23 22:48:25,543 : INFO : topic #24 (0.020): 0.149*\"tea\" + 0.035*\"flavor\" + 0.021*\"like\" + 0.020*\"taste\" + 0.020*\"bag\" + 0.013*\"drink\" + 0.011*\"good\" + 0.011*\"try\" + 0.010*\"vanilla\" + 0.009*\"cup\"\n",
      "2021-08-23 22:48:25,544 : INFO : topic #17 (0.020): 0.063*\"caramel\" + 0.024*\"product\" + 0.023*\"original\" + 0.017*\"taste\" + 0.015*\"werther\" + 0.012*\"candy\" + 0.010*\"think\" + 0.009*\"like\" + 0.009*\"try\" + 0.009*\"hard\"\n",
      "2021-08-23 22:48:25,545 : INFO : topic #13 (0.020): 0.057*\"stuff\" + 0.044*\"good\" + 0.025*\"great\" + 0.025*\"love\" + 0.022*\"like\" + 0.022*\"eat\" + 0.019*\"family\" + 0.018*\"buy\" + 0.018*\"use\" + 0.018*\"taste\"\n",
      "2021-08-23 22:48:25,546 : INFO : topic #23 (0.020): 0.045*\"clean\" + 0.040*\"use\" + 0.022*\"garlic\" + 0.021*\"lemon\" + 0.018*\"brand\" + 0.018*\"pad\" + 0.016*\"tomato\" + 0.014*\"cook\" + 0.012*\"fresh\" + 0.011*\"stove\"\n",
      "2021-08-23 22:48:25,547 : INFO : topic diff=0.314454, rho=0.160361\n",
      "2021-08-23 22:48:26,720 : INFO : -6.929 per-word bound, 121.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:26,721 : INFO : PROGRESS: pass 15, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:48:26,733 : INFO : PROGRESS: pass 15, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:48:26,735 : INFO : PROGRESS: pass 15, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:48:26,736 : INFO : PROGRESS: pass 15, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:26,747 : INFO : PROGRESS: pass 15, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:26,748 : INFO : PROGRESS: pass 15, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:26,750 : INFO : PROGRESS: pass 15, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:26,760 : INFO : PROGRESS: pass 15, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:48:26,762 : INFO : PROGRESS: pass 15, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:26,764 : INFO : PROGRESS: pass 15, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:26,765 : INFO : PROGRESS: pass 15, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:26,781 : INFO : PROGRESS: pass 15, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:26,783 : INFO : PROGRESS: pass 15, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:26,784 : INFO : PROGRESS: pass 15, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:26,786 : INFO : PROGRESS: pass 15, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:26,803 : INFO : PROGRESS: pass 15, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:48:26,806 : INFO : PROGRESS: pass 15, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:26,812 : INFO : PROGRESS: pass 15, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:26,816 : INFO : PROGRESS: pass 15, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:26,838 : INFO : PROGRESS: pass 15, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:26,848 : INFO : PROGRESS: pass 15, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:26,868 : INFO : PROGRESS: pass 15, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:26,948 : INFO : PROGRESS: pass 15, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:26,969 : INFO : PROGRESS: pass 15, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:48:28,956 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:28,978 : INFO : topic #22 (0.020): 0.128*\"tea\" + 0.083*\"green\" + 0.028*\"ginger\" + 0.015*\"leaf\" + 0.012*\"drink\" + 0.011*\"jasmine\" + 0.011*\"good\" + 0.010*\"white\" + 0.009*\"taste\" + 0.008*\"use\"\n",
      "2021-08-23 22:48:28,979 : INFO : topic #39 (0.020): 0.061*\"candy\" + 0.036*\"love\" + 0.028*\"flavor\" + 0.027*\"pop\" + 0.023*\"kid\" + 0.023*\"good\" + 0.022*\"eat\" + 0.021*\"like\" + 0.019*\"treat\" + 0.016*\"licorice\"\n",
      "2021-08-23 22:48:28,981 : INFO : topic #7 (0.020): 0.083*\"cheese\" + 0.070*\"cracker\" + 0.030*\"taste\" + 0.029*\"like\" + 0.021*\"good\" + 0.021*\"flavor\" + 0.016*\"cheddar\" + 0.013*\"snack\" + 0.013*\"mac\" + 0.012*\"eat\"\n",
      "2021-08-23 22:48:28,982 : INFO : topic #6 (0.020): 0.057*\"use\" + 0.051*\"syrup\" + 0.043*\"oil\" + 0.029*\"coconut\" + 0.027*\"maple\" + 0.017*\"skin\" + 0.014*\"grade\" + 0.012*\"hair\" + 0.011*\"good\" + 0.010*\"flavor\"\n",
      "2021-08-23 22:48:28,984 : INFO : topic #48 (0.020): 0.025*\"day\" + 0.021*\"time\" + 0.018*\"eat\" + 0.016*\"work\" + 0.013*\"hour\" + 0.013*\"help\" + 0.012*\"know\" + 0.012*\"stomach\" + 0.012*\"good\" + 0.011*\"feel\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:48:28,986 : INFO : topic diff=0.290955, rho=0.158338\n",
      "2021-08-23 22:48:31,911 : INFO : -6.938 per-word bound, 122.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:31,988 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:32,028 : INFO : topic #10 (0.020): 0.121*\"peanut\" + 0.114*\"butter\" + 0.058*\"popcorn\" + 0.021*\"taste\" + 0.021*\"like\" + 0.019*\"nut\" + 0.014*\"pop\" + 0.012*\"good\" + 0.012*\"flavor\" + 0.012*\"jar\"\n",
      "2021-08-23 22:48:32,031 : INFO : topic #33 (0.020): 0.044*\"eat\" + 0.040*\"tuna\" + 0.040*\"good\" + 0.024*\"like\" + 0.020*\"love\" + 0.020*\"buy\" + 0.016*\"taste\" + 0.016*\"great\" + 0.013*\"product\" + 0.012*\"thanks\"\n",
      "2021-08-23 22:48:32,057 : INFO : topic #14 (0.020): 0.044*\"taste\" + 0.029*\"like\" + 0.020*\"review\" + 0.018*\"know\" + 0.017*\"bad\" + 0.014*\"product\" + 0.014*\"aloe\" + 0.014*\"think\" + 0.012*\"star\" + 0.011*\"good\"\n",
      "2021-08-23 22:48:32,072 : INFO : topic #1 (0.020): 0.081*\"drink\" + 0.036*\"energy\" + 0.033*\"taste\" + 0.026*\"like\" + 0.025*\"juice\" + 0.022*\"flavor\" + 0.015*\"caffeine\" + 0.014*\"good\" + 0.014*\"soda\" + 0.010*\"vitamin\"\n",
      "2021-08-23 22:48:32,075 : INFO : topic #38 (0.020): 0.111*\"bread\" + 0.026*\"toast\" + 0.024*\"slice\" + 0.024*\"like\" + 0.017*\"loaf\" + 0.015*\"spread\" + 0.015*\"sandwich\" + 0.014*\"taste\" + 0.012*\"try\" + 0.012*\"use\"\n",
      "2021-08-23 22:48:32,092 : INFO : topic diff=0.276307, rho=0.158338\n",
      "2021-08-23 22:48:34,061 : INFO : -6.945 per-word bound, 123.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:34,100 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:34,115 : INFO : topic #10 (0.020): 0.119*\"peanut\" + 0.117*\"butter\" + 0.064*\"popcorn\" + 0.021*\"taste\" + 0.021*\"like\" + 0.017*\"nut\" + 0.015*\"pop\" + 0.012*\"flavor\" + 0.012*\"good\" + 0.011*\"pb\"\n",
      "2021-08-23 22:48:34,116 : INFO : topic #34 (0.020): 0.129*\"taste\" + 0.060*\"good\" + 0.044*\"bad\" + 0.029*\"try\" + 0.024*\"aftertaste\" + 0.023*\"like\" + 0.022*\"ok\" + 0.021*\"bitter\" + 0.019*\"smell\" + 0.016*\"pretty\"\n",
      "2021-08-23 22:48:34,117 : INFO : topic #0 (0.020): 0.041*\"like\" + 0.034*\"piece\" + 0.027*\"sweet\" + 0.024*\"flavor\" + 0.022*\"gum\" + 0.021*\"hard\" + 0.020*\"taste\" + 0.020*\"chew\" + 0.019*\"little\" + 0.019*\"mouth\"\n",
      "2021-08-23 22:48:34,118 : INFO : topic #1 (0.020): 0.082*\"drink\" + 0.040*\"energy\" + 0.033*\"taste\" + 0.026*\"like\" + 0.024*\"juice\" + 0.021*\"flavor\" + 0.015*\"caffeine\" + 0.014*\"good\" + 0.012*\"soda\" + 0.011*\"vitamin\"\n",
      "2021-08-23 22:48:34,119 : INFO : topic #29 (0.020): 0.139*\"honey\" + 0.046*\"raw\" + 0.028*\"jar\" + 0.018*\"use\" + 0.012*\"lid\" + 0.009*\"process\" + 0.009*\"organic\" + 0.008*\"yeast\" + 0.008*\"taste\" + 0.007*\"leak\"\n",
      "2021-08-23 22:48:34,120 : INFO : topic diff=0.279058, rho=0.158338\n",
      "2021-08-23 22:48:35,289 : INFO : -6.926 per-word bound, 121.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:35,291 : INFO : PROGRESS: pass 16, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:48:35,301 : INFO : PROGRESS: pass 16, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:48:35,303 : INFO : PROGRESS: pass 16, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:48:35,304 : INFO : PROGRESS: pass 16, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:35,316 : INFO : PROGRESS: pass 16, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:35,317 : INFO : PROGRESS: pass 16, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:35,319 : INFO : PROGRESS: pass 16, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:35,320 : INFO : PROGRESS: pass 16, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:48:35,334 : INFO : PROGRESS: pass 16, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:35,336 : INFO : PROGRESS: pass 16, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:35,337 : INFO : PROGRESS: pass 16, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:35,338 : INFO : PROGRESS: pass 16, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:35,358 : INFO : PROGRESS: pass 16, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:35,379 : INFO : PROGRESS: pass 16, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:35,384 : INFO : PROGRESS: pass 16, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:35,389 : INFO : PROGRESS: pass 16, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:48:35,396 : INFO : PROGRESS: pass 16, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:35,432 : INFO : PROGRESS: pass 16, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:35,439 : INFO : PROGRESS: pass 16, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:35,452 : INFO : PROGRESS: pass 16, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:35,455 : INFO : PROGRESS: pass 16, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:35,473 : INFO : PROGRESS: pass 16, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:35,484 : INFO : PROGRESS: pass 16, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:35,530 : INFO : PROGRESS: pass 16, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:48:37,489 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:37,512 : INFO : topic #47 (0.020): 0.071*\"use\" + 0.051*\"mix\" + 0.044*\"flour\" + 0.039*\"recipe\" + 0.022*\"add\" + 0.018*\"powder\" + 0.018*\"bake\" + 0.017*\"milk\" + 0.016*\"pancake\" + 0.016*\"product\"\n",
      "2021-08-23 22:48:37,513 : INFO : topic #45 (0.020): 0.061*\"cereal\" + 0.046*\"bar\" + 0.030*\"like\" + 0.024*\"taste\" + 0.022*\"granola\" + 0.020*\"eat\" + 0.019*\"good\" + 0.017*\"sweet\" + 0.015*\"flavor\" + 0.014*\"milk\"\n",
      "2021-08-23 22:48:37,515 : INFO : topic #44 (0.020): 0.060*\"fat\" + 0.047*\"calorie\" + 0.027*\"gram\" + 0.024*\"fiber\" + 0.020*\"sodium\" + 0.020*\"protein\" + 0.019*\"high\" + 0.017*\"low\" + 0.015*\"serving\" + 0.015*\"serve\"\n",
      "2021-08-23 22:48:37,516 : INFO : topic #17 (0.020): 0.060*\"caramel\" + 0.024*\"original\" + 0.023*\"product\" + 0.016*\"taste\" + 0.014*\"werther\" + 0.012*\"candy\" + 0.009*\"think\" + 0.009*\"try\" + 0.009*\"like\" + 0.009*\"hard\"\n",
      "2021-08-23 22:48:37,517 : INFO : topic #41 (0.020): 0.064*\"like\" + 0.046*\"spicy\" + 0.046*\"flavor\" + 0.030*\"good\" + 0.024*\"try\" + 0.022*\"taste\" + 0.019*\"biscuit\" + 0.016*\"truffle\" + 0.014*\"bit\" + 0.013*\"think\"\n",
      "2021-08-23 22:48:37,519 : INFO : topic diff=0.257971, rho=0.156389\n",
      "2021-08-23 22:48:40,181 : INFO : -6.933 per-word bound, 122.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:40,270 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:40,304 : INFO : topic #2 (0.020): 0.085*\"pasta\" + 0.056*\"oil\" + 0.039*\"olive\" + 0.024*\"spaghetti\" + 0.020*\"cook\" + 0.020*\"barilla\" + 0.018*\"taste\" + 0.018*\"good\" + 0.018*\"grain\" + 0.016*\"like\"\n",
      "2021-08-23 22:48:40,308 : INFO : topic #39 (0.020): 0.063*\"candy\" + 0.036*\"love\" + 0.027*\"flavor\" + 0.027*\"pop\" + 0.024*\"kid\" + 0.023*\"eat\" + 0.022*\"good\" + 0.021*\"like\" + 0.021*\"treat\" + 0.016*\"licorice\"\n",
      "2021-08-23 22:48:40,325 : INFO : topic #47 (0.020): 0.072*\"use\" + 0.051*\"mix\" + 0.042*\"flour\" + 0.040*\"recipe\" + 0.022*\"add\" + 0.019*\"powder\" + 0.018*\"milk\" + 0.018*\"bake\" + 0.016*\"product\" + 0.016*\"pancake\"\n",
      "2021-08-23 22:48:40,328 : INFO : topic #44 (0.020): 0.060*\"fat\" + 0.047*\"calorie\" + 0.027*\"gram\" + 0.025*\"fiber\" + 0.020*\"protein\" + 0.020*\"sodium\" + 0.019*\"high\" + 0.017*\"low\" + 0.015*\"serve\" + 0.015*\"serving\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:48:40,331 : INFO : topic #12 (0.020): 0.084*\"ingredient\" + 0.064*\"corn\" + 0.036*\"syrup\" + 0.034*\"oat\" + 0.034*\"list\" + 0.024*\"oil\" + 0.023*\"sugar\" + 0.023*\"natural\" + 0.020*\"fructose\" + 0.018*\"contain\"\n",
      "2021-08-23 22:48:40,335 : INFO : topic diff=0.245067, rho=0.156389\n",
      "2021-08-23 22:48:42,337 : INFO : -6.941 per-word bound, 122.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:42,384 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:42,404 : INFO : topic #30 (0.020): 0.109*\"chip\" + 0.050*\"package\" + 0.032*\"small\" + 0.024*\"bag\" + 0.022*\"size\" + 0.017*\"ahoy\" + 0.017*\"gooey\" + 0.015*\"like\" + 0.014*\"good\" + 0.014*\"open\"\n",
      "2021-08-23 22:48:42,405 : INFO : topic #35 (0.020): 0.139*\"love\" + 0.066*\"flavor\" + 0.066*\"try\" + 0.046*\"like\" + 0.045*\"great\" + 0.044*\"taste\" + 0.039*\"buy\" + 0.024*\"husband\" + 0.016*\"good\" + 0.016*\"brand\"\n",
      "2021-08-23 22:48:42,406 : INFO : topic #11 (0.020): 0.101*\"water\" + 0.050*\"bottle\" + 0.045*\"coconut\" + 0.031*\"taste\" + 0.029*\"like\" + 0.023*\"flavor\" + 0.021*\"drink\" + 0.020*\"squeeze\" + 0.016*\"add\" + 0.016*\"use\"\n",
      "2021-08-23 22:48:42,407 : INFO : topic #38 (0.020): 0.112*\"bread\" + 0.027*\"toast\" + 0.025*\"slice\" + 0.023*\"like\" + 0.017*\"loaf\" + 0.017*\"spread\" + 0.016*\"sandwich\" + 0.013*\"taste\" + 0.012*\"mix\" + 0.012*\"try\"\n",
      "2021-08-23 22:48:42,409 : INFO : topic #24 (0.020): 0.153*\"tea\" + 0.035*\"flavor\" + 0.021*\"like\" + 0.020*\"bag\" + 0.020*\"taste\" + 0.013*\"drink\" + 0.011*\"good\" + 0.011*\"try\" + 0.010*\"vanilla\" + 0.009*\"cup\"\n",
      "2021-08-23 22:48:42,410 : INFO : topic diff=0.248936, rho=0.156389\n",
      "2021-08-23 22:48:43,573 : INFO : -6.921 per-word bound, 121.2 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:43,574 : INFO : PROGRESS: pass 17, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:48:43,588 : INFO : PROGRESS: pass 17, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:48:43,589 : INFO : PROGRESS: pass 17, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:48:43,591 : INFO : PROGRESS: pass 17, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:43,592 : INFO : PROGRESS: pass 17, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:43,606 : INFO : PROGRESS: pass 17, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:43,608 : INFO : PROGRESS: pass 17, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:43,610 : INFO : PROGRESS: pass 17, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:48:43,624 : INFO : PROGRESS: pass 17, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:43,628 : INFO : PROGRESS: pass 17, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:43,629 : INFO : PROGRESS: pass 17, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:43,632 : INFO : PROGRESS: pass 17, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:43,654 : INFO : PROGRESS: pass 17, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:43,655 : INFO : PROGRESS: pass 17, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:43,656 : INFO : PROGRESS: pass 17, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:43,659 : INFO : PROGRESS: pass 17, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:48:43,677 : INFO : PROGRESS: pass 17, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:43,681 : INFO : PROGRESS: pass 17, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:43,684 : INFO : PROGRESS: pass 17, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:43,714 : INFO : PROGRESS: pass 17, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:43,716 : INFO : PROGRESS: pass 17, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:43,734 : INFO : PROGRESS: pass 17, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:43,742 : INFO : PROGRESS: pass 17, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:43,780 : INFO : PROGRESS: pass 17, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:48:46,085 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:46,106 : INFO : topic #2 (0.020): 0.088*\"pasta\" + 0.058*\"oil\" + 0.043*\"olive\" + 0.022*\"spaghetti\" + 0.021*\"cook\" + 0.019*\"taste\" + 0.018*\"good\" + 0.017*\"barilla\" + 0.016*\"grain\" + 0.016*\"like\"\n",
      "2021-08-23 22:48:46,108 : INFO : topic #15 (0.020): 0.120*\"sugar\" + 0.045*\"use\" + 0.030*\"sweetener\" + 0.027*\"stevia\" + 0.025*\"taste\" + 0.023*\"sweet\" + 0.021*\"splenda\" + 0.018*\"like\" + 0.017*\"product\" + 0.015*\"sweeten\"\n",
      "2021-08-23 22:48:46,128 : INFO : topic #38 (0.020): 0.115*\"bread\" + 0.027*\"toast\" + 0.024*\"slice\" + 0.023*\"like\" + 0.018*\"loaf\" + 0.016*\"sandwich\" + 0.016*\"spread\" + 0.013*\"taste\" + 0.012*\"mix\" + 0.012*\"try\"\n",
      "2021-08-23 22:48:46,130 : INFO : topic #47 (0.020): 0.072*\"use\" + 0.052*\"mix\" + 0.043*\"flour\" + 0.039*\"recipe\" + 0.023*\"add\" + 0.019*\"powder\" + 0.018*\"milk\" + 0.018*\"bake\" + 0.016*\"pancake\" + 0.016*\"product\"\n",
      "2021-08-23 22:48:46,131 : INFO : topic #39 (0.020): 0.063*\"candy\" + 0.036*\"love\" + 0.028*\"pop\" + 0.027*\"flavor\" + 0.025*\"kid\" + 0.023*\"eat\" + 0.022*\"good\" + 0.021*\"treat\" + 0.021*\"like\" + 0.016*\"licorice\"\n",
      "2021-08-23 22:48:46,133 : INFO : topic diff=0.229960, rho=0.154511\n",
      "2021-08-23 22:48:49,137 : INFO : -6.930 per-word bound, 121.9 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:49,256 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:49,296 : INFO : topic #8 (0.020): 0.142*\"salt\" + 0.032*\"flavor\" + 0.025*\"sea\" + 0.021*\"taste\" + 0.020*\"salty\" + 0.019*\"use\" + 0.015*\"like\" + 0.013*\"good\" + 0.011*\"little\" + 0.011*\"newman\"\n",
      "2021-08-23 22:48:49,304 : INFO : topic #17 (0.020): 0.065*\"caramel\" + 0.027*\"original\" + 0.022*\"product\" + 0.018*\"werther\" + 0.016*\"taste\" + 0.014*\"candy\" + 0.009*\"hard\" + 0.009*\"think\" + 0.009*\"try\" + 0.008*\"like\"\n",
      "2021-08-23 22:48:49,338 : INFO : topic #41 (0.020): 0.066*\"like\" + 0.049*\"flavor\" + 0.044*\"spicy\" + 0.031*\"good\" + 0.024*\"try\" + 0.022*\"taste\" + 0.018*\"truffle\" + 0.017*\"biscuit\" + 0.015*\"bit\" + 0.013*\"think\"\n",
      "2021-08-23 22:48:49,342 : INFO : topic #2 (0.020): 0.087*\"pasta\" + 0.054*\"oil\" + 0.040*\"olive\" + 0.024*\"spaghetti\" + 0.021*\"cook\" + 0.020*\"barilla\" + 0.019*\"taste\" + 0.019*\"good\" + 0.018*\"grain\" + 0.016*\"like\"\n",
      "2021-08-23 22:48:49,347 : INFO : topic #31 (0.020): 0.097*\"cherry\" + 0.052*\"pepper\" + 0.039*\"black\" + 0.034*\"peach\" + 0.031*\"flavor\" + 0.028*\"aid\" + 0.026*\"mango\" + 0.021*\"kool\" + 0.018*\"like\" + 0.018*\"taste\"\n",
      "2021-08-23 22:48:49,349 : INFO : topic diff=0.218350, rho=0.154511\n",
      "2021-08-23 22:48:51,353 : INFO : -6.937 per-word bound, 122.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:51,399 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:51,415 : INFO : topic #7 (0.020): 0.083*\"cheese\" + 0.078*\"cracker\" + 0.030*\"taste\" + 0.029*\"like\" + 0.021*\"flavor\" + 0.021*\"good\" + 0.017*\"cheddar\" + 0.014*\"snack\" + 0.012*\"box\" + 0.012*\"eat\"\n",
      "2021-08-23 22:48:51,416 : INFO : topic #5 (0.020): 0.189*\"cup\" + 0.055*\"coffee\" + 0.038*\"cream\" + 0.034*\"keurig\" + 0.029*\"ice\" + 0.022*\"flavor\" + 0.021*\"like\" + 0.017*\"use\" + 0.014*\"good\" + 0.012*\"favorite\"\n",
      "2021-08-23 22:48:51,417 : INFO : topic #49 (0.020): 0.144*\"coffee\" + 0.027*\"flavor\" + 0.025*\"like\" + 0.021*\"taste\" + 0.019*\"cup\" + 0.016*\"roast\" + 0.015*\"good\" + 0.015*\"strong\" + 0.014*\"blend\" + 0.013*\"vanilla\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:48:51,418 : INFO : topic #4 (0.020): 0.085*\"fruit\" + 0.057*\"apple\" + 0.029*\"flavor\" + 0.027*\"juice\" + 0.022*\"natural\" + 0.021*\"ingredient\" + 0.019*\"blueberry\" + 0.018*\"dry\" + 0.018*\"dried\" + 0.016*\"like\"\n",
      "2021-08-23 22:48:51,419 : INFO : topic #29 (0.020): 0.146*\"honey\" + 0.048*\"raw\" + 0.031*\"jar\" + 0.018*\"use\" + 0.011*\"lid\" + 0.010*\"process\" + 0.008*\"organic\" + 0.008*\"yeast\" + 0.008*\"leak\" + 0.007*\"taste\"\n",
      "2021-08-23 22:48:51,420 : INFO : topic diff=0.222899, rho=0.154511\n",
      "2021-08-23 22:48:52,621 : INFO : -6.919 per-word bound, 121.0 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:52,622 : INFO : PROGRESS: pass 18, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:48:52,633 : INFO : PROGRESS: pass 18, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:48:52,635 : INFO : PROGRESS: pass 18, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:48:52,637 : INFO : PROGRESS: pass 18, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n",
      "2021-08-23 22:48:52,638 : INFO : PROGRESS: pass 18, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:48:52,649 : INFO : PROGRESS: pass 18, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:48:52,650 : INFO : PROGRESS: pass 18, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:48:52,651 : INFO : PROGRESS: pass 18, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:48:52,663 : INFO : PROGRESS: pass 18, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:48:52,666 : INFO : PROGRESS: pass 18, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:48:52,667 : INFO : PROGRESS: pass 18, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:48:52,669 : INFO : PROGRESS: pass 18, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:48:52,687 : INFO : PROGRESS: pass 18, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:48:52,688 : INFO : PROGRESS: pass 18, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:48:52,690 : INFO : PROGRESS: pass 18, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:48:52,694 : INFO : PROGRESS: pass 18, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:48:52,714 : INFO : PROGRESS: pass 18, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:48:52,717 : INFO : PROGRESS: pass 18, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:48:52,722 : INFO : PROGRESS: pass 18, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:48:52,729 : INFO : PROGRESS: pass 18, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:48:52,749 : INFO : PROGRESS: pass 18, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:48:52,754 : INFO : PROGRESS: pass 18, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:48:52,778 : INFO : PROGRESS: pass 18, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:48:52,820 : INFO : PROGRESS: pass 18, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:48:54,785 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:54,809 : INFO : topic #48 (0.020): 0.028*\"day\" + 0.022*\"time\" + 0.019*\"eat\" + 0.017*\"work\" + 0.015*\"help\" + 0.013*\"hour\" + 0.013*\"know\" + 0.013*\"feel\" + 0.012*\"stomach\" + 0.011*\"good\"\n",
      "2021-08-23 22:48:54,810 : INFO : topic #35 (0.020): 0.140*\"love\" + 0.067*\"flavor\" + 0.066*\"try\" + 0.048*\"great\" + 0.046*\"like\" + 0.045*\"taste\" + 0.040*\"buy\" + 0.024*\"husband\" + 0.017*\"brand\" + 0.016*\"good\"\n",
      "2021-08-23 22:48:54,812 : INFO : topic #39 (0.020): 0.064*\"candy\" + 0.036*\"love\" + 0.028*\"pop\" + 0.027*\"kid\" + 0.026*\"flavor\" + 0.024*\"eat\" + 0.022*\"treat\" + 0.021*\"good\" + 0.021*\"like\" + 0.016*\"licorice\"\n",
      "2021-08-23 22:48:54,814 : INFO : topic #28 (0.020): 0.222*\"chocolate\" + 0.046*\"dark\" + 0.032*\"milk\" + 0.029*\"bar\" + 0.025*\"cocoa\" + 0.022*\"taste\" + 0.021*\"like\" + 0.019*\"sweet\" + 0.018*\"good\" + 0.012*\"rich\"\n",
      "2021-08-23 22:48:54,815 : INFO : topic #29 (0.020): 0.146*\"honey\" + 0.051*\"raw\" + 0.032*\"jar\" + 0.018*\"use\" + 0.011*\"lid\" + 0.010*\"process\" + 0.010*\"yeast\" + 0.009*\"organic\" + 0.007*\"taste\" + 0.007*\"heat\"\n",
      "2021-08-23 22:48:54,817 : INFO : topic diff=0.205913, rho=0.152699\n",
      "2021-08-23 22:48:57,522 : INFO : -6.927 per-word bound, 121.7 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:57,613 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:57,649 : INFO : topic #16 (0.020): 0.100*\"price\" + 0.045*\"amazon\" + 0.038*\"good\" + 0.035*\"great\" + 0.030*\"save\" + 0.027*\"buy\" + 0.018*\"subscribe\" + 0.016*\"order\" + 0.014*\"deal\" + 0.012*\"best\"\n",
      "2021-08-23 22:48:57,651 : INFO : topic #49 (0.020): 0.145*\"coffee\" + 0.028*\"flavor\" + 0.025*\"like\" + 0.021*\"taste\" + 0.018*\"cup\" + 0.016*\"roast\" + 0.015*\"good\" + 0.015*\"strong\" + 0.014*\"vanilla\" + 0.014*\"blend\"\n",
      "2021-08-23 22:48:57,687 : INFO : topic #30 (0.020): 0.113*\"chip\" + 0.052*\"package\" + 0.035*\"small\" + 0.025*\"bag\" + 0.023*\"size\" + 0.015*\"like\" + 0.015*\"potato\" + 0.015*\"good\" + 0.014*\"gooey\" + 0.013*\"ahoy\"\n",
      "2021-08-23 22:48:57,698 : INFO : topic #33 (0.020): 0.046*\"eat\" + 0.041*\"tuna\" + 0.040*\"good\" + 0.024*\"like\" + 0.020*\"buy\" + 0.020*\"love\" + 0.016*\"taste\" + 0.014*\"great\" + 0.013*\"product\" + 0.013*\"thanks\"\n",
      "2021-08-23 22:48:57,710 : INFO : topic #21 (0.020): 0.032*\"peppermint\" + 0.020*\"hot\" + 0.019*\"mocha\" + 0.017*\"house\" + 0.016*\"like\" + 0.015*\"latte\" + 0.015*\"flavor\" + 0.011*\"good\" + 0.011*\"powder\" + 0.011*\"mix\"\n",
      "2021-08-23 22:48:57,736 : INFO : topic diff=0.195524, rho=0.152699\n",
      "2021-08-23 22:48:59,566 : INFO : -6.934 per-word bound, 122.3 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:48:59,608 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:48:59,623 : INFO : topic #10 (0.020): 0.123*\"peanut\" + 0.121*\"butter\" + 0.069*\"popcorn\" + 0.021*\"taste\" + 0.020*\"like\" + 0.016*\"pop\" + 0.015*\"nut\" + 0.012*\"good\" + 0.012*\"flavor\" + 0.012*\"pb\"\n",
      "2021-08-23 22:48:59,624 : INFO : topic #18 (0.020): 0.112*\"bag\" + 0.025*\"use\" + 0.015*\"pizza\" + 0.015*\"crust\" + 0.013*\"time\" + 0.013*\"bake\" + 0.011*\"pound\" + 0.011*\"fresh\" + 0.010*\"easy\" + 0.009*\"come\"\n",
      "2021-08-23 22:48:59,625 : INFO : topic #6 (0.020): 0.060*\"use\" + 0.059*\"oil\" + 0.049*\"syrup\" + 0.042*\"coconut\" + 0.027*\"maple\" + 0.016*\"skin\" + 0.014*\"grade\" + 0.012*\"hair\" + 0.011*\"cook\" + 0.010*\"good\"\n",
      "2021-08-23 22:48:59,626 : INFO : topic #19 (0.020): 0.089*\"cooky\" + 0.060*\"cookie\" + 0.030*\"like\" + 0.024*\"mint\" + 0.022*\"taste\" + 0.019*\"fudge\" + 0.018*\"oreo\" + 0.015*\"good\" + 0.014*\"flavor\" + 0.013*\"fig\"\n",
      "2021-08-23 22:48:59,627 : INFO : topic #36 (0.020): 0.085*\"seed\" + 0.021*\"chia\" + 0.021*\"food\" + 0.020*\"sesame\" + 0.020*\"consume\" + 0.019*\"flax\" + 0.017*\"nutrient\" + 0.015*\"quinoa\" + 0.013*\"high\" + 0.011*\"oil\"\n",
      "2021-08-23 22:48:59,628 : INFO : topic diff=0.200529, rho=0.152699\n",
      "2021-08-23 22:49:00,755 : INFO : -6.917 per-word bound, 120.8 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:49:00,756 : INFO : PROGRESS: pass 19, dispatched chunk #0 = documents up to #2000/47774, outstanding queue size 1\n",
      "2021-08-23 22:49:00,768 : INFO : PROGRESS: pass 19, dispatched chunk #1 = documents up to #4000/47774, outstanding queue size 2\n",
      "2021-08-23 22:49:00,769 : INFO : PROGRESS: pass 19, dispatched chunk #2 = documents up to #6000/47774, outstanding queue size 3\n",
      "2021-08-23 22:49:00,770 : INFO : PROGRESS: pass 19, dispatched chunk #3 = documents up to #8000/47774, outstanding queue size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:49:00,771 : INFO : PROGRESS: pass 19, dispatched chunk #4 = documents up to #10000/47774, outstanding queue size 5\n",
      "2021-08-23 22:49:00,781 : INFO : PROGRESS: pass 19, dispatched chunk #5 = documents up to #12000/47774, outstanding queue size 6\n",
      "2021-08-23 22:49:00,783 : INFO : PROGRESS: pass 19, dispatched chunk #6 = documents up to #14000/47774, outstanding queue size 7\n",
      "2021-08-23 22:49:00,784 : INFO : PROGRESS: pass 19, dispatched chunk #7 = documents up to #16000/47774, outstanding queue size 8\n",
      "2021-08-23 22:49:00,795 : INFO : PROGRESS: pass 19, dispatched chunk #8 = documents up to #18000/47774, outstanding queue size 9\n",
      "2021-08-23 22:49:00,797 : INFO : PROGRESS: pass 19, dispatched chunk #9 = documents up to #20000/47774, outstanding queue size 10\n",
      "2021-08-23 22:49:00,798 : INFO : PROGRESS: pass 19, dispatched chunk #10 = documents up to #22000/47774, outstanding queue size 11\n",
      "2021-08-23 22:49:00,799 : INFO : PROGRESS: pass 19, dispatched chunk #11 = documents up to #24000/47774, outstanding queue size 12\n",
      "2021-08-23 22:49:00,812 : INFO : PROGRESS: pass 19, dispatched chunk #12 = documents up to #26000/47774, outstanding queue size 13\n",
      "2021-08-23 22:49:00,814 : INFO : PROGRESS: pass 19, dispatched chunk #13 = documents up to #28000/47774, outstanding queue size 14\n",
      "2021-08-23 22:49:00,815 : INFO : PROGRESS: pass 19, dispatched chunk #14 = documents up to #30000/47774, outstanding queue size 15\n",
      "2021-08-23 22:49:00,817 : INFO : PROGRESS: pass 19, dispatched chunk #15 = documents up to #32000/47774, outstanding queue size 16\n",
      "2021-08-23 22:49:00,835 : INFO : PROGRESS: pass 19, dispatched chunk #16 = documents up to #34000/47774, outstanding queue size 17\n",
      "2021-08-23 22:49:00,838 : INFO : PROGRESS: pass 19, dispatched chunk #17 = documents up to #36000/47774, outstanding queue size 18\n",
      "2021-08-23 22:49:00,842 : INFO : PROGRESS: pass 19, dispatched chunk #18 = documents up to #38000/47774, outstanding queue size 19\n",
      "2021-08-23 22:49:00,863 : INFO : PROGRESS: pass 19, dispatched chunk #19 = documents up to #40000/47774, outstanding queue size 20\n",
      "2021-08-23 22:49:00,866 : INFO : PROGRESS: pass 19, dispatched chunk #20 = documents up to #42000/47774, outstanding queue size 21\n",
      "2021-08-23 22:49:00,872 : INFO : PROGRESS: pass 19, dispatched chunk #21 = documents up to #44000/47774, outstanding queue size 22\n",
      "2021-08-23 22:49:00,909 : INFO : PROGRESS: pass 19, dispatched chunk #22 = documents up to #46000/47774, outstanding queue size 23\n",
      "2021-08-23 22:49:00,949 : INFO : PROGRESS: pass 19, dispatched chunk #23 = documents up to #47774/47774, outstanding queue size 24\n",
      "2021-08-23 22:49:02,763 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:49:02,784 : INFO : topic #48 (0.020): 0.029*\"day\" + 0.023*\"time\" + 0.019*\"eat\" + 0.017*\"work\" + 0.015*\"help\" + 0.014*\"hour\" + 0.013*\"feel\" + 0.013*\"know\" + 0.012*\"stomach\" + 0.010*\"start\"\n",
      "2021-08-23 22:49:02,785 : INFO : topic #0 (0.020): 0.042*\"like\" + 0.036*\"piece\" + 0.029*\"sweet\" + 0.026*\"flavor\" + 0.024*\"hard\" + 0.022*\"gum\" + 0.021*\"mouth\" + 0.021*\"little\" + 0.021*\"chew\" + 0.019*\"taste\"\n",
      "2021-08-23 22:49:02,786 : INFO : topic #43 (0.020): 0.105*\"snack\" + 0.036*\"great\" + 0.031*\"healthy\" + 0.025*\"good\" + 0.024*\"eat\" + 0.019*\"lunch\" + 0.018*\"tasty\" + 0.015*\"pack\" + 0.015*\"little\" + 0.014*\"like\"\n",
      "2021-08-23 22:49:02,788 : INFO : topic #30 (0.020): 0.116*\"chip\" + 0.052*\"package\" + 0.035*\"small\" + 0.025*\"bag\" + 0.023*\"size\" + 0.016*\"potato\" + 0.016*\"like\" + 0.015*\"ahoy\" + 0.015*\"gooey\" + 0.015*\"good\"\n",
      "2021-08-23 22:49:02,791 : INFO : topic #23 (0.020): 0.050*\"clean\" + 0.040*\"use\" + 0.026*\"lemon\" + 0.023*\"garlic\" + 0.020*\"tomato\" + 0.017*\"brand\" + 0.016*\"pad\" + 0.013*\"cook\" + 0.013*\"fresh\" + 0.010*\"stove\"\n",
      "2021-08-23 22:49:02,793 : INFO : topic diff=0.185418, rho=0.150950\n",
      "2021-08-23 22:49:05,339 : INFO : -6.924 per-word bound, 121.4 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:49:05,436 : INFO : merging changes from 16000 documents into a model of 47774 documents\n",
      "2021-08-23 22:49:05,473 : INFO : topic #3 (0.020): 0.179*\"organic\" + 0.062*\"spice\" + 0.021*\"pumpkin\" + 0.014*\"food\" + 0.014*\"taste\" + 0.014*\"ring\" + 0.014*\"certify\" + 0.012*\"curry\" + 0.012*\"brand\" + 0.012*\"great\"\n",
      "2021-08-23 22:49:05,479 : INFO : topic #1 (0.020): 0.086*\"drink\" + 0.038*\"energy\" + 0.032*\"taste\" + 0.026*\"like\" + 0.026*\"juice\" + 0.022*\"flavor\" + 0.015*\"caffeine\" + 0.014*\"soda\" + 0.014*\"good\" + 0.011*\"vitamin\"\n",
      "2021-08-23 22:49:05,516 : INFO : topic #5 (0.020): 0.190*\"cup\" + 0.057*\"coffee\" + 0.038*\"cream\" + 0.034*\"keurig\" + 0.029*\"ice\" + 0.021*\"flavor\" + 0.020*\"like\" + 0.017*\"use\" + 0.013*\"good\" + 0.013*\"favorite\"\n",
      "2021-08-23 22:49:05,536 : INFO : topic #8 (0.020): 0.149*\"salt\" + 0.032*\"flavor\" + 0.026*\"sea\" + 0.023*\"salty\" + 0.021*\"taste\" + 0.020*\"use\" + 0.015*\"like\" + 0.012*\"good\" + 0.011*\"little\" + 0.011*\"cacao\"\n",
      "2021-08-23 22:49:05,550 : INFO : topic #9 (0.020): 0.037*\"box\" + 0.034*\"packaging\" + 0.033*\"open\" + 0.031*\"package\" + 0.028*\"plastic\" + 0.025*\"container\" + 0.021*\"come\" + 0.019*\"product\" + 0.015*\"arrive\" + 0.015*\"wrap\"\n",
      "2021-08-23 22:49:05,564 : INFO : topic diff=0.176068, rho=0.150950\n",
      "2021-08-23 22:49:07,373 : INFO : -6.931 per-word bound, 122.0 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:49:07,415 : INFO : merging changes from 15774 documents into a model of 47774 documents\n",
      "2021-08-23 22:49:07,430 : INFO : topic #26 (0.020): 0.143*\"free\" + 0.102*\"gluten\" + 0.021*\"good\" + 0.019*\"product\" + 0.019*\"mix\" + 0.019*\"shake\" + 0.017*\"bake\" + 0.017*\"taste\" + 0.015*\"like\" + 0.014*\"try\"\n",
      "2021-08-23 22:49:07,431 : INFO : topic #36 (0.020): 0.085*\"seed\" + 0.021*\"chia\" + 0.021*\"food\" + 0.020*\"sesame\" + 0.020*\"consume\" + 0.019*\"flax\" + 0.017*\"nutrient\" + 0.015*\"quinoa\" + 0.013*\"high\" + 0.011*\"oil\"\n",
      "2021-08-23 22:49:07,432 : INFO : topic #19 (0.020): 0.090*\"cooky\" + 0.061*\"cookie\" + 0.030*\"like\" + 0.024*\"mint\" + 0.022*\"taste\" + 0.019*\"fudge\" + 0.018*\"oreo\" + 0.014*\"good\" + 0.013*\"flavor\" + 0.013*\"fig\"\n",
      "2021-08-23 22:49:07,433 : INFO : topic #20 (0.020): 0.080*\"sauce\" + 0.023*\"use\" + 0.021*\"hot\" + 0.020*\"flavor\" + 0.017*\"like\" + 0.016*\"add\" + 0.014*\"chicken\" + 0.013*\"taste\" + 0.013*\"heat\" + 0.012*\"good\"\n",
      "2021-08-23 22:49:07,434 : INFO : topic #45 (0.020): 0.064*\"cereal\" + 0.046*\"bar\" + 0.030*\"like\" + 0.023*\"taste\" + 0.023*\"granola\" + 0.020*\"eat\" + 0.019*\"good\" + 0.017*\"sweet\" + 0.015*\"flavor\" + 0.015*\"milk\"\n",
      "2021-08-23 22:49:07,435 : INFO : topic diff=0.181423, rho=0.150950\n",
      "2021-08-23 22:49:08,723 : INFO : -6.914 per-word bound, 120.6 perplexity estimate based on a held-out corpus of 1774 documents with 78463 words\n",
      "2021-08-23 22:49:08,746 : INFO : LdaMulticore lifecycle event {'msg': 'trained LdaModel(num_terms=5662, num_topics=50, decay=0.5, chunksize=2000) in 189.88s', 'datetime': '2021-08-23T22:49:08.746567', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=50, id2word=dictionary, passes=20, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7f26ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-23 22:49:08,786 : INFO : CorpusAccumulator accumulated stats from 1000 documents\n",
      "2021-08-23 22:49:08,805 : INFO : CorpusAccumulator accumulated stats from 2000 documents\n",
      "2021-08-23 22:49:08,823 : INFO : CorpusAccumulator accumulated stats from 3000 documents\n",
      "2021-08-23 22:49:08,848 : INFO : CorpusAccumulator accumulated stats from 4000 documents\n",
      "2021-08-23 22:49:08,872 : INFO : CorpusAccumulator accumulated stats from 5000 documents\n",
      "2021-08-23 22:49:08,897 : INFO : CorpusAccumulator accumulated stats from 6000 documents\n",
      "2021-08-23 22:49:08,927 : INFO : CorpusAccumulator accumulated stats from 7000 documents\n",
      "2021-08-23 22:49:08,955 : INFO : CorpusAccumulator accumulated stats from 8000 documents\n",
      "2021-08-23 22:49:08,981 : INFO : CorpusAccumulator accumulated stats from 9000 documents\n",
      "2021-08-23 22:49:09,003 : INFO : CorpusAccumulator accumulated stats from 10000 documents\n",
      "2021-08-23 22:49:09,026 : INFO : CorpusAccumulator accumulated stats from 11000 documents\n",
      "2021-08-23 22:49:09,056 : INFO : CorpusAccumulator accumulated stats from 12000 documents\n",
      "2021-08-23 22:49:09,084 : INFO : CorpusAccumulator accumulated stats from 13000 documents\n",
      "2021-08-23 22:49:09,109 : INFO : CorpusAccumulator accumulated stats from 14000 documents\n",
      "2021-08-23 22:49:09,135 : INFO : CorpusAccumulator accumulated stats from 15000 documents\n",
      "2021-08-23 22:49:09,158 : INFO : CorpusAccumulator accumulated stats from 16000 documents\n",
      "2021-08-23 22:49:09,183 : INFO : CorpusAccumulator accumulated stats from 17000 documents\n",
      "2021-08-23 22:49:09,207 : INFO : CorpusAccumulator accumulated stats from 18000 documents\n",
      "2021-08-23 22:49:09,232 : INFO : CorpusAccumulator accumulated stats from 19000 documents\n",
      "2021-08-23 22:49:09,256 : INFO : CorpusAccumulator accumulated stats from 20000 documents\n",
      "2021-08-23 22:49:09,282 : INFO : CorpusAccumulator accumulated stats from 21000 documents\n",
      "2021-08-23 22:49:09,307 : INFO : CorpusAccumulator accumulated stats from 22000 documents\n",
      "2021-08-23 22:49:09,337 : INFO : CorpusAccumulator accumulated stats from 23000 documents\n",
      "2021-08-23 22:49:09,361 : INFO : CorpusAccumulator accumulated stats from 24000 documents\n",
      "2021-08-23 22:49:09,385 : INFO : CorpusAccumulator accumulated stats from 25000 documents\n",
      "2021-08-23 22:49:09,409 : INFO : CorpusAccumulator accumulated stats from 26000 documents\n",
      "2021-08-23 22:49:09,431 : INFO : CorpusAccumulator accumulated stats from 27000 documents\n",
      "2021-08-23 22:49:09,457 : INFO : CorpusAccumulator accumulated stats from 28000 documents\n",
      "2021-08-23 22:49:09,480 : INFO : CorpusAccumulator accumulated stats from 29000 documents\n",
      "2021-08-23 22:49:09,506 : INFO : CorpusAccumulator accumulated stats from 30000 documents\n",
      "2021-08-23 22:49:09,527 : INFO : CorpusAccumulator accumulated stats from 31000 documents\n",
      "2021-08-23 22:49:09,551 : INFO : CorpusAccumulator accumulated stats from 32000 documents\n",
      "2021-08-23 22:49:09,572 : INFO : CorpusAccumulator accumulated stats from 33000 documents\n",
      "2021-08-23 22:49:09,592 : INFO : CorpusAccumulator accumulated stats from 34000 documents\n",
      "2021-08-23 22:49:09,613 : INFO : CorpusAccumulator accumulated stats from 35000 documents\n",
      "2021-08-23 22:49:09,636 : INFO : CorpusAccumulator accumulated stats from 36000 documents\n",
      "2021-08-23 22:49:09,660 : INFO : CorpusAccumulator accumulated stats from 37000 documents\n",
      "2021-08-23 22:49:09,683 : INFO : CorpusAccumulator accumulated stats from 38000 documents\n",
      "2021-08-23 22:49:09,704 : INFO : CorpusAccumulator accumulated stats from 39000 documents\n",
      "2021-08-23 22:49:09,728 : INFO : CorpusAccumulator accumulated stats from 40000 documents\n",
      "2021-08-23 22:49:09,752 : INFO : CorpusAccumulator accumulated stats from 41000 documents\n",
      "2021-08-23 22:49:09,773 : INFO : CorpusAccumulator accumulated stats from 42000 documents\n",
      "2021-08-23 22:49:09,798 : INFO : CorpusAccumulator accumulated stats from 43000 documents\n",
      "2021-08-23 22:49:09,824 : INFO : CorpusAccumulator accumulated stats from 44000 documents\n",
      "2021-08-23 22:49:09,850 : INFO : CorpusAccumulator accumulated stats from 45000 documents\n",
      "2021-08-23 22:49:09,878 : INFO : CorpusAccumulator accumulated stats from 46000 documents\n",
      "2021-08-23 22:49:09,904 : INFO : CorpusAccumulator accumulated stats from 47000 documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -2.621079025395095\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, corpus=bow_corpus, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e2951",
   "metadata": {},
   "source": [
    "# Retrieving User/Item Topic Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c94bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews = train.groupby([\"reviewerID\"])['processedReviewText'].apply(lambda x: ' '.join(x))\n",
    "item_reviews = train.groupby([\"asin\"])[\"processedReviewText\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# get unique users and items\n",
    "unique_users = user_reviews.index.tolist()\n",
    "unique_items = item_reviews.index.tolist()\n",
    "\n",
    "# tokenize reviews\n",
    "user_reviews_list = user_reviews.apply(lambda x: x.split()).tolist()\n",
    "item_reviews_list = item_reviews.apply(lambda x: x.split()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1df5a61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random user:\n",
      "like dark chocolate bar sweet creamy taste come score square break piece rip curtain window chocolate day purchase prefer organic hate love cooky like cracker crunchy slightly sweet sweetness come fig smell wonderfully honey great tea\n",
      "\n",
      "Random item:\n",
      "love chocolate hazelnut crispy wafer heaven careful togobble time little appetizing world gluten free product happy order frequent treat good product great individualized packaging crisp good chocolate flavor gluten free adult love gluten free kid like look gluten free snack fatten candy wonderful light snack satisfy sweet tooth\n"
     ]
    }
   ],
   "source": [
    "print(f\"Random user:\\n{user_reviews[np.random.randint(0, user_reviews.shape[0])]}\")\n",
    "print(f\"\\nRandom item:\\n{item_reviews[np.random.randint(0, item_reviews.shape[0])]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0665ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_corpus = [dictionary.doc2bow(doc) for doc in user_reviews_list]\n",
    "item_corpus = [dictionary.doc2bow(doc) for doc in item_reviews_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec6f1cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_vectors(model, corpus, n_topics=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    topic_vecs = []\n",
    "    for i in tqdm(range(len(corpus))):\n",
    "        top_topics = lda_model.get_document_topics(corpus[i], minimum_probability=0.0)\n",
    "        topic_vecs.append([top_topics[i][1] for i in range(n_topics)])\n",
    "        \n",
    "    return topic_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "655ec479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 13397/13397 [00:10<00:00, 1274.06it/s]\n",
      "100%|██████████████████████████████████████████████████████████| 4729/4729 [00:05<00:00, 906.25it/s]\n"
     ]
    }
   ],
   "source": [
    "user_vecs = get_topic_vectors(lda_model, user_corpus)\n",
    "item_vecs = get_topic_vectors(lda_model, item_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ede2a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  0.022746114,\n",
      "  0.2064711,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  0.0055703362,\n",
      "  0.07597777,\n",
      "  4.4983804e-05,\n",
      "  0.02293062,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  0.021429373,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  0.04324505,\n",
      "  4.4983804e-05,\n",
      "  0.13243595,\n",
      "  4.4983804e-05,\n",
      "  0.055566017,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  0.118809834,\n",
      "  4.4983804e-05,\n",
      "  0.006932182,\n",
      "  0.032745745,\n",
      "  4.4983804e-05,\n",
      "  0.0055222968,\n",
      "  4.4983804e-05,\n",
      "  0.011608914,\n",
      "  4.4983804e-05,\n",
      "  0.014234855,\n",
      "  0.079787165,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  4.4983804e-05,\n",
      "  0.073859334,\n",
      "  0.032581452,\n",
      "  0.036151372,\n",
      "  4.4983804e-05]]\n"
     ]
    }
   ],
   "source": [
    "# checking topic vector\n",
    "pprint(item_vecs[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbabfeed",
   "metadata": {},
   "source": [
    "# Create Topic Vector Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71c3656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_map = {k: unique_users[k] for k in range(len(unique_users))}\n",
    "item_idx_map = {k: unique_items[k] for k in range(len(unique_items))}\n",
    "\n",
    "user_vec_map = {k: v for k, v in zip(unique_users, user_vecs)}\n",
    "item_vec_map = {k: v for k, v in zip(unique_items, item_vecs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b9dded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading user topic vectors into DF\n",
    "user_vecs = pd.DataFrame.from_dict(user_vec_map, orient='index')\n",
    "user_vecs.index.name = 'reviewerID'\n",
    "# loading item topic vectors into DF\n",
    "item_vecs = pd.DataFrame.from_dict(item_vec_map, orient='index')\n",
    "item_vecs.index.name = 'asin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ec6b6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A00177463W0XWB16A9O05</th>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.138876</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.434725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A022899328A0QROR32DCT</th>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.027636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.024822</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A068255029AHTHDXZURNU</th>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.181789</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A06944662TFWOKKV4GJKX</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.181364</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.126235</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.050043</td>\n",
       "      <td>0.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1004703RC79J9</th>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.055492</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.721624</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.001429</td>\n",
       "      <td>0.104630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZWRZZAMX90VT</th>\n",
       "      <td>0.052026</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.023446</td>\n",
       "      <td>0.032928</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.083292</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.016636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.409704</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.005510</td>\n",
       "      <td>0.000083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZXKAH2DE6C8A</th>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.086734</td>\n",
       "      <td>0.108827</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.210080</td>\n",
       "      <td>0.089864</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.101732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZXON596A1VXC</th>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.029245</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.021816</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.035655</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.244129</td>\n",
       "      <td>0.040758</td>\n",
       "      <td>0.028318</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZYXC63SS008M</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.132769</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.161001</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZZ5ASC403N74</th>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.040539</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13397 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0         1         2         3         4   \\\n",
       "reviewerID                                                                \n",
       "A00177463W0XWB16A9O05  0.001429  0.001429  0.001429  0.001429  0.001429   \n",
       "A022899328A0QROR32DCT  0.051083  0.000247  0.000247  0.000247  0.000247   \n",
       "A068255029AHTHDXZURNU  0.000572  0.000572  0.000572  0.000572  0.000572   \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.000800  0.000800  0.000800  0.000800   \n",
       "A1004703RC79J9         0.001429  0.055492  0.001429  0.001429  0.001429   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "AZWRZZAMX90VT          0.052026  0.000083  0.000083  0.023446  0.032928   \n",
       "AZXKAH2DE6C8A          0.000150  0.000150  0.000150  0.000150  0.041372   \n",
       "AZXON596A1VXC          0.000179  0.029245  0.000179  0.000179  0.000179   \n",
       "AZYXC63SS008M          0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.040539  0.000714   \n",
       "\n",
       "                             5         6         7         8         9   ...  \\\n",
       "reviewerID                                                               ...   \n",
       "A00177463W0XWB16A9O05  0.001429  0.001429  0.001429  0.001429  0.001429  ...   \n",
       "A022899328A0QROR32DCT  0.000247  0.000247  0.000247  0.000247  0.027636  ...   \n",
       "A068255029AHTHDXZURNU  0.181789  0.000572  0.000572  0.000572  0.000572  ...   \n",
       "A06944662TFWOKKV4GJKX  0.181364  0.000800  0.000800  0.000800  0.000800  ...   \n",
       "A1004703RC79J9         0.001429  0.001429  0.001429  0.001429  0.001429  ...   \n",
       "...                         ...       ...       ...       ...       ...  ...   \n",
       "AZWRZZAMX90VT          0.020232  0.000083  0.083292  0.000083  0.016636  ...   \n",
       "AZXKAH2DE6C8A          0.000150  0.086734  0.108827  0.000150  0.000150  ...   \n",
       "AZXON596A1VXC          0.000179  0.000179  0.000179  0.000179  0.000179  ...   \n",
       "AZYXC63SS008M          0.001667  0.001667  0.001667  0.001667  0.001667  ...   \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714  ...   \n",
       "\n",
       "                             40        41        42        43        44  \\\n",
       "reviewerID                                                                \n",
       "A00177463W0XWB16A9O05  0.001429  0.001429  0.001429  0.001429  0.138876   \n",
       "A022899328A0QROR32DCT  0.000247  0.000247  0.024822  0.000247  0.000247   \n",
       "A068255029AHTHDXZURNU  0.000572  0.000572  0.000572  0.000572  0.000572   \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.000800  0.000800  0.000800  0.000800   \n",
       "A1004703RC79J9         0.001429  0.001429  0.721624  0.001429  0.001429   \n",
       "...                         ...       ...       ...       ...       ...   \n",
       "AZWRZZAMX90VT          0.000083  0.024583  0.000083  0.000083  0.000083   \n",
       "AZXKAH2DE6C8A          0.000150  0.000150  0.210080  0.089864  0.000150   \n",
       "AZXON596A1VXC          0.000179  0.000179  0.021816  0.000179  0.035655   \n",
       "AZYXC63SS008M          0.001667  0.132769  0.001667  0.161001  0.001667   \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714   \n",
       "\n",
       "                             45        46        47        48        49  \n",
       "reviewerID                                                               \n",
       "A00177463W0XWB16A9O05  0.001429  0.001429  0.001429  0.001429  0.434725  \n",
       "A022899328A0QROR32DCT  0.000247  0.000247  0.000247  0.000247  0.000247  \n",
       "A068255029AHTHDXZURNU  0.000572  0.000572  0.000572  0.000572  0.000572  \n",
       "A06944662TFWOKKV4GJKX  0.000800  0.126235  0.000800  0.050043  0.000800  \n",
       "A1004703RC79J9         0.001429  0.001429  0.001429  0.001429  0.104630  \n",
       "...                         ...       ...       ...       ...       ...  \n",
       "AZWRZZAMX90VT          0.000083  0.409704  0.000083  0.005510  0.000083  \n",
       "AZXKAH2DE6C8A          0.000150  0.000150  0.000150  0.000150  0.101732  \n",
       "AZXON596A1VXC          0.000179  0.244129  0.040758  0.028318  0.000179  \n",
       "AZYXC63SS008M          0.001667  0.001667  0.001667  0.001667  0.001667  \n",
       "AZZ5ASC403N74          0.000714  0.000714  0.000714  0.000714  0.000714  \n",
       "\n",
       "[13397 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6b5167a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9742356831</th>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.022746</td>\n",
       "      <td>0.206471</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.005570</td>\n",
       "      <td>0.075978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.014235</td>\n",
       "      <td>0.079787</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.073859</td>\n",
       "      <td>0.032581</td>\n",
       "      <td>0.036151</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00004S1C5</th>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.083453</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.277205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016198</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.245093</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00005344V</th>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.230676</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>0.116510</td>\n",
       "      <td>0.000081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0000CDEPD</th>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.102506</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.061988</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.080238</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0000CFPI2</th>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.028132</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035172</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.083337</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.091257</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.021162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00I08JNWU</th>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.138002</td>\n",
       "      <td>0.840174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00I33696K</th>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.063299</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168045</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.017794</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.038334</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00ID9VSOM</th>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094652</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.119456</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00IRL93SY</th>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.683272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00ISVHJ3Y</th>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.188283</td>\n",
       "      <td>0.090542</td>\n",
       "      <td>0.001112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4729 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1         2         3         4         5   \\\n",
       "asin                                                                     \n",
       "9742356831  0.000045  0.000045  0.022746  0.206471  0.000045  0.000045   \n",
       "B00004S1C5  0.000057  0.000057  0.000057  0.000057  0.083453  0.000057   \n",
       "B00005344V  0.000081  0.000081  0.000081  0.000081  0.000081  0.000081   \n",
       "B0000CDEPD  0.000128  0.000128  0.000128  0.076923  0.000128  0.000128   \n",
       "B0000CFPI2  0.000083  0.000083  0.000083  0.000083  0.000083  0.000083   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "B00I08JNWU  0.000455  0.000455  0.000455  0.000455  0.000455  0.000455   \n",
       "B00I33696K  0.000308  0.000308  0.000308  0.000308  0.000308  0.063299   \n",
       "B00ID9VSOM  0.000371  0.000371  0.000371  0.000371  0.000371  0.000371   \n",
       "B00IRL93SY  0.001667  0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "B00ISVHJ3Y  0.001112  0.001112  0.001112  0.001112  0.001112  0.001112   \n",
       "\n",
       "                  6         7         8         9   ...        40        41  \\\n",
       "asin                                                ...                       \n",
       "9742356831  0.000045  0.000045  0.005570  0.075978  ...  0.000045  0.014235   \n",
       "B00004S1C5  0.000057  0.000057  0.019323  0.277205  ...  0.016198  0.000057   \n",
       "B00005344V  0.000081  0.000081  0.000081  0.000081  ...  0.000081  0.230676   \n",
       "B0000CDEPD  0.102506  0.000128  0.000128  0.000128  ...  0.030720  0.000128   \n",
       "B0000CFPI2  0.000083  0.000083  0.028132  0.000083  ...  0.035172  0.000083   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "B00I08JNWU  0.000455  0.000455  0.000455  0.000455  ...  0.000455  0.000455   \n",
       "B00I33696K  0.000308  0.000308  0.000308  0.000308  ...  0.168045  0.000308   \n",
       "B00ID9VSOM  0.000371  0.000371  0.000371  0.000371  ...  0.094652  0.000371   \n",
       "B00IRL93SY  0.001667  0.001667  0.001667  0.001667  ...  0.001667  0.001667   \n",
       "B00ISVHJ3Y  0.001112  0.001112  0.001112  0.001112  ...  0.001112  0.001112   \n",
       "\n",
       "                  42        43        44        45        46        47  \\\n",
       "asin                                                                     \n",
       "9742356831  0.079787  0.000045  0.000045  0.000045  0.073859  0.032581   \n",
       "B00004S1C5  0.000057  0.000057  0.000057  0.000057  0.000057  0.245093   \n",
       "B00005344V  0.000081  0.000081  0.000081  0.000081  0.000081  0.026756   \n",
       "B0000CDEPD  0.061988  0.000128  0.000128  0.000128  0.000128  0.080238   \n",
       "B0000CFPI2  0.083337  0.000083  0.000083  0.000083  0.000083  0.091257   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "B00I08JNWU  0.000455  0.000455  0.000455  0.000455  0.000455  0.000455   \n",
       "B00I33696K  0.053929  0.000308  0.000308  0.017794  0.000308  0.000308   \n",
       "B00ID9VSOM  0.000371  0.000371  0.000371  0.000371  0.000371  0.119456   \n",
       "B00IRL93SY  0.001667  0.001667  0.001667  0.001667  0.001667  0.001667   \n",
       "B00ISVHJ3Y  0.001112  0.001112  0.001112  0.001112  0.001112  0.188283   \n",
       "\n",
       "                  48        49  \n",
       "asin                            \n",
       "9742356831  0.036151  0.000045  \n",
       "B00004S1C5  0.000057  0.000057  \n",
       "B00005344V  0.116510  0.000081  \n",
       "B0000CDEPD  0.000128  0.000128  \n",
       "B0000CFPI2  0.000083  0.021162  \n",
       "...              ...       ...  \n",
       "B00I08JNWU  0.138002  0.840174  \n",
       "B00I33696K  0.038334  0.000308  \n",
       "B00ID9VSOM  0.000371  0.000371  \n",
       "B00IRL93SY  0.001667  0.683272  \n",
       "B00ISVHJ3Y  0.090542  0.001112  \n",
       "\n",
       "[4729 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f41ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting factors into numpy obj\n",
    "user_factors = user_vecs.to_numpy()\n",
    "item_factors = item_vecs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31cbeccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.12296482, 0.0014288 , 0.0014288 , 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.11177909, 0.12735918, 0.0014288 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.1388757 ,\n",
       "       0.0014288 , 0.0014288 , 0.0014288 , 0.0014288 , 0.43472537],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd79bc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.49838044e-05, 4.49838044e-05, 2.27461141e-02, 2.06471100e-01,\n",
       "       4.49838044e-05, 4.49838044e-05, 4.49838044e-05, 4.49838044e-05,\n",
       "       5.57033625e-03, 7.59777725e-02, 4.49838044e-05, 2.29306202e-02,\n",
       "       4.49838044e-05, 4.49838044e-05, 4.49838044e-05, 2.14293730e-02,\n",
       "       4.49838044e-05, 4.49838044e-05, 4.32450511e-02, 4.49838044e-05,\n",
       "       1.32435948e-01, 4.49838044e-05, 5.55660166e-02, 4.49838044e-05,\n",
       "       4.49838044e-05, 4.49838044e-05, 4.49838044e-05, 4.49838044e-05,\n",
       "       4.49838044e-05, 4.49838044e-05, 4.49838044e-05, 4.49838044e-05,\n",
       "       1.18809834e-01, 4.49838044e-05, 6.93218177e-03, 3.27457450e-02,\n",
       "       4.49838044e-05, 5.52229676e-03, 4.49838044e-05, 1.16089135e-02,\n",
       "       4.49838044e-05, 1.42348548e-02, 7.97871649e-02, 4.49838044e-05,\n",
       "       4.49838044e-05, 4.49838044e-05, 7.38593340e-02, 3.25814523e-02,\n",
       "       3.61513719e-02, 4.49838044e-05], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5903a6c",
   "metadata": {},
   "source": [
    "# Train `EmbeddedMF` Class w/ Initialized Topic Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ba16818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import emf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1fb009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emf = emf.EmbeddedMF(user_map=user_idx_map,\n",
    "                     item_map=item_idx_map,\n",
    "                     user_factor=user_factors,\n",
    "                     item_factor=item_factors,\n",
    "                     learning_rate=.005,\n",
    "                     beta=.02,\n",
    "                     num_epochs=5,\n",
    "                     num_factors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f214fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data required for surprise\n",
    "\n",
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[['reviewerID', 'asin', 'overall']], reader)\n",
    "# generating training set\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a14405fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 5/5 [02:12<00:00, 26.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 8s, sys: 1.26 s, total: 2min 10s\n",
      "Wall time: 2min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fitting algo to training set\n",
    "emf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2d8f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.1 s, sys: 10.5 s, total: 47.6 s\n",
      "Wall time: 55.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate candidate items for user to predict rating\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ecb38503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 35s, sys: 6min 6s, total: 14min 42s\n",
      "Wall time: 18min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "predictions = emf.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487ebf2e",
   "metadata": {},
   "source": [
    "# Evaluate Top-N Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfc060",
   "metadata": {},
   "source": [
    "### Defining Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58335bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating precision@K - relevant / total recommended\n",
    "    precision_at_k = num_relevant / k\n",
    "    \n",
    "    return precision_at_k\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "386ce9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in tqdm(predictions):\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in tqdm(top_n.items()):\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91208e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")\n",
    "\n",
    "# generating test rating history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e8b34e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:45<00:00, 599445.62it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:50<00:00, 264.03it/s]\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62cb82bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A2VIX3WXF4HG9T:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "33340  B0041CIR62  Peacock Brown Rice Vermicelli, 7-Ounce Package...\n",
      "40399  B005DVVB9K              Chocolate Sampler Gift Basket by ig4U\n",
      "\n",
      "Recommending:\n",
      "\n",
      "             asin                                              title\n",
      "354    B00014JNI0  YS Organic Bee Farms CERTIFIED ORGANIC RAW HON...\n",
      "1115   B0001M0Z6Q  Spicy World Peppercorn (Whole)-Black Tellicher...\n",
      "4768   B000EDG4V2       Bob's Red Mill Guar Gum, 8 Ounce (Case of 8)\n",
      "4819   B000EDBPO8  Bob's Red Mill White Rice Flour, Organic, 24-O...\n",
      "6712   B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "8390   B000G82L62  Lundberg Family Farms Wild Blend Rice, 16 Ounc...\n",
      "9469   B000HDJXH6  Enjoy Life Chewy Bars, Soy free, Nut free, Glu...\n",
      "13711  B000Z93FQC               Y.S. Eco Bee Farms Raw Honey - 22 oz\n",
      "25518  B001PEWJWC  Garbanzo Beans aka Chickpeas or Ceci Beans | N...\n",
      "47552  B00DS842HS  Viva Naturals Organic Extra Virgin Coconut Oil...\n",
      "\n",
      "[('B00014JNI0', 4.692522540406702), ('B000EDG4V2', 4.664654344387276), ('B000Z93FQC', 4.6557003486847455), ('B000EDBPO8', 4.641866630338896), ('B000G82L62', 4.6304237827381645), ('B00DS842HS', 4.622402085641086), ('B001PEWJWC', 4.621965703493052), ('B0001M0Z6Q', 4.6193002192204915), ('B000F4D5GC', 4.593068713572729), ('B000HDJXH6', 4.574595330034814)]\n"
     ]
    }
   ],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "print(f\"For user: {random_user}:\")\n",
    "print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "# find the recommendations\n",
    "# NOTE: This is not sorted in ranking\n",
    "print(f\"\\nRecommending:\\n\")\n",
    "print(f\"{train[train['asin'].isin([i[0] for i in top_ns[random_user]])][['asin', 'title']].drop_duplicates(subset='asin')}\")\n",
    "print(f\"\\n{top_ns[random_user]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d01182",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd6c4fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [02:00<00:00, 525528.39it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:43<00:00, 306.64it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46043.05it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 47577.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@10: 0.00233, average recall@10: 0.01200.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074081e0",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0d7af19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:31<00:00, 693803.14it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [01:06<00:00, 202.34it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 43452.64it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46870.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@25: 0.00155, average recall@25: 0.01998.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc69f1ce",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc9a8bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:38<00:00, 642650.49it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:48<00:00, 276.60it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 41152.35it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 39409.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@30: 0.00143, average recall@30: 0.02194.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5895cbcd",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b79dcff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:34<00:00, 670253.03it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [01:04<00:00, 208.24it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 45297.16it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 47126.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@45: 0.00118, average recall@45: 0.02697.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29a08b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>pred_asin</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A101RRYMZM4KYV</td>\n",
       "      <td>[B000HDI5O8, B00C1LXBFC]</td>\n",
       "      <td>[B00014JNI0, B000EDG4V2, B00D1G7LZM, B000Z93FQ...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A1047EDJ84IMAS</td>\n",
       "      <td>[B00014JNI0, B00014JNI0, B004CWO9Y0, B004I5KO9...</td>\n",
       "      <td>[B00014JNI0, B000Z93FQC, B0001M0Z6Q, B000EDG4V...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>A10BWUA2MGA9BK</td>\n",
       "      <td>[B000S8593W]</td>\n",
       "      <td>[B001MSZK04, B000Z93FQC, B00014JNI0, B000EDG4V...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>A10C4O0Q0TWXOL</td>\n",
       "      <td>[B001E5E1L4, B001P74NXM, B00DS842HS]</td>\n",
       "      <td>[B00014JNI0, B004VLVFFI, B00DS842HS, B000Z93FQ...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A10Y058K7B96C6</td>\n",
       "      <td>[B000HDK0DC, B004U49QU2]</td>\n",
       "      <td>[B00014JNI0, B00DS842HS, B000EDG4V2, B000Z93FQ...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>AZGV51M0UUJ8B</td>\n",
       "      <td>[B00DS842HS]</td>\n",
       "      <td>[B00014JNI0, B000Z93FQC, B000EDG4V2, B001PEWJW...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>AZNS7TH82KH9K</td>\n",
       "      <td>[B00DS842HS]</td>\n",
       "      <td>[B00014JNI0, B00DS842HS, B0001M0Z6Q, B000EDBPO...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13260</th>\n",
       "      <td>AZQGJ5CEAJGXB</td>\n",
       "      <td>[B005A1LINC, B00DS842HS]</td>\n",
       "      <td>[B00014JNI0, B00DS842HS, B000EDG4V2, B000Z93FQ...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13270</th>\n",
       "      <td>AZVJHW8TARWV9</td>\n",
       "      <td>[B001PEWJWC]</td>\n",
       "      <td>[B00014JNI0, B000EDG4V2, B00DS842HS, B000Z93FQ...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13277</th>\n",
       "      <td>AZYXC63SS008M</td>\n",
       "      <td>[B0054TWPNC]</td>\n",
       "      <td>[B00014JNI0, B000Z93FQC, B00DS842HS, B000EDG4V...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>693 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "16     A101RRYMZM4KYV                           [B000HDI5O8, B00C1LXBFC]   \n",
       "21     A1047EDJ84IMAS  [B00014JNI0, B00014JNI0, B004CWO9Y0, B004I5KO9...   \n",
       "44     A10BWUA2MGA9BK                                       [B000S8593W]   \n",
       "45     A10C4O0Q0TWXOL               [B001E5E1L4, B001P74NXM, B00DS842HS]   \n",
       "99     A10Y058K7B96C6                           [B000HDK0DC, B004U49QU2]   \n",
       "...               ...                                                ...   \n",
       "13238   AZGV51M0UUJ8B                                       [B00DS842HS]   \n",
       "13251   AZNS7TH82KH9K                                       [B00DS842HS]   \n",
       "13260   AZQGJ5CEAJGXB                           [B005A1LINC, B00DS842HS]   \n",
       "13270   AZVJHW8TARWV9                                       [B001PEWJWC]   \n",
       "13277   AZYXC63SS008M                                       [B0054TWPNC]   \n",
       "\n",
       "                                               pred_asin  precision@k  \\\n",
       "16     [B00014JNI0, B000EDG4V2, B00D1G7LZM, B000Z93FQ...     0.022222   \n",
       "21     [B00014JNI0, B000Z93FQC, B0001M0Z6Q, B000EDG4V...     0.022222   \n",
       "44     [B001MSZK04, B000Z93FQC, B00014JNI0, B000EDG4V...     0.022222   \n",
       "45     [B00014JNI0, B004VLVFFI, B00DS842HS, B000Z93FQ...     0.022222   \n",
       "99     [B00014JNI0, B00DS842HS, B000EDG4V2, B000Z93FQ...     0.022222   \n",
       "...                                                  ...          ...   \n",
       "13238  [B00014JNI0, B000Z93FQC, B000EDG4V2, B001PEWJW...     0.022222   \n",
       "13251  [B00014JNI0, B00DS842HS, B0001M0Z6Q, B000EDBPO...     0.022222   \n",
       "13260  [B00014JNI0, B00DS842HS, B000EDG4V2, B000Z93FQ...     0.022222   \n",
       "13270  [B00014JNI0, B000EDG4V2, B00DS842HS, B000Z93FQ...     0.022222   \n",
       "13277  [B00014JNI0, B000Z93FQC, B00DS842HS, B000EDG4V...     0.022222   \n",
       "\n",
       "       recall@k  \n",
       "16     0.500000  \n",
       "21     0.166667  \n",
       "44     1.000000  \n",
       "45     0.333333  \n",
       "99     0.500000  \n",
       "...         ...  \n",
       "13238  1.000000  \n",
       "13251  1.000000  \n",
       "13260  0.500000  \n",
       "13270  1.000000  \n",
       "13277  1.000000  \n",
       "\n",
       "[693 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at how many get correct\n",
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd0798b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
