{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61ee0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30a64d5",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f8f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variable\n",
    "CATEGORY = \"Grocery_and_Gourmet_Food\"\n",
    "DATA_PATH = \"data/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4756c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35bbcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A23RYWDS884TUL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This curry paste makes a delicious curry.  I j...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>curry paste delicious curry fry chicken vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A945RBQWGZXCK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've purchased different curries in the grocer...</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>purchase different curry grocery store complet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3AMNY44OP8AOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I started a new diet restricting all added sug...</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>start new diet restrict added sugar brand suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3IB4CQ2QEJLJ8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>So many flavors. I can't begin to tell you how...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>flavor begin tell love mae ploy curry ask reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>AQA5DF3RWKETQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've used this a lot recently in some of my ch...</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>use lot recently chicken dish use lot like spi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        asin                              title  \\\n",
       "0      0  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1      1  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2      3  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "3      4  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "4      5  9742356831  Mae Ploy Green Curry Paste, 14 oz   \n",
       "\n",
       "                                          categories      reviewerID  overall  \\\n",
       "0  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A23RYWDS884TUL      5.0   \n",
       "1  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   A945RBQWGZXCK      5.0   \n",
       "2  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3AMNY44OP8AOU      4.0   \n",
       "3  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3IB4CQ2QEJLJ8      5.0   \n",
       "4  ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   AQA5DF3RWKETQ      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  \\\n",
       "0  This curry paste makes a delicious curry.  I j...  2013-05-28   \n",
       "1  I've purchased different curries in the grocer...  2012-09-17   \n",
       "2  I started a new diet restricting all added sug...  2014-01-23   \n",
       "3  So many flavors. I can't begin to tell you how...  2014-04-27   \n",
       "4  I've used this a lot recently in some of my ch...  2012-11-27   \n",
       "\n",
       "                                 processedReviewText  \n",
       "0  curry paste delicious curry fry chicken vegeta...  \n",
       "1  purchase different curry grocery store complet...  \n",
       "2  start new diet restrict added sugar brand suga...  \n",
       "3  flavor begin tell love mae ploy curry ask reci...  \n",
       "4  use lot recently chicken dish use lot like spi...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check first 5 rows\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0bccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[['reviewerID', 'asin', 'overall']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4936fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating training set\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f213f36",
   "metadata": {},
   "source": [
    "# Training Funk's SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82c2453",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = SVD(n_factors=50, n_epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb6c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting to the trainset\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2180a4e3",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432dc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4544e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "predictions = algo.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ac0a28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in tqdm(predictions):\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in tqdm(top_n.items()):\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ad6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30bb89f",
   "metadata": {},
   "source": [
    "# Evaluate Top-N Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce4146",
   "metadata": {},
   "source": [
    "### Defining Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723f6dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating precision@K - relevant / total recommended\n",
    "    precision_at_k = num_relevant / k\n",
    "    \n",
    "    return precision_at_k\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297f223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test dataset\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")\n",
    "\n",
    "# generating test rating history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce9c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "print(f\"For user: {random_user}:\")\n",
    "print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "# find the recommendations\n",
    "print(f\"\\nRecommending:\\n\")\n",
    "print(f\"{train[train['asin'].isin([i[0] for i in top_ns[random_user]])][['asin', 'title']].drop_duplicates(subset='asin')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87694d56",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da18a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aae6acb",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd65daae",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86881b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7881bd",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab11e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ns = get_top_n(predictions, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68adba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at how many get correct\n",
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b1e638",
   "metadata": {},
   "source": [
    "# Evaluate `FunkMF` Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43f4ec60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from src.models import cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4c887e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating funk's svd/mf\n",
    "funk_mf = cf.FunkMF(n_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc66287f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n"
     ]
    }
   ],
   "source": [
    "# fitting to training data\n",
    "funk_mf.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "439523f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A23RYWDS884TUL', 'B00004S1C5', 4.244714698371499),\n",
       " ('A23RYWDS884TUL', 'B00005344V', 4.244714698371499),\n",
       " ('A23RYWDS884TUL', 'B0000CDEPD', 4.244714698371499),\n",
       " ('A23RYWDS884TUL', 'B0000CFPI2', 4.244714698371499),\n",
       " ('A23RYWDS884TUL', 'B0000CH39R', 4.244714698371499)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check trainset and testset availability\n",
    "funk_mf.testset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91f63343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 54s, sys: 2min 29s, total: 9min 23s\n",
      "Wall time: 10min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generating predictions\n",
    "predictions = funk_mf.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17050dbe",
   "metadata": {},
   "source": [
    "### N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f148bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 63307346/63307346 [00:53<00:00, 1186295.07it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:51<00:00, 259.87it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 44104.84it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46562.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@10: 0.00279, average recall@10: 0.01434.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=10)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 10\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba926c02",
   "metadata": {},
   "source": [
    "### N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba196bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:56<00:00, 541456.69it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:57<00:00, 231.25it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 37074.18it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46545.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@25: 0.00210, average recall@25: 0.02678.\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=25)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 25\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f8be8",
   "metadata": {},
   "source": [
    "### N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07fccf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:30<00:00, 701828.37it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:52<00:00, 252.91it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 38075.14it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 49282.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@30: 0.00202, average recall@30: 0.03096.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=30)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 30\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b86cad",
   "metadata": {},
   "source": [
    "### N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f3b92cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 63307346/63307346 [01:32<00:00, 687870.58it/s]\n",
      "100%|████████████████████████████████████████████████████████| 13397/13397 [00:46<00:00, 288.41it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 46487.42it/s]\n",
      "100%|██████████████████████████████████████████████████████| 13279/13279 [00:00<00:00, 48520.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MEM-ECF has a average precision@45: 0.00184, average recall@45: 0.04235.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "top_ns = get_top_n(predictions, n=45)\n",
    "\n",
    "test_recommendations = pd.DataFrame(top_ns.items(), columns=['reviewerID', 'pred_asin'])\n",
    "test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "\n",
    "# combined test dataset and recommendations\n",
    "test_merged = pd.merge(test_user_history, test_recommendations, on='reviewerID', how='inner')\n",
    "\n",
    "k = 45\n",
    "test_merged['precision@k'] = test_merged.progress_apply(lambda x: precision_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "test_merged['recall@k'] = test_merged.progress_apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "\n",
    "average_precision_at_k = test_merged[\"precision@k\"].mean()\n",
    "average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "\n",
    "print(f\"The MEM-ECF has a average precision@{k}: {average_precision_at_k:.5f}, average recall@{k}: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d687bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>pred_asin</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A100VQNP6I54HS</td>\n",
       "      <td>[B001VNEICQ, B004EKHN4I, B0057POYGY]</td>\n",
       "      <td>[B00DS842HS, B00017028M, B0054TWQMM, B000BD0SD...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A1025ZA8TGG21H</td>\n",
       "      <td>[B000ED9L6C, B002BTI9B0]</td>\n",
       "      <td>[B001PEWJWC, B00DS842HS, B000EDG3UE, B00014JNI...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>A1047EDJ84IMAS</td>\n",
       "      <td>[B00014JNI0, B00014JNI0, B004CWO9Y0, B004I5KO9...</td>\n",
       "      <td>[B00014JNI0, B00271OPVU, B000Z93FQC, B0001CXUH...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>A105S56ODHGJEK</td>\n",
       "      <td>[B0025UCHRC, B005V9YXTO, B007JFXXJY, B00934WBRO]</td>\n",
       "      <td>[B00014JNI0, B005ZBZLT4, B001EO5U3I, B0001M0Z6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>A10BD0288TGRVS</td>\n",
       "      <td>[B00017LEXE, B00017LEXE, B001D3K2GA, B0029XLH4Y]</td>\n",
       "      <td>[B00014JNI0, B00DS842HS, B000Z93FQC, B0001M0Z6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13238</th>\n",
       "      <td>AZGV51M0UUJ8B</td>\n",
       "      <td>[B00DS842HS]</td>\n",
       "      <td>[B00014JNI0, B000Z93FQC, B00DS842HS, B00271OPV...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13251</th>\n",
       "      <td>AZNS7TH82KH9K</td>\n",
       "      <td>[B00DS842HS]</td>\n",
       "      <td>[B0001M0Z6Q, B00014JNI0, B000Z93FQC, B000ED9L6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13260</th>\n",
       "      <td>AZQGJ5CEAJGXB</td>\n",
       "      <td>[B005A1LINC, B00DS842HS]</td>\n",
       "      <td>[B00014JNI0, B00DS842HS, B000G82L62, B00271OPV...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13270</th>\n",
       "      <td>AZVJHW8TARWV9</td>\n",
       "      <td>[B001PEWJWC]</td>\n",
       "      <td>[B0001M0Z6Q, B00014JNI0, B00DS842HS, B000EDG3U...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13273</th>\n",
       "      <td>AZWP97BZPJI1D</td>\n",
       "      <td>[B0025UCHS6, B0025UCHT0, B00BIEU5QQ]</td>\n",
       "      <td>[B00014JNI0, B00DS842HS, B00271OPVU, B000EDDS6...</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1053 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "10     A100VQNP6I54HS               [B001VNEICQ, B004EKHN4I, B0057POYGY]   \n",
       "18     A1025ZA8TGG21H                           [B000ED9L6C, B002BTI9B0]   \n",
       "21     A1047EDJ84IMAS  [B00014JNI0, B00014JNI0, B004CWO9Y0, B004I5KO9...   \n",
       "26     A105S56ODHGJEK   [B0025UCHRC, B005V9YXTO, B007JFXXJY, B00934WBRO]   \n",
       "42     A10BD0288TGRVS   [B00017LEXE, B00017LEXE, B001D3K2GA, B0029XLH4Y]   \n",
       "...               ...                                                ...   \n",
       "13238   AZGV51M0UUJ8B                                       [B00DS842HS]   \n",
       "13251   AZNS7TH82KH9K                                       [B00DS842HS]   \n",
       "13260   AZQGJ5CEAJGXB                           [B005A1LINC, B00DS842HS]   \n",
       "13270   AZVJHW8TARWV9                                       [B001PEWJWC]   \n",
       "13273   AZWP97BZPJI1D               [B0025UCHS6, B0025UCHT0, B00BIEU5QQ]   \n",
       "\n",
       "                                               pred_asin  precision@k  \\\n",
       "10     [B00DS842HS, B00017028M, B0054TWQMM, B000BD0SD...     0.022222   \n",
       "18     [B001PEWJWC, B00DS842HS, B000EDG3UE, B00014JNI...     0.022222   \n",
       "21     [B00014JNI0, B00271OPVU, B000Z93FQC, B0001CXUH...     0.022222   \n",
       "26     [B00014JNI0, B005ZBZLT4, B001EO5U3I, B0001M0Z6...     0.022222   \n",
       "42     [B00014JNI0, B00DS842HS, B000Z93FQC, B0001M0Z6...     0.022222   \n",
       "...                                                  ...          ...   \n",
       "13238  [B00014JNI0, B000Z93FQC, B00DS842HS, B00271OPV...     0.022222   \n",
       "13251  [B0001M0Z6Q, B00014JNI0, B000Z93FQC, B000ED9L6...     0.022222   \n",
       "13260  [B00014JNI0, B00DS842HS, B000G82L62, B00271OPV...     0.022222   \n",
       "13270  [B0001M0Z6Q, B00014JNI0, B00DS842HS, B000EDG3U...     0.022222   \n",
       "13273  [B00014JNI0, B00DS842HS, B00271OPVU, B000EDDS6...     0.022222   \n",
       "\n",
       "       recall@k  \n",
       "10     0.333333  \n",
       "18     0.500000  \n",
       "21     0.166667  \n",
       "26     0.250000  \n",
       "42     0.250000  \n",
       "...         ...  \n",
       "13238  1.000000  \n",
       "13251  1.000000  \n",
       "13260  0.500000  \n",
       "13270  1.000000  \n",
       "13273  0.333333  \n",
       "\n",
       "[1053 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at how many get correct\n",
    "test_merged[test_merged['recall@k'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b92e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
