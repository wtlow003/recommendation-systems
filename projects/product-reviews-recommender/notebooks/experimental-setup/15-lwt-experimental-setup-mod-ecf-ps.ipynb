{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36551cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import yaml\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pandarallel import pandarallel\n",
    "from surprise import Dataset, Reader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import cf\n",
    "\n",
    "pandarallel.initialize()\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e56bfe5",
   "metadata": {},
   "source": [
    "# Load Data and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4e036df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = \"data/evaluation\"\n",
    "# D2V_PATH = \"models/d2v\"\n",
    "CATEGORY = \"Pet_Supplies\"\n",
    "\n",
    "# training parameters\n",
    "N_EPOCHS = 10\n",
    "LR_ALL = 0.005\n",
    "BETA = 0.1\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b085128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1223000893</td>\n",
       "      <td>Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3</td>\n",
       "      <td>[]</td>\n",
       "      <td>A14CK12J7C7JRK</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I purchased the Trilogy with hoping my two cat...</td>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>purchase trilogy hop cat age interested yr old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1223000893</td>\n",
       "      <td>Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3</td>\n",
       "      <td>[]</td>\n",
       "      <td>A2CR37UY3VR7BN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I bought the triliogy and have tested out all ...</td>\n",
       "      <td>2012-12-19</td>\n",
       "      <td>buy triliogy test dvd appear volume receive re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1223000893</td>\n",
       "      <td>Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3</td>\n",
       "      <td>[]</td>\n",
       "      <td>A2A4COGL9VW2HY</td>\n",
       "      <td>4.0</td>\n",
       "      <td>My female kitty could care less about these vi...</td>\n",
       "      <td>2011-05-12</td>\n",
       "      <td>female kitty care video care little male dig a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1223000893</td>\n",
       "      <td>Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3</td>\n",
       "      <td>[]</td>\n",
       "      <td>A2UBQA85NIGLHA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>If I had gotten just volume two, I would have ...</td>\n",
       "      <td>2012-03-05</td>\n",
       "      <td>volume star trilogy star read review know vol ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B00005MF9U</td>\n",
       "      <td>LitterMaid LM900 Mega Self-Cleaning Litter Box</td>\n",
       "      <td>['Pet Supplies', 'Cats', 'Litter &amp;amp; Housebr...</td>\n",
       "      <td>A2BH04B9G9LOYA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>First off, it seems that someone is spamming t...</td>\n",
       "      <td>2006-12-31</td>\n",
       "      <td>spamming review glow reviewer review amazon ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68865</th>\n",
       "      <td>111581</td>\n",
       "      <td>B00K3YPOO0</td>\n",
       "      <td>Brightest Black Light Flashlight on Amazon- UV...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A11J1FHCK5U06J</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Now I know exactly where the trouble spots are...</td>\n",
       "      <td>2014-05-23</td>\n",
       "      <td>know exactly trouble spot sniffing guess invis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68866</th>\n",
       "      <td>111585</td>\n",
       "      <td>B00K3YPOO0</td>\n",
       "      <td>Brightest Black Light Flashlight on Amazon- UV...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A18JF0T0GOCORW</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I use this light to help me find stains when I...</td>\n",
       "      <td>2014-05-24</td>\n",
       "      <td>use light help stain carpet clean pre treat ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68867</th>\n",
       "      <td>111595</td>\n",
       "      <td>B00K7EG97C</td>\n",
       "      <td>Nutro Crunchy Dog Treats with Real Mixed Berri...</td>\n",
       "      <td>['Pet Supplies', 'Dogs', 'Treats', 'Cookies, B...</td>\n",
       "      <td>A3GRPCW9DG427Z</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We are owned by the 3 pickiest pooches in the ...</td>\n",
       "      <td>2013-07-27</td>\n",
       "      <td>pickiest pooch world love fool reject doggie t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68868</th>\n",
       "      <td>111598</td>\n",
       "      <td>B00K7EG97C</td>\n",
       "      <td>Nutro Crunchy Dog Treats with Real Mixed Berri...</td>\n",
       "      <td>['Pet Supplies', 'Dogs', 'Treats', 'Cookies, B...</td>\n",
       "      <td>A2X6TLAX3JEO1A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My highly allergic white boxer loves these tre...</td>\n",
       "      <td>2014-05-09</td>\n",
       "      <td>highly allergic white boxer love treat meat co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68869</th>\n",
       "      <td>111602</td>\n",
       "      <td>B00KJGFGFO</td>\n",
       "      <td>Curry Brush with Coarse or Fine Bristles. High...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A9PG9ODPPP31N</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Works great on my medium sized dog. She has ve...</td>\n",
       "      <td>2014-07-09</td>\n",
       "      <td>work great medium size dog coarse hair work gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        asin                                              title  \\\n",
       "0           0  1223000893    Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3   \n",
       "1           2  1223000893    Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3   \n",
       "2           3  1223000893    Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3   \n",
       "3           4  1223000893    Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3   \n",
       "4           5  B00005MF9U     LitterMaid LM900 Mega Self-Cleaning Litter Box   \n",
       "68865  111581  B00K3YPOO0  Brightest Black Light Flashlight on Amazon- UV...   \n",
       "68866  111585  B00K3YPOO0  Brightest Black Light Flashlight on Amazon- UV...   \n",
       "68867  111595  B00K7EG97C  Nutro Crunchy Dog Treats with Real Mixed Berri...   \n",
       "68868  111598  B00K7EG97C  Nutro Crunchy Dog Treats with Real Mixed Berri...   \n",
       "68869  111602  B00KJGFGFO  Curry Brush with Coarse or Fine Bristles. High...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0                                                     []  A14CK12J7C7JRK   \n",
       "1                                                     []  A2CR37UY3VR7BN   \n",
       "2                                                     []  A2A4COGL9VW2HY   \n",
       "3                                                     []  A2UBQA85NIGLHA   \n",
       "4      ['Pet Supplies', 'Cats', 'Litter &amp; Housebr...  A2BH04B9G9LOYA   \n",
       "68865                                                 []  A11J1FHCK5U06J   \n",
       "68866                                                 []  A18JF0T0GOCORW   \n",
       "68867  ['Pet Supplies', 'Dogs', 'Treats', 'Cookies, B...  A3GRPCW9DG427Z   \n",
       "68868  ['Pet Supplies', 'Dogs', 'Treats', 'Cookies, B...  A2X6TLAX3JEO1A   \n",
       "68869                                                 []   A9PG9ODPPP31N   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          3.0  I purchased the Trilogy with hoping my two cat...  2011-01-12   \n",
       "1          4.0  I bought the triliogy and have tested out all ...  2012-12-19   \n",
       "2          4.0  My female kitty could care less about these vi...  2011-05-12   \n",
       "3          3.0  If I had gotten just volume two, I would have ...  2012-03-05   \n",
       "4          1.0  First off, it seems that someone is spamming t...  2006-12-31   \n",
       "68865      4.0  Now I know exactly where the trouble spots are...  2014-05-23   \n",
       "68866      4.0  I use this light to help me find stains when I...  2014-05-24   \n",
       "68867      5.0  We are owned by the 3 pickiest pooches in the ...  2013-07-27   \n",
       "68868      5.0  My highly allergic white boxer loves these tre...  2014-05-09   \n",
       "68869      5.0  Works great on my medium sized dog. She has ve...  2014-07-09   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      purchase trilogy hop cat age interested yr old...  \n",
       "1      buy triliogy test dvd appear volume receive re...  \n",
       "2      female kitty care video care little male dig a...  \n",
       "3      volume star trilogy star read review know vol ...  \n",
       "4      spamming review glow reviewer review amazon ba...  \n",
       "68865  know exactly trouble spot sniffing guess invis...  \n",
       "68866  use light help stain carpet clean pre treat ca...  \n",
       "68867  pickiest pooch world love fool reject doggie t...  \n",
       "68868  highly allergic white boxer love treat meat co...  \n",
       "68869  work great medium size dog coarse hair work gr...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking train dataframe\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3152a",
   "metadata": {},
   "source": [
    "# Train Doc2Vec Model (User & Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9b295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38f07b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dm': 1, 'vector_size': 50, 'min_count': 1, 'negative': 5, 'ns_exponent': 0.5, 'sample': 1e-05, 'workers': 8, 'epochs': 10}\n"
     ]
    }
   ],
   "source": [
    "# read params\n",
    "params = yaml.safe_load(open(\"params.yaml\"))[\"generate_vectors\"]\n",
    "MODEL_PARAMS = params[\"d2v_params\"]\n",
    "\n",
    "print(MODEL_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b8c2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68870/68870 [00:00<00:00, 173894.29it/s]\n"
     ]
    }
   ],
   "source": [
    "train[\"processedReviewText\"] = train[\"processedReviewText\"].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f469a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_corpus = [\n",
    "    TaggedDocument(review, [asin])\n",
    "    for asin, review in list(zip(train[\"asin\"], train[\"processedReviewText\"]))\n",
    "]\n",
    "\n",
    "user_corpus = [\n",
    "    TaggedDocument(review, [reviewerID])\n",
    "    for reviewerID, review in list(zip(train[\"reviewerID\"], train[\"processedReviewText\"]))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ef918f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = item_corpus + user_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d0bfa",
   "metadata": {},
   "source": [
    "## Training Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2e7978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.utils:starting a new internal lifecycle event log for Doc2Vec\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d50,n5,w5,s1e-05,t8)', 'datetime': '2021-09-10T02:30:36.639826', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'created'}\n",
      "INFO:gensim.models.doc2vec:collecting all words and their counts\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #10000, processed 328019 words (4456260/s), 10456 word types, 296 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #20000, processed 621905 words (4437470/s), 14219 word types, 588 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #30000, processed 973691 words (4659207/s), 18951 word types, 1070 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #40000, processed 1319005 words (1330613/s), 23818 word types, 1763 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #50000, processed 1684919 words (4822062/s), 28410 word types, 2652 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #60000, processed 2063708 words (4722946/s), 32183 word types, 3625 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #70000, processed 2456766 words (4859324/s), 35504 word types, 5464 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #80000, processed 2774890 words (5446946/s), 35504 word types, 9603 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #90000, processed 3089550 words (5264023/s), 35504 word types, 13132 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #100000, processed 3424760 words (5173787/s), 35504 word types, 16998 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #110000, processed 3774610 words (5003671/s), 35504 word types, 20157 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #120000, processed 4139266 words (4898510/s), 35504 word types, 22158 tags\n",
      "INFO:gensim.models.doc2vec:PROGRESS: at example #130000, processed 4523485 words (5141615/s), 35504 word types, 23409 tags\n",
      "INFO:gensim.models.doc2vec:collected 35504 word types and 23936 unique tags from a corpus of 137740 examples and 4829848 words\n",
      "INFO:gensim.models.word2vec:Creating a fresh vocabulary\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 35504 unique words (100.0%% of original 35504, drops 0)', 'datetime': '2021-09-10T02:30:38.091577', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 4829848 word corpus (100.0%% of original 4829848, drops 0)', 'datetime': '2021-09-10T02:30:38.092219', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:deleting the raw counts dictionary of 35504 items\n",
      "INFO:gensim.models.word2vec:sample=1e-05 downsamples 3308 most-common words\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 1185902.4161147363 word corpus (24.6%% of prior 4829848)', 'datetime': '2021-09-10T02:30:38.272869', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "INFO:gensim.models.word2vec:estimated required memory for 35504 words and 50 dimensions: 41528000 bytes\n",
      "INFO:gensim.models.word2vec:resetting layer weights\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'training model with 8 workers on 35504 vocabulary and 50 features, using sg=0 hs=0 sample=1e-05 negative=5 window=5', 'datetime': '2021-09-10T02:30:38.605790', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'train'}\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 10.49% examples, 125226 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 22.04% examples, 131415 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 33.34% examples, 137325 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 44.70% examples, 143695 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 55.86% examples, 145300 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 67.36% examples, 143074 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 78.20% examples, 142434 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 1 - PROGRESS: at 89.86% examples, 144598 words/s, in_qsize 16, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 58 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 64 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 1 : training on 4829848 raw words (1324818 effective words) took 9.0s, 147200 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 10.49% examples, 125910 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 22.04% examples, 131476 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 33.53% examples, 138123 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 43.64% examples, 139543 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 53.41% examples, 139660 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 65.03% examples, 138509 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 74.68% examples, 135349 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 85.65% examples, 136740 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 2 - PROGRESS: at 95.80% examples, 137908 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 2 : training on 4829848 raw words (1323651 effective words) took 9.5s, 139926 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 10.21% examples, 123118 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 21.85% examples, 130019 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 33.12% examples, 134808 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 44.70% examples, 142333 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 55.86% examples, 144231 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 67.36% examples, 142077 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 78.20% examples, 141831 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 3 - PROGRESS: at 89.86% examples, 144286 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 58 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 65 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 3 : training on 4829848 raw words (1324197 effective words) took 9.0s, 146815 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 10.81% examples, 126509 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 22.27% examples, 133126 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 33.99% examples, 140082 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 45.09% examples, 144056 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 56.43% examples, 146281 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 68.37% examples, 144872 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 79.65% examples, 144568 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 4 - PROGRESS: at 91.02% examples, 146198 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 58 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 64 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 4 : training on 4829848 raw words (1323876 effective words) took 8.9s, 148672 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 10.49% examples, 124262 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 22.04% examples, 131007 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 33.99% examples, 138598 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 45.09% examples, 143009 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 56.43% examples, 145406 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 68.14% examples, 143702 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 79.65% examples, 143823 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 5 - PROGRESS: at 91.03% examples, 145348 words/s, in_qsize 16, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 63 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 5 : training on 4829848 raw words (1324193 effective words) took 9.0s, 147915 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 10.49% examples, 125762 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 22.04% examples, 131320 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 33.75% examples, 139136 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 44.87% examples, 144633 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 55.86% examples, 145402 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 67.49% examples, 142918 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 79.24% examples, 144094 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 6 - PROGRESS: at 90.25% examples, 144630 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 6 : training on 4829848 raw words (1323654 effective words) took 9.0s, 147677 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 10.81% examples, 128846 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 22.29% examples, 133636 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 33.99% examples, 140403 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 45.09% examples, 144478 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 56.43% examples, 146673 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 68.58% examples, 145647 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 79.65% examples, 144675 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 7 - PROGRESS: at 91.03% examples, 146270 words/s, in_qsize 15, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 58 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 63 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 7 : training on 4829848 raw words (1323888 effective words) took 8.9s, 148781 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 10.49% examples, 126152 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 22.04% examples, 132602 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 33.99% examples, 139840 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 45.09% examples, 144090 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 56.43% examples, 145740 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 68.58% examples, 144809 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 79.65% examples, 144156 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 8 - PROGRESS: at 91.02% examples, 145697 words/s, in_qsize 16, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 63 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 8 : training on 4829848 raw words (1322683 effective words) took 8.9s, 148193 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 10.49% examples, 125552 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 22.04% examples, 132345 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 33.99% examples, 139439 words/s, in_qsize 16, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 45.09% examples, 143721 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 56.23% examples, 145709 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 67.66% examples, 143228 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 79.65% examples, 143807 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 9 - PROGRESS: at 90.81% examples, 145271 words/s, in_qsize 16, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 63 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 63 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 9 : training on 4829848 raw words (1324182 effective words) took 9.0s, 147937 effective words/s\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 10.49% examples, 124733 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 22.04% examples, 131031 words/s, in_qsize 16, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 33.99% examples, 138487 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 45.09% examples, 143375 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 56.43% examples, 145628 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 68.11% examples, 143816 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 79.65% examples, 143744 words/s, in_qsize 15, out_qsize 0\n",
      "INFO:gensim.models.word2vec:EPOCH 10 - PROGRESS: at 91.03% examples, 145345 words/s, in_qsize 16, out_qsize 0\n",
      "DEBUG:gensim.models.word2vec:job loop exiting, total 485 jobs\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 60 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 7 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 6 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 5 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 4 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 3 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 61 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 2 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 59 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 1 more threads\n",
      "DEBUG:gensim.models.word2vec:worker exiting, processed 62 jobs\n",
      "INFO:gensim.models.word2vec:worker thread finished; awaiting finish of 0 more threads\n",
      "INFO:gensim.models.word2vec:EPOCH - 10 : training on 4829848 raw words (1322763 effective words) took 8.9s, 147952 effective words/s\n",
      "INFO:gensim.utils:Doc2Vec lifecycle event {'msg': 'training on 48298480 raw words (13237905 effective words) took 90.1s, 146945 effective words/s', 'datetime': '2021-09-10T02:32:08.695804', 'gensim': '4.0.1', 'python': '3.9.6 (default, Jun 29 2021, 05:25:02) \\n[Clang 12.0.5 (clang-1205.0.22.9)]', 'platform': 'macOS-11.4-x86_64-i386-64bit', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "d2v = Doc2Vec(**MODEL_PARAMS)\n",
    "d2v.build_vocab(train_corpus)\n",
    "d2v.train(train_corpus, total_examples=d2v.corpus_count, epochs=d2v.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed374ca",
   "metadata": {},
   "source": [
    "# Generating User & Item Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33188222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_user_item_vectors(train: pd.DataFrame, d2v: Doc2Vec) -> tuple:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # get unique users and items\n",
    "    unique_users = train[\"reviewerID\"].unique().tolist()\n",
    "    unique_items = train[\"asin\"].unique().tolist()\n",
    "    \n",
    "    # generating mapping\n",
    "    user_idx_map = {j: unique_users[j] for j in range(len(unique_users))}\n",
    "    item_idx_map = {k: unique_items[k] for k in range(len(unique_items))}\n",
    "    user_vec_map = {j: d2v[j] for j in unique_users}\n",
    "    item_vec_map = {k: d2v[k] for k in unique_items}\n",
    "    \n",
    "    # loading user d2v vectors into DF\n",
    "    user_vecs = pd.DataFrame.from_dict(user_vec_map, orient='index')\n",
    "    user_vecs.index.name = 'reviewerID'\n",
    "    # loading item d2v vectors into DF\n",
    "    item_vecs = pd.DataFrame.from_dict(item_vec_map, orient='index')\n",
    "    item_vecs.index.name = 'asin'\n",
    "    \n",
    "    return user_idx_map, user_vecs, item_idx_map, item_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc02f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_idx_map, user_vecs, item_idx_map, item_vecs = generate_user_item_vectors(train, d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455ba70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting factors into numpy obj\n",
    "user_factors = user_vecs.to_numpy()\n",
    "item_factors = item_vecs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e06b73c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.77922696, -0.04419504,  0.16107428, -0.25824603,  0.0884501 ,\n",
       "       -0.02654092, -0.02497942,  0.16291593, -0.37637684,  0.30814305,\n",
       "        0.11929291,  0.2186527 ,  0.18439731,  0.11816351,  0.08316469,\n",
       "        0.12371369, -0.05493512,  0.11931185, -0.2154937 , -0.31036133,\n",
       "        0.01955248,  0.26068544, -0.10980664, -0.10918962, -0.06849704,\n",
       "        0.23774654, -0.25029686, -0.4825891 , -0.2773218 , -0.19737539,\n",
       "        0.32247096, -0.10018329,  0.03507648,  0.11142119,  0.06777498,\n",
       "        0.58456314, -0.11256726, -0.14702937,  0.5582978 ,  0.37698284,\n",
       "       -0.06631536,  0.10135109, -0.05887937, -0.1210361 , -0.15826057,\n",
       "        0.27591133,  0.21363966, -0.12117494,  0.00095104,  0.03555251],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check user factors\n",
    "user_factors[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0652aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26331735, -0.11056983, -0.03232048, -0.01091432, -0.038435  ,\n",
       "        0.02057339,  0.05015131, -0.0178882 , -0.10059441,  0.05925798,\n",
       "        0.05865845,  0.13821098,  0.04844033,  0.04657209, -0.06200987,\n",
       "       -0.05522555, -0.03117626, -0.01920465, -0.0764898 ,  0.05243775,\n",
       "       -0.00426404,  0.0231584 , -0.08311716, -0.10264607, -0.05266638,\n",
       "        0.09226736, -0.0326032 , -0.15560375, -0.05665855, -0.13925622,\n",
       "        0.07608208,  0.05124145, -0.03601347,  0.10328931,  0.00628529,\n",
       "        0.13207851, -0.095514  , -0.15085706,  0.14196587,  0.00942813,\n",
       "       -0.02785949,  0.07429376, -0.041956  , -0.01490974,  0.0295794 ,\n",
       "        0.16168976,  0.11567512,  0.00170415, -0.05042413, -0.02102186],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check item factors\n",
    "item_factors[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e16880",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "148f0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in tqdm(predictions):\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in tqdm(top_n.items()):\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k\n",
    "\n",
    "def novelty_at_k(item_popularity, predicted_asins, k=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # finding avg novelty\n",
    "    popularity_sum = item_popularity.loc[predicted_asins].sum()\n",
    "    novelty_at_k = ((k*1) - popularity_sum) / k\n",
    "    \n",
    "    return novelty_at_k\n",
    "\n",
    "def generate_item_popularity(train: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a mapping of item popularatity\n",
    "    # based on sum(item's review / max reviews) / no items\n",
    "    max_reviews = (train.groupby(['asin'])\n",
    "                   .agg({'processedReviewText': 'count'})\n",
    "                   .max()\n",
    "                   .values[0])\n",
    "    item_popularity = (train.groupby(['asin'])\n",
    "                       .agg({'processedReviewText': 'count'})\n",
    "                       .apply(lambda x: x/max_reviews))\n",
    "    \n",
    "    return item_popularity\n",
    "    \n",
    "\n",
    "def evaluate_recommendations(top_ns: dict, user_rating_history: pd.DataFrame, item_popularity: pd.DataFrame, k=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        top_ns\n",
    "        user_rating_history\n",
    "    \"\"\"\n",
    "    \n",
    "    test_recommendations = pd.DataFrame(top_ns.items(), columns=[\"reviewerID\", \"pred_asin\"])\n",
    "    test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "    \n",
    "    # combined test history and recommendations\n",
    "    test_merged = pd.merge(user_rating_history, test_recommendations, on=\"reviewerID\", how=\"inner\")\n",
    "    \n",
    "    # generating recall@k metrics\n",
    "    test_merged[\"recall@k\"] = test_merged.apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "    test_merged[\"novelty@k\"] = test_merged.apply(lambda x: novelty_at_k(item_popularity, x.pred_asin, k=k), axis=1)\n",
    "    average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "    average_novelty_at_k = test_merged[\"novelty@k\"].mean()\n",
    "    \n",
    "    print(f\"The MOD-ECF has an average recall@{k}: {average_recall_at_k:.5f}, average novelty@{k}: {average_novelty_at_k:.5f}\")\n",
    "    \n",
    "    return test_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47668d",
   "metadata": {},
   "source": [
    "# Generate N-Recommendations = {10, 25, 30, 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f98d6",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11b82429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1223000893</td>\n",
       "      <td>Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3</td>\n",
       "      <td>[]</td>\n",
       "      <td>A39QHP5WLON5HV</td>\n",
       "      <td>5.0</td>\n",
       "      <td>There are usually one or more of my cats watch...</td>\n",
       "      <td>2013-09-14</td>\n",
       "      <td>usually cat watch tv stay trouble dvd play lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>B00005MF9V</td>\n",
       "      <td>LitterMaid Universal Cat Privacy Tent (LMT100)</td>\n",
       "      <td>['Pet Supplies', 'Cats', 'Litter &amp; Housebreaki...</td>\n",
       "      <td>A366V0GCEPH5CX</td>\n",
       "      <td>5.0</td>\n",
       "      <td>My cats love it and so do I. I no longer have ...</td>\n",
       "      <td>2013-02-02</td>\n",
       "      <td>cat love longer cat litter fly floor litter fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133</td>\n",
       "      <td>B00005MF9T</td>\n",
       "      <td>LitterMaid LM500 Automated Litter Box</td>\n",
       "      <td>['Pet Supplies', 'Cats', 'Litter &amp; Housebreaki...</td>\n",
       "      <td>ALWWS8QBYN80B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I have one female cat that weighs under 10 pou...</td>\n",
       "      <td>2004-11-17</td>\n",
       "      <td>female cat weigh pound year old use everclean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>B00005MF9W</td>\n",
       "      <td>LitterMaid Waste Receptacles Automatic Litter ...</td>\n",
       "      <td>['Pet Supplies', 'Cats', 'Litter &amp; Housebreaki...</td>\n",
       "      <td>A3PVI3NE7OY1SP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love these. They make the clean up so much e...</td>\n",
       "      <td>2013-09-26</td>\n",
       "      <td>love clean easy clean box manually use issue w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154</td>\n",
       "      <td>B00005MF9W</td>\n",
       "      <td>LitterMaid Waste Receptacles Automatic Litter ...</td>\n",
       "      <td>['Pet Supplies', 'Cats', 'Litter &amp; Housebreaki...</td>\n",
       "      <td>A2H83XMHUVDLJY</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I love this litter box. I do not use the lids,...</td>\n",
       "      <td>2014-06-26</td>\n",
       "      <td>love litter box use lid use receptacle tear cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41564</th>\n",
       "      <td>111601</td>\n",
       "      <td>B00KJGFGFO</td>\n",
       "      <td>Curry Brush with Coarse or Fine Bristles. High...</td>\n",
       "      <td>[]</td>\n",
       "      <td>AV34KNYW82YSS</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Pulled lots of hair out of my Labs coat. Didn'...</td>\n",
       "      <td>2014-07-18</td>\n",
       "      <td>pulled lot hair labs coat think prove wrong co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41565</th>\n",
       "      <td>111603</td>\n",
       "      <td>B00KJGFGFO</td>\n",
       "      <td>Curry Brush with Coarse or Fine Bristles. High...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A1YMNTFLNDYQ1F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have been trying to find a rubber bristle br...</td>\n",
       "      <td>2014-07-16</td>\n",
       "      <td>try rubber bristle brush persian year lose glo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41566</th>\n",
       "      <td>111604</td>\n",
       "      <td>B00KJGFGFO</td>\n",
       "      <td>Curry Brush with Coarse or Fine Bristles. High...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A1FQ3HRVXA4A5B</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great product to use on your pets knowing this...</td>\n",
       "      <td>2014-07-11</td>\n",
       "      <td>great product use pet know gentle rubber damag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41567</th>\n",
       "      <td>111605</td>\n",
       "      <td>B00KJGFGFO</td>\n",
       "      <td>Curry Brush with Coarse or Fine Bristles. High...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A3OP6CI0XCRQXO</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I bought a second one because I have two cats ...</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>buy second cat american short hair buy brush m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41568</th>\n",
       "      <td>111606</td>\n",
       "      <td>B00KJGFGFO</td>\n",
       "      <td>Curry Brush with Coarse or Fine Bristles. High...</td>\n",
       "      <td>[]</td>\n",
       "      <td>A11LC938XF35XN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Our dogs love getting brushed with this.  It m...</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>dog love brush massage remove heavy undercoat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        index        asin                                              title  \\\n",
       "0           1  1223000893    Cat Sitter DVD Trilogy - Vol 1, Vol 2 and Vol 3   \n",
       "1         104  B00005MF9V     LitterMaid Universal Cat Privacy Tent (LMT100)   \n",
       "2         133  B00005MF9T              LitterMaid LM500 Automated Litter Box   \n",
       "3         153  B00005MF9W  LitterMaid Waste Receptacles Automatic Litter ...   \n",
       "4         154  B00005MF9W  LitterMaid Waste Receptacles Automatic Litter ...   \n",
       "41564  111601  B00KJGFGFO  Curry Brush with Coarse or Fine Bristles. High...   \n",
       "41565  111603  B00KJGFGFO  Curry Brush with Coarse or Fine Bristles. High...   \n",
       "41566  111604  B00KJGFGFO  Curry Brush with Coarse or Fine Bristles. High...   \n",
       "41567  111605  B00KJGFGFO  Curry Brush with Coarse or Fine Bristles. High...   \n",
       "41568  111606  B00KJGFGFO  Curry Brush with Coarse or Fine Bristles. High...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0                                                     []  A39QHP5WLON5HV   \n",
       "1      ['Pet Supplies', 'Cats', 'Litter & Housebreaki...  A366V0GCEPH5CX   \n",
       "2      ['Pet Supplies', 'Cats', 'Litter & Housebreaki...   ALWWS8QBYN80B   \n",
       "3      ['Pet Supplies', 'Cats', 'Litter & Housebreaki...  A3PVI3NE7OY1SP   \n",
       "4      ['Pet Supplies', 'Cats', 'Litter & Housebreaki...  A2H83XMHUVDLJY   \n",
       "41564                                                 []   AV34KNYW82YSS   \n",
       "41565                                                 []  A1YMNTFLNDYQ1F   \n",
       "41566                                                 []  A1FQ3HRVXA4A5B   \n",
       "41567                                                 []  A3OP6CI0XCRQXO   \n",
       "41568                                                 []  A11LC938XF35XN   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          5.0  There are usually one or more of my cats watch...  2013-09-14   \n",
       "1          5.0  My cats love it and so do I. I no longer have ...  2013-02-02   \n",
       "2          1.0  I have one female cat that weighs under 10 pou...  2004-11-17   \n",
       "3          5.0  I love these. They make the clean up so much e...  2013-09-26   \n",
       "4          4.0  I love this litter box. I do not use the lids,...  2014-06-26   \n",
       "41564      4.0  Pulled lots of hair out of my Labs coat. Didn'...  2014-07-18   \n",
       "41565      5.0  I have been trying to find a rubber bristle br...  2014-07-16   \n",
       "41566      5.0  Great product to use on your pets knowing this...  2014-07-11   \n",
       "41567      5.0  I bought a second one because I have two cats ...  2014-07-22   \n",
       "41568      5.0  Our dogs love getting brushed with this.  It m...  2014-07-17   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      usually cat watch tv stay trouble dvd play lik...  \n",
       "1      cat love longer cat litter fly floor litter fl...  \n",
       "2      female cat weigh pound year old use everclean ...  \n",
       "3      love clean easy clean box manually use issue w...  \n",
       "4      love litter box use lid use receptacle tear cr...  \n",
       "41564  pulled lot hair labs coat think prove wrong co...  \n",
       "41565  try rubber bristle brush persian year lose glo...  \n",
       "41566  great product use pet know gentle rubber damag...  \n",
       "41567  buy second cat american short hair buy brush m...  \n",
       "41568  dog love brush massage remove heavy undercoat ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")\n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc34f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating test history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b19cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  reviewerID                                  asin\n",
      "0      A04173782GDZSQ91AJ7OD              [B0090Z9AYS, B00CPDWT2M]\n",
      "1      A042274212BJJVOBS4Q85              [B005AZ4M3Q, B00771WQIY]\n",
      "2       A0436342QLT4257JODYJ  [B0018CDR68, B003SJTM8Q, B00474A3DY]\n",
      "3      A04795073FIBKY8GSLZYI              [B001PKT30M, B005DGI2RY]\n",
      "4      A06658082A27F4VB5UG8E              [B000TZ1TTM, B0019VUHH0]\n",
      "...                      ...                                   ...\n",
      "18993          AZYJE40XW6MFG              [B00HVAKJZS, B00IDZT294]\n",
      "18994          AZZ56WF4X19G2                          [B004A7X218]\n",
      "18995          AZZNK89PXD006  [B0002DHV16, B005BP8MQ8, B009RTX4SU]\n",
      "18996          AZZV9PDNMCOZW              [B007EQL390, B00ISBWVT6]\n",
      "18997          AZZYW4YOE1B6E  [B0002AQPA2, B0002AQPA2, B0002ARQV4]\n",
      "\n",
      "[18998 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_user_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d650855",
   "metadata": {},
   "source": [
    "# Preparing Dataset for Surprise's Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05afcd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "# generating trainset\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07343755",
   "metadata": {},
   "source": [
    "# Instantiate Pre-Initialised Matrix Factorization (Paragraph Vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd71b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating mod-ecf\n",
    "mod_ecf = cf.PreInitialisedMF(user_map=user_idx_map,\n",
    "                              item_map=item_idx_map,\n",
    "                              user_factor=user_factors,\n",
    "                              item_factor=item_factors,\n",
    "                              learning_rate=LR_ALL,\n",
    "                              beta=BETA,\n",
    "                              num_epochs=N_EPOCHS,\n",
    "                              num_factors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1eeabadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "CPU times: user 5min 38s, sys: 996 ms, total: 5min 39s\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fitting to training data\n",
    "mod_ecf.fit(trainset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa587004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.9 s, sys: 1.94 s, total: 46.8 s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate candidate items for user to predict rating\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8e539de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 3s, sys: 5min 35s, total: 17min 38s\n",
      "Wall time: 19min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "candidate_items = mod_ecf.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006c2beb",
   "metadata": {},
   "source": [
    "## Loop through N = {10, 25, 30, 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98c854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate item popularity\n",
    "item_popularity = generate_item_popularity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2caa53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92907537/92907537 [01:38<00:00, 939765.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19058/19058 [02:03<00:00, 154.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@10: 0.00912, average novelty@10: 0.94959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92907537/92907537 [01:57<00:00, 793229.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19058/19058 [01:05<00:00, 292.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@25: 0.01850, average novelty@25: 0.95902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92907537/92907537 [02:05<00:00, 739274.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19058/19058 [01:13<00:00, 258.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@30: 0.02161, average novelty@30: 0.96069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 92907537/92907537 [01:56<00:00, 795803.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 19058/19058 [01:13<00:00, 260.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MOD-ECF has an average recall@45: 0.02921, average novelty@45: 0.96408\n"
     ]
    }
   ],
   "source": [
    "n_recommendations = {}\n",
    "for n in [10, 25, 30, 45]:\n",
    "    # retrieve the top-n items based on similarities\n",
    "    top_ns = get_top_n(candidate_items, n)\n",
    "    # evaluate how well the recommended items predicted the future purchases\n",
    "    n_recommended_items = evaluate_recommendations(top_ns, test_user_history, item_popularity, n)\n",
    "    # saving the n-value and recommended items\n",
    "    n_recommendations[n] = (top_ns, n_recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e73163",
   "metadata": {},
   "source": [
    "# Evaluate N-Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9262bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_recommendations(train: pd.DataFrame, top_ns: dict):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # generating a random user\n",
    "    random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "    print(f\"For user: {random_user}:\")\n",
    "    print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "    # find the recommendations\n",
    "    print(f\"\\nRecommending:\\n\")\n",
    "    recommendations = (train[train['asin']\n",
    "                             .isin([i[0] for i in top_ns[random_user]])][['asin', 'title']]\n",
    "                       .drop_duplicates(subset='asin')\n",
    "                       .set_index('asin'))\n",
    "    print(f\"{recommendations.loc[[i[0] for i in top_ns[random_user]]].reset_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e36de",
   "metadata": {},
   "source": [
    "## N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e86fdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A567QYRZ56S3N:\n",
      "Purchase History:\n",
      "             asin                                          title\n",
      "27728  B0006JKCN0          KONG Frog Dog Toy, Extra Small, Green\n",
      "62945  B0057XF9R4  Catit Design Senses Illuminated Ball - 2-Pack\n",
      "\n",
      "Recommending:\n",
      "\n",
      "         asin                                              title\n",
      "0  B000F4AVPA                                Chuckit! Ultra Ball\n",
      "1  B0017J8NDY  Mammoth Flossy Chews Cottonblend Color 5-Knot ...\n",
      "2  B00168OD80                   Coleman Pterodactyl Dino Dog Toy\n",
      "3  B000FWAP8A  GoCat Da Bird Rod and Feather Cat Toy, Handmad...\n",
      "4  B0014AOC68                                         Smart Ramp\n",
      "5  B000BART6M  Planet Dog Orbee Tuff Diamond Plate Dog Ball, ...\n",
      "6  B000K9JRH8  GoCat DaBird Feather Refill, Assorted Colors, ...\n",
      "7  B000OWXA4C  JW Pet Company Activitoy Disco Ball Small Bird...\n",
      "8  B004IN9NAS                Pet Studio Pine Frame Dog RampSteps\n",
      "9  B0002DGVY4  Herm Sprenger Pet Supply Imports Chrome Plated...\n"
     ]
    }
   ],
   "source": [
    "top_ns_10 = n_recommendations[10][0]\n",
    "retrieve_recommendations(train, top_ns_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca424cf6",
   "metadata": {},
   "source": [
    "## N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4522e6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: ASFQXOU7XHTDV:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "45197  B0016ZP4B8  PoochieBells Original Housetraining &amp; Pott...\n",
      "64474  B005VEWAN0  Dental Teeth Cleaning Chew Toys for Small Dogs...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B0002DHV16           Cat Dancer - Cat Charmer Wand Teaser Toy\n",
      "1   B0029NVJFQ  Whiskas Temptations Creamy Dairy Flavour Treat...\n",
      "2   B0002DGVY4  Herm Sprenger Pet Supply Imports Chrome Plated...\n",
      "3   B005799UUK                              Redbarn Bully Springs\n",
      "4   B000084F4T  Purina Pro Plan Focus Weight Management Chicke...\n",
      "5   B00025Z6Q6  Tetra TetraCichlid Balanced Diet Flakes Food f...\n",
      "6   B00008434T                Ticked Off Pets Tick Remover, White\n",
      "7   B00027466A                            Chuckit! Travel Dog Bed\n",
      "8   B000AAIAJS                             Vitakraft Rabbit Slims\n",
      "9   B0000AH3UK            Merrick Flossies Tendon Chews Pack of 5\n",
      "10  B001F0RQEW   Boss Pet - Prestige Dome Stake 21&quot; - Col...\n",
      "11  B00025YVG2                                            Wardley\n",
      "12  B007CREG3Q  Flexi Durabelt Retractable Belt Dog Leash, Lar...\n",
      "13  B00874BSGG  Pet Waste Disposal Bags - 1000 Dog Poop Pick U...\n",
      "14  B001IMN8GW  New Kitty Cat Fun Play Tunnel 4 Feet Long Pet ...\n",
      "15  B00028ZLD6                     Panacur Canine Dewormer 1 gram\n",
      "16  B0018CK0EU  Stella &amp; Chewy'S Freeze-Dried Dinner Patti...\n",
      "17  B006SO16N2  ZippyPaws Dog Poop Waste Pick-Up Bags with Han...\n",
      "18  B002GJGD86  SHERPA SPORT DUFFLE Dog Cat Animal Pet Carrier...\n",
      "19  B002ANA70I   Natural Balance L.I.D. Limited Ingredient Die...\n",
      "20  B0029NWW5W  Pedigree Little Champions 12 Pouch Variety Pac...\n",
      "21  B003O68ZH2  Petrageous Designs KaleidoROPE Dog Toy, 25&quo...\n",
      "22  B000O5DI3W     Greenies Pill Pocket Soft Dog Treats - Chicken\n",
      "23  B0002DJODE                      Vitakraft Chinchilla Cocktail\n",
      "24  B001G0NKVO  Purina Friskies Indoor Adult Wet Cat Food - (2...\n"
     ]
    }
   ],
   "source": [
    "top_ns_25 = n_recommendations[25][0]\n",
    "retrieve_recommendations(train, top_ns_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6bc5f",
   "metadata": {},
   "source": [
    "## N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02c52994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: AYVLWK24S0E8D:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "35458  B000GA75RK  33 Pack GRIDLOCK 24&rdquo; x 24&rdquo; Puppy D...\n",
      "35609  B000GDXHQ0  Handi-Drink Dog Water Bottle- 17 Oz - The Port...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B00008434T                Ticked Off Pets Tick Remover, White\n",
      "1   B006SO16N2  ZippyPaws Dog Poop Waste Pick-Up Bags with Han...\n",
      "2   B000NSGKYY                Litter Locker Refill Cartridge 5 pk\n",
      "3   B0002DHV16           Cat Dancer - Cat Charmer Wand Teaser Toy\n",
      "4   B006JRRRQI  IRIS Airtight Pet Food Container, 50-Pound, Cl...\n",
      "5   B003B3S3TS  EZwhelp 27&quot; x 32&quot; Machine Washable, ...\n",
      "6   B000PKSW5A  Precious Cat Dr. Elsey's Kitten Attract Scoopa...\n",
      "7   B00H7PY3JA  Petseer Pet Odor Eliminator and Stain Remover ...\n",
      "8   B000084F4T  Purina Pro Plan Focus Weight Management Chicke...\n",
      "9   B00027466A                            Chuckit! Travel Dog Bed\n",
      "10  B0002ASCQC                          Van Ness 2 Cup Food Scoop\n",
      "11  B00290K0C2                LitterLocker Refill Cartridge 10 pk\n",
      "12  B00025YVG2                                            Wardley\n",
      "13  B0029NVJFQ  Whiskas Temptations Creamy Dairy Flavour Treat...\n",
      "14  B001USEYOY  Kaytee Forti Diet Pro Health Rabbit Food For A...\n",
      "15  B00874BSGG  Pet Waste Disposal Bags - 1000 Dog Poop Pick U...\n",
      "16  B00025Z6Q6  Tetra TetraCichlid Balanced Diet Flakes Food f...\n",
      "17  B007Z8LBJE         LitterLocker 6-Pack Genie Refill Cartridge\n",
      "18  B000AAIAJS                             Vitakraft Rabbit Slims\n",
      "19  B002ANA70I   Natural Balance L.I.D. Limited Ingredient Die...\n",
      "20  B0002APQ70  Simple Solution Cat Stain and Odor Remover wit...\n",
      "21  B0002ASCD0  Van Ness. Heavyweight Jumbo Crock Dish, 106 Ounce\n",
      "22  B0002DHCHO                                            Nemex 2\n",
      "23  B003P9WU74  Royal Canin Dry Cat Food, Maine Coon 31 Formul...\n",
      "24  B0002AQPX4         JW Pet Company GripSoft Flea Comb for Dogs\n",
      "25  B00272AB76   Rinse Ace 3 Way Pet Shower Sprayer with 8 foo...\n",
      "26  B0029NWW5W  Pedigree Little Champions 12 Pouch Variety Pac...\n",
      "27  B002GJGD86  SHERPA SPORT DUFFLE Dog Cat Animal Pet Carrier...\n",
      "28  B00025YVH6                    Exclusively Pet Best Buddy Bits\n",
      "29  B000084DXS  Hill's Science Diet Puppy Chicken &amp; Barley...\n"
     ]
    }
   ],
   "source": [
    "top_ns_30 = n_recommendations[30][0]\n",
    "retrieve_recommendations(train, top_ns_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02489a59",
   "metadata": {},
   "source": [
    "## N=45"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a540dedc",
   "metadata": {},
   "source": [
    "top_ns_45 = n_recommendations[45][0]\n",
    "retrieve_recommendations(train, top_ns_45)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
