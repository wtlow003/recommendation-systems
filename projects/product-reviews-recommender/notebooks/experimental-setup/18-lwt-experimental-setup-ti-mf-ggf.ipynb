{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8989ccfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models import cf\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6b5b6",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10702db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = \"data/evaluation\"\n",
    "CATEGORY = \"Grocery_and_Gourmet_Food\"\n",
    "\n",
    "# training parameters\n",
    "N_EPOCHS = 10\n",
    "LR_ALL = 0.005\n",
    "BETA = 0.1\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b501eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A23RYWDS884TUL</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This curry paste makes a delicious curry.  I j...</td>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>curry paste delicious curry fry chicken vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A945RBQWGZXCK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've purchased different curries in the grocer...</td>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>purchase different curry grocery store complet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3AMNY44OP8AOU</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I started a new diet restricting all added sug...</td>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>start new diet restrict added sugar brand suga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A3IB4CQ2QEJLJ8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>So many flavors. I can't begin to tell you how...</td>\n",
       "      <td>2014-04-27</td>\n",
       "      <td>flavor begin tell love mae ploy curry ask reci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>AQA5DF3RWKETQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've used this a lot recently in some of my ch...</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>use lot recently chicken dish use lot like spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47769</th>\n",
       "      <td>77420</td>\n",
       "      <td>B00I33696K</td>\n",
       "      <td>Reese's Miniature Peanut Butter Cups .31oz - 1...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Candy &amp; Chocolate'...</td>\n",
       "      <td>A192LQZWDYPR4U</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Another quality Reese Peanut Butter Cup produc...</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>quality reese peanut butter cup product great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47770</th>\n",
       "      <td>77421</td>\n",
       "      <td>B00I33696K</td>\n",
       "      <td>Reese's Miniature Peanut Butter Cups .31oz - 1...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Candy &amp; Chocolate'...</td>\n",
       "      <td>A2QKXW3LDQ66P5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I purchased these for my husband who has every...</td>\n",
       "      <td>2013-02-20</td>\n",
       "      <td>purchase husband love reeses valentine day pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47771</th>\n",
       "      <td>77430</td>\n",
       "      <td>B00ID9VSOM</td>\n",
       "      <td>Viva Labs Organic Coconut Sugar: Non-GMO, Low-...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A2P3TGJU301KXD</td>\n",
       "      <td>5.0</td>\n",
       "      <td>this stuff is INCREDIBILY yummy! SO much bette...</td>\n",
       "      <td>2014-07-15</td>\n",
       "      <td>stuff incredibily yummy good regular brown sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47772</th>\n",
       "      <td>77456</td>\n",
       "      <td>B00IRL93SY</td>\n",
       "      <td>Barrie House Kenya Estate - AA Single Cup Caps...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Beverages', 'Coffe...</td>\n",
       "      <td>AEFE9VDHTQ199</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Very nice aroma, body and taste! Will buy this...</td>\n",
       "      <td>2014-05-24</td>\n",
       "      <td>nice aroma body taste buy coffee good coffee a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47773</th>\n",
       "      <td>77508</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A2AEZQ3DGBBLPR</td>\n",
       "      <td>2.0</td>\n",
       "      <td>This is a no go for diabetics according to my ...</td>\n",
       "      <td>2014-06-26</td>\n",
       "      <td>diabetic accord wife doctor order intention us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        asin                                              title  \\\n",
       "0          0  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1          1  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2          3  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "3          4  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "4          5  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "47769  77420  B00I33696K  Reese's Miniature Peanut Butter Cups .31oz - 1...   \n",
       "47770  77421  B00I33696K  Reese's Miniature Peanut Butter Cups .31oz - 1...   \n",
       "47771  77430  B00ID9VSOM  Viva Labs Organic Coconut Sugar: Non-GMO, Low-...   \n",
       "47772  77456  B00IRL93SY  Barrie House Kenya Estate - AA Single Cup Caps...   \n",
       "47773  77508  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A23RYWDS884TUL   \n",
       "1      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   A945RBQWGZXCK   \n",
       "2      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3AMNY44OP8AOU   \n",
       "3      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A3IB4CQ2QEJLJ8   \n",
       "4      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...   AQA5DF3RWKETQ   \n",
       "47769  ['Grocery & Gourmet Food', 'Candy & Chocolate'...  A192LQZWDYPR4U   \n",
       "47770  ['Grocery & Gourmet Food', 'Candy & Chocolate'...  A2QKXW3LDQ66P5   \n",
       "47771  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A2P3TGJU301KXD   \n",
       "47772  ['Grocery & Gourmet Food', 'Beverages', 'Coffe...   AEFE9VDHTQ199   \n",
       "47773  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A2AEZQ3DGBBLPR   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          5.0  This curry paste makes a delicious curry.  I j...  2013-05-28   \n",
       "1          5.0  I've purchased different curries in the grocer...  2012-09-17   \n",
       "2          4.0  I started a new diet restricting all added sug...  2014-01-23   \n",
       "3          5.0  So many flavors. I can't begin to tell you how...  2014-04-27   \n",
       "4          5.0  I've used this a lot recently in some of my ch...  2012-11-27   \n",
       "47769      5.0  Another quality Reese Peanut Butter Cup produc...  2014-02-27   \n",
       "47770      5.0  I purchased these for my husband who has every...  2013-02-20   \n",
       "47771      5.0  this stuff is INCREDIBILY yummy! SO much bette...  2014-07-15   \n",
       "47772      5.0  Very nice aroma, body and taste! Will buy this...  2014-05-24   \n",
       "47773      2.0  This is a no go for diabetics according to my ...  2014-06-26   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      curry paste delicious curry fry chicken vegeta...  \n",
       "1      purchase different curry grocery store complet...  \n",
       "2      start new diet restrict added sugar brand suga...  \n",
       "3      flavor begin tell love mae ploy curry ask reci...  \n",
       "4      use lot recently chicken dish use lot like spi...  \n",
       "47769  quality reese peanut butter cup product great ...  \n",
       "47770  purchase husband love reeses valentine day pre...  \n",
       "47771  stuff incredibily yummy good regular brown sug...  \n",
       "47772  nice aroma body taste buy coffee good coffee a...  \n",
       "47773  diabetic accord wife doctor order intention us...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking train dataframe\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7cc66e",
   "metadata": {},
   "source": [
    "# Preparing Topic Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5481e594",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        self.lda = None\n",
    "        self.dictionary = None\n",
    "\n",
    "    def train(self, n_topics=50, n_epochs=20, workers=8):\n",
    "        # tokenizations\n",
    "        dictionary = gensim.corpora.Dictionary(self.reviews)\n",
    "        # filtering tokens less than 5 reviews, more than 0.85 reviews\n",
    "        dictionary.filter_extremes(no_below=5, no_above=0.85)\n",
    "        # creating dict how many words and time it appears\n",
    "        bow_corpus = [dictionary.doc2bow(doc) for doc in self.reviews]\n",
    "        \n",
    "        # train model\n",
    "        self.lda = gensim.models.LdaMulticore(bow_corpus, \n",
    "                                              num_topics=n_topics, \n",
    "                                              id2word=dictionary, \n",
    "                                              passes=n_epochs,\n",
    "                                              workers=workers)\n",
    "        # save dictionary\n",
    "        self.dictionary = dictionary\n",
    "        \n",
    "    def get_document_topics(self, doc, minimum_probability=0.0):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        return self.lda.get_document_topics(doc, minimum_probability=minimum_probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df05785c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47774/47774 [00:00<00:00, 171945.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# generating tokenized reviews\n",
    "processed_reviews = train[\"processedReviewText\"].progress_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928d28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate lda model\n",
    "lda_model = LDA(processed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b80e17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/Users/jensen/Desktop/recommendation-systems/projects/product-reviews-recommender/.venv/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 50s, sys: 18.3 s, total: 3min 8s\n",
      "Wall time: 2min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training the LDA model\n",
    "lda_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53537751",
   "metadata": {},
   "source": [
    "# Generating User/Item Topic Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c660a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_vectors(model, corpus, n_topics=50):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    topic_vecs = []\n",
    "    for i in tqdm(range(len(corpus))):\n",
    "        top_topics = model.get_document_topics(corpus[i])\n",
    "        topic_vecs.append([top_topics[i][1] for i in range(n_topics)])\n",
    "        \n",
    "    return topic_vecs\n",
    "\n",
    "def generate_user_item_vectors(lda: LDA, train: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    user_reviews = train.groupby([\"reviewerID\"])['processedReviewText'].apply(lambda x: ' '.join(x))\n",
    "    item_reviews = train.groupby([\"asin\"])[\"processedReviewText\"].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    # get unique users and items\n",
    "    unique_users = user_reviews.index.tolist()\n",
    "    unique_items = item_reviews.index.tolist()\n",
    "    \n",
    "    # tokenize reviews\n",
    "    user_reviews_list = user_reviews.apply(lambda x: x.split()).tolist()\n",
    "    item_reviews_list = item_reviews.apply(lambda x: x.split()).tolist()\n",
    "    \n",
    "    # generate corpus based on aggregate of user/item reviews\n",
    "    user_corpus = [lda.dictionary.doc2bow(doc) for doc in user_reviews_list]\n",
    "    item_corpus = [lda.dictionary.doc2bow(doc) for doc in item_reviews_list]\n",
    "    \n",
    "    # retrieve user and item topics vectors\n",
    "    user_vecs = get_topic_vectors(lda, user_corpus)\n",
    "    item_vecs = get_topic_vectors(lda, item_corpus)\n",
    "    \n",
    "    # generate a mapping \n",
    "    user_idx_map = {k: unique_users[k] for k in range(len(unique_users))}\n",
    "    item_idx_map = {k: unique_items[k] for k in range(len(unique_items))}\n",
    "    user_vec_map = {k: v for k, v in zip(unique_users, user_vecs)}\n",
    "    item_vec_map = {k: v for k, v in zip(unique_items, item_vecs)}\n",
    "    \n",
    "    # loading user topic vectors into DF\n",
    "    user_vecs = pd.DataFrame.from_dict(user_vec_map, orient='index')\n",
    "    user_vecs.index.name = 'reviewerID'\n",
    "    # loading item topic vectors into DF\n",
    "    item_vecs = pd.DataFrame.from_dict(item_vec_map, orient='index')\n",
    "    item_vecs.index.name = 'asin'\n",
    "    \n",
    "    return user_idx_map, user_vecs, item_idx_map, item_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e0d386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:09<00:00, 1417.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4729/4729 [00:04<00:00, 975.66it/s]\n"
     ]
    }
   ],
   "source": [
    "user_idx_map, user_vecs, item_idx_map, item_vecs = generate_user_item_vectors(lda_model, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9bebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting factors into numpy obj\n",
    "user_factors = user_vecs.to_numpy()\n",
    "item_factors = item_vecs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "549515a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.14620695, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.00133466, 0.09169909, 0.00133466, 0.57021385, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.13048595, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466,\n",
       "       0.00133466, 0.00133466, 0.00133466, 0.00133466, 0.00133466],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check user factors\n",
    "user_factors[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d06c7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.4094846e-05, 4.4094846e-05, 4.8933003e-02, 7.1832053e-02,\n",
       "       8.0743708e-02, 4.4094846e-05, 4.4094846e-05, 4.4094846e-05,\n",
       "       1.0947618e-01, 4.4094846e-05, 3.5948649e-02, 4.4094846e-05,\n",
       "       4.4094846e-05, 1.8174406e-02, 4.4094846e-05, 2.4109175e-02,\n",
       "       4.4094846e-05, 4.2666155e-03, 1.6192118e-02, 4.4094846e-05,\n",
       "       1.1335680e-02, 4.4094846e-05, 4.4094846e-05, 4.4094846e-05,\n",
       "       4.4094846e-05, 4.4094846e-05, 4.4094846e-05, 4.4094846e-05,\n",
       "       4.4094846e-05, 4.4094846e-05, 4.4094846e-05, 4.4094846e-05,\n",
       "       4.4094846e-05, 4.4094846e-05, 4.8612170e-02, 3.6693811e-01,\n",
       "       4.4094846e-05, 4.4094846e-05, 4.4094846e-05, 4.4094846e-05,\n",
       "       4.4094846e-05, 7.4354723e-02, 4.4094846e-05, 4.4094846e-05,\n",
       "       1.8433521e-02, 4.4094846e-05, 5.2157536e-02, 1.0093035e-02,\n",
       "       4.4094846e-05, 6.9441656e-03], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check item factors\n",
    "item_factors[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94084615",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57666372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in tqdm(predictions):\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in tqdm(top_n.items()):\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k\n",
    "\n",
    "def novelty_at_k(item_popularity, predicted_asins, k=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # finding avg novelty\n",
    "    popularity_sum = item_popularity.loc[predicted_asins].sum()\n",
    "    novelty_at_k = ((k*1) - popularity_sum) / k\n",
    "    \n",
    "    return novelty_at_k\n",
    "\n",
    "def generate_item_popularity(train: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # create a mapping of item popularatity\n",
    "    # based on sum(item's review / max reviews) / no items\n",
    "    max_reviews = (train.groupby(['asin'])\n",
    "                   .agg({'processedReviewText': 'count'})\n",
    "                   .max()\n",
    "                   .values[0])\n",
    "    item_popularity = (train.groupby(['asin'])\n",
    "                       .agg({'processedReviewText': 'count'})\n",
    "                       .apply(lambda x: x/max_reviews))\n",
    "    \n",
    "    return item_popularity\n",
    "    \n",
    "\n",
    "def evaluate_recommendations(top_ns: dict, user_rating_history: pd.DataFrame, item_popularity: pd.DataFrame, k=10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        top_ns\n",
    "        user_rating_history\n",
    "    \"\"\"\n",
    "    \n",
    "    test_recommendations = pd.DataFrame(top_ns.items(), columns=[\"reviewerID\", \"pred_asin\"])\n",
    "    test_recommendations['pred_asin'] = test_recommendations['pred_asin'].apply(lambda x: [i[0] for i in x])\n",
    "    \n",
    "    # combined test history and recommendations\n",
    "    test_merged = pd.merge(user_rating_history, test_recommendations, on=\"reviewerID\", how=\"inner\")\n",
    "    \n",
    "    # generating recall@k metrics\n",
    "    test_merged[\"recall@k\"] = test_merged.apply(lambda x: recall_at_k(x.asin, x.pred_asin, k=k), axis=1)\n",
    "    test_merged[\"novelty@k\"] = test_merged.apply(lambda x: novelty_at_k(item_popularity, x.pred_asin, k=k), axis=1)\n",
    "    average_recall_at_k = test_merged[\"recall@k\"].mean()\n",
    "    average_novelty_at_k = test_merged[\"novelty@k\"].mean()\n",
    "    \n",
    "    print(f\"The TI-MF has an average recall@{k}: {average_recall_at_k:.5f}, average novelty@{k}: {average_novelty_at_k:.5f}\")\n",
    "    \n",
    "    return test_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea420a3f",
   "metadata": {},
   "source": [
    "# Generate N-Recommendations = {10, 25, 30, 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057aa77f",
   "metadata": {},
   "source": [
    "## Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c2f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c8e1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A1TCSC0YWT82Q0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love ethnic foods and to cook them. I recent...</td>\n",
       "      <td>2013-08-03</td>\n",
       "      <td>love ethnic food cook recently purchase produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>9742356831</td>\n",
       "      <td>Mae Ploy Green Curry Paste, 14 oz</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Sauces, Gravies &amp; ...</td>\n",
       "      <td>A1Z7Y2GMAP9SRY</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I like to make my own curry but this is a tast...</td>\n",
       "      <td>2014-06-27</td>\n",
       "      <td>like curry tasty alternative use base kind dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>B00004S1C5</td>\n",
       "      <td>Ateco Food Coloring Kit, 6 colors</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A14YSMLYLJEMET</td>\n",
       "      <td>1.0</td>\n",
       "      <td>This product is no where near natural / organi...</td>\n",
       "      <td>2013-03-29</td>\n",
       "      <td>product near natural organic wish review purch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>B00005344V</td>\n",
       "      <td>Traditional Medicinals Organic Breathe Easy Se...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Beverages', 'Coffe...</td>\n",
       "      <td>A2F488C4PLWGEI</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If my wife drinks a cup of this tea when she f...</td>\n",
       "      <td>2014-03-23</td>\n",
       "      <td>wife drink cup tea feel attack come help avoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>B00005344V</td>\n",
       "      <td>Traditional Medicinals Organic Breathe Easy Se...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Beverages', 'Coffe...</td>\n",
       "      <td>AO1HXV7DWZZIR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I don't know about the medicinal aspects of th...</td>\n",
       "      <td>2014-02-06</td>\n",
       "      <td>know medicinal aspect tea flavor downright scr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28001</th>\n",
       "      <td>77519</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A1WT3TVHANP7ZF</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Hmmm. I really wanted to love this sweetener. ...</td>\n",
       "      <td>2014-07-22</td>\n",
       "      <td>hmmm want love sweetener half sugar half stevi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28002</th>\n",
       "      <td>77520</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A3NEAETOSXDBOM</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I confess I have a sweet tooth, and love the t...</td>\n",
       "      <td>2014-06-30</td>\n",
       "      <td>confess sweet tooth love taste sugar recognize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28003</th>\n",
       "      <td>77521</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>AD1ZOPB0BBEHB</td>\n",
       "      <td>4.0</td>\n",
       "      <td>It has a little of the stevia aftertaste, but ...</td>\n",
       "      <td>2014-07-17</td>\n",
       "      <td>little stevia aftertaste fair compromise able ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28004</th>\n",
       "      <td>77522</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A18ECVX2RJ7HUE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>i love marinade for grilled flank steak or lon...</td>\n",
       "      <td>2014-05-30</td>\n",
       "      <td>love marinade grilled flank steak london broil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28005</th>\n",
       "      <td>77523</td>\n",
       "      <td>B00ISVHJ3Y</td>\n",
       "      <td>Wholesome Sweeteners, Organic Sweet and Lite S...</td>\n",
       "      <td>['Grocery &amp; Gourmet Food', 'Cooking &amp; Baking',...</td>\n",
       "      <td>A2G04D4QZAXL15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I've been using Truvia (a form of stevia) on m...</td>\n",
       "      <td>2014-05-27</td>\n",
       "      <td>use truvia form stevia cereal greek yogurt yea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index        asin                                              title  \\\n",
       "0          2  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "1          8  9742356831                  Mae Ploy Green Curry Paste, 14 oz   \n",
       "2         23  B00004S1C5                  Ateco Food Coloring Kit, 6 colors   \n",
       "3         31  B00005344V  Traditional Medicinals Organic Breathe Easy Se...   \n",
       "4         32  B00005344V  Traditional Medicinals Organic Breathe Easy Se...   \n",
       "28001  77519  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28002  77520  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28003  77521  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28004  77522  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "28005  77523  B00ISVHJ3Y  Wholesome Sweeteners, Organic Sweet and Lite S...   \n",
       "\n",
       "                                              categories      reviewerID  \\\n",
       "0      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A1TCSC0YWT82Q0   \n",
       "1      ['Grocery & Gourmet Food', 'Sauces, Gravies & ...  A1Z7Y2GMAP9SRY   \n",
       "2      ['Grocery & Gourmet Food', 'Cooking & Baking',...  A14YSMLYLJEMET   \n",
       "3      ['Grocery & Gourmet Food', 'Beverages', 'Coffe...  A2F488C4PLWGEI   \n",
       "4      ['Grocery & Gourmet Food', 'Beverages', 'Coffe...   AO1HXV7DWZZIR   \n",
       "28001  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A1WT3TVHANP7ZF   \n",
       "28002  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A3NEAETOSXDBOM   \n",
       "28003  ['Grocery & Gourmet Food', 'Cooking & Baking',...   AD1ZOPB0BBEHB   \n",
       "28004  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A18ECVX2RJ7HUE   \n",
       "28005  ['Grocery & Gourmet Food', 'Cooking & Baking',...  A2G04D4QZAXL15   \n",
       "\n",
       "       overall                                         reviewText  reviewTime  \\\n",
       "0          5.0  I love ethnic foods and to cook them. I recent...  2013-08-03   \n",
       "1          5.0  I like to make my own curry but this is a tast...  2014-06-27   \n",
       "2          1.0  This product is no where near natural / organi...  2013-03-29   \n",
       "3          5.0  If my wife drinks a cup of this tea when she f...  2014-03-23   \n",
       "4          5.0  I don't know about the medicinal aspects of th...  2014-02-06   \n",
       "28001      3.0  Hmmm. I really wanted to love this sweetener. ...  2014-07-22   \n",
       "28002      5.0  I confess I have a sweet tooth, and love the t...  2014-06-30   \n",
       "28003      4.0  It has a little of the stevia aftertaste, but ...  2014-07-17   \n",
       "28004      5.0  i love marinade for grilled flank steak or lon...  2014-05-30   \n",
       "28005      3.0  I've been using Truvia (a form of stevia) on m...  2014-05-27   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      love ethnic food cook recently purchase produc...  \n",
       "1      like curry tasty alternative use base kind dif...  \n",
       "2      product near natural organic wish review purch...  \n",
       "3      wife drink cup tea feel attack come help avoid...  \n",
       "4      know medicinal aspect tea flavor downright scr...  \n",
       "28001  hmmm want love sweetener half sugar half stevi...  \n",
       "28002  confess sweet tooth love taste sugar recognize...  \n",
       "28003  little stevia aftertaste fair compromise able ...  \n",
       "28004  love marinade grilled flank steak london broil...  \n",
       "28005  use truvia form stevia cereal greek yogurt yea...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fea6fb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating test history\n",
    "test_user_history = (pd.DataFrame(test.groupby(['reviewerID'])['asin']\n",
    "                                  .apply(list).reset_index()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9b316c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  reviewerID  \\\n",
      "0      A00177463W0XWB16A9O05   \n",
      "1      A022899328A0QROR32DCT   \n",
      "2      A068255029AHTHDXZURNU   \n",
      "3      A06944662TFWOKKV4GJKX   \n",
      "4             A1004703RC79J9   \n",
      "...                      ...   \n",
      "13274          AZWRZZAMX90VT   \n",
      "13275          AZXKAH2DE6C8A   \n",
      "13276          AZXON596A1VXC   \n",
      "13277          AZYXC63SS008M   \n",
      "13278          AZZ5ASC403N74   \n",
      "\n",
      "                                                    asin  \n",
      "0                               [B00474OR8G, B00BFM6OAW]  \n",
      "1                                           [B00CMQDKES]  \n",
      "2                                           [B001FA1K2G]  \n",
      "3                                           [B000GFYRHG]  \n",
      "4                                           [B003GTR8IO]  \n",
      "...                                                  ...  \n",
      "13274  [B0007R9L4M, B000CN7BMA, B001EQ5D1K, B002VT3GX...  \n",
      "13275   [B000MAK41I, B004X8TJP2, B006H34CUS, B007W14RMM]  \n",
      "13276                           [B001EO5S0I, B00271QQ7Q]  \n",
      "13277                                       [B0054TWPNC]  \n",
      "13278                                       [B00BIEU5PC]  \n",
      "\n",
      "[13279 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_user_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74b499",
   "metadata": {},
   "source": [
    "# Preparing Dataset for Surprise's Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22d9e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reader\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "# generate data required for surprise\n",
    "data = Dataset.load_from_df(train[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "# generating trainset\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c289d",
   "metadata": {},
   "source": [
    "# Instantiate Pre-Initialised Matrix Factorization (Topic Modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f59e06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating ti_mf\n",
    "ti_mf = cf.PreInitialisedMF(user_map=user_idx_map,\n",
    "                            item_map=item_idx_map,\n",
    "                            user_factor=user_factors,\n",
    "                            item_factor=item_factors,\n",
    "                            learning_rate=LR_ALL,\n",
    "                            beta=BETA,\n",
    "                            num_epochs=N_EPOCHS,\n",
    "                            num_factors=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc866db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "CPU times: user 3min 59s, sys: 866 ms, total: 4min\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fitting to training data\n",
    "ti_mf.fit(trainset, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab9b930d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.1 s, sys: 1.58 s, total: 33.7 s\n",
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate candidate items for user to predict rating\n",
    "testset = trainset.build_anti_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5a239a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 45s, sys: 1min 19s, total: 9min 5s\n",
      "Wall time: 9min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# predict ratings for all pairs (u, i) that are NOT in the training set\n",
    "candidate_items = ti_mf.test(testset, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773e39b0",
   "metadata": {},
   "source": [
    "## Loop through N = {10, 25, 30, 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74a1d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate item popularity\n",
    "item_popularity = generate_item_popularity(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cdfce793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [00:39<00:00, 1617340.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:39<00:00, 337.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TI-MF has an average recall@10: 0.01268, average novelty@10: 0.90050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [01:05<00:00, 968861.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:40<00:00, 327.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TI-MF has an average recall@25: 0.01994, average novelty@25: 0.92528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [01:08<00:00, 920533.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:41<00:00, 323.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TI-MF has an average recall@30: 0.02180, average novelty@30: 0.93025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63307346/63307346 [01:06<00:00, 949836.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13397/13397 [00:38<00:00, 349.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TI-MF has an average recall@45: 0.02647, average novelty@45: 0.93792\n"
     ]
    }
   ],
   "source": [
    "n_recommendations = {}\n",
    "for n in [10, 25, 30, 45]:\n",
    "    # retrieve the top-n items based on similarities\n",
    "    top_ns = get_top_n(candidate_items, n)\n",
    "    # evaluate how well the recommended items predicted the future purchases\n",
    "    n_recommended_items = evaluate_recommendations(top_ns, test_user_history, item_popularity, n)\n",
    "    # saving the n-value and recommended items\n",
    "    n_recommendations[n] = (top_ns, n_recommended_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733a392d",
   "metadata": {},
   "source": [
    "# Evaluate N-Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ff283a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_recommendations(train: pd.DataFrame, top_ns: dict):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # generating a random user\n",
    "    random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "    print(f\"For user: {random_user}:\")\n",
    "    print(f\"Purchase History:\\n{train[train['reviewerID'] == random_user][['asin', 'title']]}\")\n",
    "\n",
    "    # find the recommendations\n",
    "    print(f\"\\nRecommending:\\n\")\n",
    "    recommendations = (train[train['asin']\n",
    "                             .isin([i[0] for i in top_ns[random_user]])][['asin', 'title']]\n",
    "                       .drop_duplicates(subset='asin')\n",
    "                       .set_index('asin'))\n",
    "    print(f\"{recommendations.loc[[i[0] for i in top_ns[random_user]]].reset_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e936d5be",
   "metadata": {},
   "source": [
    "## N=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a97ac0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A26NSWOAKB86LM:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "34174  B00473SRCY  Kona Coast Macadamia Nut Pancake Mix, 24-Ounce...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "         asin                                              title\n",
      "0  B000EDBPO8  Bob's Red Mill White Rice Flour, Organic, 24-O...\n",
      "1  B000EDG4V2       Bob's Red Mill Guar Gum, 8 Ounce (Case of 8)\n",
      "2  B000G82L62  Lundberg Family Farms Wild Blend Rice, 16 Ounc...\n",
      "3  B001PEWJWC  Garbanzo Beans aka Chickpeas or Ceci Beans | N...\n",
      "4  B00DS842HS  Viva Naturals Organic Extra Virgin Coconut Oil...\n",
      "5  B0001M0Z6Q  Spicy World Peppercorn (Whole)-Black Tellicher...\n",
      "6  B00014JNI0  YS Organic Bee Farms CERTIFIED ORGANIC RAW HON...\n",
      "7  B003OGKCDC  Nature's Way Organic Extra Virgin Coconut Oil-...\n",
      "8  B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "9  B00338DSQ4      Barilla Spaghetti Pasta, 32 Ounce (Pack of 6)\n"
     ]
    }
   ],
   "source": [
    "top_ns_10 = n_recommendations[10][0]\n",
    "retrieve_recommendations(train, top_ns_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc28d45",
   "metadata": {},
   "source": [
    "## N=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad7a350d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A28703KGCS8P2P:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "31250  B003AYEHIO  Starwest Botanicals Organic Dried Lavender Flo...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B000EDG4V2       Bob's Red Mill Guar Gum, 8 Ounce (Case of 8)\n",
      "1   B00DS842HS  Viva Naturals Organic Extra Virgin Coconut Oil...\n",
      "2   B000EDBPO8  Bob's Red Mill White Rice Flour, Organic, 24-O...\n",
      "3   B0001M0Z6Q  Spicy World Peppercorn (Whole)-Black Tellicher...\n",
      "4   B001PEWJWC  Garbanzo Beans aka Chickpeas or Ceci Beans | N...\n",
      "5   B000G82L62  Lundberg Family Farms Wild Blend Rice, 16 Ounc...\n",
      "6   B003OGKCDC  Nature's Way Organic Extra Virgin Coconut Oil-...\n",
      "7   B00014JNI0  YS Organic Bee Farms CERTIFIED ORGANIC RAW HON...\n",
      "8   B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "9   B000JMAXMY                   Mustard Seeds 7oz by Spicy World\n",
      "10  B000Z93FQC               Y.S. Eco Bee Farms Raw Honey - 22 oz\n",
      "11  B000HDK0DC  YumEarth Organic Lollipops, Assorted Flavors, ...\n",
      "12  B005C3IVME     Anderson's Pure Maple Syrup, Grade A, 32-Ounce\n",
      "13  B00271QQ7Q  Coombs Family Farms 100% Pure Organic Maple Sy...\n",
      "14  B00271OPVU   Coombs Family Farms Maple Syrup, Organic, Gra...\n",
      "15  B000S8593W           Nutiva Hempseeds, Shelled, Pouch 8.00 OZ\n",
      "16  B00338DSQ4      Barilla Spaghetti Pasta, 32 Ounce (Pack of 6)\n",
      "17  B0029JHHO2  Ricochet Candies with Xylitol, Grape Escape, 1...\n",
      "18  B001E5E056  Kashi Heart to Heart Oat Flakes and Blueberry ...\n",
      "19  B0001CXUH2                            Egg White Powder, 8 oz.\n",
      "20  B005C3IVN8  Anderson's Pure Maple Syrup, Grade A Very Dark...\n",
      "21  B001VNEHXG  Frontier Co-op Organic White Onion Powder, 2 1...\n",
      "22  B000HDJXH6  Enjoy Life Chewy Bars, Soy free, Nut free, Glu...\n",
      "23  B001O1Q0NA  The Spice Lab Pink Himalayan Salt - 1 Pound X-...\n",
      "24  B001E5DZJS   Rapunzel Pure Vegan Vegetable Bouillon, No Sa...\n"
     ]
    }
   ],
   "source": [
    "top_ns_25 = n_recommendations[25][0]\n",
    "retrieve_recommendations(train, top_ns_25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc3b85",
   "metadata": {},
   "source": [
    "## N=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db0a60a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A31SXZGGA9AGN2:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "42595  B006307HT8  Chef Paul Prudhomme's Magic Seasoning Blends N...\n",
      "46333  B00A64NLOM  WERTHER'S ORIGINAL Creamy Caramel Filled Hard ...\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B000EDG4V2       Bob's Red Mill Guar Gum, 8 Ounce (Case of 8)\n",
      "1   B00DS842HS  Viva Naturals Organic Extra Virgin Coconut Oil...\n",
      "2   B000EDBPO8  Bob's Red Mill White Rice Flour, Organic, 24-O...\n",
      "3   B0001M0Z6Q  Spicy World Peppercorn (Whole)-Black Tellicher...\n",
      "4   B001PEWJWC  Garbanzo Beans aka Chickpeas or Ceci Beans | N...\n",
      "5   B003OGKCDC  Nature's Way Organic Extra Virgin Coconut Oil-...\n",
      "6   B00014JNI0  YS Organic Bee Farms CERTIFIED ORGANIC RAW HON...\n",
      "7   B000G82L62  Lundberg Family Farms Wild Blend Rice, 16 Ounc...\n",
      "8   B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "9   B000HDK0DC  YumEarth Organic Lollipops, Assorted Flavors, ...\n",
      "10  B000Z93FQC               Y.S. Eco Bee Farms Raw Honey - 22 oz\n",
      "11  B000S8593W           Nutiva Hempseeds, Shelled, Pouch 8.00 OZ\n",
      "12  B000JMAXMY                   Mustard Seeds 7oz by Spicy World\n",
      "13  B000HDJXH6  Enjoy Life Chewy Bars, Soy free, Nut free, Glu...\n",
      "14  B0029JHHO2  Ricochet Candies with Xylitol, Grape Escape, 1...\n",
      "15  B001E5E056  Kashi Heart to Heart Oat Flakes and Blueberry ...\n",
      "16  B00338DSQ4      Barilla Spaghetti Pasta, 32 Ounce (Pack of 6)\n",
      "17  B0054TWPNC  NongShim Bowl Noodle Soup, Hot and Spicy, 3.03...\n",
      "18  B001O1Q0NA  The Spice Lab Pink Himalayan Salt - 1 Pound X-...\n",
      "19  B001E5DZJS   Rapunzel Pure Vegan Vegetable Bouillon, No Sa...\n",
      "20  B001VNEHXG  Frontier Co-op Organic White Onion Powder, 2 1...\n",
      "21  B00BJH59ZO  Gratify Gluten Free Sea Salt Sticks Pretzel, 1...\n",
      "22  B000WSK5N2  NOW Foods Certified Organic Golden Flax Seeds,...\n",
      "23  B0025UCGRS  Armour Vienna Sausages, 4.75-Ounce Cans(Pack o...\n",
      "24  B000HDJZEM  Season Black Capelin Caviar from Iceland, 3.5-...\n",
      "25  B001E50UEQ  Hormel Compleats Chicken &amp; Rice, 6-10-Ounc...\n",
      "26  B001EO5U3I                     Grocery &amp; Gourmet Food\" />\n",
      "27  B0029JASWA  Dove Dark Chocolate Promises, 9.5-Ounce Packag...\n",
      "28  B001SB8AZC  Wild Planet Wild Skipjack Tuna (Light Tuna), 5...\n",
      "29  B000EDBPP2  Bob's Red Mill Honey Almond Granola, 18 Ounce ...\n"
     ]
    }
   ],
   "source": [
    "top_ns_30 = n_recommendations[30][0]\n",
    "retrieve_recommendations(train, top_ns_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8f8f8",
   "metadata": {},
   "source": [
    "## N=45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8daf6f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user: A24XFXUCAMWP0D:\n",
      "Purchase History:\n",
      "             asin                                              title\n",
      "4834   B000EDG3UE  Bob's Red Mill Organic Grain Quinoa, 26 Ounce ...\n",
      "47038  B00BSD9C5M          Healthworks Goji Berries Raw Organic, 2lb\n",
      "\n",
      "Recommending:\n",
      "\n",
      "          asin                                              title\n",
      "0   B0001M0Z6Q  Spicy World Peppercorn (Whole)-Black Tellicher...\n",
      "1   B000EDG4V2       Bob's Red Mill Guar Gum, 8 Ounce (Case of 8)\n",
      "2   B001PEWJWC  Garbanzo Beans aka Chickpeas or Ceci Beans | N...\n",
      "3   B00DS842HS  Viva Naturals Organic Extra Virgin Coconut Oil...\n",
      "4   B003OGKCDC  Nature's Way Organic Extra Virgin Coconut Oil-...\n",
      "5   B000EDBPO8  Bob's Red Mill White Rice Flour, Organic, 24-O...\n",
      "6   B000F4D5GC  Let's Do Organic Shredded, Unsweetened Coconut...\n",
      "7   B000G82L62  Lundberg Family Farms Wild Blend Rice, 16 Ounc...\n",
      "8   B000Z93FQC               Y.S. Eco Bee Farms Raw Honey - 22 oz\n",
      "9   B000JMAXMY                   Mustard Seeds 7oz by Spicy World\n",
      "10  B000HDK0DC  YumEarth Organic Lollipops, Assorted Flavors, ...\n",
      "11  B00014JNI0  YS Organic Bee Farms CERTIFIED ORGANIC RAW HON...\n",
      "12  B0029JHHO2  Ricochet Candies with Xylitol, Grape Escape, 1...\n",
      "13  B000S8593W           Nutiva Hempseeds, Shelled, Pouch 8.00 OZ\n",
      "14  B000ISZ310  NOW Foods Organic Cocoa Powder, Unsweetened-12 oz\n",
      "15  B0000DI085  Simply Organic Almond Extract, Certified Organ...\n",
      "16  B001O1Q0NA  The Spice Lab Pink Himalayan Salt - 1 Pound X-...\n",
      "17  B000HDJXH6  Enjoy Life Chewy Bars, Soy free, Nut free, Glu...\n",
      "18  B0029JASWA  Dove Dark Chocolate Promises, 9.5-Ounce Packag...\n",
      "19  B001VNEHXG  Frontier Co-op Organic White Onion Powder, 2 1...\n",
      "20  B000WSK5N2  NOW Foods Certified Organic Golden Flax Seeds,...\n",
      "21  B00338DSQ4      Barilla Spaghetti Pasta, 32 Ounce (Pack of 6)\n",
      "22  B000HDJZEM  Season Black Capelin Caviar from Iceland, 3.5-...\n",
      "23  B001E5DZJS   Rapunzel Pure Vegan Vegetable Bouillon, No Sa...\n",
      "24  B001E55ZQO  Old Wisconsin Beef Snack Sticks, 7-Ounce Pouch...\n",
      "25  B0004MVRH4   Diamond of California, Shelled Walnuts, 10 Ounce\n",
      "26  B0002YB210                 Kikkoman Manjo Aji Mirin, 17 fl oz\n",
      "27  B000EDBPP2  Bob's Red Mill Honey Almond Granola, 18 Ounce ...\n",
      "28  B000BD0SDU  REDMOND Real Sea Salt - Natural Unrefined Orga...\n",
      "29  B00271OPVU   Coombs Family Farms Maple Syrup, Organic, Gra...\n",
      "30  B000XBCBW6                    Kirkland Signature Walnuts-3lbs\n",
      "31  B000OZFECU  Spicy World Citric Acid, 5-Pound (Food Grade, ...\n",
      "32  B001SB8AZC  Wild Planet Wild Skipjack Tuna (Light Tuna), 5...\n",
      "33  B0036FB6FY  Nature&rsquo;s Earthly Choice: Organic Quinoa ...\n",
      "34  B001LQWO8I  Stakich RAW HONEY - 100% Pure, Unprocessed, Un...\n",
      "35  B001E50UEQ  Hormel Compleats Chicken &amp; Rice, 6-10-Ounc...\n",
      "36  B0054TWPNC  NongShim Bowl Noodle Soup, Hot and Spicy, 3.03...\n",
      "37  B001PF1846  Green Split Peas | Non-GMO Project Verified | ...\n",
      "38  B0045H0KYA  Tropic Bee Wildflower Honeycomb, 5-Ounce Boxes...\n",
      "39  B001EO5U3I                     Grocery &amp; Gourmet Food\" />\n",
      "40  B00BJH59ZO  Gratify Gluten Free Sea Salt Sticks Pretzel, 1...\n",
      "41  B0025UCGRS  Armour Vienna Sausages, 4.75-Ounce Cans(Pack o...\n",
      "42  B003ZXHDSQ  Club Crackers, Original, 16-Ounce Boxes (Pack ...\n",
      "43  B000H1195C  Kikkoman Egg Flower, Hot and Sour Soup, 0.88-O...\n",
      "44  B0001EJ4CU  Lee Kum Kee Premium Dark Soy Sauce - 16.9 fl. ...\n"
     ]
    }
   ],
   "source": [
    "top_ns_45 = n_recommendations[45][0]\n",
    "retrieve_recommendations(train, top_ns_45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab22405",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
