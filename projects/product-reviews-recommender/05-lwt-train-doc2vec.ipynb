{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### 0. Import packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import missingno as msno\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pandarallel import pandarallel\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from src.data import load_dataset\n",
    "from src.features import build_features, preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "pandarallel.initialize()\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "source": [
    "### 1. Loading processed data pickle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = Path('data/processed/')\n",
    "CATEGORY = 'Sports_and_Outdoors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: (2242666, 8)\nTest: (434692, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check test\n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "source": [
    "### 2. Training Doc2Vec model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenising review text\n",
    "train['tokenizedReviewText'] = train['processedReviewText'].parallel_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check `tokenizedReviewText`\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing data for d2v\n",
    "indexes = list(train['index'])\n",
    "reviews = list(train['tokenizedReviewText'])\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s : %(levelname)s : %(message)s\",\n",
    "    level=logging.INFO)\n",
    "\n",
    "# creating tagged documents\n",
    "documents = [TaggedDocument(doc[1], [str(doc[0])]) for _, doc in enumerate(zip(indexes, reviews))]\n",
    "pprint(documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# generating and training d2v\n",
    "# model parameters\n",
    "VECTOR_SIZE = 150\n",
    "MIN_COUNT = 10\n",
    "NEGATIVE = 5\n",
    "SAMPLE = 1e-05\n",
    "DM = 1\n",
    "WORKERS = 8\n",
    "EPOCHS = 20\n",
    "\n",
    "# building the model\n",
    "model = Doc2Vec(\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    negative=NEGATIVE,\n",
    "    sample=SAMPLE,\n",
    "    dm=DM,\n",
    "    workers=WORKERS,\n",
    ")\n",
    "model.build_vocab(documents)\n",
    "\n",
    "# training the model\n",
    "model.train(documents, total_examples=model.corpus_count, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models/d2v/\")\n",
    "model.save(f\"{MODEL_PATH}/{CATEGORY}_d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "MODEL_PATH = Path(\"models/d2v/\")\n",
    "model = Doc2Vec.load(f\"{MODEL_PATH}/{CATEGORY}_d2v.model\")"
   ]
  },
  {
   "source": [
    "#### Testing retrieval of vectors via index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i[1] for i in documents[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.00751332, -0.03107653, -0.01384184, -0.01297431, -0.00852802,\n",
       "       -0.0106923 , -0.01367828,  0.03381048, -0.00208825,  0.02394518,\n",
       "       -0.04435515, -0.00538987, -0.00521584,  0.01179986, -0.03706737,\n",
       "       -0.03014077,  0.0459164 ,  0.0039641 ,  0.0058409 ,  0.06359709,\n",
       "        0.00169906,  0.01850473,  0.04046334, -0.00611207,  0.01891683,\n",
       "        0.0229055 , -0.0273975 ,  0.00510953, -0.01142103, -0.04234928,\n",
       "        0.00269255, -0.00932012,  0.0163039 ,  0.0085518 , -0.01792221,\n",
       "       -0.01183674, -0.0050256 ,  0.00414017, -0.00787533, -0.04172866,\n",
       "       -0.01757223,  0.01712419, -0.00416967,  0.02410017, -0.02095975,\n",
       "        0.01827184, -0.00526504, -0.01363115, -0.01183784,  0.02941062,\n",
       "       -0.03414746,  0.01961362, -0.01695325,  0.02233639, -0.00714071,\n",
       "        0.02432763, -0.03584614,  0.02528099, -0.00444841,  0.02611478,\n",
       "        0.00618138, -0.01781676, -0.03504014,  0.04539623,  0.03562992,\n",
       "        0.00398827,  0.00650692, -0.0088322 , -0.01472492,  0.04708566,\n",
       "        0.00263157,  0.02963844,  0.04703335, -0.02633141, -0.00095589,\n",
       "       -0.02252874,  0.02710084, -0.00973238, -0.06600414,  0.03434172,\n",
       "        0.04150564, -0.00016563, -0.00357373, -0.00561203,  0.0308313 ,\n",
       "        0.00749149, -0.04145496, -0.02527102, -0.03220684,  0.01743559,\n",
       "        0.01887269, -0.04455558, -0.02151629, -0.01158408, -0.00677443,\n",
       "        0.02245479,  0.01447433,  0.0469452 , -0.03275736,  0.02149301,\n",
       "        0.01659627,  0.0044418 ,  0.02311396,  0.02207689,  0.00877853,\n",
       "       -0.00439917,  0.00639206,  0.04351422, -0.03664693, -0.00900744,\n",
       "        0.01765285,  0.00464528,  0.03263863, -0.00377162,  0.02198639,\n",
       "       -0.00067108, -0.01440796,  0.00180445,  0.01293933, -0.00617681,\n",
       "       -0.00040805, -0.02099202, -0.02375114, -0.03568823,  0.02359813,\n",
       "       -0.01720689,  0.02810098,  0.02468681, -0.0184929 , -0.01556312,\n",
       "       -0.00637842,  0.03454443, -0.00551271,  0.02465272,  0.00037579,\n",
       "       -0.02439881, -0.0198758 , -0.02673003,  0.01079208, -0.03643188,\n",
       "       -0.01038455,  0.04668055,  0.01437208,  0.02297292,  0.05301273,\n",
       "        0.01145396, -0.02173989,  0.0097778 , -0.00774046, -0.00512736],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "model.dv[2]"
   ]
  },
  {
   "source": [
    "#### Testing retrieval of vectors via tags"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-0.00751332, -0.03107653, -0.01384184, -0.01297431, -0.00852802,\n",
       "       -0.0106923 , -0.01367828,  0.03381048, -0.00208825,  0.02394518,\n",
       "       -0.04435515, -0.00538987, -0.00521584,  0.01179986, -0.03706737,\n",
       "       -0.03014077,  0.0459164 ,  0.0039641 ,  0.0058409 ,  0.06359709,\n",
       "        0.00169906,  0.01850473,  0.04046334, -0.00611207,  0.01891683,\n",
       "        0.0229055 , -0.0273975 ,  0.00510953, -0.01142103, -0.04234928,\n",
       "        0.00269255, -0.00932012,  0.0163039 ,  0.0085518 , -0.01792221,\n",
       "       -0.01183674, -0.0050256 ,  0.00414017, -0.00787533, -0.04172866,\n",
       "       -0.01757223,  0.01712419, -0.00416967,  0.02410017, -0.02095975,\n",
       "        0.01827184, -0.00526504, -0.01363115, -0.01183784,  0.02941062,\n",
       "       -0.03414746,  0.01961362, -0.01695325,  0.02233639, -0.00714071,\n",
       "        0.02432763, -0.03584614,  0.02528099, -0.00444841,  0.02611478,\n",
       "        0.00618138, -0.01781676, -0.03504014,  0.04539623,  0.03562992,\n",
       "        0.00398827,  0.00650692, -0.0088322 , -0.01472492,  0.04708566,\n",
       "        0.00263157,  0.02963844,  0.04703335, -0.02633141, -0.00095589,\n",
       "       -0.02252874,  0.02710084, -0.00973238, -0.06600414,  0.03434172,\n",
       "        0.04150564, -0.00016563, -0.00357373, -0.00561203,  0.0308313 ,\n",
       "        0.00749149, -0.04145496, -0.02527102, -0.03220684,  0.01743559,\n",
       "        0.01887269, -0.04455558, -0.02151629, -0.01158408, -0.00677443,\n",
       "        0.02245479,  0.01447433,  0.0469452 , -0.03275736,  0.02149301,\n",
       "        0.01659627,  0.0044418 ,  0.02311396,  0.02207689,  0.00877853,\n",
       "       -0.00439917,  0.00639206,  0.04351422, -0.03664693, -0.00900744,\n",
       "        0.01765285,  0.00464528,  0.03263863, -0.00377162,  0.02198639,\n",
       "       -0.00067108, -0.01440796,  0.00180445,  0.01293933, -0.00617681,\n",
       "       -0.00040805, -0.02099202, -0.02375114, -0.03568823,  0.02359813,\n",
       "       -0.01720689,  0.02810098,  0.02468681, -0.0184929 , -0.01556312,\n",
       "       -0.00637842,  0.03454443, -0.00551271,  0.02465272,  0.00037579,\n",
       "       -0.02439881, -0.0198758 , -0.02673003,  0.01079208, -0.03643188,\n",
       "       -0.01038455,  0.04668055,  0.01437208,  0.02297292,  0.05301273,\n",
       "        0.01145396, -0.02173989,  0.0097778 , -0.00774046, -0.00512736],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "model.dv['2']   # '2' is at index of 2 as shown previously"
   ]
  },
  {
   "source": [
    "### 3. Examining D2V Results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### 3.1 Are inferred vectors close to the precalculated ones?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['index'] == doc_id[0]]"
   ]
  },
  {
   "source": [
    "Example of detailed review with better results:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = np.random.choice(list(train['index'].unique()), 1)\n",
    "doc_tokens = train[train['index'] == doc_id[0]]['tokenizedReviewText'].values[0]\n",
    "\n",
    "print(f\"For doc {doc_id[0]}...\\nTokens: {doc_tokens}\")\n",
    "inferred_docvec = model.infer_vector(doc_tokens, steps=100, alpha=0.025)\n",
    "print(f'Most similar D2V vectors: {model.dv.most_similar([inferred_docvec], topn=3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the 2nd similar vector\n",
    "similar_tokens = train[train['index'] == 881221]['tokenizedReviewText'].values[0]\n",
    "print(similar_tokens)"
   ]
  },
  {
   "source": [
    "Example of less-detailed review with worse results:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = np.random.choice(list(train['index'].unique()), 1)\n",
    "doc_tokens = train[train['index'] == doc_id[0]]['tokenizedReviewText'].values[0]\n",
    "\n",
    "print(f\"For doc {doc_id[0]}...\\nTokens: {doc_tokens}\")\n",
    "inferred_docvec = model.infer_vector(doc_tokens, steps=100, alpha=0.025)\n",
    "print(f'Most similar D2V vectors: {model.dv.most_similar([inferred_docvec], topn=3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_tokens = train[train['index'] == 444194]['tokenizedReviewText'].values[0]\n",
    "print(similar_tokens)"
   ]
  },
  {
   "source": [
    "### Creating appropriate mapping"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Before we can generate recommendations based on the vectors trained by `D2V`, we will need to generate a few mappings to help us aggregate vectors on both users and items level.\n",
    "\n",
    "As our model ideates based on the how both `user` and `item` can be represented by their `documents` – which, in this case is an aggregation of all the past reviews. Hence, we will need to generate mappings that identifies:\n",
    "\n",
    "1. `User-Review`: What are the reviews that have been given by a user.\n",
    "2. `Product-Review`: What are the reviews that have been received by a product.\n",
    "\n",
    "With the above mapping, we are able to develop a item-level recommendation based on the past items purchased and reviewed by the users. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_user_review_map = train.groupby(['reviewerID'])['index'].progress_apply(list).to_dict()\n",
    "pprint(list(train_user_review_map.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD METHOD\n",
    "# train_user_index_map = {}\n",
    "# users = list(set(train['reviewerID']))\n",
    "# index = 0\n",
    "# for user in tqdm(users):\n",
    "#     if user not in train_user_index_map.values():\n",
    "#         train_user_index_map[index] = user\n",
    "#         index += 1\n",
    "#     else:\n",
    "#         pass\n",
    "# print(len(train_user_index_map))\n",
    "\n",
    "train_user_index_map = pd.DataFrame({'reviewerID': list(set(train['reviewerID']))}).to_dict()['reviewerID']\n",
    "print(len(train_user_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify checks\n",
    "print(train['reviewerID'].nunique())\n",
    "print(len(train_user_review_map))\n",
    "print(len(train_user_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prod_review_map = train.groupby(['asin'])['index'].progress_apply(list).to_dict()\n",
    "pprint(list(train_prod_review_map.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD METHOD\n",
    "# train_prod_index_map = {}\n",
    "# prods = list(train_movie_reviews['asin'].unique())\n",
    "# index = 0\n",
    "# for prod in tqdm(prods):\n",
    "#     if prod not in train_prod_index_map.values():\n",
    "#         train_prod_index_map[index] = prod\n",
    "#         index += 1\n",
    "#     else:\n",
    "#         pass\n",
    "# print(len(train_prod_index_map))\n",
    "\n",
    "train_prod_index_map = pd.DataFrame({'asin': list(set(train['asin']))}).to_dict()['asin']\n",
    "pprint(list(train_prod_index_map.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify checks\n",
    "print(train['asin'].nunique())\n",
    "print(len(train_prod_review_map))\n",
    "print(len(train_prod_index_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_PATH = Path(\"data/processed/mappings/\")\n",
    "\n",
    "np.save(f'{MAP_PATH}/{CATEGORY}_train_user_review_map.npy', train_user_review_map)\n",
    "np.save(f'{MAP_PATH}/{CATEGORY}_train_user_index_map.npy', train_user_index_map)\n",
    "np.save(f'{MAP_PATH}/{CATEGORY}_train_prod_review_map.npy', train_prod_review_map)\n",
    "np.save(f'{MAP_PATH}/{CATEGORY}_train_prod_index_map.npy', train_prod_index_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP_PATH = Path(\"data/processed/mappings/\")\n",
    "\n",
    "train_user_review_map = np.load(f'{MAP_PATH}/{CATEGORY}_train_user_review_map.npy', allow_pickle=True).item()\n",
    "train_user_index_map = np.load(f'{MAP_PATH}/{CATEGORY}_train_user_index_map.npy', allow_pickle=True).item()\n",
    "train_prod_review_map = np.load(f'{MAP_PATH}/{CATEGORY}_train_prod_review_map.npy', allow_pickle=True).item()\n",
    "train_prod_index_map = np.load(f'{MAP_PATH}/{CATEGORY}_train_prod_index_map.npy', allow_pickle=True).item()"
   ]
  },
  {
   "source": [
    "### Creating aggregated vector by product `asin` and building ANN trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating approximate nearest neighbour setup\n",
    "f = 150\n",
    "t = AnnoyIndex(f, 'angular')    # using cosine measure\n",
    "\n",
    "agg_prod_vectors = {}\n",
    "# in range for all users\n",
    "for k, v in tqdm(train_prod_index_map.items()):\n",
    "    ind_reviews_vectors = np.zeros(f)\n",
    "    # retrieve the agg reviews list based on user id\n",
    "    # asin = train_prod_index_map[k]\n",
    "    agg_list = train_prod_review_map[v]\n",
    "    for j in agg_list:\n",
    "        # retrieve the row number\n",
    "        # row_num = temp.loc[temp['index'] == j].index[0]\n",
    "        # retrieve the vector from d2v\n",
    "        try:\n",
    "            ind_reviews_vectors += np.array(model.dv[str(j)])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    # aggregate all doc vectors from a prod\n",
    "    agg_vectors = np.divide(ind_reviews_vectors, len(agg_list))\n",
    "    agg_prod_vectors[k] = agg_vectors\n",
    "    # we need to add these into the ann object\n",
    "    t.add_item(k, agg_vectors)\n",
    "\n",
    "# build the trees\n",
    "ANN_PATH = Path(f\"anns/{CATEGORY}/\")\n",
    "\n",
    "t.build(300)\n",
    "t.save(f'{ANN_PATH}/{CATEGORY}-f150.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "f = 150\n",
    "\n",
    "ANN_PATH = Path(f\"anns/{CATEGORY}/\")\n",
    "u = AnnoyIndex(f, 'angular')\n",
    "u.load(f'{ANN_PATH}/{CATEGORY}-f150.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{MAP_PATH}/{CATEGORY}_agg_prod_vectors.npy', agg_prod_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_prod_vectors = np.load(f'{MAP_PATH}/{CATEGORY}_agg_prod_vectors.npy', allow_pickle=True).item()"
   ]
  },
  {
   "source": [
    "### Creating aggregated vector by users `reviewerID`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 150\n",
    "\n",
    "agg_user_vectors = {}\n",
    "# in range for all users\n",
    "for k, v in tqdm(train_user_index_map.items()):\n",
    "    ind_reviews_vectors = np.zeros(f)\n",
    "    # retrieve the agg reviews list based on user id\n",
    "    # user_id = train_user_index_map[i]\n",
    "    agg_list = train_user_review_map[v]\n",
    "    for j in agg_list:\n",
    "        # retrieve the vector from d2v\n",
    "        ind_reviews_vectors += np.array(model.dv[str(j)])\n",
    "    # aggregate all doc vectors from a prod\n",
    "    agg_vectors = np.divide(ind_reviews_vectors, len(agg_list))\n",
    "    agg_user_vectors[k] = agg_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{MAP_PATH}/{CATEGORY}_agg_user_vectors.npy', agg_user_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_user_vectors = np.load(f'{MAP_PATH}/{CATEGORY}_agg_user_vectors.npy', allow_pickle=True).item()"
   ]
  },
  {
   "source": [
    "### Using Nearest Neighbor Search (NNS) to retrieve top 10 items "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Extending the idea of generating recommendations, we able to generate recommendations based on two factors:\n",
    "\n",
    "1. Past users's purchase (using their reviews)\n",
    "2. Item-level similarities based on aggregation of reviews embeddings\n",
    "\n",
    "This meant that, given a user's past purchase history, where we generated an aggregation of reviews embeddings, we are able to use that same vector to help recommend items from the item *f*-dimensional space. Also, based on an instance where perhaps last click on a certain item, we are able to generate recommendations based on the comparison of similarities reviews from the clicked items to the other items within the item *f*-dimensional space."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### Using users-level recommendation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For user: A247LS4EOGZJK9\n\nRecommended items are:\nRank: 1 | B01BL0Z8GS | Rating: 4.28 | Reviewed: 69 | Title: Ulticlip 3\nRank: 2 | B00W5EC39K | Rating: 4.19 | Reviewed: 189 | Title: BLACKHAWK! Ambidextrous Appendix Reversible Carry Inside The Pants Holster\nRank: 3 | B01B5E3G4Q | Rating: 4.47 | Reviewed: 15 | Title: Desantis Slim-Tuk Inside Fits Glock 43 Ambidextrous Kydex Pants Holster, Black\nRank: 4 | B017AFD5JK | Rating: 3.67 | Reviewed: 57 | Title: Q-Series IWB Minimalist Concealed Carry Stealth Holster\nRank: 5 | B007F7IWGU | Rating: 4.13 | Reviewed: 30 | Title: 5.11 Tactical Unisex Adult Inside Waistband 19/23 26/27 RH Holster\nRank: 6 | B01DMMKUFC | Rating: 4.72 | Reviewed: 134 | Title: CYA Supply Co. IWB Holster Fits: Glock 43 - Veteran Owned Company - Made in USA - Inside Waistband Concealed Carry Holster\nRank: 7 | B001UOHLCU | Rating: 4.20 | Reviewed: 44 | Title: Galco Triton Kydex IWB Holster for Glock 19, 23, 32 (Black, Right-hand)\nRank: 8 | B00HZTAX42 | Rating: 4.50 | Reviewed: 133 | Title: Blade Tech Industries Klipt IWB Holster\nRank: 9 | B00G2N5WXY | Rating: 4.83 | Reviewed: 18 | Title: Safariland 7378 7TS ALS Paddle &amp; Belt Slide Concealment Glock 17 22 Holster\nRank: 10 | B00M92G9YS | Rating: 4.41 | Reviewed: 81 | Title: Fobus Evolution Paddle Holster - GL\n"
     ]
    }
   ],
   "source": [
    "def generate_random_user_recommendations():\n",
    "    user_index = np.random.randint(0, len(train_user_index_map))\n",
    "    reviewer_agg_vectors = agg_user_vectors[user_index]\n",
    "    reviewer_id = train_user_index_map[user_index]\n",
    "\n",
    "    ann_similar_items = u.get_nns_by_vector(reviewer_agg_vectors, 25, search_k=-1, include_distances=False)\n",
    "\n",
    "    recommendations = pd.DataFrame(columns=['rank', 'asin', 'overall', 'review_counts', 'titles', 'brands'])\n",
    "    ranks = [i for i in range(1,11,1)]\n",
    "    asins = []\n",
    "    overalls = []\n",
    "    review_counts = []\n",
    "    titles = []\n",
    "    brands = []\n",
    "    for item in ann_similar_items:\n",
    "        user_history_train = train[train['reviewerID'] == reviewer_id]['asin'].unique()\n",
    "        if item not in user_history_train:\n",
    "            asin = train_prod_index_map[item]\n",
    "            overall = train[train['asin'] == asin]['overall'].mean()\n",
    "            review_count = len(train[train['asin'] == asin]['reviewText'])\n",
    "            title = train[train['asin'] == asin]['title'].unique()[0]\n",
    "            brand = train[train['asin'] == asin]['brand'].unique()[0]\n",
    "\n",
    "            asins.append(asin)\n",
    "            overalls.append(overall)\n",
    "            review_counts.append(review_count)\n",
    "            titles.append(title if len(title) > 0 else '')\n",
    "            brands.append(brand if len(str(brand)) > 0 else '')\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    recommendations['rank'] = ranks\n",
    "    recommendations['asin'] = asins[:10]\n",
    "    recommendations['overall'] = overalls[:10]\n",
    "    recommendations['review_counts'] = review_counts[:10]\n",
    "    recommendations['titles'] = titles[:10]\n",
    "    recommendations['brands'] = brands[:10]\n",
    "    \n",
    "    # retrieving the recommendations\n",
    "    print(f\"For user: {reviewer_id}\\n\")\n",
    "    print(f\"Recommended items are:\")\n",
    "    for index, row in recommendations.iterrows():\n",
    "        print(f\"Rank: {row[0]} | {row[1]} | Rating: {row[2]:.2f} | Reviewed: {row[3]} | Title: {row[4]}\")\n",
    "\n",
    "    return reviewer_id\n",
    "\n",
    "reviewer_id = generate_random_user_recommendations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                     title        asin  \\\n",
       "1175232  Techna Clip Conceal Carry Gun Belt Clips for B...  B0094T6MKK   \n",
       "1875527  Browning BR182BL-BRK Vanquish Linerlock Knife,...  B00VU4MBQG   \n",
       "1881104  BLACKHAWK! Ambidextrous Appendix Reversible Ca...  B00W5EC39K   \n",
       "2137869                                         Ulticlip 3  B01BL0Z8GS   \n",
       "2173979  CYA Supply Co. IWB Holster Fits: Glock 43 - Ve...  B01DMMKUFC   \n",
       "\n",
       "         overall                                         reviewText  \n",
       "1175232      5.0  perfect accessory for the bodyguard. For just ...  \n",
       "1875527      5.0  the flip out top thumb guard is an awesome ide...  \n",
       "1881104      3.0  The clip is too flimsy, if the clip was metal ...  \n",
       "2137869      5.0  Can be a little hard to release depending on t...  \n",
       "2173979      5.0  excellent holster for the money!! bought \"claw...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>asin</th>\n      <th>overall</th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1175232</th>\n      <td>Techna Clip Conceal Carry Gun Belt Clips for B...</td>\n      <td>B0094T6MKK</td>\n      <td>5.0</td>\n      <td>perfect accessory for the bodyguard. For just ...</td>\n    </tr>\n    <tr>\n      <th>1875527</th>\n      <td>Browning BR182BL-BRK Vanquish Linerlock Knife,...</td>\n      <td>B00VU4MBQG</td>\n      <td>5.0</td>\n      <td>the flip out top thumb guard is an awesome ide...</td>\n    </tr>\n    <tr>\n      <th>1881104</th>\n      <td>BLACKHAWK! Ambidextrous Appendix Reversible Ca...</td>\n      <td>B00W5EC39K</td>\n      <td>3.0</td>\n      <td>The clip is too flimsy, if the clip was metal ...</td>\n    </tr>\n    <tr>\n      <th>2137869</th>\n      <td>Ulticlip 3</td>\n      <td>B01BL0Z8GS</td>\n      <td>5.0</td>\n      <td>Can be a little hard to release depending on t...</td>\n    </tr>\n    <tr>\n      <th>2173979</th>\n      <td>CYA Supply Co. IWB Holster Fits: Glock 43 - Ve...</td>\n      <td>B01DMMKUFC</td>\n      <td>5.0</td>\n      <td>excellent holster for the money!! bought \"claw...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# looking at the past purchase history of the user\n",
    "user_history_train= train[train['reviewerID'] == reviewer_id]\n",
    "user_history_train[['title', 'asin', 'overall', 'reviewText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    title        asin  \\\n",
       "419015  Fairwin EDC Tactical Belt - Reinforced Thick C...  B01D3842OA   \n",
       "\n",
       "        overall                                         reviewText  \n",
       "419015      5.0  can't beat the cost VS product for this belt. ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>asin</th>\n      <th>overall</th>\n      <th>reviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>419015</th>\n      <td>Fairwin EDC Tactical Belt - Reinforced Thick C...</td>\n      <td>B01D3842OA</td>\n      <td>5.0</td>\n      <td>can't beat the cost VS product for this belt. ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "user_history_test = test[test['reviewerID'] == reviewer_id]\n",
    "user_history_test[['title', 'asin', 'overall', 'reviewText']]"
   ]
  },
  {
   "source": [
    "#### Using items-level recommendation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "For user: AZJF5T6HWZZFD, given last viewed/clicked product: B00029EWIA – Spark-Lite Fire Starter...\n\nRecommended items are:\nRank: 1 | B00029EWIA | Rating: 4.14 | Reviewed: 7 | Title: Spark-Lite Fire Starter\nRank: 2 | B00QGKYKJA | Rating: 4.91 | Reviewed: 57 | Title: Lightning Strike Standard Fire Starter Holland\nRank: 3 | B00029EWYY | Rating: 4.30 | Reviewed: 168 | Title: Four Seasons Survival Tinder-Quik Fire Tab\nRank: 4 | B0027T0KJS | Rating: 4.56 | Reviewed: 72 | Title: S.O.L. Survive Outdoors Longer Tinder Quik Fire Starters (12-Count)\nRank: 5 | B001H9N8BG | Rating: 4.62 | Reviewed: 52 | Title: Ultimate Survival Technologies StrikeForce Fire Starter\nRank: 6 | B0013L2DKU | Rating: 4.76 | Reviewed: 265 | Title: Light My Fire Original Swedish FireSteel Army 12,000 Strike Fire Starter - Black\nRank: 7 | B003R9VMPS | Rating: 4.69 | Reviewed: 32 | Title: FireSteel Armageddon with Super Scraper and Lanyard\nRank: 8 | B0035LVZFK | Rating: 4.03 | Reviewed: 32 | Title: Zippo Emergency Fire Starter Kit\nRank: 9 | B00FVZ4IE8 | Rating: 4.18 | Reviewed: 55 | Title: Ultimate Survival Technologies UST Micro Sparkwheel\nRank: 10 | B005IPL15A | Rating: 4.14 | Reviewed: 103 | Title: UST Sparkie Fire Starter\nRank: 11 | B00LDYLJDE | Rating: 4.89 | Reviewed: 18 | Title: Epiphany Outdoor Gear Bellows Fire Starting Kit\n"
     ]
    }
   ],
   "source": [
    "def generate_random_prod_recommendations():\n",
    "    user_index = np.random.randint(0, len(train_user_index_map))\n",
    "    reviewer_agg_vectors = agg_user_vectors[user_index]\n",
    "    reviewer_id = train_user_index_map[user_index]\n",
    "\n",
    "    prod_index = np.random.randint(0, len(train_prod_index_map))\n",
    "    prod_agg_vectors = agg_prod_vectors[prod_index]\n",
    "    prod_asin = train_prod_index_map[prod_index]\n",
    "    prod_title = train[train['asin'] == prod_asin]['title'].unique()[0]\n",
    "\n",
    "    ann_similar_items = u.get_nns_by_vector(prod_agg_vectors, 50, search_k=-1, include_distances=False)\n",
    "\n",
    "    recommendations = pd.DataFrame(columns=['rank', 'asin', 'overall', 'review_counts', 'titles', 'brands'])\n",
    "    ranks = [i for i in range(1,12,1)]\n",
    "    asins = []\n",
    "    overalls = []\n",
    "    review_counts = []\n",
    "    titles = []\n",
    "    brands = []\n",
    "    for item in ann_similar_items:\n",
    "        user_history_train = train[train['reviewerID'] == reviewer_id]['asin'].unique()\n",
    "        if item not in user_history_train:\n",
    "            asin = train_prod_index_map[item]\n",
    "            overall = train[train['asin'] == asin]['overall'].mean()\n",
    "            review_count = len(train[train['asin'] == asin]['reviewText'])\n",
    "            title = train[train['asin'] == asin]['title'].unique()[0]\n",
    "            brand = train[train['asin'] == asin]['brand'].unique()[0]\n",
    "\n",
    "            asins.append(asin)\n",
    "            overalls.append(overall)\n",
    "            review_counts.append(review_count)\n",
    "            titles.append(title if len(title) > 0 else '')\n",
    "            brands.append(brand if len(str(brand)) > 0 else '')\n",
    "\n",
    "    recommendations['rank'] = ranks\n",
    "    recommendations['asin'] = asins[:11]\n",
    "    recommendations['overall'] = overalls[:11]\n",
    "    recommendations['review_counts'] = review_counts[:11]\n",
    "    recommendations['titles'] = titles[:11]\n",
    "    recommendations['brands'] = brands[:11]\n",
    "    \n",
    "    # retrieving the recommendations\n",
    "    print(f\"For user: {reviewer_id}, given last viewed/clicked product: {prod_asin} – {prod_title}...\\n\")\n",
    "    print(f\"Recommended items are:\")\n",
    "    for index, row in recommendations.iterrows():\n",
    "        print(f\"Rank: {row[0]} | {row[1]} | Rating: {row[2]:.2f} | Reviewed: {row[3]} | Title: {row[4]}\")\n",
    "\n",
    "generate_random_prod_recommendations()"
   ]
  },
  {
   "source": [
    "### Computing Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}