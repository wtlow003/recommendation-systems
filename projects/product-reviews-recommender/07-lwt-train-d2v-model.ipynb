{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "25ff572cf74667139a08e9b3925acace09b8544c3d9e895a2455f974072b7e88"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: gensim in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.7.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from gensim) (5.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.21.1)\n",
      "Requirement already satisfied: pandas in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from pandas) (1.21.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: pandarallel in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (1.5.2)\n",
      "Requirement already satisfied: dill in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from pandarallel) (0.3.4)\n",
      "Requirement already satisfied: numpy in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (1.21.1)\n",
      "Requirement already satisfied: tqdm in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (4.61.2)\n",
      "Requirement already satisfied: ipywidgets in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (7.6.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (1.0.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (5.0.5)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: appnope in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.12)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.0)\n",
      "Requirement already satisfied: decorator in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (5.0.9)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pickleshare in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.17)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets) (2.9.0)\n",
      "Requirement already satisfied: parso>=0.7.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: ipython-genutils in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.7.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.10.1)\n",
      "Requirement already satisfied: prometheus-client in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: argon2-cffi in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.0.0)\n",
      "Requirement already satisfied: jinja2 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: nbconvert in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: bleach in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.3.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: testpath in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.3)\n",
      "Requirement already satisfied: async-generator in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: packaging in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: webencodings in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/jensen/opt/anaconda3/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install pandas\n",
    "!pip install pandarallel\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "/Users/jensen/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from pandarallel import pandarallel\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from src.features import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "source": [
    "# 1. Load data\n",
    "\n",
    "Let's load the train/test data that we have processed previously. We will do a quick check on the shape of both datasets, and also visually inspect that the `processedReviewText` should still be `str` format – hence, we are required to tokenized it before parsing into the `Doc2Vec` model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = Path('data/processed/')\n",
    "CATEGORY = 'Clothing_Shoes_and_Jewelry'\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: (231491, 5), unique users: 39387, unique items: 23033\nTest: (47145, 5), unique users: 39380, unique items: 17949\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {train.shape}, unique users: {train.reviewerID.nunique()}, unique items: {train.asin.nunique()}\")\n",
    "print(f\"Test: {test.shape}, unique users: {test.reviewerID.nunique()}, unique items: {test.asin.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        overall      reviewerID        asin  \\\n",
       "0           5.0  A1KLRMWW2FWPL4  0000031887   \n",
       "1           5.0  A2G5TCU2WDFZ65  0000031887   \n",
       "2           5.0  A1RLQXYNCMWRWN  0000031887   \n",
       "3           4.0   A27UF1MSF3DB2  0000031887   \n",
       "4           5.0  A16GFPNVF4Y816  0000031887   \n",
       "231486      5.0   ACJT8MUC0LRF0  B00KKXCJQU   \n",
       "231487      5.0  A2DG63DN704LOI  B00KKXCJQU   \n",
       "231488      5.0  A1UQBFCERIP7VJ  B00KKXCJQU   \n",
       "231489      5.0  A22CW0ZHY3NJH8  B00KKXCJQU   \n",
       "231490      5.0  A30VWT3R25QAVD  B00KKXCJQU   \n",
       "\n",
       "                                               reviewText  \\\n",
       "0       This is a great tutu and at a really great pri...   \n",
       "1       I bought this for my 4 yr old daughter for dan...   \n",
       "2       What can I say... my daughters have it in oran...   \n",
       "3       I received this today and I'm not a fan of it ...   \n",
       "4       Bought this as a backup to the regular ballet ...   \n",
       "231486  When I pack it looks like a disaster area in a...   \n",
       "231487  I don't normally go ga-ga over a product very ...   \n",
       "231488  These are very nice packing cubes and the 18 x...   \n",
       "231489  I am on vacation with my family of four and th...   \n",
       "231490  When I signed up to receive a free set of Shac...   \n",
       "\n",
       "                                      processedReviewText  \n",
       "0       this great tutu great price it look cheap glad...  \n",
       "1       buy yr old daughter dance class wore today tim...  \n",
       "2       what daughters orange black white pink think b...  \n",
       "3       receive today fan daughter think puffier look ...  \n",
       "4       bought backup regular ballet outfit daughter w...  \n",
       "231486  when pack look like disaster area suitcase pac...  \n",
       "231487  normally ga ga product cub awesome help review...  \n",
       "231488  these nice packing cube laundry storage bag ni...  \n",
       "231489  vacation family shacke pak set wonderful excep...  \n",
       "231490  when sign receive free set shacke pak review t...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewText</th>\n      <th>processedReviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>A1KLRMWW2FWPL4</td>\n      <td>0000031887</td>\n      <td>This is a great tutu and at a really great pri...</td>\n      <td>this great tutu great price it look cheap glad...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>A2G5TCU2WDFZ65</td>\n      <td>0000031887</td>\n      <td>I bought this for my 4 yr old daughter for dan...</td>\n      <td>buy yr old daughter dance class wore today tim...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>A1RLQXYNCMWRWN</td>\n      <td>0000031887</td>\n      <td>What can I say... my daughters have it in oran...</td>\n      <td>what daughters orange black white pink think b...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.0</td>\n      <td>A27UF1MSF3DB2</td>\n      <td>0000031887</td>\n      <td>I received this today and I'm not a fan of it ...</td>\n      <td>receive today fan daughter think puffier look ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>A16GFPNVF4Y816</td>\n      <td>0000031887</td>\n      <td>Bought this as a backup to the regular ballet ...</td>\n      <td>bought backup regular ballet outfit daughter w...</td>\n    </tr>\n    <tr>\n      <th>231486</th>\n      <td>5.0</td>\n      <td>ACJT8MUC0LRF0</td>\n      <td>B00KKXCJQU</td>\n      <td>When I pack it looks like a disaster area in a...</td>\n      <td>when pack look like disaster area suitcase pac...</td>\n    </tr>\n    <tr>\n      <th>231487</th>\n      <td>5.0</td>\n      <td>A2DG63DN704LOI</td>\n      <td>B00KKXCJQU</td>\n      <td>I don't normally go ga-ga over a product very ...</td>\n      <td>normally ga ga product cub awesome help review...</td>\n    </tr>\n    <tr>\n      <th>231488</th>\n      <td>5.0</td>\n      <td>A1UQBFCERIP7VJ</td>\n      <td>B00KKXCJQU</td>\n      <td>These are very nice packing cubes and the 18 x...</td>\n      <td>these nice packing cube laundry storage bag ni...</td>\n    </tr>\n    <tr>\n      <th>231489</th>\n      <td>5.0</td>\n      <td>A22CW0ZHY3NJH8</td>\n      <td>B00KKXCJQU</td>\n      <td>I am on vacation with my family of four and th...</td>\n      <td>vacation family shacke pak set wonderful excep...</td>\n    </tr>\n    <tr>\n      <th>231490</th>\n      <td>5.0</td>\n      <td>A30VWT3R25QAVD</td>\n      <td>B00KKXCJQU</td>\n      <td>When I signed up to receive a free set of Shac...</td>\n      <td>when sign receive free set shacke pak review t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# check train\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       overall      reviewerID        asin  \\\n",
       "0          5.0   A8U3FAMSJVHS5  0000031887   \n",
       "1          5.0  A3GEOILWLK86XM  0000031887   \n",
       "2          5.0  A2A2WZYLU528RO  0000031887   \n",
       "3          5.0  A34ATJR9KFIXL9  0000031887   \n",
       "4          5.0  A1MXJVYXE2QU6H  0000031887   \n",
       "47140      5.0  A2XX2A4OJCDNLZ  B00KF9180W   \n",
       "47141      2.0  A34BZM6S9L7QI4  B00KGCLROK   \n",
       "47142      5.0  A25C2M3QF9G7OQ  B00KGCLROK   \n",
       "47143      5.0   AEL6CQNQXONBX  B00KKXCJQU   \n",
       "47144      5.0  A1EVV74UQYVKRY  B00KKXCJQU   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0      We bought several tutus at once, and they are ...   \n",
       "1      Thank you Halo Heaven great product for Little...   \n",
       "2      My daughter has worn this skirt almost every d...   \n",
       "3      Full and well stitched.  This tutu is a beauti...   \n",
       "4      Perfect for my budding grand daughter ballerin...   \n",
       "47140  While balaclavas can be used for a variety of ...   \n",
       "47141  These were a free sample for review.  I was ex...   \n",
       "47142  These socks are very nicely made and quite com...   \n",
       "47143  This set of travel organizers includes four pi...   \n",
       "47144  I've been traveling back and forth to England ...   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      we buy tutu get high review sturdy seemingly t...  \n",
       "1      thank halo heaven great product little girls m...  \n",
       "2      my daughter worn skirt day receive washer clot...  \n",
       "3      full stitch this tutu beautiful purple color l...  \n",
       "4      perfect bud grand daughter ballerina beautiful...  \n",
       "47140  while balaclavas variety thing use mainly late...  \n",
       "47141  these free sample review excite try unfortunat...  \n",
       "47142  these sock nicely comfortable wear the grip do...  \n",
       "47143  this set travel organizer include piece total ...  \n",
       "47144  travel forth england pack way suitcases some p...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewText</th>\n      <th>processedReviewText</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>A8U3FAMSJVHS5</td>\n      <td>0000031887</td>\n      <td>We bought several tutus at once, and they are ...</td>\n      <td>we buy tutu get high review sturdy seemingly t...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>A3GEOILWLK86XM</td>\n      <td>0000031887</td>\n      <td>Thank you Halo Heaven great product for Little...</td>\n      <td>thank halo heaven great product little girls m...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>A2A2WZYLU528RO</td>\n      <td>0000031887</td>\n      <td>My daughter has worn this skirt almost every d...</td>\n      <td>my daughter worn skirt day receive washer clot...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>A34ATJR9KFIXL9</td>\n      <td>0000031887</td>\n      <td>Full and well stitched.  This tutu is a beauti...</td>\n      <td>full stitch this tutu beautiful purple color l...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>A1MXJVYXE2QU6H</td>\n      <td>0000031887</td>\n      <td>Perfect for my budding grand daughter ballerin...</td>\n      <td>perfect bud grand daughter ballerina beautiful...</td>\n    </tr>\n    <tr>\n      <th>47140</th>\n      <td>5.0</td>\n      <td>A2XX2A4OJCDNLZ</td>\n      <td>B00KF9180W</td>\n      <td>While balaclavas can be used for a variety of ...</td>\n      <td>while balaclavas variety thing use mainly late...</td>\n    </tr>\n    <tr>\n      <th>47141</th>\n      <td>2.0</td>\n      <td>A34BZM6S9L7QI4</td>\n      <td>B00KGCLROK</td>\n      <td>These were a free sample for review.  I was ex...</td>\n      <td>these free sample review excite try unfortunat...</td>\n    </tr>\n    <tr>\n      <th>47142</th>\n      <td>5.0</td>\n      <td>A25C2M3QF9G7OQ</td>\n      <td>B00KGCLROK</td>\n      <td>These socks are very nicely made and quite com...</td>\n      <td>these sock nicely comfortable wear the grip do...</td>\n    </tr>\n    <tr>\n      <th>47143</th>\n      <td>5.0</td>\n      <td>AEL6CQNQXONBX</td>\n      <td>B00KKXCJQU</td>\n      <td>This set of travel organizers includes four pi...</td>\n      <td>this set travel organizer include piece total ...</td>\n    </tr>\n    <tr>\n      <th>47144</th>\n      <td>5.0</td>\n      <td>A1EVV74UQYVKRY</td>\n      <td>B00KKXCJQU</td>\n      <td>I've been traveling back and forth to England ...</td>\n      <td>travel forth england pack way suitcases some p...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# check test\n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "source": [
    "# 2. Doc2Vec model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1 Preparing `TaggedDocument` for Doc2Vec model\n",
    "\n",
    "In this following section, we will generating tagged documents that will be feed into the `Doc2Vec` model. We will be required to generate documents, where each is 'tagged' with the corresponding `asin` of which the review is addressing. This enables the Doc2Vec model to identify documents that are associated to each of the asin within our training dataset, and create a document vector based on the seperated documents for each asin. \n",
    "\n",
    "The intuition behind this preparation is that we assume that each asin is a representation of all the reviews customers has left after purchasing. If customers like any aspect of the product, the reviews should leave relevant positive feedback on that particular e.g., \"the boots is comfortable\" – hence, we know that this particular boots is comfortable. If a product (asin) has many of such reviews, semantically, we can build an item profile that associates this boots as a product that is comfortable. As embeddings are generated in *n*-dimensional vector space, we can then attempt to find similar products within the neighbourhood that has a similar profile be it is either a pair of boots, or a product that is comfortable in nature. \n",
    "\n",
    "The reason why we are building this in an item-item level is because at a user-level, interests may vary greatly depending on the user needs when purchasing items. Also, as some users may be more negative in nature, their reviews may generally be more critical which will inherently develop a profile that is critical in nature. Assuming this, if we were to place this user profile vector into the *n*-dimensional vector space, we will likely be recommending products that were also critically (or negatively) reviewed. This meant that for this user, we might only be generating poor recommendations due to how its neighbourhood is associated with a negatively semantics. However, in terms of item-level, it is highly unlike that a user has only made poor purchases on the site and hence, its more likely that the items profile develop should have a mix of good and possibly poor semantics. This ensures that we will have positive recommendations generated if we were to implement a treshold of sort, to ensure that the average/weighted average rating of the products meets an initial criteria for recommendations."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=28937), Label(value='0 / 28937')))…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3c792367beb44e09e93c198d456da6c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Process ForkPoolWorker-37:\n",
      "Process ForkPoolWorker-38:\n",
      "Process ForkPoolWorker-36:\n",
      "Process ForkPoolWorker-32:\n",
      "Process ForkPoolWorker-35:\n",
      "Process ForkPoolWorker-34:\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mclosure\u001b[0;34m(data, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             results = get_workers_result(\n\u001b[0m\u001b[1;32m    454\u001b[0m                 \u001b[0muse_memory_fs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                 \u001b[0mnb_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandarallel/pandarallel.py\u001b[0m in \u001b[0;36mget_workers_result\u001b[0;34m(use_memory_fs, nb_workers, show_progress_bar, nb_columns, queue, chunk_lengths, input_files, output_files, map_result)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mmessage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmessage_type\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mINPUT_FILE_READ\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/managers.py\u001b[0m in \u001b[0;36m_callmethod\u001b[0;34m(self, methodname, args, kwds)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'#RETURN'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenizng the `processedReviewText`\n",
    "train['tokenizedReviewText'] = train['processedReviewText'].parallel_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "source": [
    "## 2.2 Preparing `item-level` tagged documents"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, item_documents = preprocessing.prepare_tagged_documents(users='reviewerID', asins='asin', reviews='tokenizedReviewText', df=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(item_documents[:10])"
   ]
  },
  {
   "source": [
    "## 2.3 Training `Doc2Vec` model\n",
    "\n",
    "We will be training a `Doc2Vec` model with initial hyperparameters decided based on a study by [Caselles-Dupré, Lesaint, and Royo-Letelier (2018)](https://arxiv.org/abs/1804.04212), where they observed that `negative sampling distribution`, `number of epochs`, `subsampling parameter` and `window size` can significantly improve performance on recommendation tasks. Hence, we will have decided to start with values that similar to those presented in the studies as the basis for improvement during this project."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(message)s')\n",
    "\n",
    "# model parameters\n",
    "VECTOR_SIZE = 150\n",
    "MIN_COUNT = 10\n",
    "NEGATIVE = 5\n",
    "NS_EXPONENT = 0.5\n",
    "SAMPLE = 1e-05\n",
    "DM = 1\n",
    "WORKERS = 8\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    negative=NEGATIVE,\n",
    "    sample=SAMPLE,\n",
    "    ns_exponent=NS_EXPONENT,\n",
    "    dm=DM,\n",
    "    workers=WORKERS,\n",
    ")\n",
    "\n",
    "# building vocab\n",
    "model.build_vocab(item_documents)\n",
    "\n",
    "# training model\n",
    "model.train(item_documents, total_examples=model.corpus_count, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "MODEL_PATH = Path(\"models/d2v/\")\n",
    "\n",
    "model.save(f\"{MODEL_PATH}/{CATEGORY}_{VECTOR_SIZE}_{SAMPLE}_{EPOCHS}_d2v.model\")"
   ]
  },
  {
   "source": [
    "## 2.4 Verifying Doc2Vec model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = Path(\"models/d2v/\")\n",
    "\n",
    "model = Doc2Vec.load(f\"{MODEL_PATH}/{CATEGORY}_{VECTOR_SIZE}_{SAMPLE}_{EPOCHS}_d2v.model\")"
   ]
  },
  {
   "source": [
    "### 2.4.1 Testing retrieval of vectors via index"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dv[0] # '0000031887'"
   ]
  },
  {
   "source": [
    "### 2.4.2 Testing retrieval of vectors via tags"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([i[1] for i in item_documents[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.dv['0000031887']"
   ]
  },
  {
   "source": [
    "### 2.4.3 Checking number of document vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of document vectors: {len(model.dv.index_to_key)}\")"
   ]
  },
  {
   "source": [
    "We observed that by calling the document vector via both index and actual tags returns the same vector. We also generated `23033` vectors that is aligned with the number of unique items we have in training data. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.5 Examining Doc2Vec results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.5.1 Are inferred vectors close to the precalculated ones?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to generate a random item id and infer its vector and compare if we can get similar items back\n",
    "random_asin = np.random.choice(list(train['asin'].unique()), 1)[0]\n",
    "\n",
    "# combining all the words from the all reviews\n",
    "all_review = []\n",
    "for review in train[train['asin'] == random_asin][\"tokenizedReviewText\"]:\n",
    "    all_review.extend(review)\n",
    "\n",
    "# inferring vector\n",
    "print(f\"For item {random_asin}...\\n\")\n",
    "print(f'Most similar D2V vectors: {model.dv.most_similar([model.infer_vector(all_review, epochs=5)], topn=5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to generate a random item id and infer its vector and compare if we can get similar items back\n",
    "random_asin = np.random.choice(list(train['asin'].unique()), 1)[0]\n",
    "\n",
    "# combining all the words from the all reviews\n",
    "all_review = []\n",
    "for review in train[train['asin'] == random_asin][\"tokenizedReviewText\"]:\n",
    "    all_review.extend(review)\n",
    "\n",
    "# inferring vector\n",
    "print(f\"For item {random_asin}...\\n\")\n",
    "print(f'Most similar D2V vectors: {model.dv.most_similar([model.infer_vector(all_review, epochs=5)], topn=5)}')"
   ]
  },
  {
   "source": [
    "We are able to verify that by using the same tokens used for training, we were able to still infer accurate vectors from the model."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2.5.2 Generating top-N recommendations based on aggregated item history\n",
    "\n",
    "As mentioned previously, we wanted to generate recommendations based on item-level instead of user-level due to the fact that user's nature is dynamic. What user like now, might not be the same a few days or weeks later. However, on a item perspective, if an item is good, general public who purchased the item should have positive feedback. The nature of the item profile should not vary as much as it would on a user-level. \n",
    "\n",
    "Hence, instead of building a user profile based on the reviews that the user has given, instead, we will build an *aggregated* item history profile based on the past purchase history of the users. A simplification of the algorithm would be:\n",
    "\n",
    "1. Identify the list of items previously purchased by a user\n",
    "2. Using the Doc2Vec model trained on unique tags based on `asin`, we mean-aggregate the item's document vectors to produce a aggregate item purchase history vector\n",
    "3. Using the aggregated item purchase history vector, we find the top-N, 10, recommendations while excluding previously purchased item and setting a treshold for the mean/weighted-mean rating of the recommended items to ensure that items purchase is popular among others as well."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to figure how to define a treshold\n",
    "def get_top_n(user, n=10, threshold=4):\n",
    "\n",
    "    # retrieving user's purchase history\n",
    "    purchase_history = train.groupby(['reviewerID'])['asin'].apply(list)[user]\n",
    "\n",
    "    purchase_history_vec = np.zeros(150)\n",
    "    for item in purchase_history:\n",
    "        purchase_history_vec += model.dv[item]\n",
    "    # mean aggregation\n",
    "    purchase_history_vec /= len(purchase_history)\n",
    "\n",
    "    return [i[0] for i in model.dv.most_similar([purchase_history_vec], topn=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "# looking at user records\n",
    "pprint(train[train['reviewerID'] == random_user][[\"asin\", \"reviewText\"]])\n",
    "\n",
    "print(f\"\\nFor user {random_user}...\\n\")\n",
    "print(f'Most similar item D2V vectors: {get_top_n(random_user)}')"
   ]
  },
  {
   "source": [
    "The example of recommendation above where user `A2OSOO0NRPLZRH`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3. Computing Metrics\n",
    "\n",
    "Now that we are able to generate recommendations for users, we are going to compute metrics to better evaluate our model with existing techniques used in recommendations for comparison. \n",
    "\n",
    "We will be using the following metrics:\n",
    "\n",
    "1. `Precision@K`: Proportion of recommendations that are relevant (which means that items that users has already make a purchase before).\n",
    "2. `Recall@K`: Proportion of relevant recommendations retrieved.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let take a look at our testing set \n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the purchase history of users in the testing set\n",
    "test_purchase_history = test.groupby(['reviewerID'])['asin'].apply(list).to_frame().reset_index()\n",
    "\n",
    "pprint(test_purchase_history.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_purchase_history['reviewerID'].parallel_apply(get_top_n)"
   ]
  }
 ]
}