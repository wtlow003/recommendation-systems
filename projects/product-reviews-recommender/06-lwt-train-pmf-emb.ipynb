{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import surprise\n",
    "\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load processed data pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = Path('data/processed/')\n",
    "CATEGORY = 'Sports_and_Outdoors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2242666, 8)\n",
      "Test: (434692, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {train.shape}\")\n",
    "print(f\"Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 2242666 ratings.\n",
      "The number of unique users we have is: 332231.\n",
      "The number of unique items we have is: 104536\n",
      "The median user rated 5.0 items.\n",
      "The max rating is 5.0, the min rating is 1.0.\n"
     ]
    }
   ],
   "source": [
    "# summary\n",
    "print(f\"We have {train.shape[0]} ratings.\")\n",
    "print(f\"The number of unique users we have is: {train['reviewerID'].nunique()}.\")\n",
    "print(f\"The number of unique items we have is: {train['asin'].nunique()}\")\n",
    "print(f\"The median user rated {train['reviewerID'].value_counts().median()} items.\")\n",
    "print(f\"The max rating is {max(train['overall'])}, the min rating is {min(train['overall'])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preparing the dataset for training with `Surprise`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need swap columns in the following order: `reviewerID`, `asin`, `overall`\n",
    "train = train[['reviewerID', 'asin', 'overall']]\n",
    "reader = surprise.Reader(rating_scale=(1.0,5.0))\n",
    "data = surprise.Dataset.load_from_df(train, reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg user/item mapping\n",
    "MAP_PATH = Path(\"data/processed/mappings/\")\n",
    "agg_user_vectors = np.load(f'{MAP_PATH}/{CATEGORY}_agg_user_vectors.npy', allow_pickle=True).item()\n",
    "agg_prod_vectors = np.load(f'{MAP_PATH}/{CATEGORY}_agg_prod_vectors.npy', allow_pickle=True).item()\n",
    "\n",
    "# user/item index mapping\n",
    "train_user_index_map = np.load(f'{MAP_PATH}/{CATEGORY}_train_user_index_map.npy', allow_pickle=True).item()\n",
    "train_prod_index_map = np.load(f'{MAP_PATH}/{CATEGORY}_train_prod_index_map.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviewerID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A2ERDJDHL5250E</th>\n",
       "      <td>-0.001393</td>\n",
       "      <td>0.010706</td>\n",
       "      <td>0.057688</td>\n",
       "      <td>0.032961</td>\n",
       "      <td>0.055388</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>-0.008693</td>\n",
       "      <td>-0.046846</td>\n",
       "      <td>0.082394</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>-0.072811</td>\n",
       "      <td>0.075028</td>\n",
       "      <td>-0.031598</td>\n",
       "      <td>0.013310</td>\n",
       "      <td>-0.084575</td>\n",
       "      <td>-0.052641</td>\n",
       "      <td>0.133030</td>\n",
       "      <td>-0.047659</td>\n",
       "      <td>-0.114660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3OT1IGGIRP4SX</th>\n",
       "      <td>0.042955</td>\n",
       "      <td>0.003859</td>\n",
       "      <td>-0.021228</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>-0.021593</td>\n",
       "      <td>-0.009716</td>\n",
       "      <td>-0.072479</td>\n",
       "      <td>0.054780</td>\n",
       "      <td>0.042466</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031440</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>0.037963</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>0.071702</td>\n",
       "      <td>0.025748</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.015087</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>-0.011319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AV7OE2XLHXNAX</th>\n",
       "      <td>-0.017765</td>\n",
       "      <td>-0.024089</td>\n",
       "      <td>-0.003950</td>\n",
       "      <td>-0.007635</td>\n",
       "      <td>-0.019528</td>\n",
       "      <td>-0.006370</td>\n",
       "      <td>-0.022975</td>\n",
       "      <td>0.025297</td>\n",
       "      <td>-0.015457</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005269</td>\n",
       "      <td>0.039201</td>\n",
       "      <td>0.021330</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.047936</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>-0.018338</td>\n",
       "      <td>0.020829</td>\n",
       "      <td>-0.014701</td>\n",
       "      <td>-0.012528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3JXYXZHH8MXEL</th>\n",
       "      <td>0.029713</td>\n",
       "      <td>-0.093453</td>\n",
       "      <td>0.094964</td>\n",
       "      <td>-0.079168</td>\n",
       "      <td>-0.044471</td>\n",
       "      <td>0.012140</td>\n",
       "      <td>-0.125511</td>\n",
       "      <td>0.029961</td>\n",
       "      <td>-0.088458</td>\n",
       "      <td>0.018941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009258</td>\n",
       "      <td>0.093152</td>\n",
       "      <td>-0.051942</td>\n",
       "      <td>0.033540</td>\n",
       "      <td>0.190262</td>\n",
       "      <td>0.025575</td>\n",
       "      <td>-0.043788</td>\n",
       "      <td>0.063773</td>\n",
       "      <td>-0.012849</td>\n",
       "      <td>-0.120540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2W6QWMWVYS5JR</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.168407</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.029849</td>\n",
       "      <td>0.100621</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>-0.093841</td>\n",
       "      <td>0.075829</td>\n",
       "      <td>-0.025472</td>\n",
       "      <td>0.212360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086917</td>\n",
       "      <td>0.055823</td>\n",
       "      <td>-0.030929</td>\n",
       "      <td>0.055677</td>\n",
       "      <td>0.049179</td>\n",
       "      <td>0.067016</td>\n",
       "      <td>0.046185</td>\n",
       "      <td>0.052996</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>-0.025873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0         1         2         3         4         5    \\\n",
       "reviewerID                                                                   \n",
       "A2ERDJDHL5250E -0.001393  0.010706  0.057688  0.032961  0.055388  0.004883   \n",
       "A3OT1IGGIRP4SX  0.042955  0.003859 -0.021228  0.035249 -0.021593 -0.009716   \n",
       "AV7OE2XLHXNAX  -0.017765 -0.024089 -0.003950 -0.007635 -0.019528 -0.006370   \n",
       "A3JXYXZHH8MXEL  0.029713 -0.093453  0.094964 -0.079168 -0.044471  0.012140   \n",
       "A2W6QWMWVYS5JR -0.000132 -0.168407  0.001205  0.029849  0.100621  0.006307   \n",
       "\n",
       "                     6         7         8         9    ...       140  \\\n",
       "reviewerID                                              ...             \n",
       "A2ERDJDHL5250E -0.008693 -0.046846  0.082394 -0.010865  ...  0.008918   \n",
       "A3OT1IGGIRP4SX -0.072479  0.054780  0.042466  0.015016  ...  0.031440   \n",
       "AV7OE2XLHXNAX  -0.022975  0.025297 -0.015457  0.008040  ... -0.005269   \n",
       "A3JXYXZHH8MXEL -0.125511  0.029961 -0.088458  0.018941  ... -0.009258   \n",
       "A2W6QWMWVYS5JR -0.093841  0.075829 -0.025472  0.212360  ...  0.086917   \n",
       "\n",
       "                     141       142       143       144       145       146  \\\n",
       "reviewerID                                                                   \n",
       "A2ERDJDHL5250E -0.072811  0.075028 -0.031598  0.013310 -0.084575 -0.052641   \n",
       "A3OT1IGGIRP4SX  0.022644  0.037963 -0.000707  0.071702  0.025748  0.004151   \n",
       "AV7OE2XLHXNAX   0.039201  0.021330  0.016538  0.047936 -0.010439 -0.018338   \n",
       "A3JXYXZHH8MXEL  0.093152 -0.051942  0.033540  0.190262  0.025575 -0.043788   \n",
       "A2W6QWMWVYS5JR  0.055823 -0.030929  0.055677  0.049179  0.067016  0.046185   \n",
       "\n",
       "                     147       148       149  \n",
       "reviewerID                                    \n",
       "A2ERDJDHL5250E  0.133030 -0.047659 -0.114660  \n",
       "A3OT1IGGIRP4SX  0.015087  0.005266 -0.011319  \n",
       "AV7OE2XLHXNAX   0.020829 -0.014701 -0.012528  \n",
       "A3JXYXZHH8MXEL  0.063773 -0.012849 -0.120540  \n",
       "A2W6QWMWVYS5JR  0.052996  0.048270 -0.025873  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_user_index = pd.DataFrame.from_dict(train_user_index_map, orient='index')\n",
    "train_user_index.columns = ['reviewerID']\n",
    "\n",
    "train_user_vectors = pd.DataFrame.from_dict(agg_user_vectors, orient='index')\n",
    "\n",
    "# merging user vector and their D2V vectors\n",
    "user_factors = pd.merge(train_user_index, train_user_vectors, left_index=True, right_index=True).set_index('reviewerID')\n",
    "# user_factors.to_csv(\"user_factors.csv\")\n",
    "user_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asin</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B00XVGXGB0</th>\n",
       "      <td>-0.028735</td>\n",
       "      <td>-0.056108</td>\n",
       "      <td>-0.032460</td>\n",
       "      <td>0.008095</td>\n",
       "      <td>-0.011243</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>-0.037507</td>\n",
       "      <td>0.033322</td>\n",
       "      <td>-0.015832</td>\n",
       "      <td>0.026648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>0.039632</td>\n",
       "      <td>0.029524</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.077395</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.030874</td>\n",
       "      <td>0.033687</td>\n",
       "      <td>0.011769</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B004R7G33K</th>\n",
       "      <td>-0.033160</td>\n",
       "      <td>-0.049536</td>\n",
       "      <td>-0.007573</td>\n",
       "      <td>-0.036987</td>\n",
       "      <td>-0.009941</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>-0.023759</td>\n",
       "      <td>0.044294</td>\n",
       "      <td>-0.009924</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037824</td>\n",
       "      <td>0.054730</td>\n",
       "      <td>-0.004647</td>\n",
       "      <td>0.061898</td>\n",
       "      <td>0.057449</td>\n",
       "      <td>0.016520</td>\n",
       "      <td>-0.037705</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>-0.016702</td>\n",
       "      <td>-0.019501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B00TK31ZY8</th>\n",
       "      <td>-0.090267</td>\n",
       "      <td>-0.073928</td>\n",
       "      <td>0.045832</td>\n",
       "      <td>-0.022734</td>\n",
       "      <td>-0.010380</td>\n",
       "      <td>-0.085362</td>\n",
       "      <td>-0.188818</td>\n",
       "      <td>0.041648</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>0.029686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094035</td>\n",
       "      <td>0.077640</td>\n",
       "      <td>0.067982</td>\n",
       "      <td>0.060320</td>\n",
       "      <td>0.172293</td>\n",
       "      <td>-0.024297</td>\n",
       "      <td>-0.102928</td>\n",
       "      <td>0.085987</td>\n",
       "      <td>0.109246</td>\n",
       "      <td>0.005954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0016PM67I</th>\n",
       "      <td>-0.037176</td>\n",
       "      <td>-0.054300</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.018531</td>\n",
       "      <td>-0.015814</td>\n",
       "      <td>-0.044274</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>-0.034617</td>\n",
       "      <td>0.050554</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019872</td>\n",
       "      <td>0.055698</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.017568</td>\n",
       "      <td>0.084163</td>\n",
       "      <td>-0.009300</td>\n",
       "      <td>-0.037548</td>\n",
       "      <td>0.049070</td>\n",
       "      <td>-0.013736</td>\n",
       "      <td>-0.005158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B01D3ID6S8</th>\n",
       "      <td>-0.026588</td>\n",
       "      <td>-0.058351</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>-0.003730</td>\n",
       "      <td>-0.002862</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.023442</td>\n",
       "      <td>0.012216</td>\n",
       "      <td>-0.044792</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012459</td>\n",
       "      <td>0.100076</td>\n",
       "      <td>0.042812</td>\n",
       "      <td>0.040686</td>\n",
       "      <td>0.058932</td>\n",
       "      <td>-0.008527</td>\n",
       "      <td>-0.028917</td>\n",
       "      <td>0.047138</td>\n",
       "      <td>-0.032607</td>\n",
       "      <td>0.025038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1         2         3         4         5    \\\n",
       "asin                                                                     \n",
       "B00XVGXGB0 -0.028735 -0.056108 -0.032460  0.008095 -0.011243  0.003498   \n",
       "B004R7G33K -0.033160 -0.049536 -0.007573 -0.036987 -0.009941  0.000644   \n",
       "B00TK31ZY8 -0.090267 -0.073928  0.045832 -0.022734 -0.010380 -0.085362   \n",
       "B0016PM67I -0.037176 -0.054300  0.003290  0.000629 -0.018531 -0.015814   \n",
       "B01D3ID6S8 -0.026588 -0.058351  0.032157 -0.003730 -0.002862  0.005076   \n",
       "\n",
       "                 6         7         8         9    ...       140       141  \\\n",
       "asin                                                ...                       \n",
       "B00XVGXGB0 -0.037507  0.033322 -0.015832  0.026648  ... -0.000462  0.039632   \n",
       "B004R7G33K -0.023759  0.044294 -0.009924  0.006038  ... -0.037824  0.054730   \n",
       "B00TK31ZY8 -0.188818  0.041648  0.032018  0.029686  ...  0.094035  0.077640   \n",
       "B0016PM67I -0.044274  0.026129 -0.034617  0.050554  ... -0.019872  0.055698   \n",
       "B01D3ID6S8  0.023442  0.012216 -0.044792  0.043934  ... -0.012459  0.100076   \n",
       "\n",
       "                 142       143       144       145       146       147  \\\n",
       "asin                                                                     \n",
       "B00XVGXGB0  0.029524  0.015292  0.077395  0.001761 -0.030874  0.033687   \n",
       "B004R7G33K -0.004647  0.061898  0.057449  0.016520 -0.037705  0.024926   \n",
       "B00TK31ZY8  0.067982  0.060320  0.172293 -0.024297 -0.102928  0.085987   \n",
       "B0016PM67I  0.017198  0.017568  0.084163 -0.009300 -0.037548  0.049070   \n",
       "B01D3ID6S8  0.042812  0.040686  0.058932 -0.008527 -0.028917  0.047138   \n",
       "\n",
       "                 148       149  \n",
       "asin                            \n",
       "B00XVGXGB0  0.011769  0.000154  \n",
       "B004R7G33K -0.016702 -0.019501  \n",
       "B00TK31ZY8  0.109246  0.005954  \n",
       "B0016PM67I -0.013736 -0.005158  \n",
       "B01D3ID6S8 -0.032607  0.025038  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prod_index = pd.DataFrame.from_dict(train_prod_index_map, orient='index')\n",
    "train_prod_index.columns = ['asin']\n",
    "\n",
    "train_prod_vectors = pd.DataFrame.from_dict(agg_prod_vectors, orient='index')\n",
    "\n",
    "# merging prod vector and their D2V vectors\n",
    "prod_factors = pd.merge(train_prod_index, train_prod_vectors, left_index=True, right_index=True).set_index('asin')\n",
    "# prod_factors.to_csv(\"prod_factors.csv\")\n",
    "prod_factors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting locating by `reviewerID` \n",
    "user_factors = user_factors.to_numpy()\n",
    "prod_factors = prod_factors.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00139326,  0.01070629,  0.05768845,  0.0329612 ,  0.0553879 ,\n",
       "         0.00488296, -0.00869327, -0.04684592,  0.0823941 , -0.0108649 ,\n",
       "         0.07763122, -0.02126908, -0.00717102, -0.04491281, -0.0852215 ,\n",
       "        -0.00361429,  0.00978789,  0.02764019,  0.0751814 ,  0.03089333,\n",
       "         0.04117684, -0.02936736, -0.03353109, -0.0487733 , -0.02659133,\n",
       "         0.02188961,  0.05667667, -0.07675944, -0.0991408 , -0.04386722,\n",
       "        -0.0236766 , -0.03231909,  0.01497382,  0.06736004, -0.1045417 ,\n",
       "         0.06539939, -0.01146153, -0.08201144, -0.01348285, -0.10803379,\n",
       "        -0.00763431, -0.01746873,  0.09882042,  0.07719737,  0.02758413,\n",
       "        -0.00700441, -0.06778047, -0.0578411 ,  0.05345424,  0.01154411,\n",
       "        -0.0755935 , -0.01014541,  0.10010977,  0.02350248, -0.03878367,\n",
       "        -0.07902477, -0.05026945, -0.05100492, -0.01060421, -0.03957319,\n",
       "        -0.02523186,  0.00523646, -0.07418991,  0.04406072,  0.00268527,\n",
       "         0.05271197, -0.0352231 ,  0.00733327,  0.00331961,  0.02317442,\n",
       "         0.04906564,  0.04225339,  0.08344623, -0.02857191,  0.00388061,\n",
       "        -0.03126608, -0.02890796, -0.01002211, -0.1031754 ,  0.05831686,\n",
       "         0.11110176, -0.13641866, -0.02697527,  0.00436807,  0.05482035,\n",
       "        -0.08237004,  0.00865884,  0.00792007, -0.12876996,  0.08013881,\n",
       "         0.0777422 , -0.0297273 ,  0.00220407, -0.08916748, -0.02256253,\n",
       "        -0.06558468, -0.01798971, -0.05167177,  0.04767198,  0.05228603,\n",
       "        -0.04017848, -0.00878159, -0.00228229, -0.04664595,  0.06961929,\n",
       "         0.06870424,  0.02797105,  0.08851707, -0.1199593 , -0.05738958,\n",
       "         0.07131932, -0.04998273, -0.03903536, -0.01681228, -0.00705189,\n",
       "        -0.02398796,  0.00494353, -0.12747182,  0.00547961,  0.05053347,\n",
       "        -0.00335942, -0.04575219,  0.14068187,  0.03538465, -0.00341955,\n",
       "         0.01036991,  0.02622952,  0.11283531, -0.10311464, -0.02447872,\n",
       "         0.07438649,  0.0081372 ,  0.11549204,  0.05859112,  0.01203137,\n",
       "        -0.00390903,  0.065967  , -0.07396609,  0.01951582, -0.06820827,\n",
       "         0.00891796, -0.07281065,  0.07502765, -0.03159809,  0.01330973,\n",
       "        -0.08457519, -0.05264129,  0.13303022, -0.04765933, -0.11466035]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.028735  , -0.05610809, -0.03246031,  0.00809488, -0.01124282,\n",
       "         0.00349831, -0.03750717,  0.03332187, -0.01583213,  0.0266481 ,\n",
       "        -0.05674835,  0.02126554, -0.02077972, -0.00088326, -0.04692468,\n",
       "        -0.03824457,  0.06779764, -0.00106158, -0.00204537,  0.03976614,\n",
       "        -0.0072909 ,  0.00621938, -0.00539656, -0.0202763 ,  0.03027143,\n",
       "        -0.00676155, -0.02396085,  0.01934781, -0.04280524, -0.00847415,\n",
       "         0.02121852, -0.011075  ,  0.00964169, -0.00404767, -0.03746314,\n",
       "        -0.04091518, -0.02265925,  0.00279981, -0.01768054, -0.05730085,\n",
       "        -0.00446327,  0.00063171, -0.00562225,  0.0249576 , -0.02717521,\n",
       "         0.03735483, -0.00190488, -0.01923786, -0.0243962 ,  0.03877954,\n",
       "        -0.04356486,  0.04290394, -0.01410717, -0.00746643,  0.00715857,\n",
       "         0.0245075 , -0.04210267,  0.00834428,  0.00451602, -0.00280327,\n",
       "        -0.02343168, -0.03064212, -0.05588719,  0.03104548,  0.04021582,\n",
       "         0.0024844 ,  0.03063204,  0.01558907, -0.059092  ,  0.0598966 ,\n",
       "         0.01711169,  0.02289857,  0.05088942, -0.0058041 , -0.01696857,\n",
       "         0.00276749,  0.0296821 , -0.03278557, -0.0581846 ,  0.02064305,\n",
       "         0.05794271, -0.02385188,  0.0108151 , -0.01232058,  0.03142855,\n",
       "         0.01127662, -0.02319966, -0.05641455, -0.00785272,  0.05173154,\n",
       "         0.02144575, -0.00447865, -0.00610806, -0.00297505, -0.00386226,\n",
       "         0.04873746,  0.00622788,  0.03792583, -0.01910644,  0.01484181,\n",
       "         0.02796668,  0.02425131,  0.03761956,  0.05655655,  0.03474843,\n",
       "        -0.01709548,  0.0140258 ,  0.0269658 , -0.02004877,  0.00847159,\n",
       "         0.00467931,  0.02229841, -0.00850716, -0.04188399,  0.02161829,\n",
       "         0.01612055,  0.01939596, -0.01831255,  0.01376771, -0.01846482,\n",
       "        -0.01565539, -0.0202114 , -0.01951874, -0.04926021,  0.01503871,\n",
       "        -0.03684447,  0.04951441,  0.04391941,  0.00285228, -0.06268819,\n",
       "        -0.01285511,  0.03145272, -0.01581298,  0.04035699,  0.00383747,\n",
       "        -0.05178141,  0.00537396, -0.02423435, -0.00252947, -0.0464311 ,\n",
       "        -0.00046154,  0.03963195,  0.02952353,  0.01529238,  0.07739462,\n",
       "         0.00176139, -0.03087429,  0.03368666,  0.01176916,  0.00015368]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_factors[:1,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving user and item embeddings as initialized latent factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(message)s',\n",
    "                    handlers=[logging.FileHandler(\"epmf.log\"),\n",
    "                              logging.StreamHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddedPMF(surprise.AlgoBase):\n",
    "    \"\"\"Latent factors of users and items are generated based off D2V embedding vectors.\n",
    "       This in turns, allows us to create `P` and `Q` without needing random initialization.\n",
    "    \"\"\"\n",
    "    def __init__(self, user_map, item_map, user_factor, item_factor, learning_rate, num_epochs, num_factors):\n",
    "        surprise.AlgoBase.__init__(self)\n",
    "        self.user_map = dict((v,k) for k,v in user_map.items())\n",
    "        self.item_map = dict((v,k) for k,v in item_map.items())\n",
    "        self.user_embedding = user_factor\n",
    "        self.item_embedding = item_factor\n",
    "        self.alpha = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_factors = num_factors\n",
    "\n",
    "    def fit(self, train):\n",
    "        # Instead of random initialization n-latent factors,\n",
    "        # We initialiazed the latent factors using the D2V aggregated embedding vectors\n",
    "        # By both user and items, where each embedding is represented by the content\n",
    "        # of their reviews.\n",
    "        # This is based on the idea: https://doi.org/10.1145/3383313.3412207\n",
    "        # Where they initialized the latent factor models using topic vectors generated\n",
    "        # through NMF.\n",
    "        surprise.AlgoBase.fit(self, train)\n",
    "        P = self.user_embedding\n",
    "        Q = self.item_embedding\n",
    "\n",
    "        for epoch in tqdm(range(self.num_epochs)):\n",
    "            for u, i, r_ui in train.all_ratings():\n",
    "                # retrieving raw uid, iid\n",
    "                raw_uid = trainset.to_raw_uid(u)\n",
    "                raw_iid = trainset.to_raw_iid(i)\n",
    "\n",
    "                # locating the index of the user/item vector\n",
    "                user_map_index = self.user_map[raw_uid]\n",
    "                item_map_index = self.item_map[raw_iid]\n",
    "\n",
    "                # casting to np.float128 to prevent memory overflow\n",
    "                residual = r_ui - np.dot(np.array(P[user_map_index], dtype=np.float128), np.array(Q[item_map_index], dtype=np.float128))\n",
    "                temp = np.array(P[user_map_index,:], dtype=np.float128)\n",
    "                P[user_map_index,:] = np.array(P[user_map_index,:], dtype=np.float128) + self.alpha * residual * np.array(Q[item_map_index], dtype=np.float128)\n",
    "                Q[item_map_index,:] = np.array(Q[item_map_index,:], dtype=np.float128) + self.alpha * residual * temp\n",
    "\n",
    "            \n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "\n",
    "        self.trainset = train\n",
    "\n",
    "    def estimate(self, u, i):\n",
    "        \"\"\"Returns estimated rating for user u, and item i.\n",
    "\n",
    "           Prerequisite: Algorithm must be fit to training set.\n",
    "        \"\"\"\n",
    "        if self.trainset.knows_user(u) and self.trainset.knows_item(i):\n",
    "            nanCheck = np.dot(self.P[u], self.Q[i])\n",
    "\n",
    "            if np.isnan(nanCheck):\n",
    "                return self.trainset.global_mean\n",
    "            else:\n",
    "                return np.dot(self.P[u,:], self.Q[i,:])\n",
    "        else:\n",
    "            return self.trainset.global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epmf = EmbeddedPMF(train_user_index_map, train_prod_index_map, user_factors, prod_factors, 0.025, 5, 10)\n",
    "epmf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random rating for a user given a product\n",
    "random_user_index = np.random.randint(0, len(train_user_index_map))\n",
    "random_prod_index = np.random.randint(0, len(train_prod_index_map))\n",
    "random_user = train_user_index_map[random_prod_index]\n",
    "random_prod = train_prod_index_map[random_prod_index]\n",
    "\n",
    "print(f\"User: {random_user}, {trainset.to_inner_uid(random_user)}\")\n",
    "print(f\"Product: {random_prod}, {trainset.to_inner_iid(random_prod)}\")\n",
    "\n",
    "print(f\"Estimated rating is: {epmf.estimate(trainset.to_inner_uid(random_user), trainset.to_inner_iid(random_prod))}\")\n",
    "print(f\"Estimated rating is: {epmf.estimate(5000000, 5000000000)}\\n\")    # not available, hence return global mean\n",
    "# train[train['asin'] == random_prod][['asin', 'title', 'brand', 'overall',]].groupby(['asin', 'title', 'brand']).agg({'overall': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['reviewerID'] == 'A3MC5PWXS2FG5M'][['asin', 'title', 'brand', 'overall']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.model_selection.cross_validate(epmf, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running baseline `SVD` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x14e3e2fd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = surprise.SVD(n_factors=150, lr_all=0.05, reg_all=0.01, n_epochs=1, verbose=True)\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281666\n",
      "19448\n",
      "Estimated rating is: 4.9303075092797854\n"
     ]
    }
   ],
   "source": [
    "# generate a random rating for a user given a product\n",
    "random_user_index = np.random.randint(0, len(train_user_index_map))\n",
    "random_prod_index = np.random.randint(0, len(train_prod_index_map))\n",
    "random_user = train_user_index_map[random_prod_index]\n",
    "random_prod = train_prod_index_map[random_prod_index]\n",
    "\n",
    "print(trainset.to_inner_uid(random_user))\n",
    "print(trainset.to_inner_iid(random_prod))\n",
    "\n",
    "print(f\"Estimated rating is: {svd.estimate(trainset.to_inner_uid(random_user), trainset.to_inner_iid(random_prod))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise.model_selection.cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining matrix factorization with `regularisation` and `biases`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check if I can numba this class with @jitclass or @jit\n",
    "class EmbeddedMF(surprise.AlgoBase):\n",
    "    \"\"\"Latent factors of users and items are generated based off D2V embedding vectors.\n",
    "       This in turns, allows us to create `P` and `Q` without needing random initialization.\n",
    "\n",
    "        Args:\n",
    "            user_map ([dict]): Index-User mapping.\n",
    "            item_map ([dict]): Index-Item mapping.\n",
    "            user_factors ([np.array]): Predefined user latent factors initialized using Doc2Vec embeddings.\n",
    "            item_factors ([np.array]): Predefined item latent factors initialized using Doc2Vec embeddings.\n",
    "            learning_rate ([float]):\n",
    "            beta ([float]):\n",
    "            num_epochs ([int]): Number of training iterations.\n",
    "\n",
    "        Returns:\n",
    "            ([None]): Initialized model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        user_map,\n",
    "        item_map,\n",
    "        user_factor,\n",
    "        item_factor,\n",
    "        learning_rate,\n",
    "        beta,\n",
    "        num_epochs,\n",
    "        num_factors\n",
    "    ):\n",
    "        surprise.AlgoBase.__init__(self)\n",
    "        self.user_map = {v: k for k, v in user_map.items()}\n",
    "        self.item_map = {v: k for k, v in item_map.items()}\n",
    "        self.user_embedding = user_factor\n",
    "        self.item_embedding = item_factor\n",
    "        self.alpha = learning_rate\n",
    "        self.beta = beta\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_factors = num_factors\n",
    "\n",
    "    def fit(self, train):\n",
    "        # Instead of random initialization n-latent factors,\n",
    "        # We initialiazed the latent factors using the D2V aggregated embedding vectors\n",
    "        # By both user and items, where each embedding is represented by the content\n",
    "        # of their reviews.\n",
    "        # This is based on the idea: https://doi.org/10.1145/3383313.3412207\n",
    "        # Where they initialized the latent factor models using topic vectors generated\n",
    "        # through NMF.\n",
    "        surprise.AlgoBase.fit(self, train)\n",
    "        P = self.user_embedding\n",
    "        Q = self.item_embedding\n",
    "        bias_u = np.zeros(len(self.user_embedding))\n",
    "        bias_i = np.zeros(len(self.item_embedding))\n",
    "        bias_global = train.global_mean\n",
    "\n",
    "        for _ in tqdm(range(self.num_epochs)):\n",
    "            for u, i, r_ui in train.all_ratings():\n",
    "                # retrieving raw uid, iid from iid\n",
    "                raw_uid = train.to_raw_uid(u)\n",
    "                raw_iid = train.to_raw_iid(i)\n",
    "\n",
    "                # locating the index of the user/item vector\n",
    "                ui = self.user_map[raw_uid]\n",
    "                ii = self.item_map[raw_iid]\n",
    "\n",
    "                # compute current error\n",
    "                dot = 0 # <P_u, Q_i>\n",
    "                for f in range(self.num_factors):\n",
    "                    dot += P[ui, f] * Q[ii, f]\n",
    "                err = r_ui - (bias_global + bias_u[ui] + bias_i[ii] + dot)\n",
    "\n",
    "                # update biases\n",
    "                bias_u[ui] += self.alpha * (err - self.beta * bias_u[ui])\n",
    "                bias_i[ii] += self.alpha * (err - self.beta * bias_i[ii])\n",
    "\n",
    "                # update user and iten latent feature matrices\n",
    "                for f in range(self.num_factors):\n",
    "                    P_uf = P[ui, f]\n",
    "                    Q_if = Q[ii, f]\n",
    "                    P[ui, f] += self.alpha * (err * Q_if - self.beta * P_uf)\n",
    "                    Q[ii, f] += self.alpha * (err * P_uf - self.beta * Q_if)\n",
    "\n",
    "                # print(P[ui, :], Q[ii, :], sep='\\n')\n",
    "\n",
    "        self.P = P\n",
    "        self.Q = Q\n",
    "        self.bias_u = bias_u\n",
    "        self.bias_i = bias_i\n",
    "        self.trainset = train\n",
    "\n",
    "    def estimate(self, u, i, clip=True):\n",
    "        \"\"\"Returns estimated rating for user u, and item i.\n",
    "\n",
    "           Prerequisite: Algorithm must be fit to training set.\n",
    "        \"\"\"\n",
    "        known_user = self.trainset.knows_user(u)\n",
    "        known_item = self.trainset.knows_item(i)\n",
    "        \n",
    "        est = self.trainset.global_mean\n",
    "\n",
    "        if known_user:\n",
    "            est += self.bias_u[u]\n",
    "        \n",
    "        if known_item:\n",
    "            est += self.bias_i[i]\n",
    "\n",
    "        if known_user and known_item:\n",
    "            est += np.dot(self.P[u, :], self.Q[i, :])\n",
    "\n",
    "        if clip:\n",
    "            min_rating, max_rating = self.trainset.rating_scale\n",
    "            est = max_rating if est > max_rating else est\n",
    "            est = min_rating if est < min_rating else est\n",
    "\n",
    "        return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emf = EmbeddedMF(train_user_index_map, train_prod_index_map, user_factors, prod_factors, learning_rate=0.05, beta=0.01, num_epochs=5,  num_factors=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# takes about 10mins ~epoch\n",
    "emf.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ~30mins per cv-fold\n",
    "surprise.model_selection.cross_validate(emf, data, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random rating for a user given a product\n",
    "random_user_index = np.random.randint(0, len(train_user_index_map))\n",
    "random_prod_index = np.random.randint(0, len(train_prod_index_map))\n",
    "random_user = train_user_index_map[random_prod_index]\n",
    "random_prod = train_prod_index_map[random_prod_index]\n",
    "\n",
    "print(f\"User: {random_user}, {trainset.to_inner_uid(random_user)}\")\n",
    "print(f\"Product: {random_prod}, {trainset.to_inner_iid(random_prod)}\")\n",
    "\n",
    "print(f\"Estimated rating is: {emf.estimate(trainset.to_inner_uid(random_user), trainset.to_inner_iid(random_prod))}\")\n",
    "print(f\"Estimated rating is: {emf.estimate(5000000, 5000000000)}\\n\")    # not available, hence return global mean\n",
    "train[train['asin'] == random_prod][['asin', 'title', 'brand', 'overall',]].groupby(['asin', 'title', 'brand']).agg({'overall': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating top-N recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_n(predictions, n=5):\n",
    "\n",
    "    # first map the predictions to the user\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # sort predictions for each user and retrieve k highest ones\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_rating.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_rating[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1UUUZI6UL8LR</td>\n",
       "      <td>B00APXK61A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3RSKVYE1PV3M4</td>\n",
       "      <td>B0043M4MPK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BHQ6GAA60YPB</td>\n",
       "      <td>B00943971M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2OK32J1KDQ7F7</td>\n",
       "      <td>B00GL9WKE8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A10N7L0GMRODUO</td>\n",
       "      <td>B0055Q43XO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104531</th>\n",
       "      <td>AW1PCGDQSGC1B</td>\n",
       "      <td>B00B2PNHWK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104532</th>\n",
       "      <td>AMIP1FQNUYZ9S</td>\n",
       "      <td>B00070QE1W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104533</th>\n",
       "      <td>A1LR49AAUE0JIS</td>\n",
       "      <td>B00398FWLW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104534</th>\n",
       "      <td>AQPR0YGOZ6NXZ</td>\n",
       "      <td>B01CNDFS5I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104535</th>\n",
       "      <td>AYRJV2MD1LY1I</td>\n",
       "      <td>B000Q7V704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104536 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            reviewerID        asin\n",
       "0        A1UUUZI6UL8LR  B00APXK61A\n",
       "1       A3RSKVYE1PV3M4  B0043M4MPK\n",
       "2       A1BHQ6GAA60YPB  B00943971M\n",
       "3       A2OK32J1KDQ7F7  B00GL9WKE8\n",
       "4       A10N7L0GMRODUO  B0055Q43XO\n",
       "...                ...         ...\n",
       "104531   AW1PCGDQSGC1B  B00B2PNHWK\n",
       "104532   AMIP1FQNUYZ9S  B00070QE1W\n",
       "104533  A1LR49AAUE0JIS  B00398FWLW\n",
       "104534   AQPR0YGOZ6NXZ  B01CNDFS5I\n",
       "104535   AYRJV2MD1LY1I  B000Q7V704\n",
       "\n",
       "[104536 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get total unique items in train set\n",
    "uniq_train_items = set(train['asin'])\n",
    "# load test users\n",
    "uniq_test_users = set(test['reviewerID'])\n",
    "\n",
    "pd.DataFrame(list(zip(uniq_test_users, uniq_train_items)), columns=['reviewerID', 'asin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((x, y) for x in uniq_test_users for y in uniq_train_items)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
