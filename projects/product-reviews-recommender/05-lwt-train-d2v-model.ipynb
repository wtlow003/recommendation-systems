{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install pandas\n",
    "!pip install pandarallel\n",
    "!pip install numpy\n",
    "!pip install tqdm\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.similarities.annoy import AnnoyIndexer\n",
    "from pandarallel import pandarallel\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from src.features import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data\n",
    "\n",
    "Let's load the train/test data that we have processed previously. We will do a quick check on the shape of both datasets, and also visually inspect that the `processedReviewText` should still be `str` format – hence, we are required to tokenized it before parsing into the `Doc2Vec` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DATA_PATH = Path('data/processed/')\n",
    "CATEGORY = 'Clothing_Shoes_and_Jewelry'\n",
    "\n",
    "train = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_train.csv\")\n",
    "test = pd.read_csv(f\"{DATA_PATH}/{CATEGORY}_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (231491, 5), unique users: 39387, unique items: 23033\n",
      "Test: (47145, 5), unique users: 39380, unique items: 17949\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {train.shape}, unique users: {train.reviewerID.nunique()}, unique items: {train.asin.nunique()}\")\n",
    "print(f\"Test: {test.shape}, unique users: {test.reviewerID.nunique()}, unique items: {test.asin.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>this great tutu great price it look cheap glad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>buy yr old daughter dance class wore today tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>what daughters orange black white pink think b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A27UF1MSF3DB2</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>I received this today and I'm not a fan of it ...</td>\n",
       "      <td>receive today fan daughter think puffier look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A16GFPNVF4Y816</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Bought this as a backup to the regular ballet ...</td>\n",
       "      <td>bought backup regular ballet outfit daughter w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231486</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ACJT8MUC0LRF0</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>When I pack it looks like a disaster area in a...</td>\n",
       "      <td>when pack look like disaster area suitcase pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231487</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2DG63DN704LOI</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>I don't normally go ga-ga over a product very ...</td>\n",
       "      <td>normally ga ga product cub awesome help review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231488</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1UQBFCERIP7VJ</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>These are very nice packing cubes and the 18 x...</td>\n",
       "      <td>these nice packing cube laundry storage bag ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231489</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A22CW0ZHY3NJH8</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>I am on vacation with my family of four and th...</td>\n",
       "      <td>vacation family shacke pak set wonderful excep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231490</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A30VWT3R25QAVD</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>When I signed up to receive a free set of Shac...</td>\n",
       "      <td>when sign receive free set shacke pak review t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall      reviewerID        asin  \\\n",
       "0           5.0  A1KLRMWW2FWPL4  0000031887   \n",
       "1           5.0  A2G5TCU2WDFZ65  0000031887   \n",
       "2           5.0  A1RLQXYNCMWRWN  0000031887   \n",
       "3           4.0   A27UF1MSF3DB2  0000031887   \n",
       "4           5.0  A16GFPNVF4Y816  0000031887   \n",
       "231486      5.0   ACJT8MUC0LRF0  B00KKXCJQU   \n",
       "231487      5.0  A2DG63DN704LOI  B00KKXCJQU   \n",
       "231488      5.0  A1UQBFCERIP7VJ  B00KKXCJQU   \n",
       "231489      5.0  A22CW0ZHY3NJH8  B00KKXCJQU   \n",
       "231490      5.0  A30VWT3R25QAVD  B00KKXCJQU   \n",
       "\n",
       "                                               reviewText  \\\n",
       "0       This is a great tutu and at a really great pri...   \n",
       "1       I bought this for my 4 yr old daughter for dan...   \n",
       "2       What can I say... my daughters have it in oran...   \n",
       "3       I received this today and I'm not a fan of it ...   \n",
       "4       Bought this as a backup to the regular ballet ...   \n",
       "231486  When I pack it looks like a disaster area in a...   \n",
       "231487  I don't normally go ga-ga over a product very ...   \n",
       "231488  These are very nice packing cubes and the 18 x...   \n",
       "231489  I am on vacation with my family of four and th...   \n",
       "231490  When I signed up to receive a free set of Shac...   \n",
       "\n",
       "                                      processedReviewText  \n",
       "0       this great tutu great price it look cheap glad...  \n",
       "1       buy yr old daughter dance class wore today tim...  \n",
       "2       what daughters orange black white pink think b...  \n",
       "3       receive today fan daughter think puffier look ...  \n",
       "4       bought backup regular ballet outfit daughter w...  \n",
       "231486  when pack look like disaster area suitcase pac...  \n",
       "231487  normally ga ga product cub awesome help review...  \n",
       "231488  these nice packing cube laundry storage bag ni...  \n",
       "231489  vacation family shacke pak set wonderful excep...  \n",
       "231490  when sign receive free set shacke pak review t...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check train\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>we buy tutu get high review sturdy seemingly t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>thank halo heaven great product little girls m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2A2WZYLU528RO</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>My daughter has worn this skirt almost every d...</td>\n",
       "      <td>my daughter worn skirt day receive washer clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A34ATJR9KFIXL9</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Full and well stitched.  This tutu is a beauti...</td>\n",
       "      <td>full stitch this tutu beautiful purple color l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1MXJVYXE2QU6H</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Perfect for my budding grand daughter ballerin...</td>\n",
       "      <td>perfect bud grand daughter ballerina beautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47140</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2XX2A4OJCDNLZ</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>While balaclavas can be used for a variety of ...</td>\n",
       "      <td>while balaclavas variety thing use mainly late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47141</th>\n",
       "      <td>2.0</td>\n",
       "      <td>A34BZM6S9L7QI4</td>\n",
       "      <td>B00KGCLROK</td>\n",
       "      <td>These were a free sample for review.  I was ex...</td>\n",
       "      <td>these free sample review excite try unfortunat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47142</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A25C2M3QF9G7OQ</td>\n",
       "      <td>B00KGCLROK</td>\n",
       "      <td>These socks are very nicely made and quite com...</td>\n",
       "      <td>these sock nicely comfortable wear the grip do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47143</th>\n",
       "      <td>5.0</td>\n",
       "      <td>AEL6CQNQXONBX</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>This set of travel organizers includes four pi...</td>\n",
       "      <td>this set travel organizer include piece total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47144</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1EVV74UQYVKRY</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>I've been traveling back and forth to England ...</td>\n",
       "      <td>travel forth england pack way suitcases some p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall      reviewerID        asin  \\\n",
       "0          5.0   A8U3FAMSJVHS5  0000031887   \n",
       "1          5.0  A3GEOILWLK86XM  0000031887   \n",
       "2          5.0  A2A2WZYLU528RO  0000031887   \n",
       "3          5.0  A34ATJR9KFIXL9  0000031887   \n",
       "4          5.0  A1MXJVYXE2QU6H  0000031887   \n",
       "47140      5.0  A2XX2A4OJCDNLZ  B00KF9180W   \n",
       "47141      2.0  A34BZM6S9L7QI4  B00KGCLROK   \n",
       "47142      5.0  A25C2M3QF9G7OQ  B00KGCLROK   \n",
       "47143      5.0   AEL6CQNQXONBX  B00KKXCJQU   \n",
       "47144      5.0  A1EVV74UQYVKRY  B00KKXCJQU   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0      We bought several tutus at once, and they are ...   \n",
       "1      Thank you Halo Heaven great product for Little...   \n",
       "2      My daughter has worn this skirt almost every d...   \n",
       "3      Full and well stitched.  This tutu is a beauti...   \n",
       "4      Perfect for my budding grand daughter ballerin...   \n",
       "47140  While balaclavas can be used for a variety of ...   \n",
       "47141  These were a free sample for review.  I was ex...   \n",
       "47142  These socks are very nicely made and quite com...   \n",
       "47143  This set of travel organizers includes four pi...   \n",
       "47144  I've been traveling back and forth to England ...   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      we buy tutu get high review sturdy seemingly t...  \n",
       "1      thank halo heaven great product little girls m...  \n",
       "2      my daughter worn skirt day receive washer clot...  \n",
       "3      full stitch this tutu beautiful purple color l...  \n",
       "4      perfect bud grand daughter ballerina beautiful...  \n",
       "47140  while balaclavas variety thing use mainly late...  \n",
       "47141  these free sample review excite try unfortunat...  \n",
       "47142  these sock nicely comfortable wear the grip do...  \n",
       "47143  this set travel organizer include piece total ...  \n",
       "47144  travel forth england pack way suitcases some p...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check test\n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Doc2Vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Preparing `TaggedDocument` for Doc2Vec model\n",
    "\n",
    "In this following section, we will generating tagged documents that will be feed into the `Doc2Vec` model. We will be required to generate documents, where each is 'tagged' with the corresponding `asin` of which the review is addressing. This enables the Doc2Vec model to identify documents that are associated to each of the asin within our training dataset, and create a document vector based on the seperated documents for each asin. \n",
    "\n",
    "The intuition behind this preparation is that we assume that each asin is a representation of all the reviews customers has left after purchasing. If customers like any aspect of the product, the reviews should leave relevant positive feedback on that particular e.g., \"the boots is comfortable\" – hence, we know that this particular boots is comfortable. If a product (asin) has many of such reviews, semantically, we can build an item profile that associates this boots as a product that is comfortable. As embeddings are generated in *n*-dimensional vector space, we can then attempt to find similar products within the neighbourhood that has a similar profile be it is either a pair of boots, or a product that is comfortable in nature. \n",
    "\n",
    "The reason why we are building this in an item-item level is because at a user-level, interests may vary greatly depending on the user needs when purchasing items. Also, as some users may be more negative in nature, their reviews may generally be more critical which will inherently develop a profile that is critical in nature. Assuming this, if we were to place this user profile vector into the *n*-dimensional vector space, we will likely be recommending products that were also critically (or negatively) reviewed. This meant that for this user, we might only be generating poor recommendations due to how its neighbourhood is associated with a negatively semantics. However, in terms of item-level, it is highly unlike that a user has only made poor purchases on the site and hence, its more likely that the items profile develop should have a mix of good and possibly poor semantics. This ensures that we will have positive recommendations generated if we were to implement a treshold of sort, to ensure that the average/weighted average rating of the products meets an initial criteria for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db8e721dd1d4cc48ae1d4d9d4da9d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=14469), Label(value='0 / 14469')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.45 s, sys: 374 ms, total: 1.82 s\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# tokenizng the `processedReviewText`\n",
    "train['tokenizedReviewText'] = train['processedReviewText'].parallel_apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>processedReviewText</th>\n",
       "      <th>tokenizedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1KLRMWW2FWPL4</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>This is a great tutu and at a really great pri...</td>\n",
       "      <td>this great tutu great price it look cheap glad...</td>\n",
       "      <td>[this, great, tutu, great, price, it, look, ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2G5TCU2WDFZ65</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>I bought this for my 4 yr old daughter for dan...</td>\n",
       "      <td>buy yr old daughter dance class wore today tim...</td>\n",
       "      <td>[buy, yr, old, daughter, dance, class, wore, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1RLQXYNCMWRWN</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>What can I say... my daughters have it in oran...</td>\n",
       "      <td>what daughters orange black white pink think b...</td>\n",
       "      <td>[what, daughters, orange, black, white, pink, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A27UF1MSF3DB2</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>I received this today and I'm not a fan of it ...</td>\n",
       "      <td>receive today fan daughter think puffier look ...</td>\n",
       "      <td>[receive, today, fan, daughter, think, puffier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A16GFPNVF4Y816</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Bought this as a backup to the regular ballet ...</td>\n",
       "      <td>bought backup regular ballet outfit daughter w...</td>\n",
       "      <td>[bought, backup, regular, ballet, outfit, daug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231486</th>\n",
       "      <td>5.0</td>\n",
       "      <td>ACJT8MUC0LRF0</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>When I pack it looks like a disaster area in a...</td>\n",
       "      <td>when pack look like disaster area suitcase pac...</td>\n",
       "      <td>[when, pack, look, like, disaster, area, suitc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231487</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2DG63DN704LOI</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>I don't normally go ga-ga over a product very ...</td>\n",
       "      <td>normally ga ga product cub awesome help review...</td>\n",
       "      <td>[normally, ga, ga, product, cub, awesome, help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231488</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1UQBFCERIP7VJ</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>These are very nice packing cubes and the 18 x...</td>\n",
       "      <td>these nice packing cube laundry storage bag ni...</td>\n",
       "      <td>[these, nice, packing, cube, laundry, storage,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231489</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A22CW0ZHY3NJH8</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>I am on vacation with my family of four and th...</td>\n",
       "      <td>vacation family shacke pak set wonderful excep...</td>\n",
       "      <td>[vacation, family, shacke, pak, set, wonderful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231490</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A30VWT3R25QAVD</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>When I signed up to receive a free set of Shac...</td>\n",
       "      <td>when sign receive free set shacke pak review t...</td>\n",
       "      <td>[when, sign, receive, free, set, shacke, pak, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall      reviewerID        asin  \\\n",
       "0           5.0  A1KLRMWW2FWPL4  0000031887   \n",
       "1           5.0  A2G5TCU2WDFZ65  0000031887   \n",
       "2           5.0  A1RLQXYNCMWRWN  0000031887   \n",
       "3           4.0   A27UF1MSF3DB2  0000031887   \n",
       "4           5.0  A16GFPNVF4Y816  0000031887   \n",
       "231486      5.0   ACJT8MUC0LRF0  B00KKXCJQU   \n",
       "231487      5.0  A2DG63DN704LOI  B00KKXCJQU   \n",
       "231488      5.0  A1UQBFCERIP7VJ  B00KKXCJQU   \n",
       "231489      5.0  A22CW0ZHY3NJH8  B00KKXCJQU   \n",
       "231490      5.0  A30VWT3R25QAVD  B00KKXCJQU   \n",
       "\n",
       "                                               reviewText  \\\n",
       "0       This is a great tutu and at a really great pri...   \n",
       "1       I bought this for my 4 yr old daughter for dan...   \n",
       "2       What can I say... my daughters have it in oran...   \n",
       "3       I received this today and I'm not a fan of it ...   \n",
       "4       Bought this as a backup to the regular ballet ...   \n",
       "231486  When I pack it looks like a disaster area in a...   \n",
       "231487  I don't normally go ga-ga over a product very ...   \n",
       "231488  These are very nice packing cubes and the 18 x...   \n",
       "231489  I am on vacation with my family of four and th...   \n",
       "231490  When I signed up to receive a free set of Shac...   \n",
       "\n",
       "                                      processedReviewText  \\\n",
       "0       this great tutu great price it look cheap glad...   \n",
       "1       buy yr old daughter dance class wore today tim...   \n",
       "2       what daughters orange black white pink think b...   \n",
       "3       receive today fan daughter think puffier look ...   \n",
       "4       bought backup regular ballet outfit daughter w...   \n",
       "231486  when pack look like disaster area suitcase pac...   \n",
       "231487  normally ga ga product cub awesome help review...   \n",
       "231488  these nice packing cube laundry storage bag ni...   \n",
       "231489  vacation family shacke pak set wonderful excep...   \n",
       "231490  when sign receive free set shacke pak review t...   \n",
       "\n",
       "                                      tokenizedReviewText  \n",
       "0       [this, great, tutu, great, price, it, look, ch...  \n",
       "1       [buy, yr, old, daughter, dance, class, wore, t...  \n",
       "2       [what, daughters, orange, black, white, pink, ...  \n",
       "3       [receive, today, fan, daughter, think, puffier...  \n",
       "4       [bought, backup, regular, ballet, outfit, daug...  \n",
       "231486  [when, pack, look, like, disaster, area, suitc...  \n",
       "231487  [normally, ga, ga, product, cub, awesome, help...  \n",
       "231488  [these, nice, packing, cube, laundry, storage,...  \n",
       "231489  [vacation, family, shacke, pak, set, wonderful...  \n",
       "231490  [when, sign, receive, free, set, shacke, pak, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check train\n",
    "train.head().append(train.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Preparing `item-level` tagged documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, item_documents = preprocessing.prepare_tagged_documents(users='reviewerID', asins='asin', reviews='tokenizedReviewText', df=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['this', 'great', 'tutu', 'great', 'price', 'it', 'look', 'cheap', 'glad', 'look', 'amazon', 'affordable', 'tutu', 'poorly'], tags=['0000031887']),\n",
      " TaggedDocument(words=['buy', 'yr', 'old', 'daughter', 'dance', 'class', 'wore', 'today', 'time', 'teacher', 'think', 'adorable', 'buy', 'light', 'blue', 'long', 'sleeve', 'leotard', 'happy', 'color', 'match', 'great', 'price', 'good', 'dollar'], tags=['0000031887']),\n",
      " TaggedDocument(words=['what', 'daughters', 'orange', 'black', 'white', 'pink', 'think', 'buy', 'fuccia', 'it', 'good', 'way', 'exalt', 'dancer', 'outfit', 'great', 'color', 'comfortable', 'look', 'great', 'easy', 'wear', 'durables', 'little', 'girls', 'love', 'think', 'great', 'buy', 'costumer', 'play'], tags=['0000031887']),\n",
      " TaggedDocument(words=['receive', 'today', 'fan', 'daughter', 'think', 'puffier', 'look', 'pic', 'sent', 'pink', 'underneath', 'waist', 'band', 'pink', 'want', 'fact', 'sandal', 'go', 'wear', 'get', 'pair', 'sandal', 'cuz', 'like'], tags=['0000031887']),\n",
      " TaggedDocument(words=['bought', 'backup', 'regular', 'ballet', 'outfit', 'daughter', 'wear', 'so', 'far', 'play', 'cinderella', 'dream', 'sure', 'able', 'use', 'recital', 'soon', 'the', 'quality', 'fine', 'price', 'pay', 'expect', 'designer', 'skirt', 'price', 'get', 'exactly', 'pay'], tags=['0000031887']),\n",
      " TaggedDocument(words=['great', 'tutu', 'great', 'price', 'it', 'high', 'quality', 'skirt', 'perfect', 'daughter', 'wear', 'legging', 'little', 'outfit'], tags=['0000031887']),\n",
      " TaggedDocument(words=['my', 'daughter', 'like', 'costume', 'liked', 'bit', 'fuller'], tags=['0000031887']),\n",
      " TaggedDocument(words=['for', 'pay', 'tutu', 'unbeatable', 'order', 'pink', 'turquios', 'vibrant', 'beautiful', 'the', 'tutu', 'princess', 'style', 'not', 'cheaply', 'not', 'cheap', 'materia', 'obviously', 'love', 'care', 'pay', 'buck', 'tutu', 'feel', 'proud', 'self', 'research', 'point', 'find', 'gold', 'recommend', 'year', 'my', 'daughter', 'wears', 'size', 'skirt', 'size', 'fit', 'perfect', 'probaly', 'able', 'accommodate', 'quickly', 'grow', 'waist', 'time'], tags=['0000031887']),\n",
      " TaggedDocument(words=['wonder', 'niece', 'wear', 'single', 'day', 'yellow', 'favorite', 'color', 'right', 'cute', 'little', 'tutu', 'da', 'it', 'build', 'hope', 'get', 'lot', 'wear'], tags=['0000031887']),\n",
      " TaggedDocument(words=['purchased', 'tutu', 'granddaughter', 'birthday', 'it', 'fit', 'nicely', 'room', 'grow', 'purchase', 'vary', 'color', 'future'], tags=['0000031887'])]\n"
     ]
    }
   ],
   "source": [
    "pprint(item_documents[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Training `Doc2Vec` model\n",
    "\n",
    "We will be training a `Doc2Vec` model with initial hyperparameters decided based on a study by [Caselles-Dupré, Lesaint, and Royo-Letelier (2018)](https://arxiv.org/abs/1804.04212), where they observed that `negative sampling distribution`, `number of epochs`, `subsampling parameter` and `window size` can significantly improve performance on recommendation tasks. Hence, we will have decided to start with values that similar to those presented in the studies as the basis for improvement during this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s %(message)s')\n",
    "\n",
    "# model parameters\n",
    "VECTOR_SIZE = 150\n",
    "MIN_COUNT = 10\n",
    "NEGATIVE = 5\n",
    "NS_EXPONENT = 0.5\n",
    "SAMPLE = 1e-05\n",
    "DM = 1\n",
    "WORKERS = 8\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(\n",
    "    vector_size=VECTOR_SIZE,\n",
    "    min_count=MIN_COUNT,\n",
    "    negative=NEGATIVE,\n",
    "    sample=SAMPLE,\n",
    "    ns_exponent=NS_EXPONENT,\n",
    "    dm=DM,\n",
    "    workers=WORKERS,\n",
    ")\n",
    "\n",
    "# building vocab\n",
    "model.build_vocab(item_documents)\n",
    "\n",
    "# training model\n",
    "model.train(item_documents, total_examples=model.corpus_count, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "MODEL_PATH = Path(\"models/d2v/\")\n",
    "\n",
    "model.save(f\"{MODEL_PATH}/{CATEGORY}_{VECTOR_SIZE}_{SAMPLE}_{EPOCHS}_d2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Verifying Doc2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 08:09:14,808 loading Doc2Vec object from models/d2v/Clothing_Shoes_and_Jewelry_150_1e-05_50_d2v.model\n",
      "2021-07-20 08:09:14,808 {'uri': 'models/d2v/Clothing_Shoes_and_Jewelry_150_1e-05_50_d2v.model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'compression': None, 'transport_params': None}\n",
      "2021-07-20 08:09:14,834 loading dv recursively from models/d2v/Clothing_Shoes_and_Jewelry_150_1e-05_50_d2v.model.dv.* with mmap=None\n",
      "2021-07-20 08:09:14,835 loading wv recursively from models/d2v/Clothing_Shoes_and_Jewelry_150_1e-05_50_d2v.model.wv.* with mmap=None\n",
      "2021-07-20 08:09:14,836 setting ignored attribute cum_table to None\n",
      "2021-07-20 08:09:14,919 Doc2Vec lifecycle event {'fname': 'models/d2v/Clothing_Shoes_and_Jewelry_150_1e-05_50_d2v.model', 'datetime': '2021-07-20T08:09:14.918615', 'gensim': '4.0.1', 'python': '3.7.10 | packaged by conda-forge | (default, Feb 19 2021, 16:07:37) \\n[GCC 9.3.0]', 'platform': 'Linux-4.19.0-17-cloud-amd64-x86_64-with-debian-10.10', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = Path(\"models/d2v/\")\n",
    "\n",
    "model = Doc2Vec.load(f\"{MODEL_PATH}/{CATEGORY}_{VECTOR_SIZE}_{SAMPLE}_{EPOCHS}_d2v.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Testing retrieval of vectors via index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.55455124, -0.06204286,  0.12651655,  0.17184411, -0.41832566,\n",
       "        0.43929744,  0.5989178 , -0.47313836, -0.26175705,  0.23614489,\n",
       "       -1.3901784 ,  0.6646123 ,  0.06347404,  0.08615484, -0.6717607 ,\n",
       "       -0.3768335 ,  1.0026171 ,  0.25654572,  0.5956967 ,  0.09548705,\n",
       "       -0.5090417 , -0.28958946,  1.0680248 , -0.2967359 ,  0.05868936,\n",
       "       -0.27846545, -0.45245284, -0.39223024, -0.13383815, -0.5927535 ,\n",
       "       -0.6065034 ,  0.11480772, -0.24187134,  0.89880323, -0.4563438 ,\n",
       "       -0.07274003, -0.25703123, -0.67628574, -0.23870592,  0.03952418,\n",
       "       -0.43918917, -0.37131128, -0.3459309 ,  0.22690648,  0.44771397,\n",
       "       -0.46793684, -0.09896857, -0.5261713 , -0.02965886,  0.6870407 ,\n",
       "       -0.49471295, -0.55824864,  0.14912887,  0.19684845,  0.06110121,\n",
       "        0.08721235, -0.67826223,  0.18145782,  0.49971262, -0.26642862,\n",
       "        0.00974132,  0.02288771, -0.05008493, -0.4627209 , -0.58579177,\n",
       "       -0.63324004,  0.05645867, -0.5750356 ,  0.32855687, -0.35113615,\n",
       "        0.7569445 , -0.67850393, -0.0524528 , -0.53823   , -1.1557726 ,\n",
       "       -0.5679395 , -1.1064653 ,  0.526135  , -0.13573413,  0.43550092,\n",
       "       -0.39238155, -0.44137383, -1.0005105 ,  1.6980033 ,  0.30435106,\n",
       "       -0.5381352 , -0.3579662 , -0.6549845 ,  0.49981952, -0.23570788,\n",
       "        0.48940828, -0.6091184 , -0.17778827, -0.21728638, -0.15546602,\n",
       "        1.4347874 ,  0.08449812, -1.0857158 , -0.58185023,  0.45998797,\n",
       "        0.17175175, -0.10798352,  0.35381648,  0.2235827 , -0.14653455,\n",
       "       -1.1150416 , -0.21234849, -0.11326766, -1.1686791 , -0.8082808 ,\n",
       "       -1.0795724 , -0.6491186 ,  0.03086999, -1.173729  ,  1.1349939 ,\n",
       "       -0.4635328 ,  0.53326315, -0.16851126, -0.05698306, -1.0091105 ,\n",
       "       -0.36412108,  0.07882185,  0.39582285, -0.7907473 ,  0.10666534,\n",
       "        0.08741264,  0.6285177 , -0.30344784,  0.4370744 ,  0.9516405 ,\n",
       "        0.19413961,  0.10110148, -0.05380991, -0.0546403 ,  0.03100655,\n",
       "        1.0864135 , -1.7737452 , -0.06892032, -0.5284419 ,  0.22118248,\n",
       "       -0.6440948 , -0.00414208,  0.02530223,  0.01232426, -0.56234187,\n",
       "        0.3020728 ,  0.20977837,  0.00233771,  0.19263285, -0.94992065],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv[0] # '0000031887'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Testing retrieval of vectors via tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0000031887'], ['0000031887'], ['0000031887'], ['0000031887'], ['0000031887']]\n"
     ]
    }
   ],
   "source": [
    "print([i[1] for i in item_documents[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.55455124, -0.06204286,  0.12651655,  0.17184411, -0.41832566,\n",
       "        0.43929744,  0.5989178 , -0.47313836, -0.26175705,  0.23614489,\n",
       "       -1.3901784 ,  0.6646123 ,  0.06347404,  0.08615484, -0.6717607 ,\n",
       "       -0.3768335 ,  1.0026171 ,  0.25654572,  0.5956967 ,  0.09548705,\n",
       "       -0.5090417 , -0.28958946,  1.0680248 , -0.2967359 ,  0.05868936,\n",
       "       -0.27846545, -0.45245284, -0.39223024, -0.13383815, -0.5927535 ,\n",
       "       -0.6065034 ,  0.11480772, -0.24187134,  0.89880323, -0.4563438 ,\n",
       "       -0.07274003, -0.25703123, -0.67628574, -0.23870592,  0.03952418,\n",
       "       -0.43918917, -0.37131128, -0.3459309 ,  0.22690648,  0.44771397,\n",
       "       -0.46793684, -0.09896857, -0.5261713 , -0.02965886,  0.6870407 ,\n",
       "       -0.49471295, -0.55824864,  0.14912887,  0.19684845,  0.06110121,\n",
       "        0.08721235, -0.67826223,  0.18145782,  0.49971262, -0.26642862,\n",
       "        0.00974132,  0.02288771, -0.05008493, -0.4627209 , -0.58579177,\n",
       "       -0.63324004,  0.05645867, -0.5750356 ,  0.32855687, -0.35113615,\n",
       "        0.7569445 , -0.67850393, -0.0524528 , -0.53823   , -1.1557726 ,\n",
       "       -0.5679395 , -1.1064653 ,  0.526135  , -0.13573413,  0.43550092,\n",
       "       -0.39238155, -0.44137383, -1.0005105 ,  1.6980033 ,  0.30435106,\n",
       "       -0.5381352 , -0.3579662 , -0.6549845 ,  0.49981952, -0.23570788,\n",
       "        0.48940828, -0.6091184 , -0.17778827, -0.21728638, -0.15546602,\n",
       "        1.4347874 ,  0.08449812, -1.0857158 , -0.58185023,  0.45998797,\n",
       "        0.17175175, -0.10798352,  0.35381648,  0.2235827 , -0.14653455,\n",
       "       -1.1150416 , -0.21234849, -0.11326766, -1.1686791 , -0.8082808 ,\n",
       "       -1.0795724 , -0.6491186 ,  0.03086999, -1.173729  ,  1.1349939 ,\n",
       "       -0.4635328 ,  0.53326315, -0.16851126, -0.05698306, -1.0091105 ,\n",
       "       -0.36412108,  0.07882185,  0.39582285, -0.7907473 ,  0.10666534,\n",
       "        0.08741264,  0.6285177 , -0.30344784,  0.4370744 ,  0.9516405 ,\n",
       "        0.19413961,  0.10110148, -0.05380991, -0.0546403 ,  0.03100655,\n",
       "        1.0864135 , -1.7737452 , -0.06892032, -0.5284419 ,  0.22118248,\n",
       "       -0.6440948 , -0.00414208,  0.02530223,  0.01232426, -0.56234187,\n",
       "        0.3020728 ,  0.20977837,  0.00233771,  0.19263285, -0.94992065],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv['0000031887']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Checking number of document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document vectors: 23033\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of document vectors: {len(model.dv.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that by calling the document vector via both index and actual tags returns the same vector. We also generated `23033` vectors that is aligned with the number of unique items we have in training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Examining Doc2Vec results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Are inferred vectors close to the precalculated ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For item B008DOGGT4...\n",
      "\n",
      "Most similar D2V vectors: [('B008DOGGT4', 0.8374003767967224), ('B0058SFF04', 0.7997447848320007), ('B004QWMMOA', 0.7816683650016785), ('B000YQZ0X2', 0.7791002988815308), ('B0009GAL9U', 0.7769829630851746)]\n"
     ]
    }
   ],
   "source": [
    "# let's try to generate a random item id and infer its vector and compare if we can get similar items back\n",
    "random_asin = np.random.choice(list(train['asin'].unique()), 1)[0]\n",
    "\n",
    "# combining all the words from the all reviews\n",
    "all_review = []\n",
    "for review in train[train['asin'] == random_asin][\"tokenizedReviewText\"]:\n",
    "    all_review.extend(review)\n",
    "\n",
    "# inferring vector\n",
    "print(f\"For item {random_asin}...\\n\")\n",
    "print(f'Most similar D2V vectors: {model.dv.most_similar([model.infer_vector(all_review, epochs=5)], topn=5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For item B009ZGY4S4...\n",
      "\n",
      "Most similar D2V vectors: [('B009ZGY4S4', 0.8567821979522705), ('B0098SG8I8', 0.6722127199172974), ('B0099L0AKG', 0.6669430136680603), ('B005IZ9JPO', 0.6657906174659729), ('B008KQT38Q', 0.6608070731163025)]\n"
     ]
    }
   ],
   "source": [
    "# let's try to generate a random item id and infer its vector and compare if we can get similar items back\n",
    "random_asin = np.random.choice(list(train['asin'].unique()), 1)[0]\n",
    "\n",
    "# combining all the words from the all reviews\n",
    "all_review = []\n",
    "for review in train[train['asin'] == random_asin][\"tokenizedReviewText\"]:\n",
    "    all_review.extend(review)\n",
    "\n",
    "# inferring vector\n",
    "print(f\"For item {random_asin}...\\n\")\n",
    "print(f'Most similar D2V vectors: {model.dv.most_similar([model.infer_vector(all_review, epochs=5)], topn=5)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to verify that by using the same tokens used for training, we were able to still infer accurate vectors from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Generating top-N recommendations based on aggregated item history\n",
    "\n",
    "As mentioned previously, we wanted to generate recommendations based on item-level instead of user-level due to the fact that user's nature is dynamic. What user like now, might not be the same a few days or weeks later. However, on a item perspective, if an item is good, general public who purchased the item should have positive feedback. The nature of the item profile should not vary as much as it would on a user-level. \n",
    "\n",
    "Hence, instead of building a user profile based on the reviews that the user has given, instead, we will build an *aggregated* item history profile based on the past purchase history of the users. A simplification of the algorithm would be:\n",
    "\n",
    "1. Identify the list of items previously purchased by a user\n",
    "2. Using the Doc2Vec model trained on unique tags based on `asin`, we mean-aggregate the item's document vectors to produce a aggregate item purchase history vector\n",
    "3. Using the aggregated item purchase history vector, we find the top-N, 10, recommendations while excluding previously purchased item and setting a treshold for the mean/weighted-mean rating of the recommended items to ensure that items purchase is popular among others as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: need to figure how to define a treshold\n",
    "def get_top_n(user, n=10, threshold=4):\n",
    "\n",
    "    # retrieving user's purchase history\n",
    "    purchase_history = train.groupby(['reviewerID'])['asin'].apply(list)[user]\n",
    "\n",
    "    purchase_history_vec = np.zeros(150)\n",
    "    for item in purchase_history:\n",
    "        purchase_history_vec += model.dv[item]\n",
    "    # mean aggregation\n",
    "    purchase_history_vec /= len(purchase_history)\n",
    "\n",
    "    return [i[0] for i in model.dv.most_similar([purchase_history_vec], topn=n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              asin                                         reviewText\n",
      "31482   B000OTRDZ2  I ordered the size I have been ordering in oth...\n",
      "106545  B004I74G1K  I love this gown. It is nice and long and flow...\n",
      "106649  B004I763ZC  Not the sexiest thing in the world but it is n...\n",
      "123577  B0058D1P62  Same as all the other 1 star reviews. I would ...\n",
      "185365  B0091SL1QE  They look nice on the models. But I ordered my...\n",
      "\n",
      "For user AJD8WV56Y8R8O...\n",
      "\n",
      "Most similar item D2V vectors: ['B0072LBZXG', 'B0058D1P62', 'B0090NRGQO', 'B00974AEWO', 'B003UU7CV2', 'B00B659X7O', 'B000EGJSUI', 'B000LOVUMW', 'B005POVNMA', 'B001GOW5LQ']\n"
     ]
    }
   ],
   "source": [
    "# generating a random user\n",
    "random_user = np.random.choice(list(train['reviewerID'].unique()), 1)[0]\n",
    "# looking at user records\n",
    "pprint(train[train['reviewerID'] == random_user][[\"asin\", \"reviewText\"]])\n",
    "\n",
    "print(f\"\\nFor user {random_user}...\\n\")\n",
    "print(f'Most similar item D2V vectors: {get_top_n(random_user)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example of recommendation above where user `A2OSOO0NRPLZRH`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Computing Metrics\n",
    "\n",
    "Now that we are able to generate recommendations for users, we are going to compute metrics to better evaluate our model with existing techniques used in recommendations for comparison. \n",
    "\n",
    "We will be using the following metrics:\n",
    "\n",
    "1. `Precision@K`: Proportion of recommendations that are relevant (which means that items that users has already make a purchase before).\n",
    "2. `Recall@K`: Proportion of relevant recommendations retrieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>processedReviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A8U3FAMSJVHS5</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>We bought several tutus at once, and they are ...</td>\n",
       "      <td>we buy tutu get high review sturdy seemingly t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A3GEOILWLK86XM</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Thank you Halo Heaven great product for Little...</td>\n",
       "      <td>thank halo heaven great product little girls m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2A2WZYLU528RO</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>My daughter has worn this skirt almost every d...</td>\n",
       "      <td>my daughter worn skirt day receive washer clot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A34ATJR9KFIXL9</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Full and well stitched.  This tutu is a beauti...</td>\n",
       "      <td>full stitch this tutu beautiful purple color l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1MXJVYXE2QU6H</td>\n",
       "      <td>0000031887</td>\n",
       "      <td>Perfect for my budding grand daughter ballerin...</td>\n",
       "      <td>perfect bud grand daughter ballerina beautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47140</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A2XX2A4OJCDNLZ</td>\n",
       "      <td>B00KF9180W</td>\n",
       "      <td>While balaclavas can be used for a variety of ...</td>\n",
       "      <td>while balaclavas variety thing use mainly late...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47141</th>\n",
       "      <td>2.0</td>\n",
       "      <td>A34BZM6S9L7QI4</td>\n",
       "      <td>B00KGCLROK</td>\n",
       "      <td>These were a free sample for review.  I was ex...</td>\n",
       "      <td>these free sample review excite try unfortunat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47142</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A25C2M3QF9G7OQ</td>\n",
       "      <td>B00KGCLROK</td>\n",
       "      <td>These socks are very nicely made and quite com...</td>\n",
       "      <td>these sock nicely comfortable wear the grip do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47143</th>\n",
       "      <td>5.0</td>\n",
       "      <td>AEL6CQNQXONBX</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>This set of travel organizers includes four pi...</td>\n",
       "      <td>this set travel organizer include piece total ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47144</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A1EVV74UQYVKRY</td>\n",
       "      <td>B00KKXCJQU</td>\n",
       "      <td>I've been traveling back and forth to England ...</td>\n",
       "      <td>travel forth england pack way suitcases some p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall      reviewerID        asin  \\\n",
       "0          5.0   A8U3FAMSJVHS5  0000031887   \n",
       "1          5.0  A3GEOILWLK86XM  0000031887   \n",
       "2          5.0  A2A2WZYLU528RO  0000031887   \n",
       "3          5.0  A34ATJR9KFIXL9  0000031887   \n",
       "4          5.0  A1MXJVYXE2QU6H  0000031887   \n",
       "47140      5.0  A2XX2A4OJCDNLZ  B00KF9180W   \n",
       "47141      2.0  A34BZM6S9L7QI4  B00KGCLROK   \n",
       "47142      5.0  A25C2M3QF9G7OQ  B00KGCLROK   \n",
       "47143      5.0   AEL6CQNQXONBX  B00KKXCJQU   \n",
       "47144      5.0  A1EVV74UQYVKRY  B00KKXCJQU   \n",
       "\n",
       "                                              reviewText  \\\n",
       "0      We bought several tutus at once, and they are ...   \n",
       "1      Thank you Halo Heaven great product for Little...   \n",
       "2      My daughter has worn this skirt almost every d...   \n",
       "3      Full and well stitched.  This tutu is a beauti...   \n",
       "4      Perfect for my budding grand daughter ballerin...   \n",
       "47140  While balaclavas can be used for a variety of ...   \n",
       "47141  These were a free sample for review.  I was ex...   \n",
       "47142  These socks are very nicely made and quite com...   \n",
       "47143  This set of travel organizers includes four pi...   \n",
       "47144  I've been traveling back and forth to England ...   \n",
       "\n",
       "                                     processedReviewText  \n",
       "0      we buy tutu get high review sturdy seemingly t...  \n",
       "1      thank halo heaven great product little girls m...  \n",
       "2      my daughter worn skirt day receive washer clot...  \n",
       "3      full stitch this tutu beautiful purple color l...  \n",
       "4      perfect bud grand daughter ballerina beautiful...  \n",
       "47140  while balaclavas variety thing use mainly late...  \n",
       "47141  these free sample review excite try unfortunat...  \n",
       "47142  these sock nicely comfortable wear the grip do...  \n",
       "47143  this set travel organizer include piece total ...  \n",
       "47144  travel forth england pack way suitcases some p...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let take a look at our testing set \n",
    "test.head().append(test.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              reviewerID          asin\n",
      "0  A001114613O3F18Q5NVR6  [B000J6ZYL0]\n",
      "1  A00146182PNM90WNNAZ5Q  [B00823Y41S]\n",
      "2  A00165422B2GAUE3EL6Z0  [B008G51WHQ]\n",
      "3  A00338282E99B8OR2JYTZ  [B00DVFNNQE]\n",
      "4  A00354001GE099Q1FL0TU  [B00BTWAZ0I]\n"
     ]
    }
   ],
   "source": [
    "# creating the purchase history of users in the testing set\n",
    "test_purchase_history = test.groupby(['reviewerID'])['asin'].apply(list).to_frame().reset_index()\n",
    "\n",
    "pprint(test_purchase_history.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           reviewerID                                               asin\n",
      "109    A104QGECCAFCI9                                       [B00592VMNI]\n",
      "15112  A2G5OW0UIBAUIT                           [B008SCM0AU, B00AOCV6OI]\n",
      "13118  A29BPMJI0ZYH4H  [B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...\n",
      "37097   ARQZEE0LA1PBB                                       [B000A2KC7O]\n",
      "31660   A8VSC4N8D63MJ                                       [B007ZRS0ZI]\n",
      "...               ...                                                ...\n",
      "33707   AG6B61Q8YV1EL                           [B000IBH9GY, B005HESA38]\n",
      "17734  A2P7NOZ0TRHZDZ                                       [B004A74Y3I]\n",
      "17972  A2Q21T5IJ7K35C                                       [B00CO8I206]\n",
      "12781  A2877AOHJFZI0E                                       [B004JZYGQ6]\n",
      "14092  A2CPPFB0S4XPH3                                       [B002ATKUEA]\n",
      "\n",
      "[1000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# let randomly sample 1000 rows to make predictions\n",
    "sampled_test_purchase_history = test_purchase_history.sample(n=1000, random_state=42)\n",
    "\n",
    "pprint(sampled_test_purchase_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [14:12<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# generating predictions\n",
    "sampled_test_purchase_history['asin_predictions'] = sampled_test_purchase_history['reviewerID'].progress_apply(get_top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>asin_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>A104QGECCAFCI9</td>\n",
       "      <td>[B00592VMNI]</td>\n",
       "      <td>[B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15112</th>\n",
       "      <td>A2G5OW0UIBAUIT</td>\n",
       "      <td>[B008SCM0AU, B00AOCV6OI]</td>\n",
       "      <td>[B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13118</th>\n",
       "      <td>A29BPMJI0ZYH4H</td>\n",
       "      <td>[B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...</td>\n",
       "      <td>[B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37097</th>\n",
       "      <td>ARQZEE0LA1PBB</td>\n",
       "      <td>[B000A2KC7O]</td>\n",
       "      <td>[B006H9S4LU, B009V7Q8YK, B0030BELDS, B0018OFU9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>A8VSC4N8D63MJ</td>\n",
       "      <td>[B007ZRS0ZI]</td>\n",
       "      <td>[B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33707</th>\n",
       "      <td>AG6B61Q8YV1EL</td>\n",
       "      <td>[B000IBH9GY, B005HESA38]</td>\n",
       "      <td>[B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>A2P7NOZ0TRHZDZ</td>\n",
       "      <td>[B004A74Y3I]</td>\n",
       "      <td>[B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17972</th>\n",
       "      <td>A2Q21T5IJ7K35C</td>\n",
       "      <td>[B00CO8I206]</td>\n",
       "      <td>[B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12781</th>\n",
       "      <td>A2877AOHJFZI0E</td>\n",
       "      <td>[B004JZYGQ6]</td>\n",
       "      <td>[B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14092</th>\n",
       "      <td>A2CPPFB0S4XPH3</td>\n",
       "      <td>[B002ATKUEA]</td>\n",
       "      <td>[B00B7F3LIK, B006QOJ8PM, B008O2YOBC, B0058XJJ8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "109    A104QGECCAFCI9                                       [B00592VMNI]   \n",
       "15112  A2G5OW0UIBAUIT                           [B008SCM0AU, B00AOCV6OI]   \n",
       "13118  A29BPMJI0ZYH4H  [B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...   \n",
       "37097   ARQZEE0LA1PBB                                       [B000A2KC7O]   \n",
       "31660   A8VSC4N8D63MJ                                       [B007ZRS0ZI]   \n",
       "33707   AG6B61Q8YV1EL                           [B000IBH9GY, B005HESA38]   \n",
       "17734  A2P7NOZ0TRHZDZ                                       [B004A74Y3I]   \n",
       "17972  A2Q21T5IJ7K35C                                       [B00CO8I206]   \n",
       "12781  A2877AOHJFZI0E                                       [B004JZYGQ6]   \n",
       "14092  A2CPPFB0S4XPH3                                       [B002ATKUEA]   \n",
       "\n",
       "                                        asin_predictions  \n",
       "109    [B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...  \n",
       "15112  [B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...  \n",
       "13118  [B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...  \n",
       "37097  [B006H9S4LU, B009V7Q8YK, B0030BELDS, B0018OFU9...  \n",
       "31660  [B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...  \n",
       "33707  [B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...  \n",
       "17734  [B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...  \n",
       "17972  [B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...  \n",
       "12781  [B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...  \n",
       "14092  [B00B7F3LIK, B006QOJ8PM, B008O2YOBC, B0058XJJ8...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataframe\n",
    "sampled_test_purchase_history.head().append(sampled_test_purchase_history.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Defining utility metrics functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating precision@K - relevant / total recommended\n",
    "    precision_at_k = num_relevant / k\n",
    "    \n",
    "    return precision_at_k\n",
    "\n",
    "def recall_at_k(asins, predicted_asins, k=10):\n",
    "    # number of relevant items\n",
    "    set_actual = set(asins)\n",
    "    set_preds = set(predicted_asins)\n",
    "    num_relevant = len(set_actual.intersection(set_preds))\n",
    "    \n",
    "    # calculating recall@K - relevant / total relevant items\n",
    "    recall_at_k = num_relevant / len(asins)\n",
    "    \n",
    "    return recall_at_k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 62798.38it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 64345.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# computing the metrics\n",
    "sampled_test_purchase_history['precision@K'] = sampled_test_purchase_history.progress_apply(lambda x: precision_at_k(x.asin, x.asin_predictions), axis=1)\n",
    "sampled_test_purchase_history['recall@K'] = sampled_test_purchase_history.progress_apply(lambda x: recall_at_k(x.asin, x.asin_predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>asin_predictions</th>\n",
       "      <th>precision@K</th>\n",
       "      <th>recall@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>A104QGECCAFCI9</td>\n",
       "      <td>[B00592VMNI]</td>\n",
       "      <td>[B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15112</th>\n",
       "      <td>A2G5OW0UIBAUIT</td>\n",
       "      <td>[B008SCM0AU, B00AOCV6OI]</td>\n",
       "      <td>[B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13118</th>\n",
       "      <td>A29BPMJI0ZYH4H</td>\n",
       "      <td>[B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...</td>\n",
       "      <td>[B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37097</th>\n",
       "      <td>ARQZEE0LA1PBB</td>\n",
       "      <td>[B000A2KC7O]</td>\n",
       "      <td>[B006H9S4LU, B009V7Q8YK, B0030BELDS, B0018OFU9...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>A8VSC4N8D63MJ</td>\n",
       "      <td>[B007ZRS0ZI]</td>\n",
       "      <td>[B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33707</th>\n",
       "      <td>AG6B61Q8YV1EL</td>\n",
       "      <td>[B000IBH9GY, B005HESA38]</td>\n",
       "      <td>[B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>A2P7NOZ0TRHZDZ</td>\n",
       "      <td>[B004A74Y3I]</td>\n",
       "      <td>[B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17972</th>\n",
       "      <td>A2Q21T5IJ7K35C</td>\n",
       "      <td>[B00CO8I206]</td>\n",
       "      <td>[B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12781</th>\n",
       "      <td>A2877AOHJFZI0E</td>\n",
       "      <td>[B004JZYGQ6]</td>\n",
       "      <td>[B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14092</th>\n",
       "      <td>A2CPPFB0S4XPH3</td>\n",
       "      <td>[B002ATKUEA]</td>\n",
       "      <td>[B00B7F3LIK, B006QOJ8PM, B008O2YOBC, B0058XJJ8...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "109    A104QGECCAFCI9                                       [B00592VMNI]   \n",
       "15112  A2G5OW0UIBAUIT                           [B008SCM0AU, B00AOCV6OI]   \n",
       "13118  A29BPMJI0ZYH4H  [B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...   \n",
       "37097   ARQZEE0LA1PBB                                       [B000A2KC7O]   \n",
       "31660   A8VSC4N8D63MJ                                       [B007ZRS0ZI]   \n",
       "33707   AG6B61Q8YV1EL                           [B000IBH9GY, B005HESA38]   \n",
       "17734  A2P7NOZ0TRHZDZ                                       [B004A74Y3I]   \n",
       "17972  A2Q21T5IJ7K35C                                       [B00CO8I206]   \n",
       "12781  A2877AOHJFZI0E                                       [B004JZYGQ6]   \n",
       "14092  A2CPPFB0S4XPH3                                       [B002ATKUEA]   \n",
       "\n",
       "                                        asin_predictions  precision@K  \\\n",
       "109    [B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...          0.0   \n",
       "15112  [B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...          0.0   \n",
       "13118  [B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...          0.0   \n",
       "37097  [B006H9S4LU, B009V7Q8YK, B0030BELDS, B0018OFU9...          0.0   \n",
       "31660  [B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...          0.0   \n",
       "33707  [B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...          0.0   \n",
       "17734  [B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...          0.0   \n",
       "17972  [B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...          0.0   \n",
       "12781  [B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...          0.0   \n",
       "14092  [B00B7F3LIK, B006QOJ8PM, B008O2YOBC, B0058XJJ8...          0.0   \n",
       "\n",
       "       recall@K  \n",
       "109         0.0  \n",
       "15112       0.0  \n",
       "13118       0.0  \n",
       "37097       0.0  \n",
       "31660       0.0  \n",
       "33707       0.0  \n",
       "17734       0.0  \n",
       "17972       0.0  \n",
       "12781       0.0  \n",
       "14092       0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataframe\n",
    "sampled_test_purchase_history.head().append(sampled_test_purchase_history.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Retrieving the average metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has a average precision@K: 0.00190, average recall@K: 0.01663.\n"
     ]
    }
   ],
   "source": [
    "average_precision_at_k = sampled_test_purchase_history[\"precision@K\"].mean()\n",
    "average_recall_at_k = sampled_test_purchase_history[\"recall@K\"].mean()\n",
    "\n",
    "print(f\"The model has a average precision@K: {average_precision_at_k:.5f}, average recall@K: {average_recall_at_k:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Looking at the correct recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>asin_predictions</th>\n",
       "      <th>precision@K</th>\n",
       "      <th>recall@K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37689</th>\n",
       "      <td>ATQVNXUU2N1GG</td>\n",
       "      <td>[B0009WXTX4]</td>\n",
       "      <td>[B000ZPMYCC, B000B5MI3Q, B0032FOSI0, B009KYJAJ...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39337</th>\n",
       "      <td>AZV969S41XUYF</td>\n",
       "      <td>[B009S3HPTE]</td>\n",
       "      <td>[B009S3HYQ8, B006NU5Z60, B006LFF850, B009S3HL9...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36648</th>\n",
       "      <td>AQA5BVA14WTJQ</td>\n",
       "      <td>[B000KPP352]</td>\n",
       "      <td>[B000KKTPD8, B000XY3XX4, B000KPPICA, B000KPP35...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37385</th>\n",
       "      <td>ASQFKYFTM1A3G</td>\n",
       "      <td>[B002YIPCJA]</td>\n",
       "      <td>[B002WUVOBA, B002VS8H3G, B001WWWAA8, B002YM52L...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2158</th>\n",
       "      <td>A17OB8ULOJ5U50</td>\n",
       "      <td>[B000UECV3U]</td>\n",
       "      <td>[B000CC3OMC, B000BVYQ9O, B000BVYQ9Y, B0006GYLO...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35465</th>\n",
       "      <td>AM74DCJX3UI7X</td>\n",
       "      <td>[B002JKZU4A]</td>\n",
       "      <td>[B002JL1ZUC, B004874ZHK, B009DKKVFW, B004DYUAX...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29431</th>\n",
       "      <td>A3TF05A315UM97</td>\n",
       "      <td>[B006GDARO4]</td>\n",
       "      <td>[B0055X1NDK, B002RS26LE, B0085U2YTC, B0064YY0D...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22453</th>\n",
       "      <td>A35ARB435GXRMH</td>\n",
       "      <td>[B006B3AOJC]</td>\n",
       "      <td>[B005UVM368, B0062WL55E, B008IZKAP4, B00EU7OYY...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29035</th>\n",
       "      <td>A3S4V8NPKKDDUL</td>\n",
       "      <td>[B001SN8BLS]</td>\n",
       "      <td>[B001N0MSI8, B002RL87OQ, B003FSPWAC, B001SN8AD...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30780</th>\n",
       "      <td>A5SYJBHLU748Z</td>\n",
       "      <td>[B008Q0E61U]</td>\n",
       "      <td>[B001PUJH3A, B001NODU36, B001B9XI3A, B001DNFAO...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29005</th>\n",
       "      <td>A3S2F1048AZND0</td>\n",
       "      <td>[B002PHLVJA]</td>\n",
       "      <td>[B001IB70JY, B0013B0IYI, B000GXPD7G, B000HEJ3L...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21856</th>\n",
       "      <td>A33BS7GBS6M4AG</td>\n",
       "      <td>[B004L8J0C6]</td>\n",
       "      <td>[B00DEMN8DW, B001N4OCII, B002GCE3R6, B002IGN8J...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26196</th>\n",
       "      <td>A3I9PXOHGTCBRJ</td>\n",
       "      <td>[B004GXBP1U]</td>\n",
       "      <td>[B004Q7AB4I, B006R0PZ5C, B001FWZ098, B007C8PUP...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5853</th>\n",
       "      <td>A1KJZVR4IMMNZ1</td>\n",
       "      <td>[B001SLB6EY]</td>\n",
       "      <td>[B001SLA884, B002LI8D12, B00AWRIQ98, B0030XTNE...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36113</th>\n",
       "      <td>AOGLLKPJHEUAZ</td>\n",
       "      <td>[B00A2XMIHS]</td>\n",
       "      <td>[B007NLX16O, B00BFDZOR0, B005BNWBMG, B000EPJIH...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID          asin  \\\n",
       "37689   ATQVNXUU2N1GG  [B0009WXTX4]   \n",
       "39337   AZV969S41XUYF  [B009S3HPTE]   \n",
       "36648   AQA5BVA14WTJQ  [B000KPP352]   \n",
       "37385   ASQFKYFTM1A3G  [B002YIPCJA]   \n",
       "2158   A17OB8ULOJ5U50  [B000UECV3U]   \n",
       "35465   AM74DCJX3UI7X  [B002JKZU4A]   \n",
       "29431  A3TF05A315UM97  [B006GDARO4]   \n",
       "22453  A35ARB435GXRMH  [B006B3AOJC]   \n",
       "29035  A3S4V8NPKKDDUL  [B001SN8BLS]   \n",
       "30780   A5SYJBHLU748Z  [B008Q0E61U]   \n",
       "29005  A3S2F1048AZND0  [B002PHLVJA]   \n",
       "21856  A33BS7GBS6M4AG  [B004L8J0C6]   \n",
       "26196  A3I9PXOHGTCBRJ  [B004GXBP1U]   \n",
       "5853   A1KJZVR4IMMNZ1  [B001SLB6EY]   \n",
       "36113   AOGLLKPJHEUAZ  [B00A2XMIHS]   \n",
       "\n",
       "                                        asin_predictions  precision@K  \\\n",
       "37689  [B000ZPMYCC, B000B5MI3Q, B0032FOSI0, B009KYJAJ...          0.1   \n",
       "39337  [B009S3HYQ8, B006NU5Z60, B006LFF850, B009S3HL9...          0.1   \n",
       "36648  [B000KKTPD8, B000XY3XX4, B000KPPICA, B000KPP35...          0.1   \n",
       "37385  [B002WUVOBA, B002VS8H3G, B001WWWAA8, B002YM52L...          0.1   \n",
       "2158   [B000CC3OMC, B000BVYQ9O, B000BVYQ9Y, B0006GYLO...          0.1   \n",
       "35465  [B002JL1ZUC, B004874ZHK, B009DKKVFW, B004DYUAX...          0.1   \n",
       "29431  [B0055X1NDK, B002RS26LE, B0085U2YTC, B0064YY0D...          0.1   \n",
       "22453  [B005UVM368, B0062WL55E, B008IZKAP4, B00EU7OYY...          0.1   \n",
       "29035  [B001N0MSI8, B002RL87OQ, B003FSPWAC, B001SN8AD...          0.1   \n",
       "30780  [B001PUJH3A, B001NODU36, B001B9XI3A, B001DNFAO...          0.1   \n",
       "29005  [B001IB70JY, B0013B0IYI, B000GXPD7G, B000HEJ3L...          0.1   \n",
       "21856  [B00DEMN8DW, B001N4OCII, B002GCE3R6, B002IGN8J...          0.1   \n",
       "26196  [B004Q7AB4I, B006R0PZ5C, B001FWZ098, B007C8PUP...          0.1   \n",
       "5853   [B001SLA884, B002LI8D12, B00AWRIQ98, B0030XTNE...          0.1   \n",
       "36113  [B007NLX16O, B00BFDZOR0, B005BNWBMG, B000EPJIH...          0.1   \n",
       "\n",
       "       recall@K  \n",
       "37689       1.0  \n",
       "39337       1.0  \n",
       "36648       1.0  \n",
       "37385       1.0  \n",
       "2158        1.0  \n",
       "35465       1.0  \n",
       "29431       1.0  \n",
       "22453       1.0  \n",
       "29035       1.0  \n",
       "30780       1.0  \n",
       "29005       1.0  \n",
       "21856       1.0  \n",
       "26196       1.0  \n",
       "5853        1.0  \n",
       "36113       1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_test_purchase_history[sampled_test_purchase_history['recall@K'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment, we have computed the metrics for the model which comes to average precision@k: `0.00190` and average recall@k: `0.01663`. As we dont have any other baseline to compare with at the moment, we are unable to better interpret model. \n",
    "\n",
    "The next step involves, using `approximate nearest neighbour` method to help us query similarities as opposed to the current brute-force search in the `Doc2Vec` model. Theoretically, we can achieve up to *11*x performance increase but still, it is subjected to the number of trees built during the indexing phase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Improving query time using `Annoy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building index using 100 trees\n",
    "annoy_index = AnnoyIndexer(model, 100)\n",
    "\n",
    "# TODO: need to figure how to define a treshold\n",
    "def get_top_n_annoy(user, n=10, threshold=4, indexer=annoy_index):\n",
    "\n",
    "    # retrieving user's purchase history\n",
    "    purchase_history = train.groupby(['reviewerID'])['asin'].apply(list)[user]\n",
    "\n",
    "    purchase_history_vec = np.zeros(150)\n",
    "    for item in purchase_history:\n",
    "        purchase_history_vec += model.dv[item]\n",
    "    # mean aggregation\n",
    "    purchase_history_vec /= len(purchase_history)\n",
    "\n",
    "    return [i[0] for i in model.dv.most_similar([purchase_history_vec], topn=n, indexer=indexer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [13:22<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# generating predictions\n",
    "sampled_test_purchase_history['asin_predictions_annoy'] = sampled_test_purchase_history['reviewerID'].progress_apply(get_top_n_annoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>asin_predictions</th>\n",
       "      <th>precision@K</th>\n",
       "      <th>recall@K</th>\n",
       "      <th>asin_predictions_annoy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>A104QGECCAFCI9</td>\n",
       "      <td>[B00592VMNI]</td>\n",
       "      <td>[B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15112</th>\n",
       "      <td>A2G5OW0UIBAUIT</td>\n",
       "      <td>[B008SCM0AU, B00AOCV6OI]</td>\n",
       "      <td>[B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13118</th>\n",
       "      <td>A29BPMJI0ZYH4H</td>\n",
       "      <td>[B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...</td>\n",
       "      <td>[B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37097</th>\n",
       "      <td>ARQZEE0LA1PBB</td>\n",
       "      <td>[B000A2KC7O]</td>\n",
       "      <td>[B006H9S4LU, B009V7Q8YK, B0030BELDS, B0018OFU9...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B009V7Q8YK, B0030BELDS, B0018OFU98, B009XB61H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31660</th>\n",
       "      <td>A8VSC4N8D63MJ</td>\n",
       "      <td>[B007ZRS0ZI]</td>\n",
       "      <td>[B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33707</th>\n",
       "      <td>AG6B61Q8YV1EL</td>\n",
       "      <td>[B000IBH9GY, B005HESA38]</td>\n",
       "      <td>[B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17734</th>\n",
       "      <td>A2P7NOZ0TRHZDZ</td>\n",
       "      <td>[B004A74Y3I]</td>\n",
       "      <td>[B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17972</th>\n",
       "      <td>A2Q21T5IJ7K35C</td>\n",
       "      <td>[B00CO8I206]</td>\n",
       "      <td>[B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12781</th>\n",
       "      <td>A2877AOHJFZI0E</td>\n",
       "      <td>[B004JZYGQ6]</td>\n",
       "      <td>[B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14092</th>\n",
       "      <td>A2CPPFB0S4XPH3</td>\n",
       "      <td>[B002ATKUEA]</td>\n",
       "      <td>[B00B7F3LIK, B006QOJ8PM, B008O2YOBC, B0058XJJ8...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[B00B7F3LIK, B0058XF6Q2, B006J8KBIS, B0058XH5P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           reviewerID                                               asin  \\\n",
       "109    A104QGECCAFCI9                                       [B00592VMNI]   \n",
       "15112  A2G5OW0UIBAUIT                           [B008SCM0AU, B00AOCV6OI]   \n",
       "13118  A29BPMJI0ZYH4H  [B0058XH5D4, B007BZ5CUU, B00A0SXLOO, B00AVPHH4...   \n",
       "37097   ARQZEE0LA1PBB                                       [B000A2KC7O]   \n",
       "31660   A8VSC4N8D63MJ                                       [B007ZRS0ZI]   \n",
       "33707   AG6B61Q8YV1EL                           [B000IBH9GY, B005HESA38]   \n",
       "17734  A2P7NOZ0TRHZDZ                                       [B004A74Y3I]   \n",
       "17972  A2Q21T5IJ7K35C                                       [B00CO8I206]   \n",
       "12781  A2877AOHJFZI0E                                       [B004JZYGQ6]   \n",
       "14092  A2CPPFB0S4XPH3                                       [B002ATKUEA]   \n",
       "\n",
       "                                        asin_predictions  precision@K  \\\n",
       "109    [B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...          0.0   \n",
       "15112  [B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...          0.0   \n",
       "13118  [B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...          0.0   \n",
       "37097  [B006H9S4LU, B009V7Q8YK, B0030BELDS, B0018OFU9...          0.0   \n",
       "31660  [B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...          0.0   \n",
       "33707  [B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...          0.0   \n",
       "17734  [B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...          0.0   \n",
       "17972  [B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...          0.0   \n",
       "12781  [B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...          0.0   \n",
       "14092  [B00B7F3LIK, B006QOJ8PM, B008O2YOBC, B0058XJJ8...          0.0   \n",
       "\n",
       "       recall@K                             asin_predictions_annoy  \n",
       "109         0.0  [B000MM8I5U, B001KVQM96, B005FDWNKM, B00FSB5SB...  \n",
       "15112       0.0  [B008SCHXGQ, B007JPJD6G, B00CVQ16S6, B0094FYRM...  \n",
       "13118       0.0  [B008KKSJYQ, B00AKSCOMO, B00BXXX3PM, B008KKSKJ...  \n",
       "37097       0.0  [B009V7Q8YK, B0030BELDS, B0018OFU98, B009XB61H...  \n",
       "31660       0.0  [B0006LMBJ6, B000S6ICUQ, B0018OHOB0, B0018OLPQ...  \n",
       "33707       0.0  [B003OYJAUU, B004H12QQO, B007IH3IPW, B0080CD0T...  \n",
       "17734       0.0  [B007WA0S0S, B00E2P9HG2, B00JKS0P7G, B00EKD4LL...  \n",
       "17972       0.0  [B006PB4FEK, B00944C95M, B00AYZBF5K, B008QZ0GF...  \n",
       "12781       0.0  [B00HFRZQCI, B000AK4DZS, B00DGPLWOY, B004NY9UZ...  \n",
       "14092       0.0  [B00B7F3LIK, B0058XF6Q2, B006J8KBIS, B0058XH5P...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the dataframe\n",
    "sampled_test_purchase_history.head().append(sampled_test_purchase_history.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 64170.37it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 65996.95it/s]\n"
     ]
    }
   ],
   "source": [
    "# computing the metrics\n",
    "sampled_test_purchase_history['precision@K_annoy'] = sampled_test_purchase_history.progress_apply(lambda x: precision_at_k(x.asin, x.asin_predictions_annoy), axis=1)\n",
    "sampled_test_purchase_history['recall@K_annoy'] = sampled_test_purchase_history.progress_apply(lambda x: recall_at_k(x.asin, x.asin_predictions_annoy), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has a average precision@K: 0.00200, average recall@K: 0.01762.\n"
     ]
    }
   ],
   "source": [
    "average_precision_at_k_annoy = sampled_test_purchase_history[\"precision@K_annoy\"].mean()\n",
    "average_recall_at_k_annoy = sampled_test_purchase_history[\"recall@K_annoy\"].mean()\n",
    "\n",
    "print(f\"The model has a average precision@K: {average_precision_at_k_annoy:.5f}, average recall@K: {average_recall_at_k_annoy:.5f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on initial observation, by no means the speed up was significant. Either the current annoy indexer setup is inappropriate or existing function design is flawed considering that we have have to do a inner `for` loop within the retrieval function. Design improvement would include shifting pre-computation user's purchase history vector into a hashmap (dictionary) to allow O(1) time complexity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the test users\n",
    "sampled_test_purchase_history['reviewerID'].to_csv(\"test_users_id.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m75"
  },
  "interpreter": {
   "hash": "25ff572cf74667139a08e9b3925acace09b8544c3d9e895a2455f974072b7e88"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
