Leveraging Unsupervised Representation Learning with Reviews to Improve Top-N Recommendation in E-commerce
==============================
Abstract
------------
The main contribution of this work is the formulation of two approaches that incorporates user-generated content such as *reviews* as both an independent and additional source of information in traditional collaborative filtering algorithms.

The unstructured text is represented as document-level embeddings in a continuous feature space of fixed length, using unsupervised representation learning, the Paragraph Vector model. Subsequently, user and item profiles are generated by aggregating the document embeddings on both user and item levels. The resulting representations are used independently in a memory-based collaborative filtering approach and combined with product ratings in a matrix factorisation collaborative filtering algorithm.

The proposed methodologies are then compared to traditional recommendation algorithms on two categories of an e-commerce dataset to assess its performance in both accuracy and novelty. The results demonstrated that we outperformed the other systems in terms of accuracy by using only reviews as the sole information while achieving relative novelty. These results suggest that our approach can tackle common problems such as data sparsity and cold-start found in traditional algorithms, thereby indicating the approach's potential.

Requirements
------------

Getting Started
------------

To run the experiments setup of this project, ensure that following files are populated in their respective folders:
* `data/evaluation/Grocery_and_Gourmet_Food_train.csv`
* `data/evaluation/Grocery_and_Gourmet_Food_test.csv`
* `data/evaluation/Pet_Supplies_train.csv`
* `data/evaluation/Pet_Supplies_test.csv`
* `models/d2v/Grocery_and_Gourmet_Food_item_50_10_d2v.model`
* `models/d2v/Grocery_and_Gourmet_Food_user_item_50_10_d2v.model`
* `models/d2v/Pet_Supplies_item_50_10_d2v.model`
* `models/d2v/Pet_Supplies_user_item_50_10_d2v.model`
* `models/lda/Grocery_and_Gourmet_Food_lda.model`
* `models/lda/Pet_Supplies_lda.model`

If any of the files is **NOT** present, run the following commands to generate all the necessary data and models:
```python
python3 src/prepare.py
python3 src/featurized.py
python3 src/split_train_test.py
python3 src/generate_vectors.py
```
* For the *lda* model, you can refer to the commented-out section `Preparing Topic Vectors [Train/Load]` in:
    * `03-lwt-updated-experimental-setup-ti-mf-ps` or
    * `09-lwt-updated-exprimentatl-setup-ti-mf-ggf`
* After generating the required *lda* model, ensure that you place the model under the directory `models/lda/{category}_lda.model`.


When all files are verified to be in the respective folders, you may run the following **TWELVE (12)** experimental notebooks, each documenting the recommendation process for a specific algorithm (e.g., `UB-CF`) in a one of two categories (`Pet_Supplies` or `Grocery_and_Gourmet_Food`).

A brief description of the notebooks (`.ipynb`) are detailed as the following:

###### For Pet Supplies:
1. `01-lwt-updated-experiment-setup-ub-cf-ps`: User-based Collaborative Filtering.
2. `02-lwt-updated-experiment-setup-funk-svd-ps`: Funk's Matrix Factorisation.
3. `03-lwt-updated-experiment-setup-ti-mf-ps`: Topic-Initialised Matrix Factorisation.
4. `04-lwt-updated-experiement-setup-random-ps`: Random Normal Rating Prediction.
5. `05-lwt-updated-experiment-setup-er-cbf-ps`: (*Proposed*) Embedded Review Content-based Filtering.
6. `06-lwt-updated-experiment-setup-mod-ecf-ps`: (*Proposed*) Model-based Embedded Collborating Filtering.

###### For Grocery and Gourmet Food:




Project Organization
------------

    ├── LICENSE
    ├── README.md          <- The top-level README for developers using this project.
    ├── data
    │   ├── external       <- Data from third party sources.
    │   ├── interim        <- Intermediate data that has been transformed, combining transaction log and item information.
    │   ├── processed      <- The final, canonical data sets for modeling.
    │   ├── evaluation     <- The train, test split of the final dataset used to train the models and test the predictions.
    │   └── raw            <- The original, immutable data dump. As file is too big, I have provided the
    │                         link to download the raw data seperately in the `data_instruction.txt`.
    │
    │
    ├── models             <- Trained and serialized models, model predictions, or model summaries
    │   └── d2v            <- Trained and serialized Paragraph Vector model (Gensim's `Doc2Vec`).
    │   └── lda            <- Trained and serialized Latent Dirchlet Allocaton (Gensim's `ldamodel`).
    │
    │
    ├── notebooks
    │   └── exploratory    <- Jupyter notebooks for initial exploration. Naming convention is a
    │                         number (for ordering), the creator's initials, and a short `-`
    │                         delimited description, e.g. `1.0-jqp-initial-data-exploration`.
    │
    │
    ├── reports
    │   └── figures        <- Generated graphics and figures for illustrating concepts.
    │   └── metrics        <- Generated graphics and figures for reporting metrics.
    │
    ├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    │                         generated with `pip freeze > requirements.txt`
    │
    ├── src                <- Source code for use in this project.
    │   ├── __init__.py    <- Makes src a Python module
    │   │
    │   ├── data           <- Functions to load, transform, and split raw/merged data.
    │   │   └── evaluate.py
    │   │   └── load_dataset.py
    │   │   └── make_dataset.py
    │   │
    │   ├── features       <- Functions to turn raw data into features for modeling
    │   │   └── build_features.py
    │   │
    │   ├── models         <- Functions to train models and then use trained models to make
    │   │   │                 predictions
    │   │   ├── algorithms.py
    │   │   └── evaluate_model.py
    │   │   └── lda.py
    │   │
    │   └── utilities      <- Functions for miscellaneous tasks, e.g. aggregating document embeddings etc.
    │       └── utilities.py
    │
    ├── presentation       <- Slides used for oral presentation.
    │
    └── literatures        <- Papers cited in the literature review.


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
